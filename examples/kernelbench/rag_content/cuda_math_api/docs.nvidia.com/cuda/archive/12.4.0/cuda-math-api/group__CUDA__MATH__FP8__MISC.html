<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-us" xml:lang="en-us">
   <head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="copyright" content="(C) Copyright 2005">
      <meta name="DC.rights.owner" content="(C) Copyright 2005">
      <meta name="DC.Type" content="cppModule">
      <meta name="DC.Title" content="FP8 Conversion and Data Movement">
      <meta name="abstract" content="">
      <meta name="description" content="">
      <meta name="DC.Format" content="XHTML">
      <meta name="DC.Identifier" content="group__CUDA__MATH__FP8__MISC">
      <link rel="stylesheet" type="text/css" href="../common/formatting/commonltr.css">
      <link rel="stylesheet" type="text/css" href="../common/formatting/site.css">
      <title>CUDA Math API :: CUDA Toolkit Documentation</title>
      <!--[if lt IE 9]>
      <script src="../common/formatting/html5shiv-printshiv.min.js"></script>
      <![endif]-->
      <script src="https://assets.adobedtm.com/5d4962a43b79/c1061d2c5e7b/launch-191c2462b890.min.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-svg.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.ba-hashchange.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/formatting/jquery.scrollintoview.min.js"></script>
      <script type="text/javascript" charset="utf-8" src="../common/scripts/geoip/geoip.js"></script>
      <script type="text/javascript" src="../search/htmlFileList.js"></script>
      <script type="text/javascript" src="../search/htmlFileInfoList.js"></script>
      <script type="text/javascript" src="../search/nwSearchFnt.min.js"></script>
      <script type="text/javascript" src="../search/stemmers/en_stemmer.min.js"></script>
      <script type="text/javascript" src="../search/index-1.js"></script>
      <script type="text/javascript" src="../search/index-2.js"></script>
      <script type="text/javascript" src="../search/index-3.js"></script>
      <link rel="canonical" href="https://docs.nvidia.com/cuda/cuda-math-api/index.html">
      <link rel="stylesheet" type="text/css" href="../common/formatting/qwcode.highlight.css">
   </head>
   <body>
      
      <header id="header"><span id="company">NVIDIA</span><span id="site-title">CUDA Toolkit Documentation</span><form id="search" method="get" action="https://docs.nvidia.com/cuda/archive/12.4.0/cuda-math-api/search">
            <input type="text" name="search-text"><fieldset id="search-location">
               <legend>Search In:</legend>
               <label><input type="radio" name="search-type" value="site">Entire Site</label>
               <label><input type="radio" name="search-type" value="document">Just This Document</label>
</fieldset>
            <button type="reset">clear search</button>
            <button id="submit" type="submit">search</button>
</form>
      </header>
      <div id="site-content">
         <nav id="site-nav">
            <div class="category closed"><a href="https://docs.nvidia.com/cuda/archive/12.4.0/index.html" title="The root of the site.">CUDA Toolkit 
                  
                  
                  v12.4.0</a></div>
            <div class="category"><a href="index.html" title="CUDA Math API">CUDA Math API</a></div>
            <ul>
               <li>
                  <div class="section-link"><a href="modules.html#modules">1. Modules</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__FP8.html#group__CUDA__MATH__INTRINSIC__FP8">1.1. FP8 Intrinsics</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC">1.1.1. FP8 Conversion and Data Movement</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__FP8__E5M2__STRUCT.html#group__CUDA__MATH__FP8__E5M2__STRUCT">1.1.2. C++ struct for handling fp8 data type of e5m2 kind.</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__FP8X2__E5M2__STRUCT.html#group__CUDA__MATH__FP8X2__E5M2__STRUCT">1.1.3. C++ struct for handling vector type of two fp8 values of e5m2 kind.</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__FP8X4__E5M2__STRUCT.html#group__CUDA__MATH__FP8X4__E5M2__STRUCT">1.1.4. C++ struct for handling vector type of four fp8 values of e5m2 kind.</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__FP8__E4M3__STRUCT.html#group__CUDA__MATH__FP8__E4M3__STRUCT">1.1.5. C++ struct for handling fp8 data type of e4m3 kind.</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__FP8X2__E4M3__STRUCT.html#group__CUDA__MATH__FP8X2__E4M3__STRUCT">1.1.6. C++ struct for handling vector type of two fp8 values of e4m3 kind.</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__FP8X4__E4M3__STRUCT.html#group__CUDA__MATH__FP8X4__E4M3__STRUCT">1.1.7. C++ struct for handling vector type of four fp8 values of e4m3 kind.</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__HALF.html#group__CUDA__MATH__INTRINSIC__HALF">1.2. Half Precision Intrinsics</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__HALF__CONSTANTS.html#group__CUDA__MATH__INTRINSIC__HALF__CONSTANTS">1.2.1. Half Arithmetic Constants</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____HALF__ARITHMETIC.html#group__CUDA__MATH____HALF__ARITHMETIC">1.2.2. Half Arithmetic Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____HALF2__ARITHMETIC.html#group__CUDA__MATH____HALF2__ARITHMETIC">1.2.3. Half2 Arithmetic Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____HALF__COMPARISON.html#group__CUDA__MATH____HALF__COMPARISON">1.2.4. Half Comparison Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____HALF2__COMPARISON.html#group__CUDA__MATH____HALF2__COMPARISON">1.2.5. Half2 Comparison Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____HALF__MISC.html#group__CUDA__MATH____HALF__MISC">1.2.6. Half Precision Conversion and Data Movement</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____HALF__FUNCTIONS.html#group__CUDA__MATH____HALF__FUNCTIONS">1.2.7. Half Math Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____HALF2__FUNCTIONS.html#group__CUDA__MATH____HALF2__FUNCTIONS">1.2.8. Half2 Math Functions</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__BFLOAT16.html#group__CUDA__MATH__INTRINSIC__BFLOAT16">1.3. Bfloat16 Precision Intrinsics</a></div>
                        <ul>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__BFLOAT16__CONSTANTS.html#group__CUDA__MATH__INTRINSIC__BFLOAT16__CONSTANTS">1.3.1. Bfloat16 Arithmetic Constants</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____BFLOAT16__ARITHMETIC.html#group__CUDA__MATH____BFLOAT16__ARITHMETIC">1.3.2. Bfloat16 Arithmetic Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____BFLOAT162__ARITHMETIC.html#group__CUDA__MATH____BFLOAT162__ARITHMETIC">1.3.3. Bfloat162 Arithmetic Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____BFLOAT16__COMPARISON.html#group__CUDA__MATH____BFLOAT16__COMPARISON">1.3.4. Bfloat16 Comparison Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____BFLOAT162__COMPARISON.html#group__CUDA__MATH____BFLOAT162__COMPARISON">1.3.5. Bfloat162 Comparison Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____BFLOAT16__MISC.html#group__CUDA__MATH____BFLOAT16__MISC">1.3.6. Bfloat16 Precision Conversion and Data Movement</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____BFLOAT16__FUNCTIONS.html#group__CUDA__MATH____BFLOAT16__FUNCTIONS">1.3.7. Bfloat16 Math Functions</a></div>
                           </li>
                           <li>
                              <div class="section-link"><a href="group__CUDA__MATH____BFLOAT162__FUNCTIONS.html#group__CUDA__MATH____BFLOAT162__FUNCTIONS">1.3.8. Bfloat162 Math Functions</a></div>
                           </li>
                        </ul>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH.html#group__CUDA__MATH">1.4. Mathematical Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__SINGLE.html#group__CUDA__MATH__SINGLE">1.5. Single Precision Mathematical Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__DOUBLE.html#group__CUDA__MATH__DOUBLE">1.6. Double Precision Mathematical Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INT.html#group__CUDA__MATH__INT">1.7. Integer Mathematical Functions</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__SINGLE.html#group__CUDA__MATH__INTRINSIC__SINGLE">1.8. Single Precision Intrinsics</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__DOUBLE.html#group__CUDA__MATH__INTRINSIC__DOUBLE">1.9. Double Precision Intrinsics</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__INT.html#group__CUDA__MATH__INTRINSIC__INT">1.10. Integer Intrinsics</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__CAST.html#group__CUDA__MATH__INTRINSIC__CAST">1.11. Type Casting Intrinsics</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="group__CUDA__MATH__INTRINSIC__SIMD.html#group__CUDA__MATH__INTRINSIC__SIMD">1.12. SIMD Intrinsics</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="annotated.html#annotated">2. Data Structures</a></div>
                  <ul>
                     <li>
                        <div class="section-link"><a href="struct____half.html#struct____half">2.1. __half</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____half2.html#struct____half2">2.2. __half2</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____half2__raw.html#struct____half2__raw">2.3. __half2_raw</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____half__raw.html#struct____half__raw">2.4. __half_raw</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__bfloat16.html#struct____nv__bfloat16">2.5. __nv_bfloat16</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__bfloat162.html#struct____nv__bfloat162">2.6. __nv_bfloat162</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__bfloat162__raw.html#struct____nv__bfloat162__raw">2.7. __nv_bfloat162_raw</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__bfloat16__raw.html#struct____nv__bfloat16__raw">2.8. __nv_bfloat16_raw</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__fp8__e4m3.html#struct____nv__fp8__e4m3">2.9. __nv_fp8_e4m3</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__fp8__e5m2.html#struct____nv__fp8__e5m2">2.10. __nv_fp8_e5m2</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__fp8x2__e4m3.html#struct____nv__fp8x2__e4m3">2.11. __nv_fp8x2_e4m3</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__fp8x2__e5m2.html#struct____nv__fp8x2__e5m2">2.12. __nv_fp8x2_e5m2</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__fp8x4__e4m3.html#struct____nv__fp8x4__e4m3">2.13. __nv_fp8x4_e4m3</a></div>
                     </li>
                     <li>
                        <div class="section-link"><a href="struct____nv__fp8x4__e5m2.html#struct____nv__fp8x4__e5m2">2.14. __nv_fp8x4_e5m2</a></div>
                     </li>
                  </ul>
               </li>
               <li>
                  <div class="section-link"><a href="functions.html#functions">3. Data Fields</a></div>
               </li>
            </ul>
         </nav>
         <div id="resize-nav"></div>
         <nav id="search-results">
            <h2>Search Results</h2>
            <ol></ol>
         </nav>
         
         <div id="contents-container">
            <div id="breadcrumbs-container">
               <div id="breadcrumbs">
<a href="group__CUDA__MATH__INTRINSIC__FP8.html" shape="rect">&lt; Previous</a> | <a href="group__CUDA__MATH__FP8__E5M2__STRUCT.html" shape="rect">Next &gt;</a>
</div>
               <div id="release-info">CUDA Math API
                  (<a href="https://docs.nvidia.com/cuda/archive/12.4.0/pdf/CUDA_Math_API.pdf">PDF</a>)
                  -
                   
                  
                  
                  v12.4.0
                  (<a href="https://developer.nvidia.com/cuda-toolkit-archive">older</a>)
                  -
                  Last updated March 5, 2024
                  -
                  <a href="mailto:CUDAIssues@nvidia.com?subject=CUDA%20Toolkit%20Documentation%20Feedback:%20CUDA%20Math%20API">Send Feedback</a>
</div>
            </div>
            <article id="contents">
               <div class="topic reference apiRef apiPackage cppModule" id="group__CUDA__MATH__FP8__MISC">
<a name="group__CUDA__MATH__FP8__MISC" shape="rect">
                     <!-- --></a><h2 class="topictitle2 cppModule">1.1.1. FP8 Conversion and Data Movement</h2>
                  <h2 class="module_header">[<a class="xref xref apiRelation cppModuleModule" href="group__CUDA__MATH__INTRINSIC__FP8.html#group__CUDA__MATH__INTRINSIC__FP8" shape="rect">FP8 Intrinsics</a>]
                  </h2>
                  <div class="section">
                     <p>To use these functions, include the header file <tt class="ph tt code">cuda_fp8.h</tt> in your program. 
                     </p>
                  </div>
                  <h3 class="fake_sectiontitle member_header">Typedefs</h3>
                  <dl class="members">
                     <dt>
<span class="member_type">typedef unsigned char  </span><span class="member_name"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" shape="rect">__nv_fp8_storage_t</a></span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">8-bit <tt class="ph tt code">unsigned</tt><tt class="ph tt code">integer</tt> type abstraction used to for <tt class="ph tt code">fp8</tt> floating-point numbers storage. </span>
</dd>
                     <dt>
<span class="member_long_type">typedef unsigned short int  </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" shape="rect">__nv_fp8x2_storage_t</a></span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">16-bit <tt class="ph tt code">unsigned</tt><tt class="ph tt code">integer</tt> type abstraction used to for storage of pairs of <tt class="ph tt code">fp8</tt> floating-point numbers. </span>
</dd>
                     <dt>
<span class="member_type">typedef unsigned int  </span><span class="member_name"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g664346dd1d821b4101e65397ca20cf02" shape="rect">__nv_fp8x4_storage_t</a></span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">32-bit <tt class="ph tt code">unsigned</tt><tt class="ph tt code">integer</tt> type abstraction used to for storage of tetrads of <tt class="ph tt code">fp8</tt> floating-point numbers. </span>
</dd>
                  </dl>
                  <h3 class="fake_sectiontitle member_header">Enumerations</h3>
                  <dl class="members">
                     <dt>
<span class="member_type">enum </span><span class="member_name"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" shape="rect">__nv_fp8_interpretation_t</a></span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Enumerates the possible interpretations of the 8-bit values when referring to them as <tt class="ph tt code">fp8</tt> types. </span>
</dd>
                     <dt>
<span class="member_type">enum </span><span class="member_name"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" shape="rect">__nv_saturation_t</a></span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Enumerates the modes applicable when performing a narrowing conversion to <tt class="ph tt code">fp8</tt> destination types. </span>
</dd>
                  </dl>
                  <h3 class="fake_sectiontitle member_header">Functions</h3>
                  <dl class="members">
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gc4be64e4818c9a9f20c5c040e75ada89" shape="rect">__nv_cvt_bfloat16raw2_to_fp8x2</a> (  const <a href="struct____nv__bfloat162__raw.html#struct____nv__bfloat162__raw" title="__nv_bfloat162_raw data type " shape="rect">__nv_bfloat162_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input vector of two <tt class="ph tt code">nv_bfloat16</tt> precision numbers packed in <tt class="ph tt code">__nv_bfloat162_raw</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g1746e30a6c3546ee42431435a1576f4c" shape="rect">__nv_cvt_bfloat16raw_to_fp8</a> (  const <a href="struct____nv__bfloat16__raw.html#struct____nv__bfloat16__raw" title="__nv_bfloat16_raw data type " shape="rect">__nv_bfloat16_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input <tt class="ph tt code">nv_bfloat16</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gc71c8e77f3fbb7abbfa33e79185a748a" shape="rect">__nv_cvt_double2_to_fp8x2</a> (  const double2<span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input vector of two <tt class="ph tt code">double</tt> precision numbers packed in <tt class="ph tt code">double2</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g832243e04f43db9cd03a65cbea10c3b8" shape="rect">__nv_cvt_double_to_fp8</a> (  const double <span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input <tt class="ph tt code">double</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g1e11a96de925101f11c7a3cb54c35bff" shape="rect">__nv_cvt_float2_to_fp8x2</a> (  const float2<span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input vector of two <tt class="ph tt code">single</tt> precision numbers packed in <tt class="ph tt code">float2</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g9f5257b63ab680b36b03c75ec596152a" shape="rect">__nv_cvt_float_to_fp8</a> (  const float <span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input <tt class="ph tt code">single</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="struct____half__raw.html#struct____half__raw" title="__half_raw data type " shape="rect">__half_raw</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g0085d490e9b16f891828d0a91933386e" shape="rect">__nv_cvt_fp8_to_halfraw</a> (  const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input <tt class="ph tt code">fp8</tt><tt class="ph tt code">x</tt> of the specified kind to <tt class="ph tt code">half</tt> precision. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="struct____half2__raw.html#struct____half2__raw" title="__half2_raw data type " shape="rect">__half2_raw</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g45b1a1f8dea928130ff9e117b9bb5fb3" shape="rect">__nv_cvt_fp8x2_to_halfraw2</a> (  const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input vector of two <tt class="ph tt code">fp8</tt> values of the specified kind to a vector of two <tt class="ph tt code">half</tt> precision values packed in <tt class="ph tt code">__half2_raw</tt> structure. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gc25513b7e1ddd8d93ce22d5cdfd3bfd8" shape="rect">__nv_cvt_halfraw2_to_fp8x2</a> (  const <a href="struct____half2__raw.html#struct____half2__raw" title="__half2_raw data type " shape="rect">__half2_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input vector of two <tt class="ph tt code">half</tt> precision numbers packed in <tt class="ph tt code">__half2_raw</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                     <dt>
<span class="member_long_type"><span class="keyword keyword apiItemName">__host__</span>
                           ​
                           <span class="keyword keyword apiItemName">__device__</span>
                           ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> </span><span class="member_name_long_type"><a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gbd9e55f6b10fadcb0be60fd779db529e" shape="rect">__nv_cvt_halfraw_to_fp8</a> (  const <a href="struct____half__raw.html#struct____half__raw" title="__half_raw data type " shape="rect">__half_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                     <dd class="shortdesc">
<span></span><span class="desc">Converts input <tt class="ph tt code">half</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. </span>
</dd>
                  </dl>
                  <div class="description">
                     <h3 class="sectiontitle">Typedefs</h3>
                     <dl class="description">
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" id="group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" shape="rect">
                              <!-- --></a><span>typedef unsigned char  __nv_fp8_storage_t</span>
</dt>
                        <dd class="description">
                           <div class="section">
                              <p>8-bit <tt class="ph tt code">unsigned</tt><tt class="ph tt code">integer</tt> type abstraction used to for <tt class="ph tt code">fp8</tt> floating-point numbers storage. 
                              </p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" id="group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" shape="rect">
                              <!-- --></a><span>typedef unsigned short int  __nv_fp8x2_storage_t</span>
</dt>
                        <dd class="description">
                           <div class="section">
                              <p>16-bit <tt class="ph tt code">unsigned</tt><tt class="ph tt code">integer</tt> type abstraction used to for storage of pairs of <tt class="ph tt code">fp8</tt> floating-point numbers. 
                              </p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g664346dd1d821b4101e65397ca20cf02" id="group__CUDA__MATH__FP8__MISC_1g664346dd1d821b4101e65397ca20cf02" shape="rect">
                              <!-- --></a><span>typedef unsigned int  __nv_fp8x4_storage_t</span>
</dt>
                        <dd class="description">
                           <div class="section">
                              <p>32-bit <tt class="ph tt code">unsigned</tt><tt class="ph tt code">integer</tt> type abstraction used to for storage of tetrads of <tt class="ph tt code">fp8</tt> floating-point numbers. 
                              </p>
                           </div>
                        </dd>
                     </dl>
                  </div>
                  <div class="description">
                     <h3 class="sectiontitle">Enumerations</h3>
                     <dl class="description">
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" id="group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" shape="rect">
                              <!-- --></a><span>enum __nv_fp8_interpretation_t</span>
</dt>
                        <dd class="description">
                           <div class="section">
                              <p></p>
                           </div>
                           <div class="enum-members">
                              <h6 class="enumerator_header">
                                 Values
                                 
                              </h6>
                              <dl class="enumerator">
                                 <dt><span class="enum-member-name-def">__NV_E4M3</span></dt>
                                 <dd>Stands for <tt class="ph tt code">fp8</tt> numbers of <tt class="ph tt code">e4m3</tt> kind. 
                                 </dd>
                                 <dt><span class="enum-member-name-def">__NV_E5M2</span></dt>
                                 <dd>Stands for <tt class="ph tt code">fp8</tt> numbers of <tt class="ph tt code">e5m2</tt> kind. 
                                 </dd>
                              </dl>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" id="group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" shape="rect">
                              <!-- --></a><span>enum __nv_saturation_t</span>
</dt>
                        <dd class="description">
                           <div class="section">
                              <p></p>
                           </div>
                           <div class="enum-members">
                              <h6 class="enumerator_header">
                                 Values
                                 
                              </h6>
                              <dl class="enumerator">
                                 <dt><span class="enum-member-name-def">__NV_NOSAT</span></dt>
                                 <dd>Means no saturation to finite is performed when conversion results in rounding values outside the range of destination type.
                                    NOTE: for fp8 type of e4m3 kind, the results that are larger than the maximum representable finite number of the target format
                                    become NaN. 
                                 </dd>
                                 <dt><span class="enum-member-name-def">__NV_SATFINITE</span></dt>
                                 <dd>Means input larger than the maximum representable finite number MAXNORM of the target format round to the MAXNORM of the same
                                    sign as input. 
                                 </dd>
                              </dl>
                           </div>
                        </dd>
                     </dl>
                  </div>
                  <div class="description">
                     <h3 class="sectiontitle">Functions</h3>
                     <dl class="description">
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1gc4be64e4818c9a9f20c5c040e75ada89" id="group__CUDA__MATH__FP8__MISC_1gc4be64e4818c9a9f20c5c040e75ada89" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> __nv_cvt_bfloat16raw2_to_fp8x2 (  const <a href="struct____nv__bfloat162__raw.html#struct____nv__bfloat162__raw" title="__nv_bfloat162_raw data type " shape="rect">__nv_bfloat162_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input vector of two <tt class="ph tt code">nv_bfloat16</tt> precision numbers packed in <tt class="ph tt code">__nv_bfloat162_raw</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8x2_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input vector <tt class="ph tt code">x</tt> to a vector of two <tt class="ph tt code">fp8</tt> values of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g1746e30a6c3546ee42431435a1576f4c" id="group__CUDA__MATH__FP8__MISC_1g1746e30a6c3546ee42431435a1576f4c" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> __nv_cvt_bfloat16raw_to_fp8 (  const <a href="struct____nv__bfloat16__raw.html#struct____nv__bfloat16__raw" title="__nv_bfloat16_raw data type " shape="rect">__nv_bfloat16_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input <tt class="ph tt code">nv_bfloat16</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1gc71c8e77f3fbb7abbfa33e79185a748a" id="group__CUDA__MATH__FP8__MISC_1gc71c8e77f3fbb7abbfa33e79185a748a" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> __nv_cvt_double2_to_fp8x2 (  const double2<span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input vector of two <tt class="ph tt code">double</tt> precision numbers packed in <tt class="ph tt code">double2</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8x2_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input vector <tt class="ph tt code">x</tt> to a vector of two <tt class="ph tt code">fp8</tt> values of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g832243e04f43db9cd03a65cbea10c3b8" id="group__CUDA__MATH__FP8__MISC_1g832243e04f43db9cd03a65cbea10c3b8" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> __nv_cvt_double_to_fp8 (  const double <span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input <tt class="ph tt code">double</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g1e11a96de925101f11c7a3cb54c35bff" id="group__CUDA__MATH__FP8__MISC_1g1e11a96de925101f11c7a3cb54c35bff" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> __nv_cvt_float2_to_fp8x2 (  const float2<span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input vector of two <tt class="ph tt code">single</tt> precision numbers packed in <tt class="ph tt code">float2</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8x2_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input vector <tt class="ph tt code">x</tt> to a vector of two <tt class="ph tt code">fp8</tt> values of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g9f5257b63ab680b36b03c75ec596152a" id="group__CUDA__MATH__FP8__MISC_1g9f5257b63ab680b36b03c75ec596152a" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> __nv_cvt_float_to_fp8 (  const float <span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input <tt class="ph tt code">single</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g0085d490e9b16f891828d0a91933386e" id="group__CUDA__MATH__FP8__MISC_1g0085d490e9b16f891828d0a91933386e" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="struct____half__raw.html#struct____half__raw" title="__half_raw data type " shape="rect">__half_raw</a> __nv_cvt_fp8_to_halfraw (  const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input <tt class="ph tt code">fp8</tt><tt class="ph tt code">x</tt> of the specified kind to <tt class="ph tt code">half</tt> precision. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code"><a class="xref" href="struct____half__raw.html#struct____half__raw" title="__half_raw data type" shape="rect">__half_raw</a></tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input <tt class="ph tt code">x</tt> of <tt class="ph tt code">fp8</tt> type of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter to <tt class="ph tt code">half</tt> precision.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1g45b1a1f8dea928130ff9e117b9bb5fb3" id="group__CUDA__MATH__FP8__MISC_1g45b1a1f8dea928130ff9e117b9bb5fb3" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="struct____half2__raw.html#struct____half2__raw" title="__half2_raw data type " shape="rect">__half2_raw</a> __nv_cvt_fp8x2_to_halfraw2 (  const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input vector of two <tt class="ph tt code">fp8</tt> values of the specified kind to a vector of two <tt class="ph tt code">half</tt> precision values packed in <tt class="ph tt code">__half2_raw</tt> structure. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code"><a class="xref" href="struct____half2__raw.html#struct____half2__raw" title="__half2_raw data type" shape="rect">__half2_raw</a></tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input vector <tt class="ph tt code">x</tt> of <tt class="ph tt code">fp8</tt> type of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter to a vector of two <tt class="ph tt code">half</tt> precision values and returns as <tt class="ph tt code"><a class="xref" href="struct____half2__raw.html#struct____half2__raw" title="__half2_raw data type" shape="rect">__half2_raw</a></tt> structure.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1gc25513b7e1ddd8d93ce22d5cdfd3bfd8" id="group__CUDA__MATH__FP8__MISC_1gc25513b7e1ddd8d93ce22d5cdfd3bfd8" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g2fca80b88f65350474b43a8e2da65526" title="16-bit unsigned           integer type abstraction used to for storage of pairs of fp8 floating-point numbers. " shape="rect">__nv_fp8x2_storage_t</a> __nv_cvt_halfraw2_to_fp8x2 (  const <a href="struct____half2__raw.html#struct____half2__raw" title="__half2_raw data type " shape="rect">__half2_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input vector of two <tt class="ph tt code">half</tt> precision numbers packed in <tt class="ph tt code">__half2_raw</tt><tt class="ph tt code">x</tt> into a vector of two values of <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8x2_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input vector <tt class="ph tt code">x</tt> to a vector of two <tt class="ph tt code">fp8</tt> values of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                        <dt class="description">
<a name="group__CUDA__MATH__FP8__MISC_1gbd9e55f6b10fadcb0be60fd779db529e" id="group__CUDA__MATH__FP8__MISC_1gbd9e55f6b10fadcb0be60fd779db529e" shape="rect">
                              <!-- --></a><span><span class="keyword keyword apiItemName">__host__</span>
                              ​
                              <span class="keyword keyword apiItemName">__device__</span>
                              ​<a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gde94244dc814b678ef39e93afe536198" title="8-bit unsigned           integer type abstraction used to for fp8 floating-point numbers storage. " shape="rect">__nv_fp8_storage_t</a> __nv_cvt_halfraw_to_fp8 (  const <a href="struct____half__raw.html#struct____half__raw" title="__half_raw data type " shape="rect">__half_raw</a><span> </span><span class="keyword keyword apiItemName">x</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1g8271a2e32ae94997d783d484cf4202a0" title="Enumerates the modes applicable when performing a narrowing conversion to fp8 destination types. " shape="rect">__nv_saturation_t</a><span> </span><span class="keyword keyword apiItemName">saturate</span>, const <a href="group__CUDA__MATH__FP8__MISC.html#group__CUDA__MATH__FP8__MISC_1gb025c9943b51c479fb483b81ec2779c0" title="Enumerates the possible interpretations of the 8-bit values when referring to them as fp8 types. " shape="rect">__nv_fp8_interpretation_t</a><span> </span><span class="keyword keyword apiItemName">fp8_interpretation</span> ) </span>
</dt>
                        <dd class="description">
                           <div class="section">Converts input <tt class="ph tt code">half</tt> precision <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the requested kind using round-to-nearest-even rounding and requested saturation mode. 
                           </div>
                           <div class="section">
                              <h6 class="return_header">Returns</h6>
                              <p class="return">
                                 </p>
<ul>
                                    <li>The <tt class="ph tt code">__nv_fp8_storage_t</tt> value holds the result of conversion. 
                                    </li>
                                 </ul>
                              
                           </div>
                           <div class="section">
                              <h6 class="description_header">Description</h6>
                              <p>Converts input <tt class="ph tt code">x</tt> to <tt class="ph tt code">fp8</tt> type of the kind specified by <tt class="ph tt code">fp8_interpretation</tt> parameter, using round-to-nearest-even rounding and saturation mode specified by <tt class="ph tt code">saturate</tt> parameter.
                              </p>
                              <p class="p"></p>
                           </div>
                        </dd>
                     </dl>
                  </div>
               </div>
               
               <hr id="contents-end">
               
            </article>
         </div>
      </div>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/formatting/common.min.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-write.js"></script>
      <script language="JavaScript" type="text/javascript" charset="utf-8" src="../common/scripts/google-analytics/google-analytics-tracker.js"></script>
      <script type="text/javascript">var switchTo5x=true;</script><script type="text/javascript">stLight.options({publisher: "998dc202-a267-4d8e-bce9-14debadb8d92", doNotHash: false, doNotCopy: false, hashAddressBar: false});</script><script type="text/javascript">_satellite.pageBottom();</script>
</body>
</html>
