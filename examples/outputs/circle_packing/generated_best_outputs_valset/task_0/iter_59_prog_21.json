{
    "best_score": 2.635983181610043,
    "best_code": "import numpy as np\nimport time\n\ndef main(timeout, current_best_solution):\n    \"\"\"\n    Breakthrough optimizer for sum-of-radii circle packing in a unit square (N=26).\n    New core idea: Bilevel optimization where radii are solved exactly by an LP and\n    centers are optimized by gradient ascent using LP dual sensitivities (or active-set\n    heuristics if duals unavailable). Hybridized with SCA linearized LP steps and\n    multi-start global exploration.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    time_budget = max(1.0, float(timeout) - 0.5)\n    rng = np.random.default_rng(12345)\n\n    eps = 1e-6\n    r_min = 1e-10\n    all_scores = []\n\n    def time_left():\n        return time_budget - (time.time() - start_time)\n\n    # Pair indices\n    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n\n    def clamp_centers(centers):\n        return np.clip(centers, eps, 1.0 - eps)\n\n    def boundary_limits(centers):\n        x = centers[:, 0]\n        y = centers[:, 1]\n        return np.minimum(np.minimum(x, 1 - x), np.minimum(y, 1 - y))\n\n    def pairwise_distances(centers):\n        diff = centers[:, None, :] - centers[None, :, :]\n        return np.sqrt(np.maximum(np.sum(diff * diff, axis=2), 0.0))\n\n    def build_lp_matrices(centers):\n        # Build A_ub r <= b_ub for LP in order:\n        # for each i: r_i <= x_i; r_i <= 1-x_i; r_i <= y_i; r_i <= 1-y_i; then all pairs r_i + r_j <= d_ij\n        x = centers[:, 0]\n        y = centers[:, 1]\n        D = pairwise_distances(centers)\n\n        m_vars = n\n        A_rows = []\n        b_vals = []\n\n        # Boundary constraints\n        for i in range(n):\n            # r_i <= x_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(x[i])\n            # r_i <= 1 - x_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0 - x[i])\n            # r_i <= y_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(y[i])\n            # r_i <= 1 - y_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0 - y[i])\n\n        # Pairwise constraints\n        for (i, j) in pairs:\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            row[j] = 1.0\n            A_rows.append(row)\n            b_vals.append(D[i, j])\n\n        if A_rows:\n            A_ub = np.vstack(A_rows)\n            b_ub = np.array(b_vals, dtype=float)\n        else:\n            A_ub, b_ub = None, None\n        return A_ub, b_ub\n\n    def solve_radii_lp_with_duals(centers, r_min_local):\n        # Solve LP maximize sum r => minimize -sum r with constraints\n        try:\n            from scipy.optimize import linprog\n            A_ub, b_ub = build_lp_matrices(centers)\n            m_vars = n\n            bounds = [(r_min_local, None)] * m_vars\n            c = -np.ones(m_vars, dtype=float)\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if not (hasattr(res, \"success\") and res.success and res.x is not None):\n                # Fallback: simple feasible radii by boundary and projection\n                b = boundary_limits(centers)\n                r = np.minimum(b, 0.5)\n                r = np.maximum(r, r_min_local)\n                return r, None, A_ub, b_ub, True\n            r = np.array(res.x, dtype=float)\n            b = boundary_limits(centers)\n            r = np.minimum(r, b)\n            r = np.maximum(r, r_min_local)\n            # Extract inequality duals (shadow prices). For minimize problem:\n            # derivative of optimal value w.r.t. b is y = res.ineqlin.marginals\n            # Our target objective is -optimal (maximize sum r), so weights = -y\n            weights = None\n            try:\n                if hasattr(res, \"ineqlin\") and res.ineqlin is not None and hasattr(res.ineqlin, \"marginals\"):\n                    y = np.array(res.ineqlin.marginals, dtype=float)\n                    weights = -y  # maximize sum r\n                    # Clip negatives to zero (non-binding or sign conventions)\n                    weights = np.maximum(weights, 0.0)\n                else:\n                    weights = None\n            except Exception:\n                weights = None\n            return r, weights, A_ub, b_ub, True\n        except Exception:\n            # Fallback if scipy unavailable: project radii heuristically and no duals\n            A_ub, b_ub = build_lp_matrices(centers)\n            b = boundary_limits(centers)\n            r = np.minimum(b, 0.5).copy()\n            r = np.maximum(r, r_min_local)\n            D = pairwise_distances(centers)\n            max_iter = 2000\n            tol = 1e-12\n            for _ in range(max_iter):\n                r = np.minimum(r, b)\n                viol = 0.0\n                for i in range(n):\n                    for j in range(i + 1, n):\n                        s = r[i] + r[j]\n                        dij = D[i, j]\n                        if s > dij:\n                            excess = s - dij\n                            dec = 0.5 * excess\n                            r[i] = max(r_min_local, r[i] - dec)\n                            r[j] = max(r_min_local, r[j] - dec)\n                            viol = max(viol, excess)\n                if viol < tol:\n                    break\n            r = np.minimum(r, b)\n            r = np.maximum(r, r_min_local)\n            return r, None, A_ub, b_ub, True\n\n    def compute_gradient_centers(centers, r, weights, A_ub, b_ub):\n        # Use dual weights if available; else use active-set heuristic based on slacks\n        grad = np.zeros_like(centers)\n        D = pairwise_distances(centers)\n        num_boundary_rows = 4 * n\n        # If no weights, build from slacks\n        if weights is None:\n            # Compute slacks: s = b - A r\n            if A_ub is None or b_ub is None:\n                return grad\n            slacks = b_ub - A_ub.dot(r)\n            # Boundary weights\n            bw = slacks[:num_boundary_rows]\n            # Scale for boundary slack\n            tau_b = max(1e-6, float(np.percentile(bw, 30)))\n            w_bound = np.exp(-np.clip(bw, 0, 1e9) / tau_b)\n            # Pair weights\n            pw = slacks[num_boundary_rows:]\n            tau_p = max(1e-6, float(np.percentile(pw, 30)))\n            w_pairs = np.exp(-np.clip(pw, 0, 1e9) / tau_p)\n        else:\n            w_full = weights\n            # Slight smoothing\n            w_full = np.maximum(w_full, 0.0)\n            # Normalize to avoid huge steps\n            scale = np.sum(w_full) + 1e-12\n            w_full = w_full / scale * (num_boundary_rows + len(pairs))\n            w_bound = w_full[:num_boundary_rows]\n            w_pairs = w_full[num_boundary_rows:]\n\n        # Boundary contributions\n        for i in range(n):\n            base = 4 * i\n            # r_i <= x_i           (d b / d x_i = +1)\n            grad[i, 0] += w_bound[base + 0] * 1.0\n            # r_i <= 1 - x_i       (d b / d x_i = -1)\n            grad[i, 0] += w_bound[base + 1] * (-1.0)\n            # r_i <= y_i\n            grad[i, 1] += w_bound[base + 2] * 1.0\n            # r_i <= 1 - y_i\n            grad[i, 1] += w_bound[base + 3] * (-1.0)\n\n        # Pair contributions\n        for k, (i, j) in enumerate(pairs):\n            w = w_pairs[k]\n            dij = D[i, j]\n            if dij > 1e-12:\n                u = (centers[i] - centers[j]) / dij\n            else:\n                ang = rng.uniform(0, 2 * np.pi)\n                u = np.array([np.cos(ang), np.sin(ang)], dtype=float)\n            grad[i] += w * u\n            grad[j] -= w * u\n        return grad\n\n    def score_from_radii(r):\n        return float(np.sum(r))\n\n    def joint_lp_step(centers0, delta):\n        # LP over centers and radii with linearized pairwise constraints and trust region\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return None, None, False\n        x0 = centers0[:, 0]\n        y0 = centers0[:, 1]\n        m_vars = 3 * n\n\n        def ix(i): return i\n        def iy(i): return n + i\n        def ir(i): return 2 * n + i\n\n        A_rows = []\n        b_vals = []\n\n        # Boundary constraints: r_i <= x_i; r_i + x_i <= 1; r_i <= y_i; r_i + y_i <= 1\n        for i in range(n):\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ix(i)] = -1.0\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ix(i)] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[iy(i)] = -1.0\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[iy(i)] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0)\n\n        # Trust region constraints L_inf\n        if delta is not None and delta > 0.0:\n            for i in range(n):\n                row = np.zeros(m_vars, dtype=float)\n                row[ix(i)] = 1.0\n                A_rows.append(row)\n                b_vals.append(float(x0[i] + delta))\n                row = np.zeros(m_vars, dtype=float)\n                row[ix(i)] = -1.0\n                A_rows.append(row)\n                b_vals.append(float(-x0[i] + delta))\n\n                row = np.zeros(m_vars, dtype=float)\n                row[iy(i)] = 1.0\n                A_rows.append(row)\n                b_vals.append(float(y0[i] + delta))\n                row = np.zeros(m_vars, dtype=float)\n                row[iy(i)] = -1.0\n                A_rows.append(row)\n                b_vals.append(float(-y0[i] + delta))\n\n        # Linearized pairwise constraints at centers0\n        D0 = pairwise_distances(centers0)\n        vs = {}\n        for (i, j) in pairs:\n            dij = D0[i, j]\n            if dij > 1e-9:\n                v = (centers0[i] - centers0[j]) / dij\n            else:\n                ang = rng.uniform(0, 2 * np.pi)\n                v = np.array([np.cos(ang), np.sin(ang)], dtype=float)\n            vs[(i, j)] = v\n\n        for (i, j) in pairs:\n            v = vs[(i, j)]\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ir(j)] = 1.0\n            row[ix(i)] += -v[0]\n            row[iy(i)] += -v[1]\n            row[ix(j)] += v[0]\n            row[iy(j)] += v[1]\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n        A_ub = np.vstack(A_rows) if A_rows else None\n        b_ub = np.array(b_vals, dtype=float) if b_vals else None\n\n        bounds = []\n        for i in range(n):\n            bounds.append((eps, 1.0 - eps))\n        for i in range(n):\n            bounds.append((eps, 1.0 - eps))\n        for i in range(n):\n            bounds.append((r_min, None))\n\n        c = np.zeros(m_vars, dtype=float)\n        c[2 * n: 3 * n] = -1.0\n\n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if not (hasattr(res, \"success\") and res.success and res.x is not None):\n                return None, None, False\n            sol = np.array(res.x, dtype=float)\n            centers = np.zeros((n, 2), dtype=float)\n            centers[:, 0] = sol[0:n]\n            centers[:, 1] = sol[n:2 * n]\n            r_lin = sol[2 * n: 3 * n]\n            centers = clamp_centers(centers)\n            r_lin = np.maximum(r_lin, r_min)\n            return centers, r_lin, True\n        except Exception:\n            return None, None, False\n\n    # Initializations\n    def hex_jitter_init(N):\n        rows = int(np.floor(np.sqrt(N)))\n        cols = int(np.ceil(N / rows))\n        xs = np.linspace(0.1, 0.9, cols)\n        ys = np.linspace(0.1, 0.9, rows)\n        centers = []\n        idx = 0\n        for ri, yy in enumerate(ys):\n            offset = 0.0 if (ri % 2 == 0) else (xs[1] - xs[0]) * 0.5 if len(xs) > 1 else 0.0\n            for _, xx in enumerate(xs):\n                if idx >= N:\n                    break\n                xi = np.clip(xx + offset, 0.05, 0.95)\n                jitter = 0.02\n                centers.append([xi + rng.normal(0, jitter), yy + rng.normal(0, jitter)])\n                idx += 1\n            if idx >= N:\n                break\n        centers = np.array(centers, dtype=float)\n        while centers.shape[0] < N:\n            centers = np.vstack([centers, rng.uniform(0.1, 0.9, size=(1, 2))])\n        return clamp_centers(centers)\n\n    def uniform_init(N):\n        return clamp_centers(rng.uniform(0.1, 0.9, size=(N, 2)))\n\n    def edge_bias_init(N):\n        k_edge = N // 3\n        k_int = N - k_edge\n        centers = [rng.uniform(0.2, 0.8, size=(k_int, 2))]\n        for _ in range(k_edge):\n            edge = rng.integers(0, 4)\n            t = rng.uniform(0.08, 0.92)\n            if edge == 0:\n                pt = [t, 0.06 + 0.02 * rng.random()]\n            elif edge == 1:\n                pt = [t, 0.94 - 0.02 * rng.random()]\n            elif edge == 2:\n                pt = [0.06 + 0.02 * rng.random(), t]\n            else:\n                pt = [0.94 - 0.02 * rng.random(), t]\n            centers.append(pt)\n        centers = np.vstack(centers)\n        return clamp_centers(centers[:N])\n\n    def corner_spokes_init(N):\n        corners = np.array([[0.1, 0.1], [0.9, 0.1], [0.1, 0.9], [0.9, 0.9]], dtype=float)\n        centers = []\n        k = N // 4\n        rem = N - 4 * k\n        for c in corners:\n            for _ in range(k):\n                ang = rng.uniform(0, 2 * np.pi)\n                rad = rng.uniform(0.0, 0.25)\n                pt = c + rad * np.array([np.cos(ang), np.sin(ang)])\n                centers.append(pt)\n        for _ in range(rem):\n            centers.append(rng.uniform(0.2, 0.8, size=2))\n        centers = np.array(centers, dtype=float)\n        return clamp_centers(centers)\n\n    init_candidates = []\n    # Use current best centers if provided\n    if isinstance(current_best_solution, np.ndarray):\n        try:\n            cb = current_best_solution\n            if cb.shape[0] == n and cb.shape[1] >= 2:\n                centers_cb = clamp_centers(cb[:, :2].astype(float))\n                init_candidates.append(centers_cb)\n                for _ in range(2):\n                    init_candidates.append(clamp_centers(centers_cb + rng.normal(0, 0.01, size=centers_cb.shape)))\n        except Exception:\n            pass\n\n    init_candidates.append(hex_jitter_init(n))\n    init_candidates.append(uniform_init(n))\n    init_candidates.append(edge_bias_init(n))\n    init_candidates.append(corner_spokes_init(n))\n    for _ in range(2):\n        init_candidates.append(uniform_init(n))\n\n    best_circles = None\n    best_score = -1e18\n\n    def try_update_best(centers, r):\n        nonlocal best_circles, best_score, all_scores\n        score = score_from_radii(r)\n        if score > best_score + 1e-12:\n            best_score = score\n            best_circles = np.hstack([centers, r.reshape(-1, 1)])\n            all_scores.append(best_score)\n            return True\n        return False\n\n    def gradient_optimize(centers_init):\n        nonlocal best_circles, best_score\n        centers = centers_init.copy()\n        # Warm-start solve\n        r, weights, A_ub, b_ub, ok = solve_radii_lp_with_duals(centers, r_min)\n        if not ok or r is None:\n            return\n        try_update_best(centers, r)\n\n        eta = 0.25\n        stagnation = 0\n        iters = 0\n        last_improve_iter = 0\n        while time_left() > 0.1:\n            iters += 1\n            # Compute gradient\n            grad = compute_gradient_centers(centers, r, weights, A_ub, b_ub)\n            # Normalize gradient by max row norm\n            row_norms = np.linalg.norm(grad, axis=1)\n            max_norm = float(np.max(row_norms)) if grad.size > 0 else 0.0\n            if not np.isfinite(max_norm) or max_norm <= 1e-18:\n                # If gradient is too small, perform a joint LP step or shake\n                if time_left() < 0.05:\n                    break\n                new_centers, r_lin, okj = joint_lp_step(centers, delta=0.05)\n                if okj and new_centers is not None:\n                    r_new, weights, A_ub, b_ub, ok2 = solve_radii_lp_with_duals(new_centers, r_min)\n                    if ok2 and r_new is not None:\n                        centers = new_centers\n                        r = r_new\n                        try_update_best(centers, r)\n                        continue\n                # Shake\n                idxs = rng.choice(n, size=max(1, n // 4), replace=False)\n                shake = np.zeros_like(centers)\n                shake[idxs] = rng.normal(0, 0.03, size=(len(idxs), 2))\n                centers_candidate = clamp_centers(centers + shake)\n                r_cand, w2, A2, b2, ok3 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                if ok3 and score_from_radii(r_cand) > score_from_radii(r) + 1e-10:\n                    centers, r = centers_candidate, r_cand\n                    weights, A_ub, b_ub = w2, A2, b2\n                    try_update_best(centers, r)\n                stagnation += 1\n                if stagnation > 10:\n                    break\n                continue\n\n            g = grad / (max_norm + 1e-18)\n            # Backtracking line search\n            base_score = score_from_radii(r)\n            success = False\n            step_eta = eta\n            for _ in range(14):\n                centers_candidate = clamp_centers(centers + step_eta * g)\n                r_cand, w2, A2, b2, ok2 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                if ok2 and r_cand is not None:\n                    sc = score_from_radii(r_cand)\n                    if sc > base_score + 1e-10:\n                        centers, r = centers_candidate, r_cand\n                        weights, A_ub, b_ub = w2, A2, b2\n                        eta = min(step_eta * 1.25, 0.5)\n                        success = True\n                        last_improve_iter = iters\n                        try_update_best(centers, r)\n                        break\n                step_eta *= 0.5\n            if not success:\n                eta *= 0.6\n                stagnation += 1\n                # Occasional SCA LP step to escape\n                if stagnation % 4 == 0 and time_left() > 0.05:\n                    delta = 0.08 if stagnation < 8 else 0.12\n                    new_centers, r_lin, okj = joint_lp_step(centers, delta)\n                    if okj and new_centers is not None:\n                        r_new, w2, A2, b2, ok2 = solve_radii_lp_with_duals(new_centers, r_min)\n                        if ok2 and r_new is not None and score_from_radii(r_new) >= base_score - 1e-9:\n                            centers, r = new_centers, r_new\n                            weights, A_ub, b_ub = w2, A2, b2\n                            try_update_best(centers, r)\n                # Random local shake\n                if stagnation % 3 == 0:\n                    idxs = rng.choice(n, size=max(1, n // 6), replace=False)\n                    shake = np.zeros_like(centers)\n                    shake[idxs] = rng.normal(0, 0.02 * (1 + 0.1 * stagnation), size=(len(idxs), 2))\n                    centers_candidate = clamp_centers(centers + shake)\n                    r_cand, w2, A2, b2, ok3 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                    if ok3 and r_cand is not None and score_from_radii(r_cand) > base_score + 1e-10:\n                        centers, r = centers_candidate, r_cand\n                        weights, A_ub, b_ub = w2, A2, b2\n                        try_update_best(centers, r)\n                # Break if too many without improvement\n                if iters - last_improve_iter > 50 or stagnation > 20:\n                    break\n            else:\n                stagnation = max(stagnation - 1, 0)\n\n    # Run multi-start optimization\n    for init_centers in init_candidates:\n        if time_left() < 0.3:\n            break\n        gradient_optimize(init_centers)\n\n    # Final fallback\n    if best_circles is None or not np.all(np.isfinite(best_circles)):\n        centers = clamp_centers(rng.uniform(0.1, 0.9, size=(n, 2)))\n        r, _, _, _, ok = solve_radii_lp_with_duals(centers, r_min)\n        if not ok or r is None:\n            b = boundary_limits(centers)\n            r = np.maximum(np.minimum(b, 0.5), r_min)\n        best_circles = np.hstack([centers, r.reshape(-1, 1)])\n        best_score = score_from_radii(r)\n        all_scores.append(best_score)\n\n    # Ensure final feasibility via radii LP\n    try:\n        centers_final = best_circles[:, :2]\n        r_final, _, _, _, ok = solve_radii_lp_with_duals(centers_final, r_min)\n        if ok and r_final is not None:\n            best_circles = np.hstack([centers_final, r_final.reshape(-1, 1)])\n            best_score = score_from_radii(r_final)\n    except Exception:\n        pass\n\n    return {\n        'circles': best_circles.astype(float),\n        'all_scores': [float(s) for s in all_scores] if all_scores else [float(best_score)]\n    }",
    "best_circles": [
        [
            0.11077901234015804,
            0.1107790016429364,
            0.1107790016429364
        ],
        [
            0.5153991994878855,
            0.10306053136927486,
            0.10306053136927486
        ],
        [
            0.6130764731244333,
            0.29474606421632765,
            0.112077161785781
        ],
        [
            0.7246573854491785,
            0.49553177554331373,
            0.11762966516657741
        ],
        [
            0.7252167171485554,
            0.10679015445364431,
            0.10679015445364431
        ],
        [
            0.9153604847461266,
            0.08463950190993788,
            0.08463950190993788
        ],
        [
            0.31674145432664647,
            0.09573234751373698,
            0.09573234751373698
        ],
        [
            0.4023652197184373,
            0.2716298680977547,
            0.09989833605858513
        ],
        [
            0.25795057006752,
            0.5952196986190672,
            0.09601904470325057
        ],
        [
            0.9211396168833024,
            0.4972844610764798,
            0.07886038311669763
        ],
        [
            0.25758295579732965,
            0.40335876319742214,
            0.09584232226696651
        ],
        [
            0.8697788813796897,
            0.2946094959358368,
            0.13022111862031027
        ],
        [
            0.09259211357151816,
            0.685943008187715,
            0.09259211357151816
        ],
        [
            0.23632638524755312,
            0.2397104930413976,
            0.06918062870274995
        ],
        [
            0.23704114788926844,
            0.7593524047304191,
            0.06944016220668167
        ],
        [
            0.47003660313836887,
            0.498668105609177,
            0.13701037979640487
        ],
        [
            0.8667414346775953,
            0.702309543459057,
            0.13325856532240465
        ],
        [
            0.6183341830417409,
            0.7026096117427499,
            0.11514887029186244
        ],
        [
            0.09239155601360272,
            0.313115789121669,
            0.09239155601360272
        ],
        [
            0.09392733242391828,
            0.4994283538145162,
            0.09392733242391828
        ],
        [
            0.4039573064042861,
            0.7269057173291149,
            0.10060039618080557
        ],
        [
            0.5174044311695637,
            0.8965327548659915,
            0.10346724513400851
        ],
        [
            0.7260471690254938,
            0.8948174295673489,
            0.10518257043265111
        ],
        [
            0.915073726943121,
            0.9150737402870565,
            0.08492625971294354
        ],
        [
            0.11115619694448861,
            0.8888438163994471,
            0.1111561836005529
        ],
        [
            0.31791996945220385,
            0.9038486503877605,
            0.09615134961223948
        ]
    ],
    "code_candidate": "import numpy as np\nimport time\n\ndef main(timeout, current_best_solution):\n    \"\"\"\n    Breakthrough optimizer for sum-of-radii circle packing in a unit square (N=26).\n    New core idea: Bilevel optimization where radii are solved exactly by an LP and\n    centers are optimized by gradient ascent using LP dual sensitivities (or active-set\n    heuristics if duals unavailable). Hybridized with SCA linearized LP steps and\n    multi-start global exploration.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    time_budget = max(1.0, float(timeout) - 0.5)\n    rng = np.random.default_rng(12345)\n\n    eps = 1e-6\n    r_min = 1e-10\n    all_scores = []\n\n    def time_left():\n        return time_budget - (time.time() - start_time)\n\n    # Pair indices\n    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n\n    def clamp_centers(centers):\n        return np.clip(centers, eps, 1.0 - eps)\n\n    def boundary_limits(centers):\n        x = centers[:, 0]\n        y = centers[:, 1]\n        return np.minimum(np.minimum(x, 1 - x), np.minimum(y, 1 - y))\n\n    def pairwise_distances(centers):\n        diff = centers[:, None, :] - centers[None, :, :]\n        return np.sqrt(np.maximum(np.sum(diff * diff, axis=2), 0.0))\n\n    def build_lp_matrices(centers):\n        # Build A_ub r <= b_ub for LP in order:\n        # for each i: r_i <= x_i; r_i <= 1-x_i; r_i <= y_i; r_i <= 1-y_i; then all pairs r_i + r_j <= d_ij\n        x = centers[:, 0]\n        y = centers[:, 1]\n        D = pairwise_distances(centers)\n\n        m_vars = n\n        A_rows = []\n        b_vals = []\n\n        # Boundary constraints\n        for i in range(n):\n            # r_i <= x_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(x[i])\n            # r_i <= 1 - x_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0 - x[i])\n            # r_i <= y_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(y[i])\n            # r_i <= 1 - y_i\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0 - y[i])\n\n        # Pairwise constraints\n        for (i, j) in pairs:\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            row[j] = 1.0\n            A_rows.append(row)\n            b_vals.append(D[i, j])\n\n        if A_rows:\n            A_ub = np.vstack(A_rows)\n            b_ub = np.array(b_vals, dtype=float)\n        else:\n            A_ub, b_ub = None, None\n        return A_ub, b_ub\n\n    def solve_radii_lp_with_duals(centers, r_min_local):\n        # Solve LP maximize sum r => minimize -sum r with constraints\n        try:\n            from scipy.optimize import linprog\n            A_ub, b_ub = build_lp_matrices(centers)\n            m_vars = n\n            bounds = [(r_min_local, None)] * m_vars\n            c = -np.ones(m_vars, dtype=float)\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if not (hasattr(res, \"success\") and res.success and res.x is not None):\n                # Fallback: simple feasible radii by boundary and projection\n                b = boundary_limits(centers)\n                r = np.minimum(b, 0.5)\n                r = np.maximum(r, r_min_local)\n                return r, None, A_ub, b_ub, True\n            r = np.array(res.x, dtype=float)\n            b = boundary_limits(centers)\n            r = np.minimum(r, b)\n            r = np.maximum(r, r_min_local)\n            # Extract inequality duals (shadow prices). For minimize problem:\n            # derivative of optimal value w.r.t. b is y = res.ineqlin.marginals\n            # Our target objective is -optimal (maximize sum r), so weights = -y\n            weights = None\n            try:\n                if hasattr(res, \"ineqlin\") and res.ineqlin is not None and hasattr(res.ineqlin, \"marginals\"):\n                    y = np.array(res.ineqlin.marginals, dtype=float)\n                    weights = -y  # maximize sum r\n                    # Clip negatives to zero (non-binding or sign conventions)\n                    weights = np.maximum(weights, 0.0)\n                else:\n                    weights = None\n            except Exception:\n                weights = None\n            return r, weights, A_ub, b_ub, True\n        except Exception:\n            # Fallback if scipy unavailable: project radii heuristically and no duals\n            A_ub, b_ub = build_lp_matrices(centers)\n            b = boundary_limits(centers)\n            r = np.minimum(b, 0.5).copy()\n            r = np.maximum(r, r_min_local)\n            D = pairwise_distances(centers)\n            max_iter = 2000\n            tol = 1e-12\n            for _ in range(max_iter):\n                r = np.minimum(r, b)\n                viol = 0.0\n                for i in range(n):\n                    for j in range(i + 1, n):\n                        s = r[i] + r[j]\n                        dij = D[i, j]\n                        if s > dij:\n                            excess = s - dij\n                            dec = 0.5 * excess\n                            r[i] = max(r_min_local, r[i] - dec)\n                            r[j] = max(r_min_local, r[j] - dec)\n                            viol = max(viol, excess)\n                if viol < tol:\n                    break\n            r = np.minimum(r, b)\n            r = np.maximum(r, r_min_local)\n            return r, None, A_ub, b_ub, True\n\n    def compute_gradient_centers(centers, r, weights, A_ub, b_ub):\n        # Use dual weights if available; else use active-set heuristic based on slacks\n        grad = np.zeros_like(centers)\n        D = pairwise_distances(centers)\n        num_boundary_rows = 4 * n\n        # If no weights, build from slacks\n        if weights is None:\n            # Compute slacks: s = b - A r\n            if A_ub is None or b_ub is None:\n                return grad\n            slacks = b_ub - A_ub.dot(r)\n            # Boundary weights\n            bw = slacks[:num_boundary_rows]\n            # Scale for boundary slack\n            tau_b = max(1e-6, float(np.percentile(bw, 30)))\n            w_bound = np.exp(-np.clip(bw, 0, 1e9) / tau_b)\n            # Pair weights\n            pw = slacks[num_boundary_rows:]\n            tau_p = max(1e-6, float(np.percentile(pw, 30)))\n            w_pairs = np.exp(-np.clip(pw, 0, 1e9) / tau_p)\n        else:\n            w_full = weights\n            # Slight smoothing\n            w_full = np.maximum(w_full, 0.0)\n            # Normalize to avoid huge steps\n            scale = np.sum(w_full) + 1e-12\n            w_full = w_full / scale * (num_boundary_rows + len(pairs))\n            w_bound = w_full[:num_boundary_rows]\n            w_pairs = w_full[num_boundary_rows:]\n\n        # Boundary contributions\n        for i in range(n):\n            base = 4 * i\n            # r_i <= x_i           (d b / d x_i = +1)\n            grad[i, 0] += w_bound[base + 0] * 1.0\n            # r_i <= 1 - x_i       (d b / d x_i = -1)\n            grad[i, 0] += w_bound[base + 1] * (-1.0)\n            # r_i <= y_i\n            grad[i, 1] += w_bound[base + 2] * 1.0\n            # r_i <= 1 - y_i\n            grad[i, 1] += w_bound[base + 3] * (-1.0)\n\n        # Pair contributions\n        for k, (i, j) in enumerate(pairs):\n            w = w_pairs[k]\n            dij = D[i, j]\n            if dij > 1e-12:\n                u = (centers[i] - centers[j]) / dij\n            else:\n                ang = rng.uniform(0, 2 * np.pi)\n                u = np.array([np.cos(ang), np.sin(ang)], dtype=float)\n            grad[i] += w * u\n            grad[j] -= w * u\n        return grad\n\n    def score_from_radii(r):\n        return float(np.sum(r))\n\n    def joint_lp_step(centers0, delta):\n        # LP over centers and radii with linearized pairwise constraints and trust region\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return None, None, False\n        x0 = centers0[:, 0]\n        y0 = centers0[:, 1]\n        m_vars = 3 * n\n\n        def ix(i): return i\n        def iy(i): return n + i\n        def ir(i): return 2 * n + i\n\n        A_rows = []\n        b_vals = []\n\n        # Boundary constraints: r_i <= x_i; r_i + x_i <= 1; r_i <= y_i; r_i + y_i <= 1\n        for i in range(n):\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ix(i)] = -1.0\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ix(i)] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[iy(i)] = -1.0\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[iy(i)] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0)\n\n        # Trust region constraints L_inf\n        if delta is not None and delta > 0.0:\n            for i in range(n):\n                row = np.zeros(m_vars, dtype=float)\n                row[ix(i)] = 1.0\n                A_rows.append(row)\n                b_vals.append(float(x0[i] + delta))\n                row = np.zeros(m_vars, dtype=float)\n                row[ix(i)] = -1.0\n                A_rows.append(row)\n                b_vals.append(float(-x0[i] + delta))\n\n                row = np.zeros(m_vars, dtype=float)\n                row[iy(i)] = 1.0\n                A_rows.append(row)\n                b_vals.append(float(y0[i] + delta))\n                row = np.zeros(m_vars, dtype=float)\n                row[iy(i)] = -1.0\n                A_rows.append(row)\n                b_vals.append(float(-y0[i] + delta))\n\n        # Linearized pairwise constraints at centers0\n        D0 = pairwise_distances(centers0)\n        vs = {}\n        for (i, j) in pairs:\n            dij = D0[i, j]\n            if dij > 1e-9:\n                v = (centers0[i] - centers0[j]) / dij\n            else:\n                ang = rng.uniform(0, 2 * np.pi)\n                v = np.array([np.cos(ang), np.sin(ang)], dtype=float)\n            vs[(i, j)] = v\n\n        for (i, j) in pairs:\n            v = vs[(i, j)]\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ir(j)] = 1.0\n            row[ix(i)] += -v[0]\n            row[iy(i)] += -v[1]\n            row[ix(j)] += v[0]\n            row[iy(j)] += v[1]\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n        A_ub = np.vstack(A_rows) if A_rows else None\n        b_ub = np.array(b_vals, dtype=float) if b_vals else None\n\n        bounds = []\n        for i in range(n):\n            bounds.append((eps, 1.0 - eps))\n        for i in range(n):\n            bounds.append((eps, 1.0 - eps))\n        for i in range(n):\n            bounds.append((r_min, None))\n\n        c = np.zeros(m_vars, dtype=float)\n        c[2 * n: 3 * n] = -1.0\n\n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if not (hasattr(res, \"success\") and res.success and res.x is not None):\n                return None, None, False\n            sol = np.array(res.x, dtype=float)\n            centers = np.zeros((n, 2), dtype=float)\n            centers[:, 0] = sol[0:n]\n            centers[:, 1] = sol[n:2 * n]\n            r_lin = sol[2 * n: 3 * n]\n            centers = clamp_centers(centers)\n            r_lin = np.maximum(r_lin, r_min)\n            return centers, r_lin, True\n        except Exception:\n            return None, None, False\n\n    # Initializations\n    def hex_jitter_init(N):\n        rows = int(np.floor(np.sqrt(N)))\n        cols = int(np.ceil(N / rows))\n        xs = np.linspace(0.1, 0.9, cols)\n        ys = np.linspace(0.1, 0.9, rows)\n        centers = []\n        idx = 0\n        for ri, yy in enumerate(ys):\n            offset = 0.0 if (ri % 2 == 0) else (xs[1] - xs[0]) * 0.5 if len(xs) > 1 else 0.0\n            for _, xx in enumerate(xs):\n                if idx >= N:\n                    break\n                xi = np.clip(xx + offset, 0.05, 0.95)\n                jitter = 0.02\n                centers.append([xi + rng.normal(0, jitter), yy + rng.normal(0, jitter)])\n                idx += 1\n            if idx >= N:\n                break\n        centers = np.array(centers, dtype=float)\n        while centers.shape[0] < N:\n            centers = np.vstack([centers, rng.uniform(0.1, 0.9, size=(1, 2))])\n        return clamp_centers(centers)\n\n    def uniform_init(N):\n        return clamp_centers(rng.uniform(0.1, 0.9, size=(N, 2)))\n\n    def edge_bias_init(N):\n        k_edge = N // 3\n        k_int = N - k_edge\n        centers = [rng.uniform(0.2, 0.8, size=(k_int, 2))]\n        for _ in range(k_edge):\n            edge = rng.integers(0, 4)\n            t = rng.uniform(0.08, 0.92)\n            if edge == 0:\n                pt = [t, 0.06 + 0.02 * rng.random()]\n            elif edge == 1:\n                pt = [t, 0.94 - 0.02 * rng.random()]\n            elif edge == 2:\n                pt = [0.06 + 0.02 * rng.random(), t]\n            else:\n                pt = [0.94 - 0.02 * rng.random(), t]\n            centers.append(pt)\n        centers = np.vstack(centers)\n        return clamp_centers(centers[:N])\n\n    def corner_spokes_init(N):\n        corners = np.array([[0.1, 0.1], [0.9, 0.1], [0.1, 0.9], [0.9, 0.9]], dtype=float)\n        centers = []\n        k = N // 4\n        rem = N - 4 * k\n        for c in corners:\n            for _ in range(k):\n                ang = rng.uniform(0, 2 * np.pi)\n                rad = rng.uniform(0.0, 0.25)\n                pt = c + rad * np.array([np.cos(ang), np.sin(ang)])\n                centers.append(pt)\n        for _ in range(rem):\n            centers.append(rng.uniform(0.2, 0.8, size=2))\n        centers = np.array(centers, dtype=float)\n        return clamp_centers(centers)\n\n    init_candidates = []\n    # Use current best centers if provided\n    if isinstance(current_best_solution, np.ndarray):\n        try:\n            cb = current_best_solution\n            if cb.shape[0] == n and cb.shape[1] >= 2:\n                centers_cb = clamp_centers(cb[:, :2].astype(float))\n                init_candidates.append(centers_cb)\n                for _ in range(2):\n                    init_candidates.append(clamp_centers(centers_cb + rng.normal(0, 0.01, size=centers_cb.shape)))\n        except Exception:\n            pass\n\n    init_candidates.append(hex_jitter_init(n))\n    init_candidates.append(uniform_init(n))\n    init_candidates.append(edge_bias_init(n))\n    init_candidates.append(corner_spokes_init(n))\n    for _ in range(2):\n        init_candidates.append(uniform_init(n))\n\n    best_circles = None\n    best_score = -1e18\n\n    def try_update_best(centers, r):\n        nonlocal best_circles, best_score, all_scores\n        score = score_from_radii(r)\n        if score > best_score + 1e-12:\n            best_score = score\n            best_circles = np.hstack([centers, r.reshape(-1, 1)])\n            all_scores.append(best_score)\n            return True\n        return False\n\n    def gradient_optimize(centers_init):\n        nonlocal best_circles, best_score\n        centers = centers_init.copy()\n        # Warm-start solve\n        r, weights, A_ub, b_ub, ok = solve_radii_lp_with_duals(centers, r_min)\n        if not ok or r is None:\n            return\n        try_update_best(centers, r)\n\n        eta = 0.25\n        stagnation = 0\n        iters = 0\n        last_improve_iter = 0\n        while time_left() > 0.1:\n            iters += 1\n            # Compute gradient\n            grad = compute_gradient_centers(centers, r, weights, A_ub, b_ub)\n            # Normalize gradient by max row norm\n            row_norms = np.linalg.norm(grad, axis=1)\n            max_norm = float(np.max(row_norms)) if grad.size > 0 else 0.0\n            if not np.isfinite(max_norm) or max_norm <= 1e-18:\n                # If gradient is too small, perform a joint LP step or shake\n                if time_left() < 0.05:\n                    break\n                new_centers, r_lin, okj = joint_lp_step(centers, delta=0.05)\n                if okj and new_centers is not None:\n                    r_new, weights, A_ub, b_ub, ok2 = solve_radii_lp_with_duals(new_centers, r_min)\n                    if ok2 and r_new is not None:\n                        centers = new_centers\n                        r = r_new\n                        try_update_best(centers, r)\n                        continue\n                # Shake\n                idxs = rng.choice(n, size=max(1, n // 4), replace=False)\n                shake = np.zeros_like(centers)\n                shake[idxs] = rng.normal(0, 0.03, size=(len(idxs), 2))\n                centers_candidate = clamp_centers(centers + shake)\n                r_cand, w2, A2, b2, ok3 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                if ok3 and score_from_radii(r_cand) > score_from_radii(r) + 1e-10:\n                    centers, r = centers_candidate, r_cand\n                    weights, A_ub, b_ub = w2, A2, b2\n                    try_update_best(centers, r)\n                stagnation += 1\n                if stagnation > 10:\n                    break\n                continue\n\n            g = grad / (max_norm + 1e-18)\n            # Backtracking line search\n            base_score = score_from_radii(r)\n            success = False\n            step_eta = eta\n            for _ in range(14):\n                centers_candidate = clamp_centers(centers + step_eta * g)\n                r_cand, w2, A2, b2, ok2 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                if ok2 and r_cand is not None:\n                    sc = score_from_radii(r_cand)\n                    if sc > base_score + 1e-10:\n                        centers, r = centers_candidate, r_cand\n                        weights, A_ub, b_ub = w2, A2, b2\n                        eta = min(step_eta * 1.25, 0.5)\n                        success = True\n                        last_improve_iter = iters\n                        try_update_best(centers, r)\n                        break\n                step_eta *= 0.5\n            if not success:\n                eta *= 0.6\n                stagnation += 1\n                # Occasional SCA LP step to escape\n                if stagnation % 4 == 0 and time_left() > 0.05:\n                    delta = 0.08 if stagnation < 8 else 0.12\n                    new_centers, r_lin, okj = joint_lp_step(centers, delta)\n                    if okj and new_centers is not None:\n                        r_new, w2, A2, b2, ok2 = solve_radii_lp_with_duals(new_centers, r_min)\n                        if ok2 and r_new is not None and score_from_radii(r_new) >= base_score - 1e-9:\n                            centers, r = new_centers, r_new\n                            weights, A_ub, b_ub = w2, A2, b2\n                            try_update_best(centers, r)\n                # Random local shake\n                if stagnation % 3 == 0:\n                    idxs = rng.choice(n, size=max(1, n // 6), replace=False)\n                    shake = np.zeros_like(centers)\n                    shake[idxs] = rng.normal(0, 0.02 * (1 + 0.1 * stagnation), size=(len(idxs), 2))\n                    centers_candidate = clamp_centers(centers + shake)\n                    r_cand, w2, A2, b2, ok3 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                    if ok3 and r_cand is not None and score_from_radii(r_cand) > base_score + 1e-10:\n                        centers, r = centers_candidate, r_cand\n                        weights, A_ub, b_ub = w2, A2, b2\n                        try_update_best(centers, r)\n                # Break if too many without improvement\n                if iters - last_improve_iter > 50 or stagnation > 20:\n                    break\n            else:\n                stagnation = max(stagnation - 1, 0)\n\n    # Run multi-start optimization\n    for init_centers in init_candidates:\n        if time_left() < 0.3:\n            break\n        gradient_optimize(init_centers)\n\n    # Final fallback\n    if best_circles is None or not np.all(np.isfinite(best_circles)):\n        centers = clamp_centers(rng.uniform(0.1, 0.9, size=(n, 2)))\n        r, _, _, _, ok = solve_radii_lp_with_duals(centers, r_min)\n        if not ok or r is None:\n            b = boundary_limits(centers)\n            r = np.maximum(np.minimum(b, 0.5), r_min)\n        best_circles = np.hstack([centers, r.reshape(-1, 1)])\n        best_score = score_from_radii(r)\n        all_scores.append(best_score)\n\n    # Ensure final feasibility via radii LP\n    try:\n        centers_final = best_circles[:, :2]\n        r_final, _, _, _, ok = solve_radii_lp_with_duals(centers_final, r_min)\n        if ok and r_final is not None:\n            best_circles = np.hstack([centers_final, r_final.reshape(-1, 1)])\n            best_score = score_from_radii(r_final)\n    except Exception:\n        pass\n\n    return {\n        'circles': best_circles.astype(float),\n        'all_scores': [float(s) for s in all_scores] if all_scores else [float(best_score)]\n    }",
    "code_score": 2.635983181610043,
    "refiner_prompt": "import numpy as np\nimport time\n\ndef main(timeout, current_best_solution):\n    \"\"\"\n    BREAKTHROUGH approach: Evolution Strategies (ES) in unconstrained parameter space\n    mapped via sigmoid to [0,1]^2 for centers, with exact LP for radii at each evaluation.\n    Multi-start ES with antithetic sampling, adaptive step-size, and final SLP polish.\n\n    Returns:\n        dict with 'circles' (N x 3) and 'all_scores' (list of floats)\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    time_budget = max(1.0, float(timeout) - 0.5)\n    rng = np.random.default_rng(2026)\n    all_scores = []\n\n    # Parameters\n    r_min = 1e-6\n    eps_box = 1e-6  # margin on [0,1]\n    margin = 1e-4   # mapping margin for sigmoid to avoid touching boundaries\n\n    def time_left():\n        return time_budget - (time.time() - start_time)\n\n    # Utility functions\n    def clamp01(x):\n        return np.clip(x, 0.0 + eps_box, 1.0 - eps_box)\n\n    def boundary_limits(centers):\n        x = centers[:, 0]\n        y = centers[:, 1]\n        return np.minimum(np.minimum(x, 1 - x), np.minimum(y, 1 - y))\n\n    def pairwise_distances(centers):\n        diff = centers[:, None, :] - centers[None, :, :]\n        D = np.sqrt(np.maximum(np.sum(diff * diff, axis=2), 0.0))\n        return D\n\n    def solve_radii_lp_fallback(centers, r_min_local):\n        # Projection-style feasibility repair (no LP dependency)\n        b = boundary_limits(centers)\n        n_local = centers.shape[0]\n        r = np.minimum(b, 0.5).copy()\n        r = np.maximum(r, r_min_local)\n        D = pairwise_distances(centers)\n        max_iter = 4000\n        tol = 1e-10\n        for _ in range(max_iter):\n            r = np.minimum(r, b)\n            viol = 0.0\n            for i in range(n_local):\n                for j in range(i + 1, n_local):\n                    dij = D[i, j]\n                    if dij <= 0:\n                        # collapse one\n                        r[j] = r_min_local\n                        continue\n                    s = r[i] + r[j]\n                    if s > dij:\n                        excess = s - dij\n                        viol = max(viol, excess)\n                        # proportional reduction by current radii\n                        total = r[i] + r[j]\n                        if total <= 1e-16:\n                            dec_i = dec_j = 0.5 * excess\n                        else:\n                            dec_i = excess * (r[i] / total)\n                            dec_j = excess * (r[j] / total)\n                        r[i] = max(r_min_local, r[i] - dec_i)\n                        r[j] = max(r_min_local, r[j] - dec_j)\n            if viol < tol:\n                break\n        r = np.minimum(r, b)\n        r = np.maximum(r, r_min_local)\n        return r, True\n\n    def solve_radii_lp(centers, r_min_local):\n        try:\n            from scipy.optimize import linprog\n            n_local = centers.shape[0]\n            b = boundary_limits(centers)\n            D = pairwise_distances(centers)\n\n            # Build A_ub and b_ub:\n            # r_i <= b_i (implicit via b constraints decomposed)\n            # Represent boundary constraints explicitly to reduce numerical issues\n            A_rows = []\n            b_vals = []\n            for i in range(n_local):\n                # r_i <= x_i\n                row = np.zeros(n_local); row[i] = 1.0\n                A_rows.append(row); b_vals.append(centers[i, 0])\n                # r_i <= 1 - x_i\n                row = np.zeros(n_local); row[i] = 1.0\n                A_rows.append(row); b_vals.append(1.0 - centers[i, 0])\n                # r_i <= y_i\n                row = np.zeros(n_local); row[i] = 1.0\n                A_rows.append(row); b_vals.append(centers[i, 1])\n                # r_i <= 1 - y_i\n                row = np.zeros(n_local); row[i] = 1.0\n                A_rows.append(row); b_vals.append(1.0 - centers[i, 1])\n\n            # Pairwise constraints\n            for i in range(n_local):\n                for j in range(i + 1, n_local):\n                    row = np.zeros(n_local)\n                    row[i] = 1.0\n                    row[j] = 1.0\n                    A_rows.append(row)\n                    b_vals.append(D[i, j])\n\n            A_ub = np.array(A_rows, dtype=float) if A_rows else None\n            b_ub = np.array(b_vals, dtype=float) if b_vals else None\n            bounds = [(r_min_local, None)] * n_local\n            c = -np.ones(n_local, dtype=float)\n\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if res.success and res.x is not None:\n                r = np.array(res.x, dtype=float)\n                r = np.minimum(r, b)\n                r = np.maximum(r, r_min_local)\n                return r, True\n            else:\n                return solve_radii_lp_fallback(centers, r_min_local)\n        except Exception:\n            return solve_radii_lp_fallback(centers, r_min_local)\n\n    def feasible_from_centers(centers):\n        centers = clamp01(centers)\n        r, _ = solve_radii_lp(centers, r_min)\n        return np.hstack([centers, r.reshape(-1, 1)]), float(np.sum(r))\n\n    # Sigmoid mapping for ES\n    def sigmoid(z):\n        return 1.0 / (1.0 + np.exp(-z))\n\n    def inv_sigmoid(p):\n        p = np.clip(p, 1e-12, 1 - 1e-12)\n        return np.log(p) - np.log(1 - p)\n\n    def params_to_centers(theta):\n        # theta is length 2n in R, map to [margin, 1-margin] via sigmoid\n        p = sigmoid(theta)\n        return (margin + (1 - 2 * margin) * p).reshape(n, 2)\n\n    def centers_to_params(centers):\n        # inverse map\n        p = (centers - margin) / max(1e-12, (1 - 2 * margin))\n        z = inv_sigmoid(p)\n        return z.ravel()\n\n    # Initialization seeds\n    def init_hex_grid():\n        K = n\n        cols = int(np.ceil(np.sqrt(K)))\n        rows = int(np.ceil(K / cols))\n        xs = np.linspace(0.12, 0.88, cols)\n        ys = np.linspace(0.12, 0.88, rows)\n        pts = []\n        cnt = 0\n        for r_idx, yy in enumerate(ys):\n            off = 0.0 if (r_idx % 2 == 0) else (xs[1] - xs[0]) * 0.5 if len(xs) > 1 else 0.0\n            for xx in xs:\n                if cnt >= K:\n                    break\n                x = np.clip(xx + off, 0.06, 0.94)\n                x += rng.normal(0, 0.01)\n                y = yy + rng.normal(0, 0.01)\n                pts.append([x, y])\n                cnt += 1\n            if cnt >= K:\n                break\n        pts = np.array(pts, dtype=float)\n        while pts.shape[0] < K:\n            pts = np.vstack([pts, rng.uniform(0.15, 0.85, size=(1, 2))])\n        return clamp01(pts[:n])\n\n    def init_edges():\n        pts = []\n        eps = 1e-3\n        corners = [[eps, eps], [1 - eps, eps], [eps, 1 - eps], [1 - eps, 1 - eps]]\n        pts.extend(corners)\n        ts = np.linspace(0.15, 0.85, 6)\n        for t in ts:\n            pts.append([t, eps])\n            pts.append([t, 1 - eps])\n            pts.append([eps, t])\n            pts.append([1 - eps, t])\n        pts = np.array(pts[:n], dtype=float)\n        if pts.shape[0] < n:\n            while pts.shape[0] < n:\n                edge = rng.integers(0, 4)\n                t = rng.uniform(0.08, 0.92)\n                if edge == 0: pts = np.vstack([pts, [t, eps]])\n                elif edge == 1: pts = np.vstack([pts, [t, 1 - eps]])\n                elif edge == 2: pts = np.vstack([pts, [eps, t]])\n                else: pts = np.vstack([pts, [1 - eps, t]])\n        return clamp01(pts[:n])\n\n    def init_center_biased():\n        pts = 0.75 * rng.uniform(0.05, 0.95, size=(n, 2)) + 0.25 * 0.5\n        pts += rng.normal(0, 0.03, size=(n, 2))\n        return clamp01(pts)\n\n    # SLP one-shot small polish (uses linearization once per call)\n    def build_slp_lp(centers, radii, s_pos, s_r_up, s_r_down):\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return None\n        N = centers.shape[0]\n        var_dim = 3 * N\n        A_rows = []\n        b_vals = []\n\n        # Boundary constraints linearized\n        for i in range(N):\n            xi, yi = centers[i]\n            ri = radii[i]\n            row = np.zeros(var_dim); row[3 * i + 0] = -1.0; row[3 * i + 2] = 1.0\n            A_rows.append(row); b_vals.append(xi - ri)\n            row = np.zeros(var_dim); row[3 * i + 0] = 1.0; row[3 * i + 2] = 1.0\n            A_rows.append(row); b_vals.append(1.0 - xi - ri)\n            row = np.zeros(var_dim); row[3 * i + 1] = -1.0; row[3 * i + 2] = 1.0\n            A_rows.append(row); b_vals.append(yi - ri)\n            row = np.zeros(var_dim); row[3 * i + 1] = 1.0; row[3 * i + 2] = 1.0\n            A_rows.append(row); b_vals.append(1.0 - yi - ri)\n\n        # Pairwise linearization\n        diff = centers[:, None, :] - centers[None, :, :]\n        D = np.sqrt(np.maximum(np.sum(diff * diff, axis=2), 0.0))\n        for i in range(N):\n            for j in range(i + 1, N):\n                dij = D[i, j]\n                if dij <= 1e-12:\n                    u = np.array([1.0, 0.0])\n                    dij = 0.0\n                else:\n                    u = diff[i, j] / dij\n                row = np.zeros(var_dim)\n                row[3 * i + 0] += -u[0]; row[3 * i + 1] += -u[1]\n                row[3 * j + 0] += u[0];  row[3 * j + 1] += u[1]\n                row[3 * i + 2] += 1.0;   row[3 * j + 2] += 1.0\n                rhs = dij - (radii[i] + radii[j])\n                A_rows.append(row); b_vals.append(rhs)\n\n        A_ub = np.array(A_rows, dtype=float) if A_rows else None\n        b_ub = np.array(b_vals, dtype=float) if b_vals else None\n\n        bounds = []\n        for i in range(N):\n            xi, yi = centers[i]; ri = radii[i]\n            dx_lo = max(-s_pos, -xi); dx_hi = min(s_pos, 1.0 - xi)\n            dy_lo = max(-s_pos, -yi); dy_hi = min(s_pos, 1.0 - yi)\n            dr_lo = max(-s_r_down, r_min - ri); dr_hi = s_r_up\n            bounds.append((dx_lo, dx_hi)); bounds.append((dy_lo, dy_hi)); bounds.append((dr_lo, dr_hi))\n\n        c = np.zeros(var_dim, dtype=float)\n        for i in range(N): c[3 * i + 2] = -1.0\n        return c, A_ub, b_ub, bounds\n\n    def slp_one_shot(centers_init, radii_init, step_scale=0.08):\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return centers_init, radii_init\n        built = build_slp_lp(centers_init, radii_init, step_scale, step_scale * 0.6, step_scale * 0.8)\n        if built is None: return centers_init, radii_init\n        c, A_ub, b_ub, bounds = built\n        try:\n            from scipy.optimize import linprog\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if not (res.success and res.x is not None):\n                return centers_init, radii_init\n            delta = res.x.reshape(-1, 3)\n            centers = centers_init + delta[:, :2]\n            r = radii_init + delta[:, 2]\n            # repair\n            centers = clamp01(centers)\n            r_rep, _ = solve_radii_lp(centers, r_min)\n            return centers, r_rep\n        except Exception:\n            return centers_init, radii_init\n\n    # ES optimizer\n    def es_optimize(theta0, time_left_func):\n        D = theta0.size\n        theta = theta0.copy()\n        sigma = 0.8  # initial step scale\n        alpha_theta = 0.2\n        alpha_sigma = 0.1\n        beta_sigma = 0.9\n        # Adam-like momentum\n        m_t = np.zeros_like(theta)\n        v_t = np.zeros_like(theta)\n        t_adam = 0\n        eps_adam = 1e-8\n\n        best_local_score = -1e18\n        best_local_centers = None\n        best_local_r = None\n        local_scores = []\n\n        # Evaluate base\n        centers0 = params_to_centers(theta)\n        circles0, score0 = feasible_from_centers(centers0)\n        if score0 > best_local_score:\n            best_local_score = score0\n            best_local_centers = centers0.copy()\n            best_local_r = circles0[:, 2].copy()\n            local_scores.append(best_local_score)\n\n        # ES loop\n        max_iters = 1000000\n        pop_base = max(12, 4 + int(3 * np.log(D + 1)))\n        antithetic = True\n        it = 0\n        last_improve_it = 0\n\n        while time_left_func() > 0.25 and it < max_iters:\n            it += 1\n            # Adapt population with time\n            pop = pop_base\n            # Sample\n            zs = rng.standard_normal(size=(pop, D))\n            if antithetic:\n                zs = np.vstack([zs, -zs])\n            k = zs.shape[0]\n\n            scores = np.empty(k, dtype=float)\n            for idx in range(k):\n                if time_left_func() <= 0.1:\n                    break\n                z = zs[idx]\n                th = theta + sigma * z\n                centers = params_to_centers(th)\n                # Quick one-shot SLP polish of centers to boost score\n                circles_pre, score_pre = feasible_from_centers(centers)\n                centers_pol, r_pol = slp_one_shot(circles_pre[:, :2], circles_pre[:, 2], step_scale=0.05)\n                score = float(np.sum(r_pol))\n                scores[idx] = score\n                if score > best_local_score + 1e-12:\n                    best_local_score = score\n                    best_local_centers = centers_pol.copy()\n                    best_local_r = r_pol.copy()\n                    local_scores.append(best_local_score)\n                    last_improve_it = it\n\n            if time_left_func() <= 0.1:\n                break\n\n            # Compute gradient estimate (OpenAI-ES style)\n            # Normalize scores\n            s = scores\n            if not np.all(np.isfinite(s)):\n                s = np.nan_to_num(s, nan=-1e9, posinf=-1e9, neginf=-1e9)\n            s_mean = np.mean(s)\n            s_std = np.std(s) + 1e-12\n            s_norm = (s - s_mean) / s_std\n            grad = (zs.T @ s_norm) / (k * 1.0)\n            # Adam update\n            t_adam += 1\n            m_t = 0.9 * m_t + 0.1 * grad\n            v_t = 0.999 * v_t + 0.001 * (grad * grad)\n            m_hat = m_t / (1 - 0.9 ** t_adam)\n            v_hat = v_t / (1 - 0.999 ** t_adam)\n            theta += alpha_theta * m_hat / (np.sqrt(v_hat) + eps_adam)\n\n            # Adapt sigma heuristically towards recent improvements\n            if it - last_improve_it > 8:\n                sigma *= 0.92\n            else:\n                sigma = sigma * beta_sigma + (1 - beta_sigma) * 0.6\n\n            sigma = float(np.clip(sigma, 0.02, 1.5))\n\n        return best_local_centers, best_local_r, best_local_score, local_scores\n\n    # Seed list buildup\n    seed_centers_list = []\n    # current best seed\n    if isinstance(current_best_solution, np.ndarray):\n        try:\n            cb = current_best_solution\n            if cb.shape[0] == n and cb.shape[1] >= 2:\n                centers_cb = clamp01(cb[:, :2].astype(float))\n                seed_centers_list.append(centers_cb)\n        except Exception:\n            pass\n    seed_centers_list.append(init_hex_grid())\n    seed_centers_list.append(init_edges())\n    seed_centers_list.append(init_center_biased())\n    jitter_hex = init_hex_grid() + rng.normal(0, 0.02, size=(n, 2))\n    seed_centers_list.append(clamp01(jitter_hex))\n\n    # Unique seeds via hash\n    unique_seeds = []\n    seen = set()\n    for c in seed_centers_list:\n        h = tuple(np.round(c.ravel(), 3))\n        if h in seen:\n            c = clamp01(c + rng.normal(0, 0.005, size=c.shape))\n        unique_seeds.append(c)\n        seen.add(h)\n    seed_centers_list = unique_seeds\n\n    best_global_circles = None\n    best_global_score = -1e18\n\n    # initial evaluation for seeds\n    for centers in seed_centers_list:\n        circles, score = feasible_from_centers(centers)\n        if score > best_global_score + 1e-12:\n            best_global_score = score\n            best_global_circles = circles\n            all_scores.append(best_global_score)\n\n    # ES per seed with time slicing\n    per_seed_time = max(0.5, time_left() / max(1, len(seed_centers_list)))\n    for idx_seed, centers0 in enumerate(seed_centers_list):\n        if time_left() < 0.4:\n            break\n        theta0 = centers_to_params(centers0)\n        t_seed_start = time.time()\n\n        def time_left_seed():\n            tl = time_left()\n            tl_seed = per_seed_time - (time.time() - t_seed_start)\n            return min(tl, tl_seed)\n\n        centers_best, r_best, score_best, local_scores = es_optimize(theta0, time_left_seed)\n        if centers_best is None or r_best is None:\n            continue\n        # Final LP repair and one more polish\n        r_rep, _ = solve_radii_lp(centers_best, r_min)\n        centers_final, r_final = slp_one_shot(centers_best, r_rep, step_scale=0.06)\n        r_final, _ = solve_radii_lp(centers_final, r_min)\n        score_final = float(np.sum(r_final))\n        if score_final > best_global_score + 1e-12:\n            best_global_score = score_final\n            best_global_circles = np.hstack([centers_final, r_final.reshape(-1, 1)])\n            all_scores.append(best_global_score)\n        for s in local_scores:\n            if not all_scores or s > all_scores[-1] + 1e-9:\n                all_scores.append(s)\n\n    # Safety fallback\n    if best_global_circles is None:\n        centers = init_edges()\n        r, _ = solve_radii_lp(centers, r_min)\n        best_global_circles = np.hstack([centers, r.reshape(-1, 1)])\n        best_global_score = float(np.sum(r))\n        all_scores.append(best_global_score)\n\n    # Ensure final feasibility\n    try:\n        centers_final = best_global_circles[:, :2]\n        r_final, _ = solve_radii_lp(centers_final, r_min)\n        best_global_circles = np.hstack([centers_final, r_final.reshape(-1, 1)])\n        best_global_score = float(np.sum(r_final))\n        if not all_scores or best_global_score > all_scores[-1] + 1e-9:\n            all_scores.append(best_global_score)\n    except Exception:\n        pass\n\n    return {\n        'circles': best_global_circles.astype(float),\n        'all_scores': [float(s) for s in all_scores] if all_scores else [float(best_global_score)]\n    }",
    "refiner_code": "import numpy as np\nimport time\n\ndef main(timeout, current_best_solution):\n    \"\"\"\n    Breakthrough optimizer for sum-of-radii circle packing in a unit square (N=26).\n    Bilevel optimization: radii solved by an LP; centers optimized via gradient ascent\n    using dual/active-set heuristics, plus occasional joint LP (SCA) steps and\n    multi-start exploration.\n    \"\"\"\n    n = 26\n    start_time = time.time()\n    time_budget = max(1.0, float(timeout) - 0.5)\n    rng = np.random.default_rng(12345)\n\n    eps = 1e-6\n    r_min = 1e-10\n    all_scores = []\n\n    def time_left():\n        return time_budget - (time.time() - start_time)\n\n    # Pair indices\n    pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]\n\n    def clamp_centers(centers):\n        return np.clip(centers, eps, 1.0 - eps)\n\n    def boundary_limits(centers):\n        x = centers[:, 0]\n        y = centers[:, 1]\n        return np.minimum(np.minimum(x, 1 - x), np.minimum(y, 1 - y))\n\n    def pairwise_distances(centers):\n        diff = centers[:, None, :] - centers[None, :, :]\n        return np.sqrt(np.maximum(np.sum(diff * diff, axis=2), 0.0))\n\n    def build_lp_matrices(centers):\n        # Build A_ub r <= b_ub: for each i: r_i<=x_i; r_i<=1-x_i; r_i<=y_i; r_i<=1-y_i;\n        # then all pairs r_i + r_j <= d_ij\n        x = centers[:, 0]\n        y = centers[:, 1]\n        D = pairwise_distances(centers)\n\n        m_vars = n\n        A_rows = []\n        b_vals = []\n\n        # Boundary constraints\n        for i in range(n):\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(x[i])\n\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0 - x[i])\n\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(y[i])\n\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0 - y[i])\n\n        # Pairwise constraints\n        for (i, j) in pairs:\n            row = np.zeros(m_vars, dtype=float)\n            row[i] = 1.0\n            row[j] = 1.0\n            A_rows.append(row)\n            b_vals.append(D[i, j])\n\n        if A_rows:\n            A_ub = np.vstack(A_rows)\n            b_ub = np.array(b_vals, dtype=float)\n        else:\n            A_ub, b_ub = None, None\n        return A_ub, b_ub\n\n    def solve_radii_lp_with_duals(centers, r_min_local):\n        # Solve LP maximize sum r => minimize -sum r with constraints\n        try:\n            from scipy.optimize import linprog\n            A_ub, b_ub = build_lp_matrices(centers)\n            m_vars = n\n            bounds = [(r_min_local, None)] * m_vars\n            c = -np.ones(m_vars, dtype=float)\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method=\"highs\")\n            if not (getattr(res, \"success\", False) and res.x is not None):\n                # Fallback: simple feasible radii by boundary\n                b = boundary_limits(centers)\n                r = np.minimum(b, 0.5)\n                r = np.maximum(r, r_min_local)\n                return r, None, A_ub, b_ub, True\n            r = np.array(res.x, dtype=float)\n            b = boundary_limits(centers)\n            r = np.minimum(r, b)\n            r = np.maximum(r, r_min_local)\n\n            # Try to extract inequality duals. If unavailable, return None for weights.\n            weights = None\n            try:\n                ineqlin = getattr(res, \"ineqlin\", None)\n                if ineqlin is not None and hasattr(ineqlin, \"marginals\"):\n                    y = np.array(ineqlin.marginals, dtype=float)\n                    weights = -y\n                    weights = np.maximum(weights, 0.0)\n                else:\n                    weights = None\n            except Exception:\n                weights = None\n            return r, weights, A_ub, b_ub, True\n        except Exception:\n            # Fallback if scipy unavailable: simple projection heuristic\n            A_ub, b_ub = build_lp_matrices(centers)\n            b = boundary_limits(centers)\n            r = np.minimum(b, 0.5).copy()\n            r = np.maximum(r, r_min_local)\n            D = pairwise_distances(centers)\n            max_iter = 1000\n            tol = 1e-11\n            for _ in range(max_iter):\n                r = np.minimum(r, b)\n                viol = 0.0\n                for i in range(n):\n                    for j in range(i + 1, n):\n                        s = r[i] + r[j]\n                        dij = D[i, j]\n                        if s > dij:\n                            excess = s - dij\n                            dec = 0.5 * excess\n                            r[i] = max(r_min_local, r[i] - dec)\n                            r[j] = max(r_min_local, r[j] - dec)\n                            viol = max(viol, excess)\n                if viol < tol:\n                    break\n            r = np.minimum(r, b)\n            r = np.maximum(r, r_min_local)\n            return r, None, A_ub, b_ub, True\n\n    def compute_gradient_centers(centers, r, weights, A_ub, b_ub):\n        # Use dual weights if available; else use active-set heuristic based on slacks\n        grad = np.zeros_like(centers)\n        D = pairwise_distances(centers)\n        num_boundary_rows = 4 * n\n\n        if weights is None:\n            if A_ub is None or b_ub is None:\n                return grad\n            slacks = b_ub - A_ub.dot(r)\n            bw = slacks[:num_boundary_rows]\n            tau_b = max(1e-6, float(np.percentile(bw, 30)))\n            w_bound = np.exp(-np.clip(bw, 0, 1e9) / tau_b)\n            pw = slacks[num_boundary_rows:]\n            tau_p = max(1e-6, float(np.percentile(pw, 30)))\n            w_pairs = np.exp(-np.clip(pw, 0, 1e9) / tau_p)\n        else:\n            w_full = np.maximum(weights, 0.0)\n            scale = np.sum(w_full) + 1e-12\n            w_full = w_full / scale * (num_boundary_rows + len(pairs))\n            w_bound = w_full[:num_boundary_rows]\n            w_pairs = w_full[num_boundary_rows:]\n\n        # Boundary contributions\n        for i in range(n):\n            base = 4 * i\n            grad[i, 0] += w_bound[base + 0]\n            grad[i, 0] += -w_bound[base + 1]\n            grad[i, 1] += w_bound[base + 2]\n            grad[i, 1] += -w_bound[base + 3]\n\n        # Pair contributions\n        for k, (i, j) in enumerate(pairs):\n            w = w_pairs[k]\n            dij = D[i, j]\n            if dij > 1e-12:\n                u = (centers[i] - centers[j]) / dij\n            else:\n                ang = rng.uniform(0, 2 * np.pi)\n                u = np.array([np.cos(ang), np.sin(ang)], dtype=float)\n            grad[i] += w * u\n            grad[j] -= w * u\n        return grad\n\n    def score_from_radii(r):\n        return float(np.sum(r))\n\n    def joint_lp_step(centers0, delta):\n        # LP over centers and radii with linearized pairwise constraints and trust region\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return None, None, False\n\n        x0 = centers0[:, 0]\n        y0 = centers0[:, 1]\n        m_vars = 3 * n\n\n        def ix(i): return i\n        def iy(i): return n + i\n        def ir(i): return 2 * n + i\n\n        A_rows = []\n        b_vals = []\n\n        # Boundary constraints: r_i <= x_i; r_i + x_i <= 1; r_i <= y_i; r_i + y_i <= 1\n        for i in range(n):\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ix(i)] = -1.0\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ix(i)] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[iy(i)] = -1.0\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[iy(i)] = 1.0\n            A_rows.append(row)\n            b_vals.append(1.0)\n\n        # Trust region constraints L_inf\n        if delta is not None and delta > 0.0:\n            for i in range(n):\n                row = np.zeros(m_vars, dtype=float)\n                row[ix(i)] = 1.0\n                A_rows.append(row)\n                b_vals.append(float(x0[i] + delta))\n                row = np.zeros(m_vars, dtype=float)\n                row[ix(i)] = -1.0\n                A_rows.append(row)\n                b_vals.append(float(-x0[i] + delta))\n\n                row = np.zeros(m_vars, dtype=float)\n                row[iy(i)] = 1.0\n                A_rows.append(row)\n                b_vals.append(float(y0[i] + delta))\n                row = np.zeros(m_vars, dtype=float)\n                row[iy(i)] = -1.0\n                A_rows.append(row)\n                b_vals.append(float(-y0[i] + delta))\n\n        # Linearized pairwise constraints at centers0\n        D0 = pairwise_distances(centers0)\n        vs = {}\n        for (i, j) in pairs:\n            dij = D0[i, j]\n            if dij > 1e-9:\n                v = (centers0[i] - centers0[j]) / dij\n            else:\n                ang = rng.uniform(0, 2 * np.pi)\n                v = np.array([np.cos(ang), np.sin(ang)], dtype=float)\n            vs[(i, j)] = v\n\n        for (i, j) in pairs:\n            v = vs[(i, j)]\n            row = np.zeros(m_vars, dtype=float)\n            row[ir(i)] = 1.0\n            row[ir(j)] = 1.0\n            row[ix(i)] += -v[0]\n            row[iy(i)] += -v[1]\n            row[ix(j)] += v[0]\n            row[iy(j)] += v[1]\n            A_rows.append(row)\n            b_vals.append(0.0)\n\n        A_ub = np.vstack(A_rows) if A_rows else None\n        b_ub = np.array(b_vals, dtype=float) if b_vals else None\n\n        bounds = []\n        for _ in range(n):\n            bounds.append((eps, 1.0 - eps))\n        for _ in range(n):\n            bounds.append((eps, 1.0 - eps))\n        for _ in range(n):\n            bounds.append((r_min, None))\n\n        c = np.zeros(m_vars, dtype=float)\n        c[2 * n: 3 * n] = -1.0\n\n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method=\"highs\")\n            if not (getattr(res, \"success\", False) and res.x is not None):\n                return None, None, False\n            sol = np.array(res.x, dtype=float)\n            centers = np.zeros((n, 2), dtype=float)\n            centers[:, 0] = sol[0:n]\n            centers[:, 1] = sol[n:2 * n]\n            r_lin = sol[2 * n:3 * n]\n            centers = clamp_centers(centers)\n            r_lin = np.maximum(r_lin, r_min)\n            return centers, r_lin, True\n        except Exception:\n            return None, None, False\n\n    # Initializations\n    def hex_jitter_init(N):\n        rows = int(np.floor(np.sqrt(N)))\n        cols = int(np.ceil(N / rows))\n        xs = np.linspace(0.1, 0.9, cols)\n        ys = np.linspace(0.1, 0.9, rows)\n        centers = []\n        idx = 0\n        for ri, yy in enumerate(ys):\n            offset = 0.0 if (ri % 2 == 0) else (xs[1] - xs[0]) * 0.5 if len(xs) > 1 else 0.0\n            for xx in xs:\n                if idx >= N:\n                    break\n                xi = np.clip(xx + offset, 0.05, 0.95)\n                jitter = 0.02\n                centers.append([xi + rng.normal(0, jitter), yy + rng.normal(0, jitter)])\n                idx += 1\n            if idx >= N:\n                break\n        centers = np.array(centers, dtype=float)\n        while centers.shape[0] < N:\n            centers = np.vstack([centers, rng.uniform(0.1, 0.9, size=(1, 2))])\n        return clamp_centers(centers)\n\n    def uniform_init(N):\n        return clamp_centers(rng.uniform(0.1, 0.9, size=(N, 2)))\n\n    def edge_bias_init(N):\n        k_edge = N // 3\n        k_int = N - k_edge\n        centers = [rng.uniform(0.2, 0.8, size=(k_int, 2))]\n        for _ in range(k_edge):\n            edge = rng.integers(0, 4)\n            t = rng.uniform(0.08, 0.92)\n            if edge == 0:\n                pt = [t, 0.06 + 0.02 * rng.random()]\n            elif edge == 1:\n                pt = [t, 0.94 - 0.02 * rng.random()]\n            elif edge == 2:\n                pt = [0.06 + 0.02 * rng.random(), t]\n            else:\n                pt = [0.94 - 0.02 * rng.random(), t]\n            centers.append(pt)\n        centers = np.vstack(centers)\n        return clamp_centers(centers[:N])\n\n    def corner_spokes_init(N):\n        corners = np.array([[0.1, 0.1], [0.9, 0.1], [0.1, 0.9], [0.9, 0.9]], dtype=float)\n        centers = []\n        k = N // 4\n        rem = N - 4 * k\n        for c in corners:\n            for _ in range(k):\n                ang = rng.uniform(0, 2 * np.pi)\n                rad = rng.uniform(0.0, 0.25)\n                pt = c + rad * np.array([np.cos(ang), np.sin(ang)])\n                centers.append(pt)\n        for _ in range(rem):\n            centers.append(rng.uniform(0.2, 0.8, size=2))\n        centers = np.array(centers, dtype=float)\n        return clamp_centers(centers)\n\n    init_candidates = []\n    # Use current best centers if provided\n    if isinstance(current_best_solution, np.ndarray):\n        try:\n            cb = current_best_solution\n            if cb.shape[0] == n and cb.shape[1] >= 2:\n                centers_cb = clamp_centers(cb[:, :2].astype(float))\n                init_candidates.append(centers_cb)\n                for _ in range(2):\n                    init_candidates.append(\n                        clamp_centers(centers_cb + rng.normal(0, 0.01, size=centers_cb.shape))\n                    )\n        except Exception:\n            pass\n\n    init_candidates.append(hex_jitter_init(n))\n    init_candidates.append(uniform_init(n))\n    init_candidates.append(edge_bias_init(n))\n    init_candidates.append(corner_spokes_init(n))\n    for _ in range(2):\n        init_candidates.append(uniform_init(n))\n\n    best_circles = None\n    best_score = -1e18\n\n    def try_update_best(centers, r):\n        nonlocal best_circles, best_score, all_scores\n        score = score_from_radii(r)\n        if score > best_score + 1e-12:\n            best_score = score\n            best_circles = np.hstack([centers, r.reshape(-1, 1)])\n            all_scores.append(best_score)\n            return True\n        return False\n\n    def gradient_optimize(centers_init):\n        nonlocal best_circles, best_score\n        centers = centers_init.copy()\n        r, weights, A_ub, b_ub, ok = solve_radii_lp_with_duals(centers, r_min)\n        if not ok or r is None:\n            return\n        try_update_best(centers, r)\n\n        eta = 0.25\n        stagnation = 0\n        iters = 0\n        last_improve_iter = 0\n        # Global cap on iterations for robustness\n        max_local_iters = 400\n        while time_left() > 0.1 and iters < max_local_iters:\n            iters += 1\n            grad = compute_gradient_centers(centers, r, weights, A_ub, b_ub)\n            row_norms = np.linalg.norm(grad, axis=1)\n            max_norm = float(np.max(row_norms)) if grad.size > 0 else 0.0\n            if not np.isfinite(max_norm) or max_norm <= 1e-18:\n                if time_left() < 0.05:\n                    break\n                # Joint LP step\n                new_centers, r_lin, okj = joint_lp_step(centers, delta=0.05)\n                if okj and new_centers is not None:\n                    r_new, weights, A_ub, b_ub, ok2 = solve_radii_lp_with_duals(new_centers, r_min)\n                    if ok2 and r_new is not None:\n                        centers = new_centers\n                        r = r_new\n                        try_update_best(centers, r)\n                        stagnation = 0\n                        continue\n                # Shake if LP step failed\n                idxs = rng.choice(n, size=max(1, n // 4), replace=False)\n                shake = np.zeros_like(centers)\n                shake[idxs] = rng.normal(0, 0.03, size=(len(idxs), 2))\n                centers_candidate = clamp_centers(centers + shake)\n                r_cand, w2, A2, b2, ok3 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                if ok3 and r_cand is not None and score_from_radii(r_cand) > score_from_radii(r) + 1e-10:\n                    centers, r = centers_candidate, r_cand\n                    weights, A_ub, b_ub = w2, A2, b2\n                    try_update_best(centers, r)\n                    stagnation = 0\n                else:\n                    stagnation += 1\n                if stagnation > 10:\n                    break\n                continue\n\n            g = grad / (max_norm + 1e-18)\n            base_score = score_from_radii(r)\n            success = False\n            step_eta = eta\n            for _ in range(10):\n                centers_candidate = clamp_centers(centers + step_eta * g)\n                r_cand, w2, A2, b2, ok2 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                if ok2 and r_cand is not None:\n                    sc = score_from_radii(r_cand)\n                    if sc > base_score + 1e-10:\n                        centers, r = centers_candidate, r_cand\n                        weights, A_ub, b_ub = w2, A2, b2\n                        eta = min(step_eta * 1.25, 0.5)\n                        success = True\n                        last_improve_iter = iters\n                        try_update_best(centers, r)\n                        break\n                step_eta *= 0.5\n                if time_left() < 0.05:\n                    break\n\n            if not success:\n                eta *= 0.6\n                stagnation += 1\n                if stagnation % 4 == 0 and time_left() > 0.05:\n                    delta = 0.08 if stagnation < 8 else 0.12\n                    new_centers, r_lin, okj = joint_lp_step(centers, delta)\n                    if okj and new_centers is not None:\n                        r_new, w2, A2, b2, ok2 = solve_radii_lp_with_duals(new_centers, r_min)\n                        if ok2 and r_new is not None and score_from_radii(r_new) >= base_score - 1e-9:\n                            centers, r = new_centers, r_new\n                            weights, A_ub, b_ub = w2, A2, b2\n                            try_update_best(centers, r)\n                            stagnation = 0\n                if stagnation % 3 == 0:\n                    idxs = rng.choice(n, size=max(1, n // 6), replace=False)\n                    shake = np.zeros_like(centers)\n                    shake[idxs] = rng.normal(0, 0.02 * (1 + 0.1 * stagnation), size=(len(idxs), 2))\n                    centers_candidate = clamp_centers(centers + shake)\n                    r_cand, w2, A2, b2, ok3 = solve_radii_lp_with_duals(centers_candidate, r_min)\n                    if ok3 and r_cand is not None and score_from_radii(r_cand) > base_score + 1e-10:\n                        centers, r = centers_candidate, r_cand\n                        weights, A_ub, b_ub = w2, A2, b2\n                        try_update_best(centers, r)\n                        stagnation = 0\n                if iters - last_improve_iter > 50 or stagnation > 20:\n                    break\n            else:\n                stagnation = max(stagnation - 1, 0)\n\n    # Run multi-start optimization\n    for init_centers in init_candidates:\n        if time_left() < 0.3:\n            break\n        gradient_optimize(init_centers)\n\n    # Final fallback\n    if best_circles is None or not np.all(np.isfinite(best_circles)):\n        centers = clamp_centers(rng.uniform(0.1, 0.9, size=(n, 2)))\n        r, _, _, _, ok = solve_radii_lp_with_duals(centers, r_min)\n        if not ok or r is None:\n            b = boundary_limits(centers)\n            r = np.maximum(np.minimum(b, 0.5), r_min)\n        best_circles = np.hstack([centers, r.reshape(-1, 1)])\n        best_score = score_from_radii(r)\n        all_scores.append(best_score)\n\n    # Ensure final feasibility via radii LP\n    try:\n        centers_final = best_circles[:, :2]\n        r_final, _, _, _, ok = solve_radii_lp_with_duals(centers_final, r_min)\n        if ok and r_final is not None:\n            best_circles = np.hstack([centers_final, r_final.reshape(-1, 1)])\n            best_score = score_from_radii(r_final)\n            if not all_scores or best_score > all_scores[-1] + 1e-12:\n                all_scores.append(best_score)\n    except Exception:\n        pass\n\n    return {\n        \"circles\": best_circles.astype(float),\n        \"all_scores\": [float(s) for s in all_scores] if all_scores else [float(best_score)],\n    }",
    "refiner_score": 2.635983181610043
}