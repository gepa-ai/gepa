{
    "best_score": 2.5590248213843623,
    "best_code": "import numpy as np\nimport time\n\ndef main(timeout, current_best_solution):\n    n = 26\n    start_time = time.time()\n    deadline = start_time + float(timeout)\n\n    rng = np.random.default_rng(12345 + int((start_time * 1e6) % 1e6))\n\n    # Helper: compute radii via LP (SciPy Highs); fallback to conservative shrink if SciPy unavailable\n    def compute_radii_lp(centers):\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return compute_radii_fallback(centers), False\n\n        N = centers.shape[0]\n        # Distances to borders\n        b = np.minimum.reduce(\n            [centers[:, 0], centers[:, 1], 1.0 - centers[:, 0], 1.0 - centers[:, 1]]\n        )\n        # Build constraints: r_i <= b_i and r_i + r_j <= d_ij\n        rows = []\n        rhs = []\n        # r_i <= b_i\n        for i in range(N):\n            row = np.zeros(N)\n            row[i] = 1.0\n            rows.append(row)\n            rhs.append(b[i])\n        # r_i + r_j <= d_ij\n        for i in range(N):\n            for j in range(i + 1, N):\n                dij = np.linalg.norm(centers[i] - centers[j])\n                # Avoid exact duplicates causing infeasibility by tiny epsilon slack\n                rows.append(_pair_row(N, i, j))\n                rhs.append(max(dij - 1e-9, 0.0))\n        A_ub = np.array(rows, dtype=float)\n        b_ub = np.array(rhs, dtype=float)\n\n        c = -np.ones(N, dtype=float)  # maximize sum r -> minimize -sum r\n        # Enforce strictly positive radii lower bound, but allow zero if geometry forces it\n        bounds = [(0.0, None)] * N\n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method=\"highs\")\n            if not res.success or res.x is None:\n                return compute_radii_fallback(centers), False\n            r = np.maximum(res.x, 1e-9)\n            # shrink slightly to ensure numerical safety\n            r *= 0.999\n            return r, True\n        except Exception:\n            return compute_radii_fallback(centers), False\n\n    def _pair_row(N, i, j):\n        row = np.zeros(N)\n        row[i] = 1.0\n        row[j] = 1.0\n        return row\n\n    # Fallback radii computation if LP solver unavailable: iterative projection (conservative)\n    def compute_radii_fallback(centers):\n        N = centers.shape[0]\n        r = np.minimum.reduce(\n            [centers[:, 0], centers[:, 1], 1.0 - centers[:, 0], 1.0 - centers[:, 1]]\n        )\n        r = np.maximum(r, 1e-4)\n        # Iteratively enforce pair constraints\n        for _ in range(12):\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dij = np.linalg.norm(centers[i] - centers[j])\n                    s = r[i] + r[j]\n                    if s > dij:\n                        if s <= 1e-12:\n                            continue\n                        scale = max(dij / s, 0.5)\n                        r[i] *= scale\n                        r[j] *= scale\n            r = np.minimum(\n                r,\n                np.minimum.reduce(\n                    [\n                        centers[:, 0],\n                        centers[:, 1],\n                        1.0 - centers[:, 0],\n                        1.0 - centers[:, 1],\n                    ]\n                ),\n            )\n            r = np.maximum(r, 1e-6)\n        r *= 0.999\n        return r\n\n    def score_radii(r):\n        return float(np.sum(r))\n\n    def ensure_valid_centers(centers, eps=1e-3):\n        centers = np.clip(centers, eps, 1.0 - eps)\n        # Tiny jitter to avoid identical centers\n        centers += (rng.random(centers.shape) - 0.5) * 1e-6\n        centers = np.clip(centers, eps, 1.0 - eps)\n        return centers\n\n    # Seeds\n    seeds = []\n    if current_best_solution is not None and current_best_solution.shape[0] == n:\n        # Warm start from existing solution; keep centers but slightly jitter to allow improvement\n        base_centers = current_best_solution[:, :2].copy()\n        base_centers += (rng.random(base_centers.shape) - 0.5) * 1e-3\n        base_centers = np.clip(base_centers, 1e-3, 1.0 - 1e-3)\n        seeds.append(base_centers)\n        seeds.append(ensure_valid_centers(base_centers + (rng.random(base_centers.shape) - 0.5) * 2e-3))\n\n    seeds.extend(generate_hex_seeds(n, rng))\n    seeds.extend(generate_random_seeds(n, rng))\n    seeds.extend(generate_edge_corner_seeds(n, rng))\n\n    # Deduplicate seeds\n    unique_seeds = []\n    seen = set()\n    for C in seeds:\n        key = tuple(np.round(C.flatten(), 3))\n        if key not in seen:\n            seen.add(key)\n            unique_seeds.append(C)\n\n    best_circles = None\n    best_score = -1.0\n    all_scores = []\n\n    # Slightly adjust per-seed budget: fewer seeds if timeout is small\n    max_seeds = len(unique_seeds)\n    if timeout < 1.5:\n        max_seeds = min(max_seeds, 4)\n    elif timeout < 3.0:\n        max_seeds = min(max_seeds, 8)\n\n    seed_idx = 0\n    while seed_idx < max_seeds and time.time() < deadline - 0.05:\n        time_left = max(0.0, deadline - time.time())\n        # Allocate dynamic time: ensure at least some time per seed\n        remaining_seeds = max_seeds - seed_idx\n        per_seed_min = 0.35\n        budget = min(time_left, max(per_seed_min, time_left / remaining_seeds))\n        centers0 = ensure_valid_centers(unique_seeds[seed_idx])\n        centers_opt, r_opt, s_opt = local_optimize(\n            centers0, budget, compute_radii_lp, rng, deadline\n        )\n        if s_opt > best_score:\n            best_score = s_opt\n            best_circles = np.hstack([centers_opt, r_opt.reshape(-1, 1)])\n        all_scores.append(best_score)\n        seed_idx += 1\n\n    if best_circles is None:\n        # Fallback trivial\n        centers = np.clip(rng.random((n, 2)) * 0.8 + 0.1, 1e-3, 1 - 1e-3)\n        r, _ = compute_radii_lp(centers)\n        best_circles = np.hstack([centers, r.reshape(-1, 1)])\n        best_score = score_radii(r)\n        all_scores.append(best_score)\n\n    return {\"circles\": best_circles, \"all_scores\": all_scores}\n\n\ndef local_optimize(centers, budget, radii_solver, rng, global_deadline):\n    start = time.time()\n    deadline = min(start + budget, global_deadline)\n\n    centers = centers.copy()\n    centers = np.clip(centers, 1e-3, 1.0 - 1e-3)\n\n    r, ok = radii_solver(centers)\n    if not ok:\n        # fall back to very small radii if solver fails\n        r = np.full(centers.shape[0], 1e-3)\n    best_centers = centers.copy()\n    best_r = r.copy()\n    best_s = float(np.sum(r))\n\n    # Pattern search with adaptive step and occasional stochastic shakes\n    step = 0.12\n    min_step = 0.0015\n    dir_count = 8\n    dirs = []\n    for k in range(dir_count):\n        ang = 2.0 * np.pi * k / dir_count\n        dirs.append(np.array([np.cos(ang), np.sin(ang)], dtype=float))\n    dirs = np.array(dirs)\n\n    while time.time() < deadline - 0.01 and step >= min_step:\n        improved = False\n        order = np.arange(centers.shape[0])\n        rng.shuffle(order)\n\n        for idx in order:\n            best_local = None\n            best_local_r = None\n            best_local_s = -1.0\n            rng.shuffle(dirs)\n            for d in dirs:\n                cand = centers.copy()\n                cand[idx] = cand[idx] + step * d\n                cand[idx] = np.clip(cand[idx], 1e-3, 1.0 - 1e-3)\n                r_cand, ok = radii_solver(cand)\n                if not ok:\n                    continue\n                s_cand = float(np.sum(r_cand))\n                if s_cand > best_local_s + 1e-9:\n                    best_local_s = s_cand\n                    best_local = cand\n                    best_local_r = r_cand\n                if time.time() > deadline - 0.005:\n                    break\n            if best_local is not None and best_local_s > best_s + 1e-9:\n                centers = best_local\n                r = best_local_r\n                best_s = best_local_s\n                best_centers = centers.copy()\n                best_r = r.copy()\n                improved = True\n            if time.time() > deadline - 0.005:\n                break\n\n        if not improved:\n            # Small random shake to escape local basin\n            step *= 0.7\n            shake_count = max(1, int(centers.shape[0] * 0.18))\n            indices = rng.choice(centers.shape[0], shake_count, replace=False)\n            shake = (rng.random((shake_count, 2)) - 0.5) * (2.0 * step)\n            cand = centers.copy()\n            cand[indices] = cand[indices] + shake\n            cand = np.clip(cand, 1e-3, 1.0 - 1e-3)\n            r_cand, ok = radii_solver(cand)\n            if ok:\n                s_cand = float(np.sum(r_cand))\n                # Accept even if slightly worse, but limit deterioration\n                if s_cand > best_s - 2e-4:\n                    centers = cand\n                    r = r_cand\n                    if s_cand > best_s:\n                        best_s = s_cand\n                        best_centers = centers.copy()\n                        best_r = r.copy()\n\n        # Occasional \"constraint-push\" step to increase distances along tight constraints\n        if time.time() < deadline - 0.005:\n            centers = constraint_push_step(centers, r, step * 0.5, rng)\n            centers = np.clip(centers, 1e-3, 1.0 - 1e-3)\n            r_new, ok = radii_solver(centers)\n            if ok:\n                s_new = float(np.sum(r_new))\n                if s_new >= best_s - 1e-8:\n                    r = r_new\n                    if s_new > best_s:\n                        best_s = s_new\n                        best_centers = centers.copy()\n                        best_r = r.copy()\n                else:\n                    centers = best_centers.copy()\n                    r = best_r.copy()\n\n    return best_centers, best_r, best_s\n\n\ndef constraint_push_step(centers, r, step, rng):\n    n = centers.shape[0]\n    disp = np.zeros_like(centers)\n\n    # Push from boundaries if tight\n    x = centers[:, 0]\n    y = centers[:, 1]\n    b = np.minimum.reduce([x, y, 1.0 - x, 1.0 - y])\n    tight = r >= b - 1e-6\n    if np.any(tight):\n        # For each tight center, push away from the closest wall\n        for i in np.where(tight)[0]:\n            dleft = x[i]\n            dright = 1.0 - x[i]\n            dbottom = y[i]\n            dtop = 1.0 - y[i]\n            m = min(dleft, dright, dbottom, dtop)\n            dx, dy = 0.0, 0.0\n            if abs(m - dleft) < 1e-9:\n                dx += step\n            if abs(m - dright) < 1e-9:\n                dx -= step\n            if abs(m - dbottom) < 1e-9:\n                dy += step\n            if abs(m - dtop) < 1e-9:\n                dy -= step\n            disp[i, 0] += dx\n            disp[i, 1] += dy\n\n    # Push apart pairs that are tight r_i + r_j ~ d_ij\n    for i in range(n):\n        for j in range(i + 1, n):\n            diff = centers[j] - centers[i]\n            dij = np.linalg.norm(diff)\n            if dij <= 1e-12:\n                # random tiny separation\n                v = (rng.random(2) - 0.5)\n                v /= max(np.linalg.norm(v), 1e-9)\n                disp[i] -= step * 0.5 * v\n                disp[j] += step * 0.5 * v\n                continue\n            if r[i] + r[j] > dij - 1e-6:\n                v = diff / dij\n                disp[i] -= v * (step * 0.5)\n                disp[j] += v * (step * 0.5)\n\n    # Normalize displacements to avoid too large steps\n    norms = np.linalg.norm(disp, axis=1)\n    mask = norms > 0\n    if np.any(mask):\n        scale = np.minimum(1.0, (step / (norms[mask] + 1e-12)))\n        disp[mask] = disp[mask] * scale[:, None]\n\n    new_centers = centers + disp\n    return new_centers\n\n\ndef generate_hex_seeds(n, rng):\n    seeds = []\n    # Estimate spacing for hex grid, slightly biased toward interior (smaller d)\n    d = np.sqrt(2.0 / (np.sqrt(3.0) * n)) * 0.96\n    dx = d\n    dy = np.sqrt(3.0) * d / 2.0\n    # Slightly reduce to fit comfortably\n    dx *= 0.95\n    dy *= 0.95\n    # Build grid\n    ys = []\n    y = dy * 0.7\n    while y < 1.0 - dy * 0.7:\n        ys.append(y)\n        y += dy\n    centers = []\n    for row, y in enumerate(ys):\n        offset = (0.0 if row % 2 == 0 else dx * 0.5)\n        x = dx * 0.7 + offset\n        row_pts = []\n        while x < 1.0 - dx * 0.7:\n            row_pts.append([x, y])\n            x += dx\n        centers.extend(row_pts)\n    centers = np.array(centers, dtype=float)\n    if centers.shape[0] < n:\n        # pad random if not enough\n        extra = rng.random((n - centers.shape[0], 2)) * 0.8 + 0.1\n        centers = np.vstack([centers, extra])\n    if centers.shape[0] > n:\n        # Select n via farthest point sampling for diversity\n        idxs = farthest_point_sampling(centers, n, rng)\n        centers = centers[idxs]\n    seeds.append(centers.copy())\n\n    # Additional jittered variants\n    for _ in range(2):\n        c = centers.copy()\n        c += (rng.random(c.shape) - 0.5) * (0.12 * d)\n        c = np.clip(c, 1e-3, 1.0 - 1e-3)\n        seeds.append(c)\n    return seeds\n\n\ndef generate_random_seeds(n, rng):\n    seeds = []\n    for _ in range(2):\n        centers = rng.random((n, 2)) * 0.9 + 0.05\n        seeds.append(centers)\n    return seeds\n\n\ndef generate_edge_corner_seeds(n, rng):\n    seeds = []\n    centers = []\n    # Corners\n    corners = np.array([[0.1, 0.1], [0.9, 0.1], [0.1, 0.9], [0.9, 0.9]])\n    centers.extend(corners.tolist())\n    # Edge midpoints and around\n    edge_points = []\n    for t in np.linspace(0.15, 0.85, 6):\n        edge_points.append([t, 0.08])\n        edge_points.append([t, 0.92])\n        edge_points.append([0.08, t])\n        edge_points.append([0.92, t])\n    rng.shuffle(edge_points)\n    centers.extend(edge_points[: max(0, n - len(centers))])\n    centers = np.array(centers, dtype=float)\n    if centers.shape[0] > n:\n        centers = centers[:n]\n    elif centers.shape[0] < n:\n        extra = rng.random((n - centers.shape[0], 2)) * 0.8 + 0.1\n        centers = np.vstack([centers, extra])\n    seeds.append(centers)\n    return seeds\n\n\ndef farthest_point_sampling(points, k, rng):\n    n = points.shape[0]\n    if k >= n:\n        return np.arange(n)\n    idxs = []\n    # start from random point\n    idx = int(rng.integers(0, n))\n    idxs.append(idx)\n    d2 = np.full(n, np.inf)\n    for _ in range(1, k):\n        p = points[idxs[-1]]\n        diff = points - p\n        dist2 = np.einsum(\"ij,ij->i\", diff, diff)\n        d2 = np.minimum(d2, dist2)\n        idx = int(np.argmax(d2))\n        if idx in idxs:\n            # fallback random\n            idx = int(rng.integers(0, n))\n        idxs.append(idx)\n    return np.array(idxs, dtype=int)",
    "best_circles": [
        [
            0.47831077040939113,
            0.4810436848044645,
            0.1415216673636689
        ],
        [
            0.7577634748690858,
            0.4294323223294112,
            0.06679760420090525
        ],
        [
            0.7068283376624972,
            0.6062680273153025,
            0.1170435167392456
        ],
        [
            0.5253621604344397,
            0.7091286926936252,
            0.0911329794641856
        ],
        [
            0.3070101732214162,
            0.6924818275611201,
            0.127412221738394
        ],
        [
            0.24380059865454792,
            0.49820092042495306,
            0.07648246289429947
        ],
        [
            0.2906376429876129,
            0.3266059227870464,
            0.10121195490169305
        ],
        [
            0.4581551841211931,
            0.26248450894805586,
            0.07774543008576515
        ],
        [
            0.6448059583648399,
            0.29100424700884747,
            0.11088282465314477
        ],
        [
            0.9017684186315095,
            0.5104319216530241,
            0.09813334978712204
        ],
        [
            0.8957147575740285,
            0.722872015835538,
            0.1041809571835455
        ],
        [
            0.914106843324852,
            0.9123424938548627,
            0.08580726351847281
        ],
        [
            0.6968442291052098,
            0.8612885359939751,
            0.13702207617032633
        ],
        [
            0.4560667480730821,
            0.8935298764188465,
            0.10566152717810241
        ],
        [
            0.2579417727199167,
            0.9070175838866907,
            0.09244336738011685
        ],
        [
            0.06236916995121055,
            0.9469142218673026,
            0.05303269235456474
        ],
        [
            0.09981970641392712,
            0.7988933732876548,
            0.09892037583182856
        ],
        [
            0.09954287519266071,
            0.6003804654878557,
            0.09935272493122044
        ],
        [
            0.0974660795873624,
            0.40369729388268155,
            0.09714471577092319
        ],
        [
            0.12354399045533233,
            0.20124043467613806,
            0.1067806158136065
        ],
        [
            0.054842670102196726,
            0.05423089916138725,
            0.05417666826222586
        ],
        [
            0.32654658810421616,
            0.11439987052930774,
            0.1137956382748474
        ],
        [
            0.5421866732715622,
            0.10260682472774658,
            0.10195071516918769
        ],
        [
            0.7464615174579043,
            0.10272246061608645,
            0.10211988587081335
        ],
        [
            0.9233698903082491,
            0.07660392465527571,
            0.07652732073062044
        ],
        [
            0.8781338687532169,
            0.2840699888367601,
            0.12174426511553635
        ]
    ],
    "code_candidate": "import numpy as np\nimport time\n\ndef main(timeout, current_best_solution):\n    n = 26\n    start_time = time.time()\n    deadline = start_time + float(timeout)\n\n    rng = np.random.default_rng(12345 + int((start_time * 1e6) % 1e6))\n\n    # Helper: compute radii via LP (SciPy Highs); fallback to conservative shrink if SciPy unavailable\n    def compute_radii_lp(centers):\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return compute_radii_fallback(centers), False\n\n        N = centers.shape[0]\n        # Distances to borders\n        b = np.minimum.reduce([centers[:,0], centers[:,1], 1.0 - centers[:,0], 1.0 - centers[:,1]])\n        # Build constraints: r_i <= b_i and r_i + r_j <= d_ij\n        # A_ub x <= b_ub\n        rows = []\n        rhs = []\n        # r_i <= b_i\n        for i in range(N):\n            row = np.zeros(N)\n            row[i] = 1.0\n            rows.append(row)\n            rhs.append(b[i])\n        # r_i + r_j <= d_ij\n        for i in range(N):\n            for j in range(i+1, N):\n                dij = np.linalg.norm(centers[i] - centers[j])\n                # Avoid exact duplicates causing infeasibility by tiny epsilon slack\n                rows.append(_pair_row(N, i, j))\n                rhs.append(max(dij - 1e-9, 0.0))\n        A_ub = np.array(rows, dtype=float)\n        b_ub = np.array(rhs, dtype=float)\n\n        c = -np.ones(N, dtype=float)  # maximize sum r -> minimize -sum r\n        # Enforce strictly positive radii lower bound, very small to avoid infeasibility near touching pairs\n        bounds = [(1e-9, None)] * N\n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n            if not res.success or res.x is None:\n                return compute_radii_fallback(centers), False\n            r = np.maximum(res.x, 1e-9)\n            # shrink slightly to ensure numerical safety\n            r *= 0.999\n            return r, True\n        except Exception:\n            return compute_radii_fallback(centers), False\n\n    def _pair_row(N, i, j):\n        row = np.zeros(N)\n        row[i] = 1.0\n        row[j] = 1.0\n        return row\n\n    # Fallback radii computation if LP solver unavailable: iterative projection (conservative)\n    def compute_radii_fallback(centers):\n        N = centers.shape[0]\n        r = np.minimum.reduce([centers[:,0], centers[:,1], 1.0 - centers[:,0], 1.0 - centers[:,1]])\n        r = np.maximum(r, 1e-4)\n        # Iteratively enforce pair constraints\n        for _ in range(10):\n            for i in range(N):\n                for j in range(i+1, N):\n                    dij = np.linalg.norm(centers[i] - centers[j])\n                    s = r[i] + r[j]\n                    if s > dij:\n                        if s <= 1e-12:\n                            continue\n                        scale = max(dij / s, 0.5)\n                        r[i] *= scale\n                        r[j] *= scale\n            r = np.minimum(r, np.minimum.reduce([centers[:,0], centers[:,1], 1.0 - centers[:,0], 1.0 - centers[:,1]]))\n            r = np.maximum(r, 1e-6)\n        r *= 0.999\n        return r\n\n    def score_radii(r):\n        return float(np.sum(r))\n\n    def ensure_valid_centers(centers, eps=1e-3):\n        centers = np.clip(centers, eps, 1.0 - eps)\n        # Tiny jitter to avoid identical centers\n        centers += (rng.random(centers.shape) - 0.5) * 1e-6\n        centers = np.clip(centers, eps, 1.0 - eps)\n        return centers\n\n    # Seeds\n    seeds = []\n    if current_best_solution is not None and current_best_solution.shape[0] == n:\n        seeds.append(current_best_solution[:, :2].copy())\n\n    seeds.extend(generate_hex_seeds(n, rng))\n    seeds.extend(generate_random_seeds(n, rng))\n    seeds.extend(generate_edge_corner_seeds(n, rng))\n\n    # Deduplicate seeds\n    unique_seeds = []\n    seen = set()\n    for C in seeds:\n        key = tuple(np.round(C.flatten(), 3))\n        if key not in seen:\n            seen.add(key)\n            unique_seeds.append(C)\n\n    best_circles = None\n    best_score = -1.0\n    all_scores = []\n\n    # Optimization per seed\n    seed_idx = 0\n    while seed_idx < len(unique_seeds) and time.time() < deadline - 0.05:\n        time_left = max(0.0, deadline - time.time())\n        # Allocate dynamic time: give more to promising seeds, but ensure at least some time\n        budget = min(time_left, max(0.5, timeout / (len(unique_seeds) * 1.2)))\n        centers0 = ensure_valid_centers(unique_seeds[seed_idx])\n        centers_opt, r_opt, s_opt = local_optimize(centers0, budget, compute_radii_lp, rng, deadline)\n        if s_opt > best_score:\n            best_score = s_opt\n            best_circles = np.hstack([centers_opt, r_opt.reshape(-1,1)])\n            all_scores.append(best_score)\n        seed_idx += 1\n\n    if best_circles is None:\n        # Fallback trivial\n        centers = np.clip(rng.random((n,2))*0.8 + 0.1, 1e-3, 1-1e-3)\n        r, _ = compute_radii_lp(centers)\n        best_circles = np.hstack([centers, r.reshape(-1,1)])\n        best_score = score_radii(r)\n        all_scores.append(best_score)\n\n    return {'circles': best_circles, 'all_scores': all_scores}\n\n\ndef local_optimize(centers, budget, radii_solver, rng, global_deadline):\n    start = time.time()\n    deadline = min(start + budget, global_deadline)\n\n    centers = centers.copy()\n    centers = np.clip(centers, 1e-3, 1.0 - 1e-3)\n\n    r, ok = radii_solver(centers)\n    best_centers = centers.copy()\n    best_r = r.copy()\n    best_s = float(np.sum(r))\n\n    # Pattern search with adaptive step and occasional stochastic shakes\n    step = 0.15\n    min_step = 0.002\n    dir_count = 8\n    dirs = []\n    for k in range(dir_count):\n        ang = 2.0 * np.pi * k / dir_count\n        dirs.append(np.array([np.cos(ang), np.sin(ang)], dtype=float))\n    dirs = np.array(dirs)\n\n    no_improve_iters = 0\n    while time.time() < deadline - 0.01 and step >= min_step:\n        improved = False\n        order = np.arange(centers.shape[0])\n        rng.shuffle(order)\n\n        for idx in order:\n            # Try greedy improvement for this center along multiple directions\n            best_local = None\n            best_local_r = None\n            best_local_s = -1.0\n            rng.shuffle(dirs)\n            for d in dirs:\n                cand = centers.copy()\n                cand[idx] = cand[idx] + step * d\n                cand[idx] = np.clip(cand[idx], 1e-3, 1.0 - 1e-3)\n                r_cand, ok = radii_solver(cand)\n                if not ok:\n                    continue\n                s_cand = float(np.sum(r_cand))\n                if s_cand > best_local_s + 1e-9:\n                    best_local_s = s_cand\n                    best_local = cand\n                    best_local_r = r_cand\n                if time.time() > deadline - 0.005:\n                    break\n            if best_local is not None and best_local_s > best_s + 1e-9:\n                centers = best_local\n                r = best_local_r\n                best_s = best_local_s\n                best_centers = centers.copy()\n                best_r = r.copy()\n                improved = True\n            if time.time() > deadline - 0.005:\n                break\n\n        if not improved:\n            # Small random shake to escape local basin\n            no_improve_iters += 1\n            step *= 0.72\n            shake_count = max(1, int(centers.shape[0] * 0.15))\n            indices = rng.choice(centers.shape[0], shake_count, replace=False)\n            shake = (rng.random((shake_count, 2)) - 0.5) * (2.0 * step)\n            cand = centers.copy()\n            cand[indices] = cand[indices] + shake\n            cand = np.clip(cand, 1e-3, 1.0 - 1e-3)\n            r_cand, ok = radii_solver(cand)\n            if ok:\n                s_cand = float(np.sum(r_cand))\n                # Accept even if slightly worse to promote exploration\n                if s_cand > best_s - 1e-4:\n                    centers = cand\n                    r = r_cand\n                    if s_cand > best_s:\n                        best_s = s_cand\n                        best_centers = centers.copy()\n                        best_r = r.copy()\n                        no_improve_iters = 0\n        else:\n            no_improve_iters = 0\n\n        # Occasional \"constraint-push\" step to increase distances along tight constraints\n        if time.time() < deadline - 0.005:\n            centers = constraint_push_step(centers, r, step * 0.5, rng)\n            centers = np.clip(centers, 1e-3, 1.0 - 1e-3)\n            r_new, ok = radii_solver(centers)\n            if ok:\n                s_new = float(np.sum(r_new))\n                if s_new >= best_s - 1e-8:\n                    r = r_new\n                    if s_new > best_s:\n                        best_s = s_new\n                        best_centers = centers.copy()\n                        best_r = r.copy()\n                else:\n                    # revert if harmful\n                    centers = best_centers.copy()\n                    r = best_r.copy()\n\n    return best_centers, best_r, best_s\n\n\ndef constraint_push_step(centers, r, step, rng):\n    n = centers.shape[0]\n    disp = np.zeros_like(centers)\n\n    # Push from boundaries if tight\n    x = centers[:,0]; y = centers[:,1]\n    b = np.minimum.reduce([x, y, 1.0 - x, 1.0 - y])\n    tight = r >= b - 1e-6\n    if np.any(tight):\n        # For each tight center, push away from the closest wall\n        for i in np.where(tight)[0]:\n            # Compute gradient approximate from wall\n            dleft = x[i]\n            dright = 1.0 - x[i]\n            dbottom = y[i]\n            dtop = 1.0 - y[i]\n            m = min(dleft, dright, dbottom, dtop)\n            dx, dy = 0.0, 0.0\n            if abs(m - dleft) < 1e-9: dx += step\n            if abs(m - dright) < 1e-9: dx -= step\n            if abs(m - dbottom) < 1e-9: dy += step\n            if abs(m - dtop) < 1e-9: dy -= step\n            disp[i,0] += dx\n            disp[i,1] += dy\n\n    # Push apart pairs that are tight r_i + r_j ~ d_ij\n    for i in range(n):\n        for j in range(i+1, n):\n            diff = centers[j] - centers[i]\n            dij = np.linalg.norm(diff)\n            if dij <= 1e-12:\n                # random tiny separation\n                v = (rng.random(2) - 0.5)\n                v /= max(np.linalg.norm(v), 1e-9)\n                disp[i] -= step * 0.5 * v\n                disp[j] += step * 0.5 * v\n                continue\n            if r[i] + r[j] > dij - 1e-6:\n                v = diff / dij\n                disp[i] -= v * (step * 0.5)\n                disp[j] += v * (step * 0.5)\n\n    # Normalize displacements to avoid too large steps\n    norms = np.linalg.norm(disp, axis=1)\n    mask = norms > 0\n    if np.any(mask):\n        scale = np.minimum(1.0, (step / (norms[mask] + 1e-12)))\n        disp[mask] = disp[mask] * scale[:,None]\n\n    new_centers = centers + disp\n    return new_centers\n\n\ndef generate_hex_seeds(n, rng):\n    seeds = []\n    # Estimate spacing for hex grid\n    d = np.sqrt(2.0 / (np.sqrt(3.0) * n))\n    dx = d\n    dy = np.sqrt(3.0) * d / 2.0\n    # Slightly reduce to fit comfortably\n    dx *= 0.95\n    dy *= 0.95\n    # Build grid\n    ys = []\n    y = dy * 0.6\n    while y < 1.0 - dy * 0.6:\n        ys.append(y)\n        y += dy\n    centers = []\n    for row, y in enumerate(ys):\n        offset = (0.0 if row % 2 == 0 else dx * 0.5)\n        x = dx * 0.6 + offset\n        row_pts = []\n        while x < 1.0 - dx * 0.6:\n            row_pts.append([x, y])\n            x += dx\n        centers.extend(row_pts)\n    centers = np.array(centers, dtype=float)\n    if centers.shape[0] < n:\n        # pad random if not enough\n        extra = rng.random((n - centers.shape[0], 2)) * 0.8 + 0.1\n        centers = np.vstack([centers, extra])\n    if centers.shape[0] > n:\n        # Select n via farthest point sampling for diversity\n        idxs = farthest_point_sampling(centers, n, rng)\n        centers = centers[idxs]\n    seeds.append(centers.copy())\n\n    # Additional jittered variants\n    for _ in range(2):\n        c = centers.copy()\n        c += (rng.random(c.shape) - 0.5) * (0.15 * d)\n        c = np.clip(c, 1e-3, 1.0 - 1e-3)\n        seeds.append(c)\n    return seeds\n\n\ndef generate_random_seeds(n, rng):\n    seeds = []\n    for _ in range(2):\n        centers = rng.random((n,2)) * 0.9 + 0.05\n        seeds.append(centers)\n    return seeds\n\n\ndef generate_edge_corner_seeds(n, rng):\n    seeds = []\n    centers = []\n    # Corners\n    corners = np.array([[0.1,0.1],[0.9,0.1],[0.1,0.9],[0.9,0.9]])\n    centers.extend(corners.tolist())\n    # Edge midpoints and around\n    edge_points = []\n    for t in np.linspace(0.15, 0.85, 6):\n        edge_points.append([t, 0.08])\n        edge_points.append([t, 0.92])\n        edge_points.append([0.08, t])\n        edge_points.append([0.92, t])\n    rng.shuffle(edge_points)\n    centers.extend(edge_points[:max(0, n - len(centers))])\n    centers = np.array(centers, dtype=float)\n    if centers.shape[0] > n:\n        centers = centers[:n]\n    elif centers.shape[0] < n:\n        extra = rng.random((n - centers.shape[0], 2)) * 0.8 + 0.1\n        centers = np.vstack([centers, extra])\n    seeds.append(centers)\n    return seeds\n\n\ndef farthest_point_sampling(points, k, rng):\n    n = points.shape[0]\n    if k >= n:\n        return np.arange(n)\n    idxs = []\n    # start from random point\n    idx = int(rng.integers(0, n))\n    idxs.append(idx)\n    d2 = np.full(n, np.inf)\n    for _ in range(1, k):\n        p = points[idxs[-1]]\n        diff = points - p\n        dist2 = np.einsum('ij,ij->i', diff, diff)\n        d2 = np.minimum(d2, dist2)\n        idx = int(np.argmax(d2))\n        if idx in idxs:\n            # fallback random\n            idx = int(rng.integers(0, n))\n        idxs.append(idx)\n    return np.array(idxs, dtype=int)",
    "code_score": 2.5536969410244823,
    "refiner_prompt": "You are an expert mathematician and computational geometry specialist.\n\nYOUR TASK: Given the current code and its execution results (provided in `code_results`), generate improved code that fixes errors and increases the score.\n\nDOMAIN KNOWLEDGE FOR CIRCLE PACKING:\n1. **Optimization strategies**: Multiple restarts, better initialization, adaptive step sizes, hybrid local+global search\n2. **Geometric improvements**: Better initial layouts, exploit symmetry, special corner/edge placement strategies\n3. **Circle size tuning**: Variable vs uniform radii, size gradients (larger center vs edges or vice versa)\n4. **Algorithm switching**: If physics-based fails, try optimization-based. If greedy fails, try force simulation\n5. **Constraint handling**: Penalty methods, projection methods, constrained optimization (scipy.optimize.minimize with bounds)\n6. **Hyperparameter tuning**: Use optuna/hyperopt for algorithmic parameters (force constants, step sizes, iterations)\n\nCRITICAL CONSTRAINTS (must be preserved):\n- Function MUST be `def main(timeout, current_best_solution):`\n- All circles fully inside [0,1]\u00d7[0,1]: 0 \u2264 x-r, x+r \u2264 1 and 0 \u2264 y-r, y+r \u2264 1\n- No overlaps: distance between centers \u2265 sum of radii\n- All radii positive, return exactly N circles with shape (N, 3)\n- Return a dict with 'circles' and 'all_scores' keys.\n\nREFINER SHOULD:\n- Build on what worked in the initial code (don't throw away good ideas)\n- Carefully analyze `code_results` (stdout, stderr, errors) to identify why the previous attempt failed or scored poorly.\n- Use `current_best_solution` (passed as argument) to warm-start if it helps.\n- Make targeted improvements rather than complete rewrites (unless necessary)\n- Return the whole refined code in executable format.\n",
    "refiner_code": "import numpy as np\nimport time\n\ndef main(timeout, current_best_solution):\n    n = 26\n    start_time = time.time()\n    deadline = start_time + float(timeout)\n\n    rng = np.random.default_rng(12345 + int((start_time * 1e6) % 1e6))\n\n    # Helper: compute radii via LP (SciPy Highs); fallback to conservative shrink if SciPy unavailable\n    def compute_radii_lp(centers):\n        try:\n            from scipy.optimize import linprog\n        except Exception:\n            return compute_radii_fallback(centers), False\n\n        N = centers.shape[0]\n        # Distances to borders\n        b = np.minimum.reduce(\n            [centers[:, 0], centers[:, 1], 1.0 - centers[:, 0], 1.0 - centers[:, 1]]\n        )\n        # Build constraints: r_i <= b_i and r_i + r_j <= d_ij\n        rows = []\n        rhs = []\n        # r_i <= b_i\n        for i in range(N):\n            row = np.zeros(N)\n            row[i] = 1.0\n            rows.append(row)\n            rhs.append(b[i])\n        # r_i + r_j <= d_ij\n        for i in range(N):\n            for j in range(i + 1, N):\n                dij = np.linalg.norm(centers[i] - centers[j])\n                # Avoid exact duplicates causing infeasibility by tiny epsilon slack\n                rows.append(_pair_row(N, i, j))\n                rhs.append(max(dij - 1e-9, 0.0))\n        A_ub = np.array(rows, dtype=float)\n        b_ub = np.array(rhs, dtype=float)\n\n        c = -np.ones(N, dtype=float)  # maximize sum r -> minimize -sum r\n        # Enforce strictly positive radii lower bound, but allow zero if geometry forces it\n        bounds = [(0.0, None)] * N\n        try:\n            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method=\"highs\")\n            if not res.success or res.x is None:\n                return compute_radii_fallback(centers), False\n            r = np.maximum(res.x, 1e-9)\n            # shrink slightly to ensure numerical safety\n            r *= 0.999\n            return r, True\n        except Exception:\n            return compute_radii_fallback(centers), False\n\n    def _pair_row(N, i, j):\n        row = np.zeros(N)\n        row[i] = 1.0\n        row[j] = 1.0\n        return row\n\n    # Fallback radii computation if LP solver unavailable: iterative projection (conservative)\n    def compute_radii_fallback(centers):\n        N = centers.shape[0]\n        r = np.minimum.reduce(\n            [centers[:, 0], centers[:, 1], 1.0 - centers[:, 0], 1.0 - centers[:, 1]]\n        )\n        r = np.maximum(r, 1e-4)\n        # Iteratively enforce pair constraints\n        for _ in range(12):\n            for i in range(N):\n                for j in range(i + 1, N):\n                    dij = np.linalg.norm(centers[i] - centers[j])\n                    s = r[i] + r[j]\n                    if s > dij:\n                        if s <= 1e-12:\n                            continue\n                        scale = max(dij / s, 0.5)\n                        r[i] *= scale\n                        r[j] *= scale\n            r = np.minimum(\n                r,\n                np.minimum.reduce(\n                    [\n                        centers[:, 0],\n                        centers[:, 1],\n                        1.0 - centers[:, 0],\n                        1.0 - centers[:, 1],\n                    ]\n                ),\n            )\n            r = np.maximum(r, 1e-6)\n        r *= 0.999\n        return r\n\n    def score_radii(r):\n        return float(np.sum(r))\n\n    def ensure_valid_centers(centers, eps=1e-3):\n        centers = np.clip(centers, eps, 1.0 - eps)\n        # Tiny jitter to avoid identical centers\n        centers += (rng.random(centers.shape) - 0.5) * 1e-6\n        centers = np.clip(centers, eps, 1.0 - eps)\n        return centers\n\n    # Seeds\n    seeds = []\n    if current_best_solution is not None and current_best_solution.shape[0] == n:\n        # Warm start from existing solution; keep centers but slightly jitter to allow improvement\n        base_centers = current_best_solution[:, :2].copy()\n        base_centers += (rng.random(base_centers.shape) - 0.5) * 1e-3\n        base_centers = np.clip(base_centers, 1e-3, 1.0 - 1e-3)\n        seeds.append(base_centers)\n        seeds.append(ensure_valid_centers(base_centers + (rng.random(base_centers.shape) - 0.5) * 2e-3))\n\n    seeds.extend(generate_hex_seeds(n, rng))\n    seeds.extend(generate_random_seeds(n, rng))\n    seeds.extend(generate_edge_corner_seeds(n, rng))\n\n    # Deduplicate seeds\n    unique_seeds = []\n    seen = set()\n    for C in seeds:\n        key = tuple(np.round(C.flatten(), 3))\n        if key not in seen:\n            seen.add(key)\n            unique_seeds.append(C)\n\n    best_circles = None\n    best_score = -1.0\n    all_scores = []\n\n    # Slightly adjust per-seed budget: fewer seeds if timeout is small\n    max_seeds = len(unique_seeds)\n    if timeout < 1.5:\n        max_seeds = min(max_seeds, 4)\n    elif timeout < 3.0:\n        max_seeds = min(max_seeds, 8)\n\n    seed_idx = 0\n    while seed_idx < max_seeds and time.time() < deadline - 0.05:\n        time_left = max(0.0, deadline - time.time())\n        # Allocate dynamic time: ensure at least some time per seed\n        remaining_seeds = max_seeds - seed_idx\n        per_seed_min = 0.35\n        budget = min(time_left, max(per_seed_min, time_left / remaining_seeds))\n        centers0 = ensure_valid_centers(unique_seeds[seed_idx])\n        centers_opt, r_opt, s_opt = local_optimize(\n            centers0, budget, compute_radii_lp, rng, deadline\n        )\n        if s_opt > best_score:\n            best_score = s_opt\n            best_circles = np.hstack([centers_opt, r_opt.reshape(-1, 1)])\n        all_scores.append(best_score)\n        seed_idx += 1\n\n    if best_circles is None:\n        # Fallback trivial\n        centers = np.clip(rng.random((n, 2)) * 0.8 + 0.1, 1e-3, 1 - 1e-3)\n        r, _ = compute_radii_lp(centers)\n        best_circles = np.hstack([centers, r.reshape(-1, 1)])\n        best_score = score_radii(r)\n        all_scores.append(best_score)\n\n    return {\"circles\": best_circles, \"all_scores\": all_scores}\n\n\ndef local_optimize(centers, budget, radii_solver, rng, global_deadline):\n    start = time.time()\n    deadline = min(start + budget, global_deadline)\n\n    centers = centers.copy()\n    centers = np.clip(centers, 1e-3, 1.0 - 1e-3)\n\n    r, ok = radii_solver(centers)\n    if not ok:\n        # fall back to very small radii if solver fails\n        r = np.full(centers.shape[0], 1e-3)\n    best_centers = centers.copy()\n    best_r = r.copy()\n    best_s = float(np.sum(r))\n\n    # Pattern search with adaptive step and occasional stochastic shakes\n    step = 0.12\n    min_step = 0.0015\n    dir_count = 8\n    dirs = []\n    for k in range(dir_count):\n        ang = 2.0 * np.pi * k / dir_count\n        dirs.append(np.array([np.cos(ang), np.sin(ang)], dtype=float))\n    dirs = np.array(dirs)\n\n    while time.time() < deadline - 0.01 and step >= min_step:\n        improved = False\n        order = np.arange(centers.shape[0])\n        rng.shuffle(order)\n\n        for idx in order:\n            best_local = None\n            best_local_r = None\n            best_local_s = -1.0\n            rng.shuffle(dirs)\n            for d in dirs:\n                cand = centers.copy()\n                cand[idx] = cand[idx] + step * d\n                cand[idx] = np.clip(cand[idx], 1e-3, 1.0 - 1e-3)\n                r_cand, ok = radii_solver(cand)\n                if not ok:\n                    continue\n                s_cand = float(np.sum(r_cand))\n                if s_cand > best_local_s + 1e-9:\n                    best_local_s = s_cand\n                    best_local = cand\n                    best_local_r = r_cand\n                if time.time() > deadline - 0.005:\n                    break\n            if best_local is not None and best_local_s > best_s + 1e-9:\n                centers = best_local\n                r = best_local_r\n                best_s = best_local_s\n                best_centers = centers.copy()\n                best_r = r.copy()\n                improved = True\n            if time.time() > deadline - 0.005:\n                break\n\n        if not improved:\n            # Small random shake to escape local basin\n            step *= 0.7\n            shake_count = max(1, int(centers.shape[0] * 0.18))\n            indices = rng.choice(centers.shape[0], shake_count, replace=False)\n            shake = (rng.random((shake_count, 2)) - 0.5) * (2.0 * step)\n            cand = centers.copy()\n            cand[indices] = cand[indices] + shake\n            cand = np.clip(cand, 1e-3, 1.0 - 1e-3)\n            r_cand, ok = radii_solver(cand)\n            if ok:\n                s_cand = float(np.sum(r_cand))\n                # Accept even if slightly worse, but limit deterioration\n                if s_cand > best_s - 2e-4:\n                    centers = cand\n                    r = r_cand\n                    if s_cand > best_s:\n                        best_s = s_cand\n                        best_centers = centers.copy()\n                        best_r = r.copy()\n\n        # Occasional \"constraint-push\" step to increase distances along tight constraints\n        if time.time() < deadline - 0.005:\n            centers = constraint_push_step(centers, r, step * 0.5, rng)\n            centers = np.clip(centers, 1e-3, 1.0 - 1e-3)\n            r_new, ok = radii_solver(centers)\n            if ok:\n                s_new = float(np.sum(r_new))\n                if s_new >= best_s - 1e-8:\n                    r = r_new\n                    if s_new > best_s:\n                        best_s = s_new\n                        best_centers = centers.copy()\n                        best_r = r.copy()\n                else:\n                    centers = best_centers.copy()\n                    r = best_r.copy()\n\n    return best_centers, best_r, best_s\n\n\ndef constraint_push_step(centers, r, step, rng):\n    n = centers.shape[0]\n    disp = np.zeros_like(centers)\n\n    # Push from boundaries if tight\n    x = centers[:, 0]\n    y = centers[:, 1]\n    b = np.minimum.reduce([x, y, 1.0 - x, 1.0 - y])\n    tight = r >= b - 1e-6\n    if np.any(tight):\n        # For each tight center, push away from the closest wall\n        for i in np.where(tight)[0]:\n            dleft = x[i]\n            dright = 1.0 - x[i]\n            dbottom = y[i]\n            dtop = 1.0 - y[i]\n            m = min(dleft, dright, dbottom, dtop)\n            dx, dy = 0.0, 0.0\n            if abs(m - dleft) < 1e-9:\n                dx += step\n            if abs(m - dright) < 1e-9:\n                dx -= step\n            if abs(m - dbottom) < 1e-9:\n                dy += step\n            if abs(m - dtop) < 1e-9:\n                dy -= step\n            disp[i, 0] += dx\n            disp[i, 1] += dy\n\n    # Push apart pairs that are tight r_i + r_j ~ d_ij\n    for i in range(n):\n        for j in range(i + 1, n):\n            diff = centers[j] - centers[i]\n            dij = np.linalg.norm(diff)\n            if dij <= 1e-12:\n                # random tiny separation\n                v = (rng.random(2) - 0.5)\n                v /= max(np.linalg.norm(v), 1e-9)\n                disp[i] -= step * 0.5 * v\n                disp[j] += step * 0.5 * v\n                continue\n            if r[i] + r[j] > dij - 1e-6:\n                v = diff / dij\n                disp[i] -= v * (step * 0.5)\n                disp[j] += v * (step * 0.5)\n\n    # Normalize displacements to avoid too large steps\n    norms = np.linalg.norm(disp, axis=1)\n    mask = norms > 0\n    if np.any(mask):\n        scale = np.minimum(1.0, (step / (norms[mask] + 1e-12)))\n        disp[mask] = disp[mask] * scale[:, None]\n\n    new_centers = centers + disp\n    return new_centers\n\n\ndef generate_hex_seeds(n, rng):\n    seeds = []\n    # Estimate spacing for hex grid, slightly biased toward interior (smaller d)\n    d = np.sqrt(2.0 / (np.sqrt(3.0) * n)) * 0.96\n    dx = d\n    dy = np.sqrt(3.0) * d / 2.0\n    # Slightly reduce to fit comfortably\n    dx *= 0.95\n    dy *= 0.95\n    # Build grid\n    ys = []\n    y = dy * 0.7\n    while y < 1.0 - dy * 0.7:\n        ys.append(y)\n        y += dy\n    centers = []\n    for row, y in enumerate(ys):\n        offset = (0.0 if row % 2 == 0 else dx * 0.5)\n        x = dx * 0.7 + offset\n        row_pts = []\n        while x < 1.0 - dx * 0.7:\n            row_pts.append([x, y])\n            x += dx\n        centers.extend(row_pts)\n    centers = np.array(centers, dtype=float)\n    if centers.shape[0] < n:\n        # pad random if not enough\n        extra = rng.random((n - centers.shape[0], 2)) * 0.8 + 0.1\n        centers = np.vstack([centers, extra])\n    if centers.shape[0] > n:\n        # Select n via farthest point sampling for diversity\n        idxs = farthest_point_sampling(centers, n, rng)\n        centers = centers[idxs]\n    seeds.append(centers.copy())\n\n    # Additional jittered variants\n    for _ in range(2):\n        c = centers.copy()\n        c += (rng.random(c.shape) - 0.5) * (0.12 * d)\n        c = np.clip(c, 1e-3, 1.0 - 1e-3)\n        seeds.append(c)\n    return seeds\n\n\ndef generate_random_seeds(n, rng):\n    seeds = []\n    for _ in range(2):\n        centers = rng.random((n, 2)) * 0.9 + 0.05\n        seeds.append(centers)\n    return seeds\n\n\ndef generate_edge_corner_seeds(n, rng):\n    seeds = []\n    centers = []\n    # Corners\n    corners = np.array([[0.1, 0.1], [0.9, 0.1], [0.1, 0.9], [0.9, 0.9]])\n    centers.extend(corners.tolist())\n    # Edge midpoints and around\n    edge_points = []\n    for t in np.linspace(0.15, 0.85, 6):\n        edge_points.append([t, 0.08])\n        edge_points.append([t, 0.92])\n        edge_points.append([0.08, t])\n        edge_points.append([0.92, t])\n    rng.shuffle(edge_points)\n    centers.extend(edge_points[: max(0, n - len(centers))])\n    centers = np.array(centers, dtype=float)\n    if centers.shape[0] > n:\n        centers = centers[:n]\n    elif centers.shape[0] < n:\n        extra = rng.random((n - centers.shape[0], 2)) * 0.8 + 0.1\n        centers = np.vstack([centers, extra])\n    seeds.append(centers)\n    return seeds\n\n\ndef farthest_point_sampling(points, k, rng):\n    n = points.shape[0]\n    if k >= n:\n        return np.arange(n)\n    idxs = []\n    # start from random point\n    idx = int(rng.integers(0, n))\n    idxs.append(idx)\n    d2 = np.full(n, np.inf)\n    for _ in range(1, k):\n        p = points[idxs[-1]]\n        diff = points - p\n        dist2 = np.einsum(\"ij,ij->i\", diff, diff)\n        d2 = np.minimum(d2, dist2)\n        idx = int(np.argmax(d2))\n        if idx in idxs:\n            # fallback random\n            idx = int(rng.integers(0, n))\n        idxs.append(idx)\n    return np.array(idxs, dtype=int)",
    "refiner_score": 2.5590248213843623
}