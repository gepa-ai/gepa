{
    "score": 0.9658549087680688,
    "Input": "Xor",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with a robust hybrid global-local search.\n\n    Strategy:\n    1. Careful initialization (random + optional warm start).\n    2. Budget-aware global search (evolutionary-style) with adaptive mutation.\n    3. Budget-aware local search around the best solution with adaptive step control.\n    4. Handles small budgets and degenerate bounds robustly.\n    \"\"\"\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    # Handle degenerate / zero budget: return something valid and cheap\n    if budget <= 0:\n        if prev_best_x is not None:\n            return clip_to_bounds(np.asarray(prev_best_x, dtype=float).reshape(dim))\n        return np.clip(np.zeros(dim, dtype=float), low, high)\n\n    # Ensure span is nonzero in every dimension to avoid zero-variance normals\n    safe_span = np.where(span > 0, span, 1.0)\n\n    evals_used = 0\n\n    # ---------- Initialization ----------\n    # Population size: scale with dim and budget, but be conservative for tiny budgets\n    if budget <= 5:\n        pop_size = budget\n    else:\n        # heuristic: between 4 and min(budget//3, 6*sqrt(dim))\n        pop_size = int(min(max(4, 2 * np.sqrt(dim)), max(4, budget // 3)))\n        pop_size = max(2, min(pop_size, budget))\n\n    population = []\n\n    # Warm start: insert prev_best_x as a candidate (clipped)\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = clip_to_bounds(x0)\n            population.append(x0)\n        except Exception:\n            # If prev_best_x has wrong shape/type, ignore it\n            pass\n\n    # Fill remaining initial population with uniform random samples\n    while len(population) < pop_size:\n        population.append(np.random.uniform(low, high, size=dim))\n\n    population = np.asarray(population, dtype=float)\n\n    # Evaluate initial population\n    fitness = np.empty(len(population), dtype=float)\n    for i, x in enumerate(population):\n        if evals_used >= budget:\n            break\n        fitness[i] = objective_function(x)\n        evals_used += 1\n\n    # If no evaluations were possible (should not happen since budget>0), return first candidate\n    if evals_used == 0:\n        return clip_to_bounds(population[0]).reshape(dim)\n\n    # Track global best\n    best_idx = np.argmin(fitness[:evals_used])\n    best_x = population[best_idx].copy()\n    best_y = fitness[best_idx]\n\n    if evals_used >= budget:\n        return best_x.reshape(dim)\n\n    # ---------- Budget planning ----------\n    remaining = budget - evals_used\n\n    # Assign at least some budget to both phases when possible\n    if remaining <= 4:\n        evo_budget = max(0, remaining - 1)\n        local_budget = remaining - evo_budget\n    else:\n        evo_budget = int(0.55 * remaining)\n        evo_budget = max(2, min(evo_budget, remaining - 2))\n        local_budget = remaining - evo_budget\n\n    # ---------- Evolutionary Global Search ----------\n    if evo_budget > 0:\n        # Number of elite parents\n        mu = max(2, min(len(population) // 2, 12))\n\n        # Batch size (offspring per generation)\n        batch_size = max(4, min(16, evo_budget))\n\n        # Initial elites\n        order = np.argsort(fitness)\n        elites = population[order[:mu]]\n\n        evo_evals = 0\n        iter_count = 0\n\n        # Global mutation scale range (relative to span)\n        max_sigma = 0.6\n        min_sigma = 0.08\n\n        while evo_evals < evo_budget and evals_used < budget:\n            if evals_used >= budget:\n                break\n\n            t = evo_evals / max(1, evo_budget - 1)\n            sigma = max_sigma * (1.0 - t) + min_sigma * t\n\n            new_points = []\n            # Generate a small batch each iteration\n            budget_left_for_evo = evo_budget - evo_evals\n            current_batch = min(batch_size, budget_left_for_evo, budget - evals_used)\n            if current_batch <= 0:\n                break\n\n            for _ in range(current_batch):\n                if np.random.rand() < 0.30:\n                    # Pure random exploration\n                    x_new = np.random.uniform(low, high, size=dim)\n                else:\n                    # Mutate an elite\n                    parent = elites[np.random.randint(mu)]\n                    step = np.random.normal(0.0, sigma * safe_span, size=dim)\n                    x_new = clip_to_bounds(parent + step)\n                new_points.append(x_new)\n\n            if not new_points:\n                break\n\n            new_points = np.asarray(new_points, dtype=float)\n\n            for x_new in new_points:\n                if evals_used >= budget or evo_evals >= evo_budget:\n                    break\n\n                y_new = objective_function(x_new)\n                evals_used += 1\n                evo_evals += 1\n\n                # Update global best\n                if y_new < best_y:\n                    best_y = y_new\n                    best_x = x_new\n\n                # Insert into population by replacing current worst\n                worst_idx = np.argmax(fitness)\n                if y_new < fitness[worst_idx]:\n                    population[worst_idx] = x_new\n                    fitness[worst_idx] = y_new\n\n            # Refresh elites occasionally\n            if (iter_count % 3 == 0) or (iter_count == 0):\n                order = np.argsort(fitness)\n                elites = population[order[:mu]]\n            iter_count += 1\n\n    if evals_used >= budget:\n        return best_x.reshape(dim)\n\n    # ---------- Local Search Around Best ----------\n    remaining = budget - evals_used\n    local_budget = min(local_budget, remaining)\n\n    if local_budget > 0:\n        # Adaptive random search with shrinking/expanding step size\n        max_scale = 0.25\n        min_scale = 0.005\n        current_scale = min(0.1, max_scale)\n\n        no_improve_streak = 0\n        for i in range(local_budget):\n            if evals_used >= budget:\n                break\n\n            t = i / max(1, local_budget - 1)\n            target_scale = max_scale * (1.0 - t) + min_scale * t\n            current_scale = 0.6 * current_scale + 0.4 * target_scale\n\n            # Occasionally try a larger \"escape\" step if stuck\n            if no_improve_streak >= max(5, dim):\n                step_scale = min(max_scale, current_scale * 3.0)\n                no_improve_streak = 0\n            else:\n                step_scale = current_scale\n\n            step = np.random.normal(0.0, step_scale * safe_span, size=dim)\n            x_new = clip_to_bounds(best_x + step)\n            y_new = objective_function(x_new)\n            evals_used += 1\n\n            if y_new < best_y:\n                best_y = y_new\n                best_x = x_new\n                current_scale *= 1.15\n                current_scale = min(current_scale, max_scale)\n                no_improve_streak = 0\n            else:\n                current_scale *= 0.85\n                current_scale = max(current_scale, min_scale)\n                no_improve_streak += 1\n\n    return best_x.reshape(dim)",
    "X": "1.0 1.0 1.0 -0.9830269462844805 0.4250051488048652 1.0 1.0 -1.0 -0.06922993735251386"
}