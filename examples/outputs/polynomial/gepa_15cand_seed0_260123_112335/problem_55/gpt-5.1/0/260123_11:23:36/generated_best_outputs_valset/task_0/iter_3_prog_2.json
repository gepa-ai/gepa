{
    "score": 0.96628772262981,
    "Input": "Xor",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with a hybrid global-local search and adaptive sampling.\n\n    Strategy:\n    1. Initial space-filling random population (with optional warm start).\n    2. Evolutionary-style global search (mutation around elites + random injections).\n    3. Intensified local search around the current best with adaptive step sizes.\n    4. Uses full budget and respects bounds; warm-starts from prev_best_x when given.\n    \"\"\"\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    # Handle degenerate budget\n    if budget <= 0:\n        if prev_best_x is not None:\n            return clip_to_bounds(np.asarray(prev_best_x, dtype=float).reshape(dim))\n        return np.random.uniform(low, high, size=dim)\n\n    # Ensure span is nonzero in every dimension (avoid zero-variance normals)\n    safe_span = np.where(span > 0, span, 1.0)\n\n    evals_used = 0\n\n    # ---- Initialization ----\n    # Population size scales with sqrt(budget) but capped by budget\n    pop_size = max(4, min(budget // 4 if budget >= 8 else budget, int(4 * np.sqrt(dim)) or 4))\n    pop_size = min(pop_size, budget)  # can't evaluate more than budget\n\n    population = []\n\n    # Warm start: insert prev_best_x as a candidate (clipped)\n    if prev_best_x is not None:\n        x0 = clip_to_bounds(np.asarray(prev_best_x, dtype=float).reshape(dim))\n        population.append(x0)\n\n    # Fill the rest of the initial population with uniform random points\n    while len(population) < pop_size:\n        population.append(np.random.uniform(low, high, size=dim))\n\n    population = np.asarray(population)\n\n    # Evaluate initial population\n    fitness = np.empty(len(population), dtype=float)\n    for i, x in enumerate(population):\n        if evals_used >= budget:\n            break\n        fitness[i] = objective_function(x)\n        evals_used += 1\n\n    # If no evaluations possible (budget very small), return first candidate\n    if evals_used == 0:\n        return clip_to_bounds(population[0]).reshape(dim)\n\n    best_idx = np.argmin(fitness)\n    best_x = population[best_idx].copy()\n    best_y = fitness[best_idx]\n\n    if evals_used >= budget:\n        return best_x.reshape(dim)\n\n    # ---- Budget planning for remaining evaluations ----\n    remaining = budget - evals_used\n    # Split remaining budget between evolutionary global search and local search\n    evo_budget = int(0.6 * remaining)\n    local_budget = remaining - evo_budget  # at least some local budget\n\n    # ---- Evolutionary Global Search ----\n    # Use simple (\u03bc, \u03bb) strategy: mutate elites + inject random points\n    if evo_budget > 0:\n        # Number of parents (elites) and offspring\n        mu = max(2, min(len(population) // 2, 10))\n        # each iteration will generate a small batch to adaptively use budget\n        batch_size = max(4, min(16, evo_budget))\n\n        # Precompute elite indices (sorted)\n        order = np.argsort(fitness)\n        elites = population[order[:mu]]\n\n        evo_evals = 0\n        iter_count = 0\n        while evo_evals < evo_budget and evals_used < budget:\n            # Decrease mutation strength over time\n            t = evo_evals / max(1, evo_budget - 1)\n            # Start with relatively global moves and narrow down\n            sigma = (0.5 - 0.1) * (1.0 - t) + 0.1  # from 0.5*span to 0.1*span\n\n            new_points = []\n            for _ in range(batch_size):\n                if len(new_points) >= evo_budget - evo_evals:\n                    break\n                # With some probability, sample purely random for exploration\n                if np.random.rand() < 0.25:\n                    x_new = np.random.uniform(low, high, size=dim)\n                else:\n                    # Choose a random elite and mutate it\n                    parent = elites[np.random.randint(mu)]\n                    step = np.random.normal(0.0, sigma * safe_span, size=dim)\n                    x_new = clip_to_bounds(parent + step)\n                new_points.append(x_new)\n\n            if not new_points:\n                break\n\n            new_points = np.asarray(new_points)\n            for x_new in new_points:\n                if evals_used >= budget or evo_evals >= evo_budget:\n                    break\n                y_new = objective_function(x_new)\n                evals_used += 1\n                evo_evals += 1\n\n                # Replace worst in population if better\n                worst_idx = np.argmax(fitness)\n                if y_new < fitness[worst_idx]:\n                    population[worst_idx] = x_new\n                    fitness[worst_idx] = y_new\n                    if y_new < best_y:\n                        best_y = y_new\n                        best_x = x_new\n\n            # Recompute elites occasionally\n            if iter_count % 3 == 0:\n                order = np.argsort(fitness)\n                elites = population[order[:mu]]\n            iter_count += 1\n\n    if evals_used >= budget:\n        return best_x.reshape(dim)\n\n    # ---- Local Search Around Best ----\n    # Adaptive random search / hill-climbing using shrinking Gaussian steps\n    remaining = budget - evals_used\n    local_budget = min(local_budget, remaining)\n\n    if local_budget > 0:\n        # step scale schedule: start moderate, end small\n        max_scale = 0.2\n        min_scale = 0.01\n        # simple adaptive: if improvement is found, slightly increase scale, else decrease\n        current_scale = 0.1\n\n        for i in range(local_budget):\n            if evals_used >= budget:\n                break\n\n            t = i / max(1, local_budget - 1)\n            target_scale = max_scale * (1.0 - t) + min_scale * t\n            # blend current scale towards target\n            current_scale = 0.7 * current_scale + 0.3 * target_scale\n            step = np.random.normal(0.0, current_scale * safe_span, size=dim)\n            x_new = clip_to_bounds(best_x + step)\n            y_new = objective_function(x_new)\n            evals_used += 1\n\n            if y_new < best_y:\n                best_y = y_new\n                best_x = x_new\n                # reward by modestly increasing scale (to escape too-local traps)\n                current_scale *= 1.2\n            else:\n                # penalize by shrinking scale\n                current_scale *= 0.8\n                current_scale = max(current_scale, min_scale)\n\n    return best_x.reshape(dim)",
    "X": "1.0 1.0 0.9999707677726403 -0.8910438486552411 0.5493295970497383 0.9897994617894335 0.9944819374460296 -1.0 -0.08507826781487697"
}