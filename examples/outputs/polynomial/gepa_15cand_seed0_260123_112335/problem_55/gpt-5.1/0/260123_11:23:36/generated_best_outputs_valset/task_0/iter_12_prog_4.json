{
    "score": 0.9656690214945864,
    "Input": "Xor",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with a robust hybrid global-local search.\n\n    Strategy:\n    1. Initialization: random + optional warm start (prev_best_x) + small perturbations.\n    2. Budget-aware global search (evolutionary-style) with adaptive mutation and\n       limited per-dimension activation for high dimensions.\n    3. Budget-aware local search around the best solution with adaptive step control.\n    4. Handles small budgets and degenerate bounds robustly.\n    \"\"\"\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    # Handle degenerate / zero budget: return something valid and cheap\n    if budget <= 0:\n        if prev_best_x is not None:\n            try:\n                return clip_to_bounds(np.asarray(prev_best_x, dtype=float).reshape(dim))\n            except Exception:\n                pass\n        # If no warm start, use middle of the box (more neutral than zeros)\n        return clip_to_bounds((low + high) * 0.5).reshape(dim)\n\n    # Ensure span is nonzero in every dimension to avoid zero-variance normals\n    # but keep true zero-span dimensions fixed during mutation and search.\n    safe_span = np.where(span > 0, span, 1.0)\n    variable_mask = span > 0\n    n_var = int(variable_mask.sum())\n\n    evals_used = 0\n\n    # ----------------- Initialization -----------------\n    # Population size: scale with dim and budget, but be conservative for tiny budgets.\n    if budget <= 5:\n        pop_size = budget\n    else:\n        # heuristic: between 4 and min(budget//3, 6*sqrt(dim), dim*3 for very low dims)\n        base = 2 * np.sqrt(max(1, dim))\n        pop_size = int(min(max(4, base), max(4, budget // 3), max(4, 3 * dim)))\n        pop_size = max(2, min(pop_size, budget))\n\n    population = []\n\n    # Warm start: insert prev_best_x as a candidate (clipped)\n    warm_added = False\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = clip_to_bounds(x0)\n            population.append(x0)\n            warm_added = True\n        except Exception:\n            warm_added = False\n\n    # Additionally, when we have a warm start and enough budget, add small perturbations\n    # around it to quickly explore its neighborhood.\n    if warm_added and budget >= 6:\n        n_perturb = min(4, budget - 1, max(1, pop_size // 3))\n        base = population[0]\n        for _ in range(n_perturb):\n            step_scale = 0.05\n            step = np.zeros(dim, dtype=float)\n            if n_var > 0:\n                active = variable_mask & (np.random.rand(dim) < min(1.0, 6.0 / max(1, dim)))\n                if not np.any(active):\n                    active[np.random.randint(dim)] = True\n                step[active] = np.random.normal(0.0, step_scale * safe_span[active])\n            x_new = clip_to_bounds(base + step)\n            population.append(x_new)\n\n    # Fill remaining initial population with uniform random samples\n    while len(population) < pop_size:\n        population.append(np.random.uniform(low, high, size=dim))\n\n    population = np.asarray(population, dtype=float)\n\n    # Evaluate initial population\n    fitness = np.empty(len(population), dtype=float)\n    valid_evals = 0\n    for i, x in enumerate(population):\n        if evals_used >= budget:\n            break\n        try:\n            y = objective_function(x)\n        except Exception:\n            # In case of occasional objective failures, skip this point\n            y = np.inf\n        fitness[i] = y\n        evals_used += 1\n        valid_evals += 1\n\n    # If no evaluations were possible, fall back to warm start or center\n    if valid_evals == 0:\n        if warm_added:\n            return population[0].reshape(dim)\n        return clip_to_bounds((low + high) * 0.5).reshape(dim)\n\n    # Track global best\n    finite_mask = np.isfinite(fitness[:valid_evals])\n    if not np.any(finite_mask):\n        # All failed/inf: return first candidate\n        return clip_to_bounds(population[0]).reshape(dim)\n    best_idx = np.argmin(np.where(finite_mask, fitness[:valid_evals], np.inf))\n    best_x = population[best_idx].copy()\n    best_y = fitness[best_idx]\n\n    if evals_used >= budget:\n        return best_x.reshape(dim)\n\n    # ----------------- Budget planning -----------------\n    remaining = budget - evals_used\n\n    # Assign at least some budget to both phases when possible\n    if remaining <= 4:\n        evo_budget = max(0, remaining - 1)\n        local_budget = remaining - evo_budget\n    else:\n        evo_budget = int(0.55 * remaining)\n        evo_budget = max(2, min(evo_budget, remaining - 2))\n        local_budget = remaining - evo_budget\n\n    # ----------------- Evolutionary Global Search -----------------\n    if evo_budget > 0:\n        # Number of elite parents\n        mu = max(2, min(len(population) // 2, 12))\n\n        # Batch size (offspring per generation)\n        batch_size = max(4, min(16, evo_budget))\n\n        # Initial elites\n        order = np.argsort(fitness)\n        elites = population[order[:mu]]\n        elite_fitness = fitness[order[:mu]].copy()\n\n        evo_evals = 0\n        iter_count = 0\n\n        # Global mutation scale range (relative to span)\n        max_sigma = 0.6\n        min_sigma = 0.06  # slightly smaller minimum for finer late search\n\n        while evo_evals < evo_budget and evals_used < budget:\n            t = evo_evals / max(1, evo_budget - 1)\n            sigma = max_sigma * (1.0 - t) + min_sigma * t\n\n            new_points = []\n            budget_left_for_evo = evo_budget - evo_evals\n            current_batch = min(batch_size, budget_left_for_evo, budget - evals_used)\n            if current_batch <= 0:\n                break\n\n            for _ in range(current_batch):\n                r = np.random.rand()\n                if r < 0.22:\n                    # Pure random exploration\n                    x_new = np.random.uniform(low, high, size=dim)\n                else:\n                    # Mutate an elite\n                    idx = np.random.randint(mu)\n                    parent = elites[idx]\n\n                    step = np.zeros(dim, dtype=float)\n                    if n_var > 0:\n                        # Activate a limited subset of dimensions for robustness in high-d\n                        if dim <= 10:\n                            active = variable_mask\n                        else:\n                            act_prob = min(1.0, 6.0 / max(1, dim))\n                            active = variable_mask & (np.random.rand(dim) < act_prob)\n                            if not np.any(active):\n                                # Ensure at least one dimension mutates\n                                j = np.random.randint(dim)\n                                active[j] = True\n                        step[active] = np.random.normal(\n                            0.0, sigma * safe_span[active], size=active.sum()\n                        )\n                    x_new = clip_to_bounds(parent + step)\n                new_points.append(x_new)\n\n            if not new_points:\n                break\n\n            new_points = np.asarray(new_points, dtype=float)\n\n            for x_new in new_points:\n                if evals_used >= budget or evo_evals >= evo_budget:\n                    break\n\n                try:\n                    y_new = objective_function(x_new)\n                except Exception:\n                    y_new = np.inf\n\n                evals_used += 1\n                evo_evals += 1\n\n                # Update global best\n                if y_new < best_y:\n                    best_y = y_new\n                    best_x = x_new\n\n                # Insert into population by replacing current worst if better\n                worst_idx = np.argmax(fitness)\n                if y_new < fitness[worst_idx]:\n                    population[worst_idx] = x_new\n                    fitness[worst_idx] = y_new\n\n            # Refresh elites periodically\n            if (iter_count % 3 == 0) or (iter_count == 0):\n                order = np.argsort(fitness)\n                elites = population[order[:mu]]\n                elite_fitness = fitness[order[:mu]]\n            iter_count += 1\n\n    if evals_used >= budget:\n        return best_x.reshape(dim)\n\n    # ----------------- Local Search Around Best -----------------\n    remaining = budget - evals_used\n    local_budget = min(local_budget, remaining)\n\n    if local_budget > 0 and np.isfinite(best_y):\n        # Adaptive random search with shrinking/expanding step size\n        max_scale = 0.25\n        min_scale = 0.003\n        current_scale = min(0.10, max_scale)\n\n        no_improve_streak = 0\n        for i in range(local_budget):\n            if evals_used >= budget:\n                break\n\n            t = i / max(1, local_budget - 1)\n            target_scale = max_scale * (1.0 - t) + min_scale * t\n            current_scale = 0.6 * current_scale + 0.4 * target_scale\n\n            # Occasionally try a larger \"escape\" step if stuck\n            if no_improve_streak >= max(5, dim):\n                step_scale = min(max_scale, current_scale * 3.0)\n                no_improve_streak = 0\n            else:\n                step_scale = current_scale\n\n            step = np.zeros(dim, dtype=float)\n            if n_var > 0:\n                if dim <= 10:\n                    active = variable_mask\n                else:\n                    act_prob = min(1.0, 4.0 / max(1, dim))\n                    active = variable_mask & (np.random.rand(dim) < act_prob)\n                    if not np.any(active):\n                        active[np.random.randint(dim)] = True\n                step[active] = np.random.normal(\n                    0.0, step_scale * safe_span[active], size=active.sum()\n                )\n\n            x_new = clip_to_bounds(best_x + step)\n            try:\n                y_new = objective_function(x_new)\n            except Exception:\n                y_new = np.inf\n\n            evals_used += 1\n\n            if y_new < best_y:\n                best_y = y_new\n                best_x = x_new\n                current_scale *= 1.15\n                current_scale = min(current_scale, max_scale)\n                no_improve_streak = 0\n            else:\n                current_scale *= 0.87\n                current_scale = max(current_scale, min_scale)\n                no_improve_streak += 1\n\n    return best_x.reshape(dim)",
    "X": "1.0 1.0 1.0 -1.0 0.5260279417893385 1.0 1.0 -1.0 -0.10952380522624494"
}