{
    "score": -1.4290621281014844,
    "Input": "McCourt18",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef _project_bounds(x, bounds):\n    return np.clip(x, bounds[:, 0], bounds[:, 1])\n\n\ndef _random_in_bounds(bounds, n=1, rng=None):\n    if rng is None:\n        rng = np.random\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    return rng.uniform(low, high, size=(n, bounds.shape[0]))\n\n\ndef _lhs_samples(bounds, n, rng):\n    \"\"\"Latin-hypercube-like sampling within bounds.\"\"\"\n    dim = bounds.shape[0]\n    if n <= 0:\n        return np.empty((0, dim), dtype=float)\n    m = n\n    base = (np.arange(m) + rng.rand(m)) / m\n    X_unit = np.empty((m, dim), dtype=float)\n    for j in range(dim):\n        rng.shuffle(base)\n        X_unit[:, j] = base\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    return low + (high - low) * X_unit\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global-local derivative-free optimizer, tuned for efficient\n    use of small-to-moderate budgets and robust performance across\n    different blackbox landscapes.\n    \"\"\"\n    # RNG handling\n    seed = config.get(\"seed\", None)\n    rng = np.random.RandomState(seed) if seed is not None else np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    # Robust reshape for possibly flattened bounds\n    bounds = bounds.reshape(dim, 2)\n\n    if budget <= 0:\n        return _random_in_bounds(bounds, n=1, rng=rng)[0]\n\n    widths = bounds[:, 1] - bounds[:, 0]\n    zero_mask = widths == 0\n    widths[zero_mask] = 1.0\n    center = (bounds[:, 0] + bounds[:, 1]) * 0.5\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    def eval_point(x):\n        nonlocal evals_used, best_x, best_y\n        x = np.asarray(x, dtype=float).reshape(dim)\n        x = _project_bounds(x, bounds)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # --- Initialization / warm start ---\n    init_points = []\n\n    # Include warm start if given and finite\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = _project_bounds(x0, bounds)\n            if np.all(np.isfinite(x0)):\n                init_points.append(x0)\n        except Exception:\n            pass\n\n    # Include center point\n    init_points.append(center.copy())\n\n    # A few boundary points to help on boundary optima\n    init_points.append(bounds[:, 0].copy())\n    init_points.append(bounds[:, 1].copy())\n\n    # A couple of random points for safety and diversity\n    if budget < 10:\n        n_init_rand = 1\n    else:\n        n_init_rand = min(5, max(2, budget // 20))\n    init_points.extend(list(_random_in_bounds(bounds, n=n_init_rand, rng=rng)))\n\n    # Deduplicate initial points\n    unique_init = []\n    for x in init_points:\n        x = np.asarray(x, dtype=float).reshape(dim)\n        if not unique_init:\n            unique_init.append(x)\n        else:\n            arr = np.asarray(unique_init)\n            if np.all(np.linalg.norm(arr - x, axis=1) > 1e-9):\n                unique_init.append(x)\n\n    for x in unique_init:\n        if evals_used >= budget:\n            break\n        eval_point(x)\n\n    if evals_used >= budget:\n        return best_x\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Global exploration phase ---\n    # Re-tune global/local split: more robust exploration\n    if budget < 20:\n        global_evals = max(0, min(remaining, budget // 2))\n    else:\n        # Use up to 55% for global, but not less than 4*dim\n        global_evals = int(0.55 * budget)\n        global_evals = max(4 * dim, global_evals)\n        global_evals = min(global_evals, remaining)\n\n    if global_evals > 0:\n        if dim <= 60 and global_evals >= dim:\n            X_global = _lhs_samples(bounds, global_evals, rng)\n        else:\n            X_global = _random_in_bounds(bounds, n=global_evals, rng=rng)\n\n        for i in range(global_evals):\n            if evals_used >= budget:\n                break\n            eval_point(X_global[i])\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Adaptive Nelder-Mead local search around best_x ---\n    # This tends to work well on smooth-ish black boxes like McCourt functions.\n    # We keep a portion of budget for a final stochastic refinement.\n    if remaining > 10:\n        nm_budget = int(0.7 * remaining)\n    else:\n        nm_budget = remaining\n    nm_budget = max(0, min(nm_budget, remaining))\n\n    if nm_budget > 0:\n        # Build initial simplex\n        x0 = best_x.copy()\n        simplex = np.zeros((dim + 1, dim), dtype=float)\n        simplex[0] = x0\n\n        # Initial step sizes relative to bounds\n        base_step = widths * 0.05\n        base_step[base_step == 0] = 1.0\n\n        for i in range(dim):\n            x = x0.copy()\n            step = base_step[i]\n            if step == 0:\n                step = 1.0\n            x[i] = np.clip(x[i] + step, bounds[i, 0], bounds[i, 1])\n            if np.allclose(x, x0):\n                # If clipping caused no move, try opposite direction\n                x[i] = np.clip(x[i] - step, bounds[i, 0], bounds[i, 1])\n            simplex[i + 1] = x\n\n        f_vals = np.empty(dim + 1, dtype=float)\n        for i in range(dim + 1):\n            if evals_used >= budget or nm_budget <= 0:\n                break\n            f_vals[i] = eval_point(simplex[i])\n            nm_budget -= 1\n\n        # Nelder-Mead parameters\n        alpha = 1.0\n        gamma = 2.0\n        rho = 0.5\n        sigma_nm = 0.5\n\n        # Main Nelder-Mead loop\n        while nm_budget > 0 and evals_used < budget:\n            # Order\n            idx = np.argsort(f_vals)\n            simplex = simplex[idx]\n            f_vals = f_vals[idx]\n\n            # Current best update is already handled in eval_point\n\n            # Centroid of all but worst\n            centroid = np.mean(simplex[:-1], axis=0)\n\n            # Reflection\n            xr = centroid + alpha * (centroid - simplex[-1])\n            xr = _project_bounds(xr, bounds)\n            if nm_budget <= 0 or evals_used >= budget:\n                break\n            fr = eval_point(xr)\n            nm_budget -= 1\n\n            if fr < f_vals[0]:\n                # Expansion\n                xe = centroid + gamma * (xr - centroid)\n                xe = _project_bounds(xe, bounds)\n                if nm_budget <= 0 or evals_used >= budget:\n                    break\n                fe = eval_point(xe)\n                nm_budget -= 1\n                if fe < fr:\n                    simplex[-1] = xe\n                    f_vals[-1] = fe\n                else:\n                    simplex[-1] = xr\n                    f_vals[-1] = fr\n            elif fr < f_vals[-2]:\n                # Accept reflection\n                simplex[-1] = xr\n                f_vals[-1] = fr\n            else:\n                # Contraction\n                if fr < f_vals[-1]:\n                    # Outside contraction\n                    xc = centroid + rho * (xr - centroid)\n                else:\n                    # Inside contraction\n                    xc = centroid - rho * (centroid - simplex[-1])\n                xc = _project_bounds(xc, bounds)\n                if nm_budget <= 0 or evals_used >= budget:\n                    break\n                fc = eval_point(xc)\n                nm_budget -= 1\n                if fc < f_vals[-1]:\n                    simplex[-1] = xc\n                    f_vals[-1] = fc\n                else:\n                    # Shrink\n                    for i in range(1, dim + 1):\n                        simplex[i] = simplex[0] + sigma_nm * (simplex[i] - simplex[0])\n                        simplex[i] = _project_bounds(simplex[i], bounds)\n                        if nm_budget <= 0 or evals_used >= budget:\n                            break\n                        f_vals[i] = eval_point(simplex[i])\n                        nm_budget -= 1\n\n            # Stopping based on simplex size or function spread could be added,\n            # but we typically want to use almost all NM budget.\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Final stochastic local refinement around best_x ---\n    # Use an anisotropic Gaussian search scaled to domain.\n    local_sigma = np.minimum(widths * 0.03, np.maximum(widths * 5e-5, widths * 0.01))\n    for _ in range(remaining):\n        step = rng.randn(dim) * local_sigma\n        x_candidate = _project_bounds(best_x + step, bounds)\n        eval_point(x_candidate)\n        if evals_used >= budget:\n            break\n\n    return best_x",
    "X": "0.2677654629372302 0.8696563476254945 0.26762444725653123 0.6594535997267916 0.1321844653490829 0.9542120382483137 0.05768360692237606 0.2949007861156469"
}