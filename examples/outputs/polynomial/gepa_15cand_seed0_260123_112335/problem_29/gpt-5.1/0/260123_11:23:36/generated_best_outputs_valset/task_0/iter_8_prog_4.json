{
    "score": -1.4287933172893326,
    "Input": "McCourt18",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef _project_bounds(x, bounds):\n    return np.clip(x, bounds[:, 0], bounds[:, 1])\n\n\ndef _random_in_bounds(bounds, n=1, rng=None):\n    if rng is None:\n        rng = np.random\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    return rng.uniform(low, high, size=(n, bounds.shape[0]))\n\n\ndef _lhs_samples(bounds, n, rng):\n    \"\"\"Latin-hypercube-like sampling within bounds.\"\"\"\n    dim = bounds.shape[0]\n    if n <= 0:\n        return np.empty((0, dim), dtype=float)\n    m = n\n    base = (np.arange(m) + rng.rand(m)) / m\n    X_unit = np.empty((m, dim), dtype=float)\n    for j in range(dim):\n        rng.shuffle(base)\n        X_unit[:, j] = base\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    return low + (high - low) * X_unit\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global-local derivative-free optimizer, tuned for efficient\n    use of small-to-moderate budgets and robust performance across\n    different blackbox landscapes.\n    \"\"\"\n    # RNG handling\n    seed = config.get(\"seed\", None)\n    rng = np.random.RandomState(seed) if seed is not None else np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    if bounds.shape[0] != dim:\n        bounds = bounds.reshape(dim, 2)\n\n    if budget <= 0:\n        return _random_in_bounds(bounds, n=1, rng=rng)[0]\n\n    widths = bounds[:, 1] - bounds[:, 0]\n    # Avoid zero widths to prevent later numerical issues\n    zero_mask = widths == 0\n    widths[zero_mask] = 1.0\n    center = (bounds[:, 0] + bounds[:, 1]) * 0.5\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    def eval_point(x):\n        nonlocal evals_used, best_x, best_y\n        # Ensure proper shape and bounds\n        x = np.asarray(x, dtype=float).reshape(dim)\n        x = _project_bounds(x, bounds)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # --- Initialization / warm start ---\n    init_points = []\n\n    # Include warm start if given\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = _project_bounds(x0, bounds)\n            init_points.append(x0)\n        except Exception:\n            pass\n\n    # Include center point\n    init_points.append(center.copy())\n\n    # A couple of random points for safety and diversity\n    n_init_rand = min(3, max(1, budget // 20))\n    init_points.extend(\n        list(_random_in_bounds(bounds, n=n_init_rand, rng=rng))\n    )\n\n    # Deduplicate initial points\n    unique_init = []\n    for x in init_points:\n        x = np.asarray(x, dtype=float).reshape(dim)\n        if not unique_init:\n            unique_init.append(x)\n        else:\n            arr = np.asarray(unique_init)\n            if np.all(np.linalg.norm(arr - x, axis=1) > 1e-9):\n                unique_init.append(x)\n\n    for x in unique_init:\n        if evals_used >= budget:\n            break\n        eval_point(x)\n\n    if evals_used >= budget:\n        return best_x\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Global exploration phase ---\n    # Allocate ~40% of total budget (not remaining) to global search,\n    # but adapt for very small budgets.\n    if budget < 30:\n        global_evals = max(0, min(remaining, budget // 3))\n    else:\n        global_evals = int(0.4 * budget)\n        global_evals = max(dim * 3, global_evals)\n        global_evals = min(global_evals, remaining)\n\n    if global_evals > 0:\n        if dim <= 60 and global_evals >= dim:\n            X_global = _lhs_samples(bounds, global_evals, rng)\n        else:\n            X_global = _random_in_bounds(bounds, n=global_evals, rng=rng)\n\n        for i in range(global_evals):\n            if evals_used >= budget:\n                break\n            eval_point(X_global[i])\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Local evolutionary / CMA-like search phase with restarts ---\n    # Step size relative to domain width\n    base_sigma = widths / 4.0\n\n    # Population size scaling: moderate for robustness, bound by budget\n    pop_size = max(6, min(40, 4 + dim // 2))\n    pop_size = min(pop_size, max(4, remaining // 2))\n    elite_frac = 0.4\n    n_elite = max(2, int(elite_frac * pop_size))\n\n    # Number of generations we can afford now\n    max_gens = max(1, remaining // pop_size)\n\n    # Restart controls\n    max_restarts = 3\n    restart_count = 0\n\n    # Initialize search distribution around current best\n    mean = best_x.copy()\n    sigma = base_sigma.copy()\n\n    no_improve_gens = 0\n    max_no_improve = max(4, min(12, dim // 2 + 4))\n\n    gen = 0\n    while gen < max_gens and evals_used < budget:\n        # Anneal sigma over generations: start a bit larger, shrink later\n        if max_gens > 1:\n            frac = gen / (max_gens - 1)\n            scale = 0.3 + 0.9 * (1.0 - frac)\n        else:\n            scale = 1.0\n        gen_sigma = sigma * scale\n\n        # Sample population\n        pop = mean + rng.randn(pop_size, dim) * gen_sigma\n        pop = _project_bounds(pop, bounds)\n\n        ys = np.empty(pop_size, dtype=float)\n        any_improve = False\n\n        for i in range(pop_size):\n            if evals_used >= budget:\n                ys[i] = np.inf\n                continue\n            y = eval_point(pop[i])\n            ys[i] = y\n            if y < best_y - 1e-12:\n                any_improve = True\n\n        if evals_used >= budget:\n            break\n\n        # Sort population\n        elite_idx = np.argsort(ys)[:n_elite]\n        elites = pop[elite_idx]\n\n        # Weighted recombination toward elites\n        weights = np.linspace(1.0, 0.1, n_elite)\n        weights /= weights.sum()\n        new_mean = np.sum(elites * weights[:, None], axis=0)\n\n        # Blend with previous mean and current global best\n        mean = 0.4 * mean + 0.4 * new_mean + 0.2 * best_x\n\n        # Adapt sigma from elite spread\n        spread = np.std(elites, axis=0)\n        target_sigma = np.maximum(spread * 2.5, widths * 1e-4)\n        sigma = 0.5 * sigma + 0.5 * target_sigma\n\n        # Bound sigma\n        sigma = np.minimum(sigma, widths)\n        sigma = np.maximum(sigma, widths * 1e-4)\n\n        # Stagnation handling\n        if any_improve:\n            no_improve_gens = 0\n        else:\n            no_improve_gens += 1\n\n        if no_improve_gens >= max_no_improve and restart_count < max_restarts:\n            restart_count += 1\n            no_improve_gens = 0\n\n            # Restart around best, but with larger spread to escape basin\n            mean = best_x.copy()\n            sigma = np.minimum(widths / 2.0, np.maximum(widths * 0.03, sigma * 2.0))\n\n            # Inject a few random points to diversify\n            inject = min(3, max(1, (budget - evals_used) // (2 * pop_size)))\n            if inject > 0:\n                rnd_pop = _random_in_bounds(bounds, n=inject, rng=rng)\n                for i in range(inject):\n                    if evals_used >= budget:\n                        break\n                    eval_point(rnd_pop[i])\n\n        gen += 1\n\n        remaining = budget - evals_used\n        if remaining <= pop_size:\n            break\n\n    # --- Final local refinement around best_x ---\n    remaining = budget - evals_used\n    if remaining > 0:\n        # Very localized anisotropic search centered on best_x\n        local_sigma = np.minimum(widths * 0.03, np.maximum(widths * 5e-5, sigma * 0.4))\n        for _ in range(remaining):\n            step = rng.randn(dim) * local_sigma\n            x_candidate = _project_bounds(best_x + step, bounds)\n            eval_point(x_candidate)\n            if evals_used >= budget:\n                break\n\n    return best_x",
    "X": "0.2690244655723098 0.8663780148774126 0.2663364733579032 0.66286218553008 0.13117820483581574 0.9568980225662941 0.05277732355237141 0.29184518167026086"
}