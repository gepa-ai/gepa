{
    "score": -1.425824866326136,
    "Input": "McCourt18",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef _project_bounds(x, bounds):\n    return np.clip(x, bounds[:, 0], bounds[:, 1])\n\n\ndef _random_in_bounds(bounds, n=1, rng=None):\n    if rng is None:\n        rng = np.random\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    return rng.uniform(low, high, size=(n, bounds.shape[0]))\n\n\ndef _lhs_samples(bounds, n, rng):\n    \"\"\"Latin-hypercube-like sampling within bounds.\"\"\"\n    dim = bounds.shape[0]\n    if n <= 0:\n        return np.empty((0, dim), dtype=float)\n    m = n\n    base = (np.arange(m) + rng.rand(m)) / m\n    X_unit = np.empty((m, dim), dtype=float)\n    for j in range(dim):\n        rng.shuffle(base)\n        X_unit[:, j] = base\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    return low + (high - low) * X_unit\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global-local derivative-free optimizer.\n\n    Strategy:\n    - Careful initialization using prev_best_x when available, otherwise LHS.\n    - Global exploration (LHS) ~40% of budget.\n    - Evolutionary / CMA-like local search for remaining budget.\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    if bounds.shape[0] != dim:\n        bounds = bounds.reshape(dim, 2)\n\n    if budget <= 0:\n        # Still return something valid\n        return _random_in_bounds(bounds, n=1, rng=rng)[0]\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # --- Initialization / warm start ---\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n        x0 = _project_bounds(x0, bounds)\n    else:\n        x0 = _random_in_bounds(bounds, n=1, rng=rng)[0]\n\n    y0 = objective_function(x0)\n    evals_used += 1\n    best_x, best_y = x0, y0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Global exploration phase ---\n    # Use about 40% of full budget (not remaining) for global search\n    global_evals = int(0.4 * budget)\n    global_evals = max(dim, global_evals)\n    global_evals = min(global_evals, remaining)\n\n    if global_evals > 0:\n        X_global = _lhs_samples(bounds, global_evals, rng)\n        for i in range(global_evals):\n            x = X_global[i]\n            y = objective_function(x)\n            evals_used += 1\n            if y < best_y:\n                best_y = y\n                best_x = x\n            if evals_used >= budget:\n                return best_x\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Local evolutionary/CMA-like search phase ---\n    widths = bounds[:, 1] - bounds[:, 0]\n    widths[widths == 0] = 1.0\n    # Initial step size: moderate relative to box width\n    sigma = widths / 5.0\n\n    # Population-based search parameters\n    # Use small population for low dims, larger for higher dims\n    pop_size = max(4, min(20, 4 + dim // 2))\n    elite_frac = 0.4\n    n_elite = max(1, int(elite_frac * pop_size))\n\n    # Determine number of generations we can afford\n    # One generation \u2248 pop_size evaluations\n    max_gens = max(1, remaining // pop_size)\n\n    mean = best_x.copy()\n\n    for gen in range(max_gens):\n        if evals_used >= budget:\n            break\n\n        # Anneal step size over generations (but not too aggressively)\n        if max_gens > 1:\n            frac = 1.0 - gen / (max_gens - 1)\n            gen_sigma = sigma * (0.3 + 0.7 * frac)\n        else:\n            gen_sigma = sigma\n\n        # Sample population around current mean\n        pop = mean + rng.randn(pop_size, dim) * gen_sigma\n        pop = _project_bounds(pop, bounds)\n\n        ys = np.empty(pop_size, dtype=float)\n        for i in range(pop_size):\n            if evals_used >= budget:\n                break\n            y = objective_function(pop[i])\n            ys[i] = y\n            evals_used += 1\n            if y < best_y:\n                best_y = y\n                best_x = pop[i].copy()\n        if evals_used >= budget:\n            break\n\n        # Update mean using elites\n        elite_idx = np.argsort(ys)[:n_elite]\n        elites = pop[elite_idx]\n        new_mean = elites.mean(axis=0)\n\n        # Safeguard: move mean, but keep tracking global best_x separately\n        mean = 0.7 * mean + 0.3 * new_mean\n\n        # Adapt sigma using spread of elites\n        spread = np.std(elites, axis=0)\n        # Blend with current sigma\n        sigma = 0.7 * sigma + 0.3 * (spread * 2.0 + 1e-12)\n        sigma = np.maximum(sigma, widths * 1e-3)\n\n    # If we still have a few evaluations left, perform a small local refinement\n    remaining = budget - evals_used\n    if remaining > 0:\n        local_sigma = np.maximum(widths * 1e-3, sigma * 0.5)\n        for _ in range(remaining):\n            step = rng.randn(dim) * local_sigma\n            x_candidate = _project_bounds(best_x + step, bounds)\n            y = objective_function(x_candidate)\n            evals_used += 1\n            if y < best_y:\n                best_y = y\n                best_x = x_candidate\n            if evals_used >= budget:\n                break\n\n    return best_x",
    "X": "0.27411717614208986 0.8673713035604587 0.24112649511471773 0.6609253572428313 0.1285771535157781 0.9562975540642887 0.05853407892713911 0.2971444755274103"
}