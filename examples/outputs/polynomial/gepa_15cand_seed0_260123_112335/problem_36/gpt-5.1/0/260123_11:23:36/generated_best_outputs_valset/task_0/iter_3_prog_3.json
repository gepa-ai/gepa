{
    "score": -3.5,
    "Input": "Michalewicz",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget-aware blackbox minimization with hybrid global + local search.\n\n    - Global exploration via Latin Hypercube Sampling (LHS) + random sampling\n    - Warm-start from prev_best_x when available\n    - Local diagonal CMA-ES\u2013like refinement around best-so-far\n    - Uses full evaluation budget and is robust for small/large budgets and dims\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Guard against zero-width bounds\n    span = np.where(span <= 0, 1.0, span)\n\n    def clip(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    def eval_point(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # Degenerate budget: no evaluations allowed\n    if budget <= 0:\n        if prev_best_x is not None:\n            return clip(np.asarray(prev_best_x, dtype=float).reshape(dim))\n        return clip((low + high) * 0.5)\n\n    # Warm start if available\n    if prev_best_x is not None:\n        try:\n            x0 = clip(np.asarray(prev_best_x, dtype=float).reshape(dim))\n            eval_point(x0)\n        except Exception:\n            pass  # Ignore malformed prev_best_x and continue\n\n    # Ensure at least one evaluated point\n    if best_x is None and evals_used < budget:\n        x0 = low + span * rng.rand(dim)\n        eval_point(x0)\n\n    # If very small remaining budget, just random sample\n    if budget - evals_used <= 3:\n        while evals_used < budget:\n            x = low + span * rng.rand(dim)\n            eval_point(x)\n        return best_x\n\n    remaining = budget - evals_used\n\n    # ---------------- Global exploration: LHS + random ----------------\n    # Allocate ~40% of remaining to global search (more for small budgets)\n    frac_global = 0.4\n    if remaining < 20:\n        frac_global = 0.6\n    global_evals = max(4, int(frac_global * remaining))\n    global_evals = min(global_evals, remaining)\n\n    def latin_hypercube(n_samples, dim_):\n        # LHS in [0,1]^dim_\n        cut = np.linspace(0.0, 1.0, n_samples + 1)\n        u = rng.rand(n_samples, dim_)\n        a = cut[:-1]\n        b = cut[1:]\n        rdpoints = a[:, None] + (b - a)[:, None] * u\n        for j in range(dim_):\n            rng.shuffle(rdpoints[:, j])\n        return rdpoints\n\n    use_lhs = global_evals >= dim + 1 and global_evals >= 4\n    if use_lhs:\n        try:\n            lhs = latin_hypercube(global_evals, dim)\n            global_points = clip(low + span * lhs)\n        except Exception:\n            global_points = clip(low + span * rng.rand(global_evals, dim))\n    else:\n        global_points = clip(low + span * rng.rand(global_evals, dim))\n\n    for i in range(global_evals):\n        if evals_used >= budget:\n            break\n        eval_point(global_points[i])\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # ---------------- Local evolutionary refinement (diagonal CMA-like) --------\n    # Population size scaled with dimension but tied to remaining budget\n    # Slightly larger for higher dimensions to maintain diversity\n    lam_base = 4 + int(3 * np.log(dim + 1))\n    lam = max(4, min(lam_base, remaining))\n\n    # Initial step size as fraction of span (more conservative)\n    sigma0 = 0.2\n    cov_diag = (span * sigma0) ** 2 + 1e-12\n    min_sigma_frac = 1e-6\n\n    no_improve_iters = 0\n    best_y_local = best_y\n    # Track iterations for adaptive global restarts\n    local_iter = 0\n\n    while remaining > 0:\n        pop_size = min(lam, remaining)\n        # Sample population around current best_x\n        Z = rng.randn(pop_size, dim)\n        candidates = clip(best_x + Z * np.sqrt(cov_diag))\n\n        ys = []\n        for i in range(pop_size):\n            if evals_used >= budget:\n                break\n            y = eval_point(candidates[i])\n            ys.append(y)\n        remaining = budget - evals_used\n        if not ys:\n            break\n\n        ys = np.asarray(ys)\n        order = np.argsort(ys)\n        candidates = candidates[order]\n        ys = ys[order]\n\n        # Local improvement tracking\n        if ys[0] < best_y_local - 1e-12:\n            best_y_local = ys[0]\n            no_improve_iters = 0\n        else:\n            no_improve_iters += 1\n\n        center = best_x\n\n        elite_count = max(2, pop_size // 2)\n        elites = candidates[:elite_count]\n        diffs = elites - center\n\n        alpha = 0.3\n        cov_diag = (1.0 - alpha) * cov_diag + alpha * (np.mean(diffs ** 2, axis=0) + 1e-12)\n\n        # Step-size adaptation\n        # If stuck, shrink; occasionally re-expand slightly\n        if no_improve_iters >= 3:\n            cov_diag *= 0.5\n            no_improve_iters = 0\n        elif local_iter % 10 == 0 and local_iter > 0:\n            cov_diag *= 1.1\n\n        cov_diag = np.maximum(cov_diag, (span * min_sigma_frac) ** 2)\n\n        local_iter += 1\n\n        # If still a lot of budget left and progress is poor, perform a mini global injection\n        if remaining > 10 * dim and local_iter % 15 == 0:\n            inject = min(5 * dim, remaining // 3)\n            if inject > 0:\n                points = clip(low + span * rng.rand(inject, dim))\n                for i in range(inject):\n                    if evals_used >= budget:\n                        break\n                    eval_point(points[i])\n                remaining = budget - evals_used\n\n        if remaining <= 0:\n            break\n\n    return best_x",
    "X": "2.2220120702142734 1.5677252810619247 2.211531164916818 1.1198370829432966"
}