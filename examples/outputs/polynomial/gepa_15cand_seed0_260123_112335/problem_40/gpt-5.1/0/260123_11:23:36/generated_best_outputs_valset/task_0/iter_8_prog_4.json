{
    "score": -1.007974610922804,
    "Input": "OddSquare",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget\u2011aware black\u2011box optimizer: hybrid global + local search\n    using an evolutionary population plus adaptive local refinement.\n\n    This version simplifies evaluation bookkeeping, removes dead code paths,\n    and uses the full budget more reliably while supporting warm starts.\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config.get(\"budget\", 1))\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    rng = np.random.default_rng()\n    evals_used = 0\n\n    # Helper to clip and ensure correct shape\n    def project(x):\n        x = np.asarray(x, dtype=float).reshape(dim)\n        return np.clip(x, low, high)\n\n    # --- Initialization / warm start ---\n    x_best = None\n    y_best = None\n\n    if prev_best_x is not None and evals_used < budget:\n        x0 = project(prev_best_x)\n        y0 = objective_function(x0)\n        evals_used += 1\n        x_best, y_best = x0.copy(), y0\n\n    if (x_best is None) and (evals_used < budget):\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        x_best, y_best = x0.copy(), y0\n\n    if evals_used >= budget:\n        return x_best\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return x_best\n\n    # --- Global evolutionary search phase ---\n    # Use about 60% of remaining budget for global search\n    global_budget = max(1, int(0.6 * remaining_budget))\n\n    # Population size: modest, scaled by remaining budget\n    if remaining_budget <= 12:\n        pop_size = 6\n    else:\n        pop_size = max(6, min(30, remaining_budget // 3))\n\n    # Initialize population: half around best, half random\n    pop = np.empty((pop_size, dim), dtype=float)\n    half = pop_size // 2\n    noise_scale = 0.25\n    for i in range(half):\n        noise = rng.normal(0.0, 1.0, size=dim)\n        candidate = x_best + noise * (noise_scale * span)\n        pop[i] = np.clip(candidate, low, high)\n    if half < pop_size:\n        pop[half:] = rng.uniform(low, high, size=(pop_size - half, dim))\n\n    fitness = np.empty(pop_size, dtype=float)\n    for i in range(pop_size):\n        if evals_used >= budget:\n            break\n        y = objective_function(pop[i])\n        evals_used += 1\n        fitness[i] = y\n        if (y_best is None) or (y < y_best):\n            x_best, y_best = pop[i].copy(), y\n\n    if evals_used >= budget:\n        return x_best\n\n    evals_for_global = min(global_budget, budget - evals_used)\n    if evals_for_global <= 0:\n        # go directly to local refinement\n        remaining = budget - evals_used\n        if remaining <= 0:\n            return x_best\n\n        steps = remaining\n        base_step = 0.2\n        for i in range(steps):\n            if evals_used >= budget:\n                break\n            progress = i / max(1, steps - 1)\n            frac = base_step * (0.05 + 0.95 * (1.0 - progress))\n            step = frac * span\n\n            if i % 2 == 0 or dim == 1:\n                noise = rng.normal(0.0, 1.0, size=dim)\n                x_candidate = x_best + noise * step\n            else:\n                x_candidate = x_best.copy()\n                coord = rng.integers(0, dim)\n                step_coord = step[coord]\n                x_candidate[coord] += rng.normal(0.0, step_coord)\n\n            x_candidate = np.clip(x_candidate, low, high)\n            y = objective_function(x_candidate)\n            evals_used += 1\n            if y < y_best:\n                x_best, y_best = x_candidate, y\n        return x_best\n\n    # Conservative upper bound: each generation uses ~pop_size evaluations\n    max_generations = max(1, evals_for_global // max(1, pop_size))\n\n    base_mut_scale = 0.2\n\n    for gen in range(max_generations):\n        if evals_used >= budget:\n            break\n\n        # Rank population\n        order = np.argsort(fitness)\n        pop = pop[order]\n        fitness = fitness[order]\n\n        elite_frac = 0.3\n        n_elite = max(1, int(elite_frac * pop_size))\n        elites = pop[:n_elite]\n        elites_fit = fitness[:n_elite]\n\n        if elites_fit[0] < y_best:\n            x_best, y_best = elites[0].copy(), elites_fit[0]\n\n        new_pop = np.empty_like(pop)\n        new_pop[:n_elite] = elites\n\n        def select_parent():\n            idx1 = rng.integers(0, n_elite)\n            idx2 = rng.integers(0, n_elite)\n            return elites[idx1] if elites_fit[idx1] < elites_fit[idx2] else elites[idx2]\n\n        gen_frac = gen / max(1, max_generations - 1)\n        mut_scale = base_mut_scale * (0.7 + 0.3 * (1.0 - gen_frac))\n\n        # Create offspring\n        for i in range(n_elite, pop_size):\n            if rng.random() < 0.8:\n                p1 = select_parent()\n                p2 = select_parent()\n                alpha = rng.random(dim)\n                child = alpha * p1 + (1.0 - alpha) * p2\n            else:\n                base = elites[0] if rng.random() < 0.5 else select_parent()\n                child = base.copy()\n\n            noise = rng.normal(0.0, 1.0, size=dim)\n            child = child + noise * (mut_scale * span)\n            new_pop[i] = np.clip(child, low, high)\n\n        pop = new_pop\n\n        # Evaluate population\n        for i in range(pop_size):\n            if evals_used >= budget:\n                break\n            # Reuse elite fitness where possible\n            if i < n_elite:\n                fitness[i] = elites_fit[i]\n                if fitness[i] < y_best:\n                    x_best, y_best = pop[i].copy(), fitness[i]\n                continue\n            y = objective_function(pop[i])\n            evals_used += 1\n            fitness[i] = y\n            if y < y_best:\n                x_best, y_best = pop[i].copy(), y\n\n    if evals_used >= budget:\n        return x_best\n\n    # --- Local refinement phase around best found ---\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    steps = remaining\n    base_step = 0.2  # fraction of span\n    for i in range(steps):\n        if evals_used >= budget:\n            break\n        progress = i / max(1, steps - 1)\n        frac = base_step * (0.05 + 0.95 * (1.0 - progress))\n        step = frac * span\n\n        if i % 2 == 0 or dim == 1:\n            noise = rng.normal(0.0, 1.0, size=dim)\n            x_candidate = x_best + noise * step\n        else:\n            x_candidate = x_best.copy()\n            coord = rng.integers(0, dim)\n            step_coord = step[coord]\n            x_candidate[coord] += rng.normal(0.0, step_coord)\n\n        x_candidate = np.clip(x_candidate, low, high)\n        y = objective_function(x_candidate)\n        evals_used += 1\n        if y < y_best:\n            x_best, y_best = x_candidate, y\n\n    return x_best",
    "X": "0.9217312675901359 1.381305722614379"
}