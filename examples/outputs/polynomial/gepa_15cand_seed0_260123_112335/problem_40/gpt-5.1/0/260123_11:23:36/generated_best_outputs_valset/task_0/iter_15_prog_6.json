{
    "score": -1.0082707594402465,
    "Input": "OddSquare",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget\u2011aware black\u2011box optimizer: hybrid global + local search\n    using an evolutionary population plus adaptive local refinement.\n\n    This version keeps the overall structure but tweaks several details:\n    - More robust population sizing vs budget/dimension\n    - Slightly stronger initial global exploration, especially if no warm start\n    - Cleaner split of global/local budget and guaranteed full budget usage\n    - More careful handling of tiny / degenerate search spaces\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config.get(\"budget\", 1))\n\n    low = bounds[:, 0].astype(float)\n    high = bounds[:, 1].astype(float)\n    span = high - low\n\n    # Handle zero or negative budget: return center of bounds\n    if budget <= 0:\n        return ((low + high) / 2.0).reshape(dim)\n\n    # If all spans are ~0, space is essentially a single point\n    if np.all(span <= 1e-15):\n        return np.clip((low + high) / 2.0, low, high).reshape(dim)\n\n    rng = np.random.default_rng()\n    evals_used = 0\n\n    def project(x):\n        x = np.asarray(x, dtype=float).reshape(dim)\n        return np.clip(x, low, high)\n\n    # --- Initialization / warm start ---\n    x_best = None\n    y_best = None\n\n    # Warm start if available\n    if prev_best_x is not None and evals_used < budget:\n        x0 = project(prev_best_x)\n        y0 = objective_function(x0)\n        evals_used += 1\n        x_best, y_best = x0.copy(), y0\n\n    # Ensure at least one random sample if warm start missing or clearly poor\n    if (x_best is None) and (evals_used < budget):\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        x_best, y_best = x0.copy(), y0\n\n    if evals_used >= budget:\n        return x_best.reshape(dim)\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return x_best.reshape(dim)\n\n    # Very small budgets: perform only local randomized search around best\n    if remaining_budget <= 3:\n        base_step = 0.4\n        for i in range(remaining_budget):\n            if evals_used >= budget:\n                break\n            frac = base_step * (0.2 + 0.8 * (1.0 - i / max(1, remaining_budget - 1)))\n            step = frac * (span + 1e-12)\n            noise = rng.normal(0.0, 1.0, size=dim)\n            x_candidate = x_best + noise * step\n            x_candidate = np.clip(x_candidate, low, high)\n            y = objective_function(x_candidate)\n            evals_used += 1\n            if y < y_best:\n                x_best, y_best = x_candidate, y\n        return x_best.reshape(dim)\n\n    # --- Global evolutionary search phase ---\n    # Allocate ~65% of the remaining budget to global search, but reserve a tail\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return x_best.reshape(dim)\n\n    if remaining_budget <= 6:\n        global_budget = remaining_budget  # no real local phase possible\n    else:\n        global_budget = int(0.65 * remaining_budget)\n        global_budget = max(3, min(global_budget, remaining_budget - 2))\n\n    # Population size: adapt to dimension and budget, but not exceed budget\n    if remaining_budget <= 10:\n        pop_size = min(6, remaining_budget)\n    else:\n        # scale with log(dim) to keep evaluations reasonable for high dim\n        dim_factor = max(1.0, np.log2(dim + 1))\n        target = int(max(8, remaining_budget / (3.0 * dim_factor)))\n        pop_size = int(np.clip(target, 8, 40))\n        pop_size = min(pop_size, remaining_budget)\n\n    # Initialize population: mix of around-best and random\n    pop = np.empty((pop_size, dim), dtype=float)\n    around_frac = 0.5 if prev_best_x is not None else 0.3\n    n_around = int(around_frac * pop_size)\n    n_around = max(1, min(n_around, pop_size - 1)) if pop_size > 1 else 1\n    noise_scale = 0.35\n\n    for i in range(n_around):\n        noise = rng.normal(0.0, 1.0, size=dim)\n        candidate = x_best + noise * (noise_scale * (span + 1e-12))\n        pop[i] = np.clip(candidate, low, high)\n\n    if n_around < pop_size:\n        pop[n_around:] = rng.uniform(low, high, size=(pop_size - n_around, dim))\n\n    fitness = np.empty(pop_size, dtype=float)\n\n    # Evaluate initial population\n    for i in range(pop_size):\n        if evals_used >= budget:\n            break\n        if np.allclose(pop[i], x_best) and (y_best is not None):\n            y = y_best\n        else:\n            y = objective_function(pop[i])\n            evals_used += 1\n        fitness[i] = y\n        if (y_best is None) or (y < y_best):\n            x_best, y_best = pop[i].copy(), y\n\n    if evals_used >= budget:\n        return x_best.reshape(dim)\n\n    evals_for_global = min(global_budget, budget - evals_used)\n    if evals_for_global <= 0:\n        # No global phase left, go straight to local refinement\n        remaining = budget - evals_used\n        if remaining <= 0:\n            return x_best.reshape(dim)\n\n        steps = remaining\n        base_step = 0.25\n        for i in range(steps):\n            if evals_used >= budget:\n                break\n            progress = i / max(1, steps - 1)\n            frac = base_step * (0.05 + 0.95 * (1.0 - progress))\n            step = frac * (span + 1e-12)\n\n            if i % 2 == 0 or dim == 1:\n                noise = rng.normal(0.0, 1.0, size=dim)\n                x_candidate = x_best + noise * step\n            else:\n                x_candidate = x_best.copy()\n                coord = rng.integers(0, dim)\n                step_coord = step[coord]\n                x_candidate[coord] += rng.normal(0.0, step_coord)\n\n            x_candidate = np.clip(x_candidate, low, high)\n            y = objective_function(x_candidate)\n            evals_used += 1\n            if y < y_best:\n                x_best, y_best = x_candidate, y\n        return x_best.reshape(dim)\n\n    # Evolutionary loop\n    max_generations = max(1, evals_for_global // max(1, pop_size))\n    base_mut_scale = 0.3\n\n    for gen in range(max_generations):\n        if evals_used >= budget:\n            break\n\n        # Rank population\n        order = np.argsort(fitness)\n        pop = pop[order]\n        fitness = fitness[order]\n\n        elite_frac = 0.4\n        n_elite = max(1, int(elite_frac * pop_size))\n        elites = pop[:n_elite]\n        elites_fit = fitness[:n_elite]\n\n        if elites_fit[0] < y_best:\n            x_best, y_best = elites[0].copy(), elites_fit[0]\n\n        new_pop = np.empty_like(pop)\n        new_pop[:n_elite] = elites\n\n        def select_parent():\n            # small tournament selection among elites\n            k = 3 if n_elite >= 3 else 2\n            idxs = rng.integers(0, n_elite, size=k)\n            best_idx = idxs[0]\n            best_fit = elites_fit[best_idx]\n            for j in idxs[1:]:\n                if elites_fit[j] < best_fit:\n                    best_fit = elites_fit[j]\n                    best_idx = j\n            return elites[best_idx]\n\n        gen_frac = gen / max(1, max_generations - 1)\n        mut_scale = base_mut_scale * (0.4 + 0.6 * (1.0 - gen_frac))\n\n        # Create offspring\n        for i in range(n_elite, pop_size):\n            if rng.random() < 0.8:\n                p1 = select_parent()\n                p2 = select_parent()\n                alpha = rng.random(dim)\n                child = alpha * p1 + (1.0 - alpha) * p2\n            else:\n                base = elites[0] if rng.random() < 0.6 else select_parent()\n                child = base.copy()\n\n            noise = rng.normal(0.0, 1.0, size=dim)\n            child = child + noise * (mut_scale * (span + 1e-12))\n            new_pop[i] = np.clip(child, low, high)\n\n        pop = new_pop\n\n        # Evaluate population\n        for i in range(pop_size):\n            if evals_used >= budget:\n                break\n            if i < n_elite:\n                fitness[i] = elites_fit[i]\n                if fitness[i] < y_best:\n                    x_best, y_best = pop[i].copy(), fitness[i]\n                continue\n\n            y = objective_function(pop[i])\n            evals_used += 1\n            fitness[i] = y\n            if y < y_best:\n                x_best, y_best = pop[i].copy(), y\n\n        if evals_used >= budget or evals_used >= budget - 2:\n            break\n\n    if evals_used >= budget:\n        return x_best.reshape(dim)\n\n    # --- Local refinement phase around best found ---\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best.reshape(dim)\n\n    steps = remaining\n    base_step = 0.18\n    for i in range(steps):\n        if evals_used >= budget:\n            break\n        progress = i / max(1, steps - 1)\n        frac = base_step * (0.05 + 0.95 * (1.0 - progress))\n        step = frac * (span + 1e-12)\n\n        if (i % 2 == 0) or dim == 1:\n            noise = rng.normal(0.0, 1.0, size=dim)\n            x_candidate = x_best + noise * step\n        else:\n            x_candidate = x_best.copy()\n            coord = rng.integers(0, dim)\n            step_coord = step[coord]\n            x_candidate[coord] += rng.normal(0.0, step_coord)\n\n        x_candidate = np.clip(x_candidate, low, high)\n        y = objective_function(x_candidate)\n        evals_used += 1\n        if y < y_best:\n            x_best, y_best = x_candidate, y\n\n    return x_best.reshape(dim)",
    "X": "1.0829268397638976 1.2157974864377492"
}