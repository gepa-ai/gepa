{
    "score": -0.10241997493890068,
    "Input": "Ned01",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config.get(\"budget\", 1))\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    ranges = high - low\n    ranges[ranges <= 0] = 1.0  # safeguard for degenerate bounds\n\n    def clip(x):\n        return np.clip(x, low, high)\n\n    # Safeguard for tiny or invalid budgets\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    evals_used = 0\n    x_best = None\n    y_best = np.inf\n\n    # Safe evaluation wrapper with hard budget guard\n    def safe_eval(x):\n        nonlocal evals_used, x_best, y_best\n        if evals_used >= budget:\n            return None\n        x = clip(np.asarray(x, dtype=float).reshape(dim))\n        try:\n            y = objective_function(x)\n        except Exception:\n            evals_used = budget\n            return None\n        evals_used += 1\n        if isinstance(y, (list, tuple, np.ndarray)):\n            try:\n                y = float(np.asarray(y).ravel()[0])\n            except Exception:\n                y = float(y)\n        if y < y_best:\n            x_best, y_best = x, y\n        return y\n\n    # --- Initialization phase ---\n\n    # 1) Warm-start from previous best if available\n    if prev_best_x is not None:\n        try:\n            x0 = clip(np.asarray(prev_best_x, dtype=float).reshape(dim))\n            y0 = safe_eval(x0)\n            if y0 is None:\n                return x0 if x_best is None else x_best\n        except Exception:\n            pass\n\n    # 2) Midpoint baseline if nothing evaluated yet\n    if x_best is None:\n        x_mid = (low + high) / 2.0\n        y_mid = safe_eval(x_mid)\n        if y_mid is None:\n            return x_mid\n\n    if evals_used >= budget:\n        return x_best\n\n    # 3) One fresh random point for diversification (if budget allows)\n    if evals_used < budget:\n        x_rand = np.random.uniform(low, high, size=dim)\n        y_rand = safe_eval(x_rand)\n        if y_rand is None:\n            return x_best\n\n    if evals_used >= budget:\n        return x_best\n\n    # Remaining evaluations after initial seeding\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # --- Global exploration: diversified random / LHS-like sampling ---\n\n    # Adjust exploration fraction to be more exploratory for low budgets and high dimensions\n    if remaining < 15:\n        global_fraction = 0.8\n    elif dim > 20:\n        global_fraction = 0.7\n    else:\n        global_fraction = 0.5\n\n    global_evals = max(1, int(global_fraction * remaining))\n    global_evals = min(global_evals, remaining)\n\n    if global_evals > 0:\n        if global_evals >= dim:\n            base = (np.arange(global_evals) + np.random.rand(global_evals)) / global_evals\n            X = np.zeros((global_evals, dim), dtype=float)\n            for d in range(dim):\n                perm = np.random.permutation(global_evals)\n                X[:, d] = base[perm]\n            X = low + X * ranges\n        else:\n            X = np.random.uniform(low, high, size=(global_evals, dim))\n\n        for i in range(global_evals):\n            if evals_used >= budget:\n                break\n            if safe_eval(X[i]) is None:\n                break\n\n    if evals_used >= budget:\n        return x_best\n\n    # --- Local exploitation: random search around best with adaptive radius ---\n\n    remaining = budget - evals_used\n    if remaining <= 0 or x_best is None:\n        return x_best\n\n    # Use adaptive coordinate-wise local search (more stable in high dim)\n    # Initial radius as moderate fraction of range\n    base_radius = 0.2 * np.maximum(ranges, 1e-8)\n    radius = base_radius.copy()\n    min_radius = 1e-8 * np.maximum(ranges, 1.0)\n    max_radius = ranges\n\n    curr_center = x_best.copy()\n    curr_val = y_best\n\n    # Hyperparameters for adaptation\n    no_improve_streak = 0\n    shrink_factor = 0.5\n    grow_factor = 1.3\n    coord_shrink_factor = 0.7\n    coord_grow_factor = 1.1\n    max_no_improve = max(5, dim)\n\n    # To exploit budget well, use batches of local proposals per iteration\n    # batch size limited to dim and remaining evals\n    while evals_used < budget:\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n\n        batch_size = min(dim, remaining)\n\n        improved = False\n\n        # Coordinate-wise perturbations: each trial perturbs a small random subset of dims\n        for _ in range(batch_size):\n            if evals_used >= budget:\n                break\n\n            # Choose number of coordinates to perturb (1 to min(5, dim))\n            k = 1 if dim <= 3 else np.random.randint(1, min(5, dim) + 1)\n            idx = np.random.choice(dim, size=k, replace=False)\n\n            step = np.zeros(dim, dtype=float)\n            # scale step per coordinate radius\n            step[idx] = np.random.uniform(-1.0, 1.0, size=k) * radius[idx]\n            x_candidate = clip(curr_center + step)\n            y_candidate = safe_eval(x_candidate)\n            if y_candidate is None:\n                break\n\n            if y_candidate < curr_val:\n                curr_center = x_candidate\n                curr_val = y_candidate\n                improved = True\n                no_improve_streak = 0\n                # Slightly expand radius for successful coordinates\n                radius[idx] = np.minimum(radius[idx] * coord_grow_factor, max_radius[idx])\n            else:\n                # Slightly shrink radius for unsuccessful coordinates\n                radius[idx] = np.maximum(radius[idx] * coord_shrink_factor, min_radius[idx])\n                no_improve_streak += 1\n\n        if improved:\n            # Global radius expansion when improvement occurs\n            radius = np.minimum(radius * grow_factor, max_radius)\n        else:\n            if no_improve_streak >= max_no_improve:\n                # Global shrink when long no-improvement streak\n                radius = np.maximum(radius * shrink_factor, min_radius)\n                no_improve_streak = 0\n\n    if x_best is None:\n        return (low + high) / 2.0\n    return x_best",
    "X": "-7.99574442358099 -2.2469013810782212"
}