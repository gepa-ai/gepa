{
    "score": -0.10239011189172649,
    "Input": "Ned01",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config.get(\"budget\", 1))\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    ranges = high - low\n    ranges[ranges <= 0] = 1.0  # safeguard for degenerate bounds\n\n    def clip(x):\n        return np.clip(x, low, high)\n\n    # Safeguard for tiny or invalid budgets\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    evals_used = 0\n    x_best = None\n    y_best = np.inf\n\n    # Safe evaluation wrapper with hard budget guard\n    def safe_eval(x):\n        nonlocal evals_used, x_best, y_best\n        if evals_used >= budget:\n            return None\n        x = clip(np.asarray(x, dtype=float).reshape(dim))\n        try:\n            y = objective_function(x)\n        except Exception:\n            # Stop evaluating further on any exception from objective\n            evals_used = budget\n            return None\n        evals_used += 1\n        if isinstance(y, (list, tuple, np.ndarray)):\n            try:\n                y = float(np.asarray(y).ravel()[0])\n            except Exception:\n                y = float(y)\n        if y < y_best:\n            x_best, y_best = x, y\n        return y\n\n    # --- Initialization phase ---\n\n    # 1) Warm-start from previous best if available\n    if prev_best_x is not None:\n        try:\n            x0 = clip(np.asarray(prev_best_x, dtype=float).reshape(dim))\n            y0 = safe_eval(x0)\n            if y0 is None:\n                return x0 if x_best is None else x_best\n        except Exception:\n            pass\n\n    # 2) Midpoint baseline if nothing evaluated yet\n    if x_best is None:\n        x_mid = (low + high) / 2.0\n        y_mid = safe_eval(x_mid)\n        if y_mid is None:\n            return x_mid\n\n    if evals_used >= budget:\n        return x_best\n\n    # 3) One fresh random point for diversification (if budget allows)\n    if evals_used < budget:\n        x_rand = np.random.uniform(low, high, size=dim)\n        y_rand = safe_eval(x_rand)\n        if y_rand is None:\n            return x_best\n\n    if evals_used >= budget:\n        return x_best\n\n    # Remaining evaluations after initial seeding\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # --- Global exploration: diversified random / LHS-like sampling ---\n\n    # Use a larger exploration fraction for tiny budgets to avoid overfitting\n    if remaining < 15:\n        global_fraction = 0.7\n    else:\n        global_fraction = 0.5\n    global_evals = max(1, int(global_fraction * remaining))\n    global_evals = min(global_evals, remaining)\n\n    if global_evals > 0:\n        # Latin-hypercube-like if enough points vs dimensions\n        if global_evals >= dim:\n            base = (np.arange(global_evals) + np.random.rand(global_evals)) / global_evals\n            X = np.zeros((global_evals, dim), dtype=float)\n            for d in range(dim):\n                perm = np.random.permutation(global_evals)\n                X[:, d] = base[perm]\n            X = low + X * ranges\n        else:\n            X = np.random.uniform(low, high, size=(global_evals, dim))\n\n        for i in range(global_evals):\n            if evals_used >= budget:\n                break\n            if safe_eval(X[i]) is None:\n                break\n\n    if evals_used >= budget:\n        return x_best\n\n    # --- Local exploitation: simple covariance-adapting ES around best ---\n\n    remaining = budget - evals_used\n    if remaining <= 0 or x_best is None:\n        return x_best\n\n    # Population size scaled with dim but capped for stability\n    lambd = max(4, min(20, 2 * dim))\n    if lambd <= 0:\n        return x_best\n\n    # Number of generations given remaining budget\n    max_generations = max(1, remaining // lambd) if remaining >= lambd else 1\n\n    # Step-size settings\n    sigma = 0.3 * ranges\n    sigma = np.maximum(sigma, 1e-8 * np.maximum(ranges, 1.0))\n    min_sigma = 1e-8 * np.maximum(ranges, 1.0)\n    max_sigma = ranges\n\n    center = x_best.copy()\n    center_val = y_best\n\n    # Pre-compute recombination weights (rank-based) to stabilize adaptation\n    mu = max(1, lambd // 2)\n    weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n    weights = weights / np.sum(weights)\n\n    for _ in range(max_generations):\n        if evals_used >= budget:\n            break\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n\n        pop_size = min(lambd, remaining)\n        if pop_size <= 0:\n            break\n\n        Z = np.random.randn(pop_size, dim)\n        X_pop = clip(center + Z * sigma)\n        Y_pop = np.full(pop_size, np.inf, dtype=float)\n\n        for i in range(pop_size):\n            if evals_used >= budget:\n                break\n            y = safe_eval(X_pop[i])\n            if y is None:\n                break\n            Y_pop[i] = y\n\n        if evals_used >= budget:\n            break\n\n        mask = np.isfinite(Y_pop)\n        if not np.any(mask):\n            break\n\n        # Sort evaluated individuals\n        valid_idx = np.where(mask)[0]\n        sorted_valid = valid_idx[np.argsort(Y_pop[valid_idx])]\n        k = min(mu, sorted_valid.size)\n        best_idx = sorted_valid[:k]\n\n        # Weighted recombination\n        new_center = np.sum(X_pop[best_idx] * weights[:k, None], axis=0)\n\n        # Update strategy parameters based on improvement\n        if y_best < center_val:\n            # Improvement: move center and slightly increase step-size\n            center = 0.6 * center + 0.4 * new_center\n            sigma = np.minimum(sigma * 1.15, max_sigma)\n            center_val = y_best\n        else:\n            # No improvement: reduce step-size to refine search\n            center = 0.5 * center + 0.5 * new_center\n            sigma = np.maximum(sigma * 0.7, min_sigma)\n\n    return x_best if x_best is not None else (low + high) / 2.0",
    "X": "-7.995744420633963 -2.246901312540581"
}