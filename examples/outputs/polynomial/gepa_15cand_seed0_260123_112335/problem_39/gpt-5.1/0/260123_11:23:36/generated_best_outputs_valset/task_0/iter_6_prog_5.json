{
    "score": -0.1024070240862908,
    "Input": "Ned01",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config.get(\"budget\", 1))\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    ranges = high - low\n    ranges[ranges <= 0] = 1.0  # safeguard for degenerate bounds\n\n    def clip(x):\n        return np.clip(x, low, high)\n\n    # Safeguard for tiny or invalid budgets\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    evals_used = 0\n    x_best = None\n    y_best = np.inf\n\n    # Safe evaluation wrapper with hard budget guard\n    def safe_eval(x):\n        nonlocal evals_used, x_best, y_best\n        if evals_used >= budget:\n            return None\n        x = clip(np.asarray(x, dtype=float).reshape(dim))\n        try:\n            y = objective_function(x)\n        except Exception:\n            evals_used = budget\n            return None\n        evals_used += 1\n        if isinstance(y, (list, tuple, np.ndarray)):\n            try:\n                y = float(np.asarray(y).ravel()[0])\n            except Exception:\n                y = float(y)\n        if y < y_best:\n            x_best, y_best = x, y\n        return y\n\n    # --- Initialization phase ---\n\n    # 1) Warm-start from previous best if available\n    if prev_best_x is not None:\n        try:\n            x0 = clip(np.asarray(prev_best_x, dtype=float).reshape(dim))\n            y0 = safe_eval(x0)\n            if y0 is None:\n                return x0 if x_best is None else x_best\n        except Exception:\n            pass\n\n    # 2) Midpoint baseline if nothing evaluated yet\n    if x_best is None:\n        x_mid = (low + high) / 2.0\n        y_mid = safe_eval(x_mid)\n        if y_mid is None:\n            return x_mid\n\n    if evals_used >= budget:\n        return x_best\n\n    # 3) One fresh random point for diversification (if budget allows)\n    if evals_used < budget:\n        x_rand = np.random.uniform(low, high, size=dim)\n        y_rand = safe_eval(x_rand)\n        if y_rand is None:\n            return x_best\n\n    if evals_used >= budget:\n        return x_best\n\n    # Remaining evaluations after initial seeding\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # --- Global exploration: diversified random / LHS-like sampling ---\n\n    # Adjust exploration fraction to be more exploratory for low budgets and high dimensions\n    if remaining < 15:\n        global_fraction = 0.8\n    elif dim > 20:\n        global_fraction = 0.7\n    else:\n        global_fraction = 0.5\n\n    global_evals = max(1, int(global_fraction * remaining))\n    global_evals = min(global_evals, remaining)\n\n    if global_evals > 0:\n        if global_evals >= dim:\n            base = (np.arange(global_evals) + np.random.rand(global_evals)) / global_evals\n            X = np.zeros((global_evals, dim), dtype=float)\n            for d in range(dim):\n                perm = np.random.permutation(global_evals)\n                X[:, d] = base[perm]\n            X = low + X * ranges\n        else:\n            X = np.random.uniform(low, high, size=(global_evals, dim))\n\n        for i in range(global_evals):\n            if evals_used >= budget:\n                break\n            if safe_eval(X[i]) is None:\n                break\n\n    if evals_used >= budget:\n        return x_best\n\n    # --- Local exploitation: random search around best with adaptive radius ---\n\n    remaining = budget - evals_used\n    if remaining <= 0 or x_best is None:\n        return x_best\n\n    # Use a robust, simple local search instead of ES to avoid step-size pathologies\n    # Start radius as fraction of range; adapt based on improvements\n    radius = 0.25 * ranges\n    min_radius = 1e-8 * np.maximum(ranges, 1.0)\n    max_radius = ranges\n\n    curr_center = x_best.copy()\n    curr_val = y_best\n\n    # We will use all remaining evaluations for local exploitation\n    # Adaptive scheme: if improvement found in last k trials, slightly expand radius,\n    # otherwise shrink.\n    no_improve_streak = 0\n    shrink_factor = 0.5\n    grow_factor = 1.2\n    max_no_improve = max(5, dim)\n\n    while evals_used < budget:\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n\n        # Single-sample local perturbation for simplicity and robustness\n        step = (np.random.uniform(-1.0, 1.0, size=dim)) * radius\n        x_candidate = clip(curr_center + step)\n        y_candidate = safe_eval(x_candidate)\n        if y_candidate is None:\n            break\n\n        if y_candidate < curr_val:\n            curr_center = x_candidate\n            curr_val = y_candidate\n            no_improve_streak = 0\n            # Expand radius slightly towards max to encourage escape from small basins\n            radius = np.minimum(radius * grow_factor, max_radius)\n        else:\n            no_improve_streak += 1\n            if no_improve_streak >= max_no_improve:\n                radius = np.maximum(radius * shrink_factor, min_radius)\n                no_improve_streak = 0\n\n    # Ensure returned best is consistent\n    if x_best is None:\n        return (low + high) / 2.0\n    return x_best",
    "X": "-7.99574442358099 -2.2469013744854722"
}