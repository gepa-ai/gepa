{
    "score": -2.5193959701738082,
    "Input": "McCourt10",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global-local derivative-free optimization with adaptive budget use.\n\n    Strategy (kept and slightly refined from previous version):\n    - Warm start from prev_best_x if provided and within bounds.\n    - Use low-discrepancy (Halton-like) sampling for global exploration.\n    - Follow with coordinate pattern search from the best point.\n    - More robust allocation of global/local evaluations, especially for small/medium budgets.\n    - Slightly more aggressive local search when budget allows.\n\n    The function always respects the evaluation budget and returns the best\n    solution found as a numpy array of shape (dim,).\n    \"\"\"\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    # Handle degenerate dimension early\n    if dim <= 0:\n        return np.zeros(0, dtype=float)\n\n    low, high = bounds[:, 0], bounds[:, 1]\n    span = high - low\n    span_safe = span.copy()\n    span_safe[span_safe == 0.0] = 1.0\n\n    def clip_to_bounds(x):\n        return np.minimum(np.maximum(x, low), high)\n\n    evals_used = 0\n\n    # If no budget, return a mid-point (best guess without evaluations)\n    if budget <= 0:\n        return clip_to_bounds((low + high) * 0.5)\n\n    best_x = None\n    best_y = None\n\n    # ---- Warm start from prev_best_x if provided ----\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float)\n            if x0.size == dim and x0.shape != (dim,):\n                x0 = x0.reshape((dim,))\n            elif x0.size != dim:\n                raise ValueError(\"prev_best_x has wrong size\")\n            x0 = clip_to_bounds(x0)\n            y0 = objective_function(x0)\n            evals_used += 1\n            best_x, best_y = x0, y0\n        except Exception:\n            best_x, best_y = None, None\n\n    if evals_used >= budget:\n        if best_x is not None:\n            return best_x\n        return clip_to_bounds((low + high) * 0.5)\n\n    # ---- If no valid warm start, create a starting point ----\n    if best_x is None:\n        if budget - evals_used == 1:\n            x0 = clip_to_bounds((low + high) * 0.5)\n        else:\n            x0 = np.random.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    if evals_used >= budget:\n        return best_x\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # ---- Extremely tiny budgets: focus on local sampling around best_x ----\n    if budget <= 5:\n        for _ in range(remaining):\n            noise_scale = 0.15 if budget <= 3 else 0.1\n            noise = noise_scale * span_safe * np.random.uniform(-1.0, 1.0, size=dim)\n            x = clip_to_bounds(best_x + noise)\n            y = objective_function(x)\n            evals_used += 1\n            if y < best_y:\n                best_x, best_y = x, y\n            if evals_used >= budget:\n                break\n        return best_x\n\n    # ---- Global search: low-discrepancy (Halton-like) sampling ----\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Budget split between global and local search.\n    # Keep some flexibility but ensure at least a small local phase.\n    if budget < 20:\n        global_frac = 0.55\n    elif dim <= 5:\n        global_frac = 0.4\n    elif dim <= 15:\n        global_frac = 0.5\n    else:\n        global_frac = 0.6\n\n    # Proposed number of global evaluations based on total budget\n    proposed_global = int(global_frac * budget)\n\n    # Ensure room for local search: at least one full coordinate sweep if possible\n    min_local_evals = 2 * dim\n    if budget < 10:\n        min_local_evals = dim  # tiny budgets can't afford full sweeps\n\n    max_global_evals = max(0, remaining - min_local_evals)\n    if max_global_evals <= 0:\n        global_evals = max(1, min(remaining, dim + 2))\n    else:\n        global_evals = min(proposed_global, max_global_evals)\n        global_evals = max(2, global_evals)\n\n    global_evals = min(global_evals, remaining)\n\n    if global_evals < 1:\n        global_evals = min(remaining, max(1, dim))\n\n    # Helper: first n primes (for Halton bases)\n    def _primes(n):\n        primes = []\n        candidate = 2\n        while len(primes) < n:\n            is_p = True\n            for p in primes:\n                if p * p > candidate:\n                    break\n                if candidate % p == 0:\n                    is_p = False\n                    break\n            if is_p:\n                primes.append(candidate)\n            candidate += 1\n        return primes\n\n    bases = _primes(dim)\n    offset = np.random.randint(0, 1_000_000)\n\n    def halton_point(index):\n        seq = np.empty(dim, dtype=float)\n        i = index + offset\n        for k, b in enumerate(bases):\n            f = 1.0\n            r = 0.0\n            ii = i\n            while ii > 0:\n                f /= b\n                r += f * (ii % b)\n                ii //= b\n            seq[k] = r\n        return seq\n\n    for j in range(1, global_evals + 1):\n        if evals_used >= budget:\n            break\n        u = halton_point(j)\n        x = low + u * span\n        x = clip_to_bounds(x)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x\n\n    if evals_used >= budget:\n        return best_x\n\n    # ---- Local search: coordinate pattern search from best_x ----\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    x = best_x.copy()\n    y = best_y\n\n    # Step size as fraction of span; adapt based on dim and budget\n    base_step_scale = 0.25\n    if dim > 20:\n        base_step_scale = 0.2\n    if budget < 50:\n        base_step_scale *= 0.7\n    if budget > 200 and dim <= 10:\n        base_step_scale *= 1.2\n\n    step = base_step_scale * span_safe\n    min_step_scale = 1e-6\n\n    # Each local iteration costs at most ~2*dim evaluations.\n    max_local_iters = max(1, remaining // (2 * dim))\n    # Allow a few extra iterations for small dims / larger budgets\n    if dim <= 5 and remaining > 4 * dim:\n        max_local_iters = min(max_local_iters + 2, remaining // max(1, dim))\n\n    it = 0\n    while evals_used < budget and it < max_local_iters:\n        it += 1\n        improved = False\n\n        for i in range(dim):\n            if evals_used >= budget:\n                break\n\n            if span[i] == 0.0 and step[i] * step[i] < 1e-16:\n                continue\n\n            # Positive direction\n            xp = x.copy()\n            xp[i] = xp[i] + step[i]\n            xp = clip_to_bounds(xp)\n            yp = objective_function(xp)\n            evals_used += 1\n\n            if yp < y:\n                x, y = xp, yp\n                improved = True\n                if y < best_y:\n                    best_x, best_y = x, y\n                if evals_used >= budget:\n                    break\n\n                # Extra extrapolated step for acceleration\n                xpp = x.copy()\n                xpp[i] = xpp[i] + step[i]\n                xpp = clip_to_bounds(xpp)\n                if evals_used < budget:\n                    ypp = objective_function(xpp)\n                    evals_used += 1\n                    if ypp < y:\n                        x, y = xpp, ypp\n                        if y < best_y:\n                            best_x, best_y = x, y\n                continue  # Skip negative step once positive improved\n\n            if evals_used >= budget:\n                break\n\n            # Negative direction\n            xn = x.copy()\n            xn[i] = xn[i] - step[i]\n            xn = clip_to_bounds(xn)\n            yn = objective_function(xn)\n            evals_used += 1\n\n            if yn < y:\n                x, y = xn, yn\n                improved = True\n                if y < best_y:\n                    best_x, best_y = x, y\n\n        if not improved:\n            step *= 0.5\n            # Stop if steps become too tiny relative to domain\n            if np.all(step < min_step_scale * np.maximum(span_safe, 1.0)):\n                break\n\n    return best_x",
    "X": "0.5085224859203518 0.5432906307061769 0.22728136272027988 1.0 0.3380583467205137 0.0254913330078125 1.0 0.5037754800774713"
}