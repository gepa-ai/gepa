{
    "score": -2.5193959700579245,
    "Input": "McCourt10",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global-local derivative-free optimization with adaptive budget use.\n\n    Improvements over previous version:\n    - Always guarantees a valid return (falls back to a reasonable point if budget==0).\n    - More robust handling of tiny budgets (1\u20135 evaluations).\n    - Slightly rebalanced global/local budget split to ensure local refinement when possible.\n    - Minor safeguards for numerical issues and degenerate bounds.\n\n    Strategy:\n    - Warm start from prev_best_x if provided and within bounds.\n    - Use low-discrepancy (Halton-like) sampling for global exploration.\n    - Follow with coordinate pattern search from the best point.\n    \"\"\"\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    # Handle degenerate dimension early\n    if dim <= 0:\n        return np.zeros(0, dtype=float)\n\n    low, high = bounds[:, 0], bounds[:, 1]\n    span = high - low\n    # Avoid zero for scaling; for zero-span dims, we'll still clip to fixed value\n    span_safe = span.copy()\n    span_safe[span_safe == 0.0] = 1.0\n\n    # Utility: project to bounds\n    def clip_to_bounds(x):\n        return np.minimum(np.maximum(x, low), high)\n\n    evals_used = 0\n\n    # ---- Handle extremely small budgets robustly ----\n    # If we have no budget, just return a mid-point (best guess without evaluations)\n    if budget <= 0:\n        return clip_to_bounds((low + high) * 0.5)\n\n    best_x = None\n    best_y = None\n\n    # ---- Initial / warm start evaluation ----\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float)\n            if x0.shape != (dim,):\n                # Try to reshape flat arrays\n                x0 = np.reshape(x0, (dim,))\n            x0 = clip_to_bounds(x0)\n            best_x = x0\n            best_y = objective_function(best_x)\n            evals_used += 1\n        except Exception:\n            # If anything goes wrong with prev_best_x, ignore it\n            best_x = None\n            best_y = None\n\n    # If we already exhausted budget via warm start, ensure we return something\n    if evals_used >= budget:\n        if best_x is not None:\n            return best_x\n        # Fallback if somehow best_x is None but budget used\n        return clip_to_bounds((low + high) * 0.5)\n\n    # If no warm start, create a random starting point (or center if very small budget)\n    if best_x is None:\n        if budget - evals_used == 1:\n            # Only one evaluation: choose center of domain\n            x0 = clip_to_bounds((low + high) * 0.5)\n        else:\n            x0 = np.random.uniform(low, high)\n        best_x = x0\n        best_y = objective_function(best_x)\n        evals_used += 1\n\n    if evals_used >= budget:\n        return best_x\n\n    # ---- If budget is tiny, skip heavy global/local logic ----\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    if budget <= 5:\n        # For very tiny budgets, just sample random points around best_x\n        for _ in range(remaining):\n            # Small perturbation relative to domain; clamp to bounds\n            noise = 0.1 * span_safe * np.random.uniform(-1.0, 1.0, size=dim)\n            x = clip_to_bounds(best_x + noise)\n            y = objective_function(x)\n            evals_used += 1\n            if y < best_y:\n                best_x, best_y = x, y\n            if evals_used >= budget:\n                break\n        return best_x\n\n    # ---- Global search: low-discrepancy sampling ----\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Budget split between global and local search.\n    # Ensure at least some evaluations for local refinement when budget allows.\n    if budget < 20:\n        global_frac = 0.55\n    elif dim <= 5:\n        global_frac = 0.35\n    elif dim <= 15:\n        global_frac = 0.45\n    else:\n        global_frac = 0.55\n\n    # Aim global based on total budget, but capped by remaining\n    global_evals = int(global_frac * budget)\n    # Guarantee at least a few global samples\n    global_evals = max(min(remaining - 2 * dim, remaining // 2), min(dim + 3, remaining, max(global_evals, 2)))\n    if global_evals < 0:\n        global_evals = min(remaining, max(dim + 2, 2))\n\n    # Helper: first n primes\n    def _primes(n):\n        primes = []\n        candidate = 2\n        while len(primes) < n:\n            is_p = True\n            for p in primes:\n                if p * p > candidate:\n                    break\n                if candidate % p == 0:\n                    is_p = False\n                    break\n            if is_p:\n                primes.append(candidate)\n            candidate += 1\n        return primes\n\n    bases = _primes(dim)\n    offset = np.random.randint(0, 1_000_000)\n\n    def halton_point(index):\n        # index >= 1\n        seq = np.empty(dim, dtype=float)\n        i = index + offset\n        for k, b in enumerate(bases):\n            f = 1.0\n            r = 0.0\n            ii = i\n            while ii > 0:\n                f /= b\n                r += f * (ii % b)\n                ii //= b\n            seq[k] = r\n        return seq\n\n    for j in range(1, global_evals + 1):\n        if evals_used >= budget:\n            break\n        u = halton_point(j)\n        x = low + u * span\n        x = clip_to_bounds(x)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x\n\n    if evals_used >= budget:\n        return best_x\n\n    # ---- Local search: coordinate pattern search starting from best_x ----\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    x = best_x.copy()\n    y = best_y\n\n    # Step size as fraction of span; adapt based on budget and dimension\n    base_step_scale = 0.25\n    if dim > 20:\n        base_step_scale = 0.2\n    if budget < 50:\n        base_step_scale *= 0.7\n\n    step = base_step_scale * span_safe\n    # For zero-span dimensions, step will be non-zero but clip_to_bounds keeps value fixed\n\n    min_step_scale = 1e-6\n\n    # each local iteration costs up to ~2*dim evaluations\n    max_local_iters = max(1, remaining // (2 * dim))\n\n    it = 0\n    while evals_used < budget and it < max_local_iters:\n        it += 1\n        improved = False\n\n        for i in range(dim):\n            if evals_used >= budget:\n                break\n\n            # Skip dimension if effectively no domain width and step is tiny\n            if span[i] == 0.0 and step[i] * step[i] < 1e-16:\n                continue\n\n            # Positive direction\n            xp = x.copy()\n            xp[i] = xp[i] + step[i]\n            xp = clip_to_bounds(xp)\n            yp = objective_function(xp)\n            evals_used += 1\n\n            if yp < y:\n                x, y = xp, yp\n                improved = True\n                if y < best_y:\n                    best_x, best_y = x, y\n                if evals_used >= budget:\n                    break\n                # Extra extrapolated step\n                xpp = x.copy()\n                xpp[i] = xpp[i] + step[i]\n                xpp = clip_to_bounds(xpp)\n                if evals_used < budget:\n                    ypp = objective_function(xpp)\n                    evals_used += 1\n                    if ypp < y:\n                        x, y = xpp, ypp\n                        if y < best_y:\n                            best_x, best_y = x, y\n                continue  # skip negative direction after improvement\n\n            if evals_used >= budget:\n                break\n\n            # Negative direction\n            xn = x.copy()\n            xn[i] = xn[i] - step[i]\n            xn = clip_to_bounds(xn)\n            yn = objective_function(xn)\n            evals_used += 1\n            if yn < y:\n                x, y = xn, yn\n                improved = True\n                if y < best_y:\n                    best_x, best_y = x, y\n\n        if not improved:\n            step *= 0.5\n            # If step sizes are tiny relative to domain, stop local search\n            if np.all(step < min_step_scale * np.maximum(span_safe, 1.0)):\n                break\n\n    return best_x",
    "X": "0.5085224859203518 0.5432997859796144 0.22728136272027988 1.0 0.3380583467205137 0.025482177734375 1.0 0.5037754800774713"
}