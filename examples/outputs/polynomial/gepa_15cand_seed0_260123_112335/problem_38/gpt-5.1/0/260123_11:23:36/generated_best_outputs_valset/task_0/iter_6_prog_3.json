{
    "score": -2.283949838435264,
    "Input": "Mishra06",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config.get(\"budget\", 1))\n\n    lower, upper = bounds[:, 0], bounds[:, 1]\n    span = upper - lower\n    # Avoid zero span issues\n    span = np.where(span == 0.0, 1.0, span)\n\n    rng = np.random.RandomState()\n\n    def project(x):\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # --- Warm start / initial points ---\n    if prev_best_x is not None and evals_used < budget:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = project(x0)\n            y0 = objective_function(x0)\n            evals_used += 1\n            best_x, best_y = x0, y0\n\n    if best_x is None and evals_used < budget:\n        x0 = rng.uniform(lower, upper, size=dim)\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    if evals_used >= budget:\n        return best_x.astype(float)\n\n    remaining = budget - evals_used\n\n    # --- Phase allocation: global + local + short line-search ---\n    if remaining <= 5:\n        global_evals = remaining\n        local_evals = 0\n        line_evals = 0\n    else:\n        # Slightly more global exploration for robustness\n        global_evals = int(0.7 * remaining)\n        global_evals = max(4, min(global_evals, remaining - 3))\n        # Reserve a few evaluations for a simple line-search refinement\n        line_evals = 2 if remaining - global_evals >= 3 else 0\n        local_evals = remaining - global_evals - line_evals\n\n    # --- Global search: mixture of uniform, best-centered Gaussian and LHS-like ---\n    # Add a simple low-discrepancy style exploration in [-0.5,0.5]^dim scaled to bounds\n    for g in range(global_evals):\n        r = rng.rand()\n        if r < 0.4 and best_x is not None:\n            # Best-centered Gaussian with adaptive scale\n            scale = 0.15 * span\n            noise = rng.normal(0.0, 1.0, size=dim) * scale\n            cand = best_x + noise\n        elif r < 0.8:\n            # Pure global uniform\n            cand = rng.uniform(lower, upper, size=dim)\n        else:\n            # Quasi-LHS like: stratified in 1D then random permutation over dims\n            t = (g + rng.rand()) / (global_evals + 1.0)\n            base = lower + span * np.clip(t, 0.0, 1.0)\n            # Add small random perturbation per dimension\n            cand = base + (rng.rand(dim) - 0.5) * 0.2 * span\n\n        cand = project(cand)\n        y = objective_function(cand)\n        evals_used += 1\n\n        if y < best_y:\n            best_x, best_y = cand, y\n\n        if evals_used >= budget:\n            return best_x.astype(float)\n\n    if evals_used >= budget or (local_evals <= 0 and line_evals <= 0):\n        return best_x.astype(float)\n\n    # --- Local search: stochastic coordinate search with adaptive radius ---\n    x = best_x.copy()\n    # Start at moderate step size; adapt later\n    step = 0.08 * span\n    step = np.where(step <= 0.0, 1.0, step)\n\n    min_step = 1e-6 * span\n    min_step = np.where(min_step <= 0.0, 1e-6, min_step)\n    max_step = 0.5 * span\n\n    for _ in range(local_evals):\n        if dim == 1:\n            idxs = [0]\n        else:\n            # Bias to 1-D moves but occasionally use 2-D\n            k = 1 if rng.rand() < 0.75 else min(2, dim)\n            idxs = rng.choice(dim, size=k, replace=False)\n\n        cand = x.copy()\n        for i in idxs:\n            direction = rng.choice([-1.0, 1.0])\n            mag = step[i] * (0.3 + 0.9 * rng.rand())\n            cand[i] += direction * mag\n\n        cand = project(cand)\n        y = objective_function(cand)\n        evals_used += 1\n\n        if y < best_y:\n            best_y = y\n            best_x = cand\n            x = cand\n            for i in idxs:\n                step[i] = min(step[i] * 1.2, max_step[i])\n        else:\n            for i in idxs:\n                step[i] *= 0.5\n                if step[i] < min_step[i]:\n                    step[i] = min_step[i]\n\n        if evals_used >= budget:\n            return best_x.astype(float)\n\n    # --- Simple line-search refinement along best direction seen so far ---\n    if line_evals > 0 and evals_used < budget and best_x is not None:\n        # Try small moves along each coordinate, pick best direction then refine there\n        x = best_x.copy()\n        # Use reduced step for fine-tuning\n        base_step = 0.02 * span\n        base_step = np.where(base_step <= 0.0, 1e-3, base_step)\n\n        # First coarse scan if budget allows\n        if line_evals >= 2:\n            for i in range(dim):\n                if evals_used >= budget or line_evals <= 0:\n                    break\n                for direction in (-1.0, 1.0):\n                    cand = x.copy()\n                    cand[i] += direction * base_step[i]\n                    cand = project(cand)\n                    y = objective_function(cand)\n                    evals_used += 1\n                    line_evals -= 1\n                    if y < best_y:\n                        best_y = y\n                        best_x = cand\n                        x = cand\n                    if evals_used >= budget or line_evals <= 0:\n                        break\n\n        # If still have budget, try a slightly larger or smaller step on best coord\n        if evals_used < budget and line_evals > 0:\n            # Choose coordinate with largest span (often more sensitive)\n            i = int(np.argmax(span))\n            for _ in range(line_evals):\n                if evals_used >= budget:\n                    break\n                direction = rng.choice([-1.0, 1.0])\n                scale = rng.choice([0.5, 1.0, 1.5])\n                cand = best_x.copy()\n                cand[i] += direction * base_step[i] * scale\n                cand = project(cand)\n                y = objective_function(cand)\n                evals_used += 1\n                if y < best_y:\n                    best_y = y\n                    best_x = cand\n\n    return best_x.astype(float)",
    "X": "2.886309364366683 1.823262308329116"
}