{
    "score": 3.5735540993807237e-10,
    "Input": "Pinter",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization using a hybrid global-local strategy:\n\n    - Global search via quasi-random (LHS-like) sampling\n    - Focused refinement around elite points\n    - Local coordinate-wise hill climbing from the best point\n    - Warm start from prev_best_x if provided\n\n    Assumes:\n        config['bounds']: array-like of shape (dim, 2)\n        config['dim']: int\n        config['budget']: int\n    Returns:\n        best_x: numpy array of shape (dim,)\n    \"\"\"\n    rng = np.random.RandomState()\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    def clip(x):\n        return np.minimum(high, np.maximum(low, x))\n\n    def eval_point(x):\n        return objective_function(x)\n\n    # Handle tiny budgets robustly\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    evals = 0\n    best_x = None\n    best_y = None\n\n    # Initialization: warm start if available, otherwise random in bounds\n    if prev_best_x is not None:\n        x0 = clip(np.asarray(prev_best_x, dtype=float).reshape(dim))\n    else:\n        x0 = rng.uniform(low, high)\n\n    y0 = eval_point(x0)\n    evals += 1\n    best_x, best_y = x0, y0\n\n    if evals >= budget:\n        return best_x\n\n    # Decide budgets for phases: global sampling, elite refinement, local search\n    remaining = budget - evals\n\n    # Use ~60% of total budget for global exploration (including the initial eval)\n    target_global_total = int(0.6 * budget)\n    target_global_total = max(dim + 3, target_global_total)\n    global_budget = max(0, min(target_global_total - 1, remaining))  # -1 for the initial eval\n\n    # Global sampling (LHS-like)\n    if global_budget > 0:\n        n_global = global_budget\n        # Latin-hypercube-like stratification on [0,1]^dim then scale\n        strata = (rng.rand(n_global, dim) + np.arange(n_global)[:, None]) / n_global\n        for d in range(dim):\n            rng.shuffle(strata[:, d])\n        samples = low + strata * span\n\n        ys = np.empty(n_global)\n        for i in range(n_global):\n            if evals >= budget:\n                break\n            x = samples[i]\n            y = eval_point(x)\n            ys[i] = y\n            evals += 1\n            if y < best_y:\n                best_x, best_y = x, y\n\n        remaining = budget - evals\n    else:\n        ys = np.empty(0)\n        samples = np.empty((0, dim))\n\n    if remaining <= 0:\n        return best_x\n\n    # Elite refinement: sample around top-k points from global phase + best_x\n    # This keeps successful global exploration but adds exploitation around elites.\n    if samples.shape[0] > 0:\n        # Combine best_x with sampled points and their scores\n        all_points = np.vstack([best_x[None, :], samples])\n        all_scores = np.concatenate([[best_y], ys])\n    else:\n        all_points = best_x[None, :]\n        all_scores = np.array([best_y])\n\n    # Determine number of elites (at least 1, at most 5 or number of available points)\n    k_elite = min(5, all_points.shape[0])\n    elite_idx = np.argpartition(all_scores, k_elite - 1)[:k_elite]\n    elites = all_points[elite_idx]\n\n    # Allocate ~20% of total budget (but not more than remaining) to elite refinement\n    target_refine_total = int(0.2 * budget)\n    refine_budget = max(0, min(target_refine_total, remaining))\n\n    if refine_budget > 0:\n        # Split evenly across elites\n        per_elite = max(1, refine_budget // k_elite)\n        sigma0 = 0.1 * span  # initial radius relative to bounds\n\n        for e in range(k_elite):\n            if evals >= budget:\n                break\n            center = elites[e]\n            sigma = sigma0.copy()\n            # Each elite gets per_elite evaluations\n            n_elite_evals = min(per_elite, budget - evals)\n            # Simple Gaussian sampling around elite with decreasing sigma\n            for _ in range(n_elite_evals):\n                if evals >= budget:\n                    break\n                z = rng.normal(size=dim)\n                cand = clip(center + z * sigma)\n                y = eval_point(cand)\n                evals += 1\n                if y < best_y:\n                    best_x, best_y = cand, y\n                    center = cand  # move center to improved point\n                # Gradually shrink sigma to focus search\n                sigma *= 0.9\n\n    remaining = budget - evals\n    if remaining <= 0:\n        return best_x\n\n    # Local search phase: coordinate-wise hill climbing from best_x\n    # This preserves the previous successful behavior but with tuned parameters.\n    current_x = clip(np.array(best_x, dtype=float))\n    current_y = best_y\n\n    # Use one extra eval to confirm current_x if it wasn't evaluated directly here\n    # (best_x was always evaluated earlier, so we skip this to save budget.)\n\n    base_step = 0.15 * span  # slightly smaller than old 0.2 to reduce overshooting\n\n    step = base_step.copy()\n    # Allocate all remaining budget to local search\n    # Each iteration can use up to 2*dim evaluations (pos + neg per dimension)\n    max_iters = max(1, remaining // (2 * dim))\n    # Allow more local iterations than before but still capped to protect exploration\n    max_iters = min(max_iters, 25)\n\n    for _ in range(max_iters):\n        if evals >= budget:\n            break\n        improved = False\n        for d in range(dim):\n            if evals >= budget:\n                break\n\n            # Positive step\n            cand_pos = current_x.copy()\n            cand_pos[d] = cand_pos[d] + step[d]\n            cand_pos = clip(cand_pos)\n            y_pos = eval_point(cand_pos)\n            evals += 1\n            if y_pos < current_y:\n                current_x, current_y = cand_pos, y_pos\n                if current_y < best_y:\n                    best_x, best_y = current_x, current_y\n                improved = True\n                continue  # move to next dimension\n\n            if evals >= budget:\n                break\n\n            # Negative step\n            cand_neg = current_x.copy()\n            cand_neg[d] = cand_neg[d] - step[d]\n            cand_neg = clip(cand_neg)\n            y_neg = eval_point(cand_neg)\n            evals += 1\n            if y_neg < current_y:\n                current_x, current_y = cand_neg, y_neg\n                if current_y < best_y:\n                    best_x, best_y = current_x, current_y\n                improved = True\n\n        if evals >= budget:\n            break\n\n        if not improved:\n            step *= 0.5\n            if np.all(step < 1e-6 * np.maximum(1.0, span)):\n                break\n\n    return best_x",
    "X": "-2.4935885356379502e-06 -1.88727538413411e-06"
}