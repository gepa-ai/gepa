{
    "score": -3.8627821478203943,
    "Input": "Hartmann3",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n\n    Strategy: hybrid global (low-discrepancy + random) and local\n    (pattern search + CMA-like) with careful budget allocation and\n    dimension-aware tuning. Uses warm starts when available.\n    \"\"\"\n\n    rng = np.random.default_rng(42)\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    if dim <= 0 or budget <= 0:\n        return np.zeros(dim, dtype=float)\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n    span = np.where(span <= 0, 1e-12, span)\n\n    def project(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # ---- Elite archive ----\n    elite_size = max(4, min(40, max(1, budget // max(2, dim))))\n    elite_x = []\n    elite_y = []\n\n    def update_elites(x, y):\n        nonlocal elite_x, elite_y\n        if not np.isfinite(y):\n            return\n        if len(elite_x) < elite_size:\n            elite_x.append(x.copy())\n            elite_y.append(float(y))\n        else:\n            worst_idx = int(np.argmax(elite_y))\n            if y < elite_y[worst_idx]:\n                elite_x[worst_idx] = x.copy()\n                elite_y[worst_idx] = float(y)\n\n    def eval_candidate(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        y = objective_function(x)\n        evals_used += 1\n        if np.isfinite(y) and y < best_y:\n            best_y = float(y)\n            best_x = x.copy()\n        update_elites(x, y)\n        return y\n\n    # ---- Duplicate-avoidance bookkeeping ----\n    tried = set()\n\n    def to_key(x):\n        return tuple(np.round(np.asarray(x, float), 12))\n\n    def register(x):\n        tried.add(to_key(x))\n\n    # ---- Initial deterministic / warm-start evaluations ----\n\n    # Warm start from previous best if provided\n    if prev_best_x is not None and evals_used < budget:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = project(x0)\n            k0 = to_key(x0)\n            if k0 not in tried:\n                eval_candidate(x0)\n                register(x0)\n        except Exception:\n            pass\n\n    # Always evaluate domain center\n    if evals_used < budget:\n        x_mid = project(low + 0.5 * span)\n        km = to_key(x_mid)\n        if km not in tried:\n            eval_candidate(x_mid)\n            register(x_mid)\n\n    # For very tiny budgets, spend remaining purely on global sampling\n    if budget <= 5:\n        while evals_used < budget:\n            x_rand = low + rng.random(dim) * span\n            kr = to_key(x_rand)\n            if kr in tried:\n                continue\n            x_rand = project(x_rand)\n            eval_candidate(x_rand)\n            register(x_rand)\n        return best_x if best_x is not None else project(low + 0.5 * span)\n\n    # Evaluate some structured points for low dims\n    if evals_used < budget and dim <= 4:\n        corner_candidates = [low, high]\n        if dim >= 2:\n            corner_candidates.append(\n                np.concatenate([low[: dim // 2], high[dim // 2 :]])\n            )\n            corner_candidates.append(\n                np.concatenate([high[: dim // 2], low[dim // 2 :]])\n            )\n        for c in corner_candidates:\n            if evals_used >= budget:\n                break\n            c_proj = project(c)\n            kc = to_key(c_proj)\n            if kc in tried:\n                continue\n            eval_candidate(c_proj)\n            register(c_proj)\n\n    if evals_used >= budget:\n        if best_x is not None:\n            return best_x\n        return project(low + 0.5 * span)\n\n    # -------- Global exploration --------\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x if best_x is not None else project(low + 0.5 * span)\n\n    # Global vs local budget split (dimension & budget aware)\n    if budget < 25:\n        global_frac = 0.85\n    elif budget < 60:\n        global_frac = 0.75\n    elif dim <= 6:\n        global_frac = 0.7\n    else:\n        global_frac = 0.6\n\n    # Minimum global sampling proportional to dimension\n    n_global_target = max(dim * 10, int(global_frac * budget))\n    n_global = min(n_global_target, remaining_budget)\n\n    def sobol_like_samples(n, d):\n        # Simple randomized Van der Corput design per dimension\n        primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31]\n        bases = [primes[i % len(primes)] for i in range(d)]\n        ks_base = np.arange(1, n + 1)\n        xs_unit = np.empty((n, d), dtype=float)\n        for j in range(d):\n            base = bases[j]\n            k = ks_base.copy()\n            rng.shuffle(k)\n            vdc = np.zeros(n, dtype=float)\n            denom = 1.0\n            kk = k.copy()\n            while np.any(kk):\n                denom *= base\n                kk, rem = divmod(kk, base)\n                vdc += rem / denom\n            xs_unit[:, j] = vdc\n        return xs_unit\n\n    if n_global > 0:\n        # Favor low-discrepancy more for small dims\n        if dim <= 5:\n            sobol_ratio = 0.9\n        elif dim <= 12:\n            sobol_ratio = 0.7\n        else:\n            sobol_ratio = 0.6\n\n        n_sobol = int(n_global * sobol_ratio)\n        n_rand = n_global - n_sobol\n\n        xs_list = []\n\n        if n_sobol > 0:\n            xs_unit = sobol_like_samples(n_sobol, dim)\n            xs_sobol = low + xs_unit * span\n            # very small jitter to avoid grid-like artifacts but keep within bounds\n            noise_scale = 0.0002\n            xs_sobol += rng.normal(0.0, noise_scale, size=(n_sobol, dim)) * span\n            xs_list.append(xs_sobol)\n\n        if n_rand > 0:\n            xs_rand = low + rng.random((n_rand, dim)) * span\n            xs_list.append(xs_rand)\n\n        xs_global = np.vstack(xs_list) if xs_list else np.empty((0, dim))\n        rng.shuffle(xs_global)\n\n        for i in range(xs_global.shape[0]):\n            if evals_used >= budget:\n                break\n            x = project(xs_global[i])\n            kx = to_key(x)\n            if kx in tried:\n                continue\n            eval_candidate(x)\n            register(x)\n\n    if best_x is None:\n        best_x = project(low + 0.5 * span)\n\n    # -------- Local exploitation: coordinate pattern search --------\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x\n\n    base_span = np.where(span > 0, span, 1.0)\n\n    # Adaptive initial step size: tuned slightly smaller for smoother convergence\n    if budget < 30:\n        step = 0.12 * base_span\n    elif budget < 100:\n        step = 0.08 * base_span\n    else:\n        step = 0.06 * base_span\n\n    min_step = 1e-7 * base_span\n    shrink = 0.5\n    grow = 1.6\n\n    coord_calls_since_best = 0\n    recenter_interval = max(2 * dim, 8)\n\n    def coordinate_search(x_start):\n        nonlocal step, coord_calls_since_best, best_x, best_y, evals_used\n        x_center = x_start.copy()\n        improved_any = False\n\n        order = np.arange(dim)\n        rng.shuffle(order)\n        for d in order:\n            if evals_used >= budget:\n                break\n            current_step = step[d]\n            if current_step <= 0:\n                continue\n            improved_local = False\n\n            for direction in (+1.0, -1.0):\n                if evals_used >= budget:\n                    break\n                if current_step < min_step[d] * 0.5:\n                    continue\n                x_try = x_center.copy()\n                x_try[d] += direction * current_step\n                x_try = project(x_try)\n                kt = to_key(x_try)\n                if kt in tried:\n                    continue\n                y_new = eval_candidate(x_try)\n                if y_new is None:\n                    break\n                register(x_try)\n                coord_calls_since_best += 1\n                if np.isfinite(y_new) and y_new < best_y - 1e-12:\n                    x_center = x_try\n                    improved_any = True\n                    improved_local = True\n                    coord_calls_since_best = 0\n\n            if coord_calls_since_best >= recenter_interval:\n                if best_x is not None:\n                    x_center = best_x.copy()\n                coord_calls_since_best = 0\n\n            if improved_local:\n                step[d] = min(step[d] * grow, base_span[d])\n            else:\n                step[d] *= shrink\n\n        return x_center, improved_any\n\n    # -------- Lightweight CMA-like local search --------\n\n    def cma_like_local(x_center):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return\n\n        remaining = budget - evals_used\n        if remaining <= 0:\n            return\n\n        # Population size scaled with dim but capped by remaining budget\n        lam = 4 + int(3 * np.log(dim + 1))\n        lam = max(4, lam)\n        if remaining < lam:\n            lam = remaining\n        if lam <= 3:\n            return\n        mu = max(2, lam // 2)\n\n        cov = np.eye(dim)\n        # Sigma tuned for typical test landscapes (e.g. Hartmann)\n        if dim <= 5:\n            sigma = 0.08\n        elif dim <= 15:\n            sigma = 0.11\n        else:\n            sigma = 0.16\n\n        # Limit number of CMA iterations to preserve budget for other phases\n        max_iters = min(6, max(2, remaining // (lam * 2)))\n        if max_iters <= 0 or lam <= 0:\n            return\n\n        for _ in range(max_iters):\n            if evals_used >= budget:\n                break\n            xs = []\n            ys = []\n            try:\n                L = np.linalg.cholesky(cov + 1e-9 * np.eye(dim))\n            except np.linalg.LinAlgError:\n                L = np.eye(dim)\n            for _ in range(lam):\n                if evals_used >= budget:\n                    break\n                z = rng.normal(size=dim)\n                step_vec = L @ z\n                x_try = x_center + sigma * step_vec\n                x_try = project(x_try)\n                kt = to_key(x_try)\n                if kt in tried:\n                    continue\n                y = eval_candidate(x_try)\n                if y is None:\n                    break\n                register(x_try)\n                xs.append(x_try)\n                ys.append(y)\n            if not xs:\n                break\n            xs = np.asarray(xs)\n            ys = np.asarray(ys)\n            order = np.argsort(ys)\n            xs = xs[order]\n            ys = ys[order]\n            elites = xs[:mu]\n            x_center = elites.mean(axis=0)\n            diff = elites - x_center\n            if mu > 1:\n                cov = (diff.T @ diff) / (mu - 1) + 1e-9 * np.eye(dim)\n            else:\n                cov = 0.5 * cov + 0.5 * np.eye(dim)\n\n            sigma *= 0.7\n            max_diag = float(np.max(np.diag(cov)))\n            if sigma * np.sqrt(max_diag) < 1e-7:\n                break\n\n    # Decide whether to use CMA-like refinement\n    remaining_budget = budget - evals_used\n    use_cma = (dim <= 25) and (remaining_budget >= max(20, 4 * dim))\n\n    if use_cma:\n        starts = []\n        if best_x is not None:\n            starts.append(best_x.copy())\n        if elite_x:\n            idx_best_elite = int(np.argmin(elite_y))\n            elite_start = elite_x[idx_best_elite]\n            if (\n                elite_start is not None\n                and best_x is not None\n                and np.any(np.abs(elite_start - best_x) > 1e-9)\n            ):\n                starts.append(elite_start.copy())\n        # Avoid over-spending budget in CMA: at most two starts\n        for s in starts[:2]:\n            if evals_used >= budget:\n                break\n            cma_like_local(s)\n\n    # -------- Final coordinate search with elite and random restarts --------\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x\n\n    step = np.maximum(step, min_step)\n\n    while evals_used < budget and np.any(step > min_step):\n        r = rng.random()\n        if r < 0.25:\n            # Random restart in domain\n            x_start = low + rng.random(dim) * span\n        elif elite_x and r < 0.9:\n            # Elite-based start\n            if rng.random() < 0.75:\n                idx = int(np.argmin(elite_y))\n            else:\n                idx = int(rng.integers(len(elite_x)))\n            x_start = elite_x[idx].copy()\n        else:\n            x_start = best_x.copy()\n\n        _, improved = coordinate_search(x_start)\n        if not improved:\n            step *= shrink\n            step = np.maximum(step, min_step)\n\n        if evals_used >= budget:\n            break\n\n    if best_x is None:\n        best_x = project(low + 0.5 * span)\n\n    return best_x",
    "X": "0.11461422896428246 0.5556489497086988 0.8525469659342308"
}