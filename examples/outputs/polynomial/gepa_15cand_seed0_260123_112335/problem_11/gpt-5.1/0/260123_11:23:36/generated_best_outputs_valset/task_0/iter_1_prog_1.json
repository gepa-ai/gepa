{
    "score": -3.8028654910255693,
    "Input": "Hartmann3",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n\n    Strategy:\n    - Use up to config['budget'] function evaluations.\n    - Start from prev_best_x (if valid) and random samples.\n    - Global exploration with random search (quasi-Latin style).\n    - Local exploitation via a simple derivative-free coordinate search\n      around the best point, with shrinking step sizes.\n    \"\"\"\n    rng = np.random.default_rng()\n\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Ensure valid dimensions\n    if dim <= 0 or budget <= 0:\n        return np.zeros(dim, dtype=float)\n\n    # Helper: project into bounds\n    def project(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # Evaluate a candidate if budget allows\n    def eval_candidate(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x\n        return y\n\n    # 1) Warm start from prev_best_x if provided and valid\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = project(x0)\n            eval_candidate(x0)\n        except Exception:\n            pass  # fall back to random initialization\n\n    # 2) Global random search for the first part of the budget\n    # Use at least dim+1 samples, up to ~70% of budget for exploration.\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x if best_x is not None else project(low)\n\n    n_global = max(dim + 1, int(0.7 * budget))\n    n_global = min(n_global, remaining_budget)\n\n    # Sample using jittered grid along each dimension (simple space-filling)\n    for i in range(n_global):\n        t = (i + rng.random()) / (n_global + 1)\n        # interpolate between low and high with some randomness\n        x = low + span * np.clip(t, 0.0, 1.0)\n        # add small noise to break grid regularity\n        noise = rng.normal(0.0, 0.05, size=dim) * span\n        x = project(x + noise)\n        eval_candidate(x)\n        if evals_used >= budget:\n            break\n\n    if best_x is None:\n        # Should not happen, but be safe\n        best_x = project(low + 0.5 * span)\n\n    # 3) Local coordinate search (pattern search) around current best\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x\n\n    # Initial step size: fraction of span per dimension\n    step = 0.25 * span\n    min_step = 1e-6 * np.maximum(span, 1.0)\n    shrink = 0.5\n\n    # Use remaining evaluations for exploitation\n    while evals_used < budget and np.any(step > min_step):\n        improved = False\n        x_center = best_x.copy()\n\n        for d in range(dim):\n            if evals_used >= budget:\n                break\n\n            for direction in (+1.0, -1.0):\n                if evals_used >= budget:\n                    break\n                x_try = x_center.copy()\n                x_try[d] += direction * step[d]\n                x_try = project(x_try)\n                y_new = eval_candidate(x_try)\n                if y_new is None:\n                    break\n                if y_new < best_y - 1e-12:\n                    # Move center to this improved point\n                    x_center = x_try\n                    improved = True\n\n        if improved:\n            # Optional slight step increase to follow promising directions\n            step *= 1.05\n            step = np.minimum(step, span)\n        else:\n            # No improvement at this scale: shrink step size\n            step *= shrink\n\n    return best_x",
    "X": "0.4390871903900637 0.5541988306901442 0.8518842385782738"
}