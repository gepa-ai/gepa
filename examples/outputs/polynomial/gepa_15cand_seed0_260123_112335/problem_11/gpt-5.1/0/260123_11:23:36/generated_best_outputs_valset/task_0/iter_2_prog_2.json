{
    "score": -3.860668534101978,
    "Input": "Hartmann3",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n\n    Strategy (hybrid global + local search):\n    - Respect config['budget'] function evaluations.\n    - Warm-start from prev_best_x if available.\n    - Global exploration with quasi-random (Sobol-like) LHS-style sampling.\n    - Maintain a small \"elite set\" of best points.\n    - Local derivative-free search (adaptive coordinate pattern search)\n      starting from the current best (and occasionally from elites).\n    \"\"\"\n\n    rng = np.random.default_rng()\n\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    if dim <= 0 or budget <= 0:\n        return np.zeros(dim, dtype=float)\n\n    # Helper: project into bounds\n    def project(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # Maintain a small archive of elite points for potential local restarts\n    elite_size = min(5, max(1, budget // max(10, dim * 2)))\n    elite_x = []\n    elite_y = []\n\n    def update_elites(x, y):\n        nonlocal elite_x, elite_y\n        if len(elite_x) < elite_size:\n            elite_x.append(x.copy())\n            elite_y.append(float(y))\n        else:\n            worst_idx = int(np.argmax(elite_y))\n            if y < elite_y[worst_idx]:\n                elite_x[worst_idx] = x.copy()\n                elite_y[worst_idx] = float(y)\n\n    # Evaluate a candidate if budget allows\n    def eval_candidate(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        update_elites(x, y)\n        return y\n\n    # 1) Warm start from prev_best_x if provided and valid\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = project(x0)\n            eval_candidate(x0)\n        except Exception:\n            pass\n\n    if evals_used >= budget:\n        return best_x if best_x is not None else project(low + 0.5 * span)\n\n    # 2) Global exploration with improved space-filling sampling\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x if best_x is not None else project(low + 0.5 * span)\n\n    # Allocate ~60% of total budget (not remaining) to global exploration,\n    # but keep at least dim+2 points and at most remaining_budget.\n    global_frac = 0.6\n    n_global = int(global_frac * budget)\n    n_global = max(dim + 2, n_global)\n    n_global = min(n_global, remaining_budget)\n\n    # Generate quasi-LHS / low-discrepancy samples\n    # Using simple stratified sampling per dimension\n    if n_global > 0:\n        # For each dimension, create stratified bins and shuffle\n        strata = (np.arange(n_global) + rng.random(n_global)) / n_global\n        strata_matrix = np.zeros((n_global, dim))\n        for d in range(dim):\n            perm = rng.permutation(n_global)\n            strata_matrix[:, d] = strata[perm]\n\n        xs = low + strata_matrix * span\n        # Add small Gaussian noise scaled to domain size, but ensure bounds\n        noise_scale = 0.02\n        xs += rng.normal(0.0, noise_scale, size=(n_global, dim)) * span\n\n        for i in range(n_global):\n            if evals_used >= budget:\n                break\n            x = project(xs[i])\n            eval_candidate(x)\n\n    if best_x is None:\n        best_x = project(low + 0.5 * span)\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x\n\n    # 3) Local exploitation: coordinate pattern search with adaptive step sizes\n    # Initial step size: moderate fraction of span; avoid being too large when span is big\n    step = 0.2 * np.maximum(span, 1e-8)\n    min_step = 1e-6 * np.maximum(span, 1.0)\n    shrink = 0.5\n    grow = 1.2\n\n    # We will sometimes restart local search from elite points\n    # to avoid getting stuck near a single basin.\n    def coordinate_search(x_start):\n        nonlocal step, evals_used, best_x, best_y\n        # Local copy of center\n        x_center = x_start.copy()\n        improved_any = False\n\n        # One full sweep over all coordinates\n        for d in range(dim):\n            if evals_used >= budget:\n                break\n\n            base_val = best_y  # current global best\n            improved_local = False\n\n            for direction in (+1.0, -1.0):\n                if evals_used >= budget:\n                    break\n                x_try = x_center.copy()\n                x_try[d] += direction * step[d]\n                x_try = project(x_try)\n                y_new = eval_candidate(x_try)\n                if y_new is None:\n                    break\n                if y_new < best_y - 1e-12:\n                    x_center = x_try\n                    base_val = y_new\n                    improved_any = True\n                    improved_local = True\n\n            # Slight per-dimension step adaptation\n            if improved_local:\n                step[d] = min(step[d] * grow, span[d] if span[d] > 0 else step[d] * grow)\n            else:\n                step[d] *= shrink\n\n        return x_center, improved_any\n\n    # Use remaining budget for repeated local refinement,\n    # with occasional restarts from elites when step sizes become small\n    while evals_used < budget and np.any(step > min_step):\n        # Decide starting point: mostly best_x, occasionally an elite\n        if elite_x and rng.random() < 0.3:\n            # Choose a random elite that is not the same object as best_x\n            idx = int(rng.integers(len(elite_x)))\n            x_start = elite_x[idx].copy()\n        else:\n            x_start = best_x.copy()\n\n        x_new, improved = coordinate_search(x_start)\n\n        if not improved:\n            # No improvement in this sweep: globally shrink step\n            step *= shrink\n        else:\n            # Update best_x toward new point if it improved best_y\n            if best_y is not None:\n                best_x = x_new.copy()\n\n        if evals_used >= budget:\n            break\n\n    return best_x",
    "X": "0.1726809403900637 0.5541988306901442 0.8519483254923362"
}