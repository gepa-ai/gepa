{
    "score": -3.8627821478181015,
    "Input": "Hartmann3",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n\n    Strategy: robust hybrid global (low-discrepancy + adaptive random) and local\n    (pattern search + CMA-like) with improved small-budget behavior and\n    better use of warm starts.\n    \"\"\"\n\n    rng = np.random.default_rng()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    if dim <= 0 or budget <= 0:\n        return np.zeros(dim, dtype=float)\n\n    # Handle degenerate bounds\n    span = np.where(span <= 0, 1e-12, span)\n\n    def project(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # Elite archive\n    elite_size = max(4, min(30, budget // max(2, dim)))\n    elite_x = []\n    elite_y = []\n\n    def update_elites(x, y):\n        nonlocal elite_x, elite_y\n        if not np.isfinite(y):\n            return\n        if len(elite_x) < elite_size:\n            elite_x.append(x.copy())\n            elite_y.append(float(y))\n        else:\n            worst_idx = int(np.argmax(elite_y))\n            if y < elite_y[worst_idx]:\n                elite_x[worst_idx] = x.copy()\n                elite_y[worst_idx] = float(y)\n\n    def eval_candidate(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        y = objective_function(x)\n        evals_used += 1\n        if np.isfinite(y) and y < best_y:\n            best_y = float(y)\n            best_x = x.copy()\n        update_elites(x, y)\n        return y\n\n    # ---- Warm starts and deterministic anchor points ----\n    tried_centers = []\n\n    # Warm start from previous best if provided\n    if prev_best_x is not None and evals_used < budget:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = project(x0)\n            eval_candidate(x0)\n            tried_centers.append(tuple(x0))\n        except Exception:\n            pass\n\n    # Always evaluate domain center\n    if evals_used < budget:\n        x_mid = project(low + 0.5 * span)\n        key = tuple(x_mid)\n        if key not in tried_centers:\n            eval_candidate(x_mid)\n            tried_centers.append(key)\n\n    # Evaluate corners for tiny budgets to improve coverage in low dim\n    if evals_used < budget and dim <= 4:\n        # Use a few corner-like points: low, high, and simple mixes\n        corner_candidates = []\n        corner_candidates.append(low)\n        corner_candidates.append(high)\n        if dim >= 2:\n            corner_candidates.append(np.concatenate([low[: dim // 2], high[dim // 2 :]]))\n            corner_candidates.append(np.concatenate([high[: dim // 2], low[dim // 2 :]]))\n\n        for c in corner_candidates:\n            if evals_used >= budget:\n                break\n            c_proj = project(c)\n            key = tuple(c_proj)\n            if key in tried_centers:\n                continue\n            eval_candidate(c_proj)\n            tried_centers.append(key)\n\n    if evals_used >= budget:\n        if best_x is not None:\n            return best_x\n        return project(low + 0.5 * span)\n\n    # -------- Global exploration: Sobol-like + random mix --------\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x if best_x is not None else project(low + 0.5 * span)\n\n    # Global vs local budget split (slightly more global on small budgets)\n    if budget < 25:\n        global_frac = 0.85\n    elif budget < 80:\n        global_frac = 0.65\n    else:\n        global_frac = 0.55\n\n    # Guarantee at least a modest number of global samples in any case\n    n_global_target = max(dim * 4, int(global_frac * budget))\n    n_global = min(n_global_target, remaining_budget)\n\n    def sobol_like_samples(n, d):\n        # Simple randomized van der Corput-based low-discrepancy design\n        primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31]\n        bases = [primes[i % len(primes)] for i in range(d)]\n        ks_base = np.arange(1, n + 1)\n        xs_unit = np.empty((n, d), dtype=float)\n        for j in range(d):\n            base = bases[j]\n            k = ks_base.copy()\n            rng.shuffle(k)\n            vdc = np.zeros(n, dtype=float)\n            denom = 1.0\n            kk = k.copy()\n            while np.any(kk):\n                denom *= base\n                kk, rem = divmod(kk, base)\n                vdc += rem / denom\n            xs_unit[:, j] = vdc\n        return xs_unit\n\n    if n_global > 0:\n        # Use more Sobol-like for low-dim problems\n        if dim <= 5:\n            sobol_ratio = 0.75\n        else:\n            sobol_ratio = 0.55\n\n        n_sobol = int(n_global * sobol_ratio)\n        n_rand = n_global - n_sobol\n\n        xs_list = []\n\n        if n_sobol > 0:\n            xs_unit = sobol_like_samples(n_sobol, dim)\n            xs_sobol = low + xs_unit * span\n            # Slight jitter to avoid pathological alignment\n            noise_scale = 0.004\n            xs_sobol += rng.normal(0.0, noise_scale, size=(n_sobol, dim)) * span\n            xs_list.append(xs_sobol)\n\n        if n_rand > 0:\n            xs_rand = low + rng.random((n_rand, dim)) * span\n            xs_list.append(xs_rand)\n\n        xs_global = np.vstack(xs_list) if xs_list else np.empty((0, dim))\n\n        rng.shuffle(xs_global)\n\n        for i in range(xs_global.shape[0]):\n            if evals_used >= budget:\n                break\n            x = project(xs_global[i])\n            eval_candidate(x)\n\n    if best_x is None:\n        best_x = project(low + 0.5 * span)\n\n    # -------- Local exploitation: coordinate pattern search --------\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x\n\n    base_span = np.where(span > 0, span, 1.0)\n\n    # Adaptive initial step size; a bit smaller to be safer on narrow basins\n    if budget < 30:\n        step = 0.14 * base_span\n    elif budget < 100:\n        step = 0.10 * base_span\n    else:\n        step = 0.07 * base_span\n\n    min_step = 1e-7 * base_span\n    shrink = 0.5\n    grow = 1.6\n\n    coord_calls_since_best = 0\n    recenter_interval = max(3 * dim, 10)\n\n    def coordinate_search(x_start):\n        nonlocal step, coord_calls_since_best, best_x, best_y, evals_used\n        x_center = x_start.copy()\n        improved_any = False\n\n        order = np.arange(dim)\n        rng.shuffle(order)\n        for d in order:\n            if evals_used >= budget:\n                break\n            current_step = step[d]\n            if current_step <= 0:\n                continue\n            improved_local = False\n\n            for direction in (+1.0, -1.0):\n                if evals_used >= budget:\n                    break\n                if current_step < min_step[d] * 0.5:\n                    continue\n                x_try = x_center.copy()\n                x_try[d] += direction * current_step\n                x_try = project(x_try)\n                y_new = eval_candidate(x_try)\n                if y_new is None:\n                    break\n                coord_calls_since_best += 1\n                if np.isfinite(y_new) and y_new < best_y - 1e-12:\n                    x_center = x_try\n                    improved_any = True\n                    improved_local = True\n                    coord_calls_since_best = 0\n\n            if coord_calls_since_best >= recenter_interval:\n                if best_x is not None:\n                    x_center = best_x.copy()\n                coord_calls_since_best = 0\n\n            if improved_local:\n                step[d] = min(step[d] * grow, base_span[d])\n            else:\n                step[d] *= shrink\n\n        return x_center, improved_any\n\n    # -------- Lightweight CMA-like local search --------\n\n    def cma_like_local(x_center):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return\n\n        remaining = budget - evals_used\n        if remaining <= 0:\n            return\n\n        # Population size adapted to dim and remaining budget\n        lam = min(6 + dim, max(6, remaining // max(4, dim)))\n        lam = max(4, lam)\n        mu = max(2, lam // 2)\n\n        cov = np.eye(dim)\n        # Slightly smaller sigma to better exploit narrow minima (e.g., Hartmann)\n        if dim <= 5:\n            sigma = 0.16\n        else:\n            sigma = 0.20\n        max_iters = min(10, max(2, remaining // (lam * 2)))\n\n        if max_iters <= 0 or lam <= 0:\n            return\n\n        for _ in range(max_iters):\n            if evals_used >= budget:\n                break\n            xs = []\n            ys = []\n            try:\n                L = np.linalg.cholesky(cov + 1e-9 * np.eye(dim))\n            except np.linalg.LinAlgError:\n                L = np.eye(dim)\n            for _ in range(lam):\n                if evals_used >= budget:\n                    break\n                z = rng.normal(size=dim)\n                step_vec = L @ z\n                x_try = x_center + sigma * step_vec\n                x_try = project(x_try)\n                y = eval_candidate(x_try)\n                if y is None:\n                    break\n                xs.append(x_try)\n                ys.append(y)\n            if not xs:\n                break\n            xs = np.asarray(xs)\n            ys = np.asarray(ys)\n            order = np.argsort(ys)\n            xs = xs[order]\n            ys = ys[order]\n            elites = xs[:mu]\n            x_center = elites.mean(axis=0)\n            diff = elites - x_center\n            if mu > 1:\n                cov = (diff.T @ diff) / (mu - 1) + 1e-9 * np.eye(dim)\n            else:\n                cov = 0.5 * cov + 0.5 * np.eye(dim)\n\n            sigma *= 0.65\n            max_diag = float(np.max(np.diag(cov)))\n            if sigma * np.sqrt(max_diag) < 1e-6:\n                break\n\n    # Decide whether to use CMA-like refinement\n    remaining_budget = budget - evals_used\n    # Also allow CMA for modest budgets but ensure enough evaluations\n    use_cma = (dim <= 20) and (remaining_budget >= max(16, 3 * dim))\n\n    if use_cma:\n        if best_x is not None:\n            cma_like_local(best_x.copy())\n        if elite_x:\n            idx_best_elite = int(np.argmin(elite_y))\n            elite_start = elite_x[idx_best_elite]\n            if elite_start is not None and best_x is not None and np.any(\n                np.abs(elite_start - best_x) > 1e-9\n            ):\n                cma_like_local(elite_start.copy())\n\n    # -------- Final coordinate search with elite and random restarts --------\n\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x\n\n    # Clamp steps to avoid zero-step stalling\n    step = np.maximum(step, min_step)\n\n    while evals_used < budget and np.any(step > min_step):\n        r = rng.random()\n        if r < 0.2:\n            # Random restart in domain\n            x_start = low + rng.random(dim) * span\n        elif elite_x and r < 0.8:\n            # Elite-based start\n            if rng.random() < 0.7:\n                idx = int(np.argmin(elite_y))\n            else:\n                idx = int(rng.integers(len(elite_x)))\n            x_start = elite_x[idx].copy()\n        else:\n            x_start = best_x.copy()\n\n        _, improved = coordinate_search(x_start)\n        if not improved:\n            step *= shrink\n            step = np.maximum(step, min_step)\n\n        if evals_used >= budget:\n            break\n\n    if best_x is None:\n        best_x = project(low + 0.5 * span)\n\n    return best_x",
    "X": "0.11461251235051292 0.5556487208268629 0.8525469659342308"
}