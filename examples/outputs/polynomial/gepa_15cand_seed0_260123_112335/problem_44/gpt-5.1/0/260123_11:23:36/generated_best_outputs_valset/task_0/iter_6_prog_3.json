{
    "score": -12.031249442167143,
    "Input": "Problem03",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Blackbox minimization using a hybrid global-local strategy:\n    - Global search via space-filling (Sobol/Halton-like) sampling + random sampling.\n    - Local refinement via adaptive coordinate-wise pattern search.\n    \"\"\"\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n    # safeguard for zero-width bounds\n    span[span <= 0] = 1.0\n\n    def clip_to_bounds(x):\n        return np.minimum(high, np.maximum(low, x))\n\n    def eval_x(x):\n        return objective_function(x)\n\n    # Handle degenerate budget\n    if budget <= 0:\n        if prev_best_x is not None:\n            return clip_to_bounds(np.asarray(prev_best_x, dtype=float).reshape(dim,))\n        # default to box center\n        return clip_to_bounds(low + 0.5 * (high - low))\n\n    # Initialize best solution\n    best_x = None\n    best_y = None\n    evals_used = 0\n\n    # Warm start from previous best if provided and feasible\n    if prev_best_x is not None:\n        x0 = clip_to_bounds(np.asarray(prev_best_x, dtype=float).reshape(dim,))\n        y0 = eval_x(x0)\n        best_x, best_y = x0, y0\n        evals_used += 1\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x.reshape(dim,)\n\n    # ---------- Global exploration ----------\n    # Use both low-discrepancy and random sampling to improve robustness.\n    # Allocate 60% of remaining budget to structured (quasi-random) search,\n    # 20% to pure random, leaving ~20% or more for local search.\n    n_structured = int(0.6 * remaining)\n    n_random = int(0.2 * remaining)\n    # Ensure at least dim+2 total global samples (if possible)\n    min_global = min(remaining, max(dim + 2, 4))\n    if n_structured + n_random < min_global:\n        extra = min_global - (n_structured + n_random)\n        n_structured += extra\n    if n_structured + n_random > remaining:\n        # scale down proportionally\n        scale = remaining / max(1, n_structured + n_random)\n        n_structured = int(n_structured * scale)\n        n_random = remaining - n_structured\n    # Safety\n    n_structured = max(0, min(n_structured, remaining))\n    n_random = max(0, min(n_random, remaining - n_structured))\n\n    # --- Structured (Halton-like) sampling ---\n    if n_structured > 0:\n        # van der Corput sequence\n        def _van_der_corput(n, base):\n            vdc = 0.0\n            denom = 1.0\n            while n:\n                n, remainder = divmod(n, base)\n                denom *= base\n                vdc += remainder / denom\n            return vdc\n\n        # first few primes as bases\n        primes = [\n            2, 3, 5, 7, 11, 13, 17, 19, 23, 29,\n            31, 37, 41, 43, 47, 53, 59, 61, 67, 71,\n            73, 79, 83, 89, 97\n        ]\n        bases = []\n        for i in range(dim):\n            if i < len(primes):\n                bases.append(primes[i])\n            else:\n                # fallback to large-ish odd numbers\n                bases.append(97 + 2 * (i - len(primes) + 1))\n\n        # Add a random offset to avoid deterministic patterns across runs\n        offset = np.random.randint(1, 10000)\n\n        for i in range(n_structured):\n            if evals_used >= budget:\n                break\n            idx = i + 1 + offset\n            u = np.empty(dim, dtype=float)\n            for d in range(dim):\n                u[d] = _van_der_corput(idx, bases[d])\n            x = clip_to_bounds(low + span * u)\n            y = eval_x(x)\n            evals_used += 1\n            if best_y is None or y < best_y:\n                best_x, best_y = x, y\n\n    # --- Pure random sampling ---\n    remaining = budget - evals_used\n    n_random = min(n_random, remaining)\n    for _ in range(n_random):\n        if evals_used >= budget:\n            break\n        x = clip_to_bounds(low + span * np.random.rand(dim))\n        y = eval_x(x)\n        evals_used += 1\n        if best_y is None or y < best_y:\n            best_x, best_y = x, y\n\n    remaining = budget - evals_used\n    if remaining <= 0 or best_x is None:\n        # If no evaluations somehow, fall back to center\n        if best_x is None:\n            best_x = clip_to_bounds(low + 0.5 * (high - low))\n        return best_x.reshape(dim,)\n\n    # ---------- Local refinement (pattern / coordinate search) ----------\n    x_center = best_x.copy()\n    # base_step proportional to box size but not too large\n    base_step = 0.2 * span\n    base_step[base_step == 0] = 1.0\n\n    max_sweeps = 30\n    # At least 1 sweep, roughly 2*dim evals per sweep\n    est_per_sweep = max(2 * dim, 1)\n    sweeps = min(max_sweeps, max(1, remaining // est_per_sweep))\n\n    for s in range(sweeps):\n        if evals_used >= budget:\n            break\n\n        # Geometric decay of step size\n        step_scale = 0.6 ** s\n        step = base_step * step_scale\n\n        improved_any = False\n        coords = np.arange(dim)\n        np.random.shuffle(coords)\n\n        for d in coords:\n            if evals_used >= budget:\n                break\n\n            # Try positive direction\n            x_trial = x_center.copy()\n            x_trial[d] = x_trial[d] + step[d]\n            x_trial = clip_to_bounds(x_trial)\n            y_trial = eval_x(x_trial)\n            evals_used += 1\n\n            if y_trial < best_y:\n                best_x, best_y = x_trial, y_trial\n                x_center = x_trial\n                improved_any = True\n            else:\n                if evals_used >= budget:\n                    break\n                # Try negative direction\n                x_trial2 = x_center.copy()\n                x_trial2[d] = x_trial2[d] - step[d]\n                x_trial2 = clip_to_bounds(x_trial2)\n                y_trial2 = eval_x(x_trial2)\n                evals_used += 1\n                if y_trial2 < best_y:\n                    best_x, best_y = x_trial2, y_trial2\n                    x_center = x_trial2\n                    improved_any = True\n\n        # If no improvement, contract base_step further to focus search\n        if not improved_any:\n            base_step *= 0.5\n\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n\n    return best_x.reshape(dim,)",
    "X": "-6.7745761403795886"
}