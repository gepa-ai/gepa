{
    "score": -0.27300943535575906,
    "Input": "McCourt11",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Blackbox minimization with simple hybrid global/local search.\n\n    Strategy:\n    1. Random / LHS-like global sampling (with optional warm start).\n    2. Local search via coordinate-wise perturbations around best point.\n    \"\"\"\n    rng = np.random\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Helper to clip points to bounds\n    def clip(x):\n        return np.minimum(np.maximum(x, low), high)\n\n    # Track best solution\n    best_x = None\n    best_y = np.inf\n    evals = 0\n\n    # Use warm start if provided and valid\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip(x0)\n            y0 = objective_function(x0)\n            evals += 1\n            best_x, best_y = x0, y0\n\n    # Ensure we have some starting point\n    if best_x is None and evals < budget:\n        x0 = low + span * rng.rand(dim)\n        y0 = objective_function(x0)\n        evals += 1\n        best_x, best_y = x0, y0\n\n    if evals >= budget:\n        return best_x.astype(float)\n\n    remaining = budget - evals\n\n    # Split remaining budget between global sampling and local search\n    # Favor global search when budget is small\n    global_frac = 0.6 if remaining > 30 else 0.4\n    n_global = max(1, int(remaining * global_frac))\n    n_local = max(0, remaining - n_global)\n\n    # ---- Global search: stratified random sampling ----\n    # LHS-like: sample in dim hyper-rectangles per candidate\n    for i in range(n_global):\n        # generate a random point; slightly biased towards best_x if available\n        if best_x is not None and rng.rand() < 0.25:\n            # sample near best_x with broad perturbation\n            step = 0.5 * span\n            candidate = best_x + rng.uniform(-step, step)\n            x = clip(candidate)\n        else:\n            # uniform sample\n            x = low + span * rng.rand(dim)\n\n        y = objective_function(x)\n        evals += 1\n        if y < best_y:\n            best_x, best_y = x, y\n\n        if evals >= budget:\n            return best_x.astype(float)\n\n    # ---- Local search around best point: coordinate perturbations ----\n    if best_x is None or n_local <= 0:\n        return best_x.astype(float)\n\n    # Start with step sizes proportional to domain size\n    base_step = 0.2 * span\n    base_step[base_step == 0] = 1.0  # fallback for zero-span dimensions\n\n    # Distribute local evaluations over a few passes\n    passes = min(5, n_local)\n    evals_per_pass = max(1, n_local // passes)\n\n    current_x = best_x.copy()\n    current_y = best_y\n\n    for p in range(passes):\n        # gradually shrink step size\n        step_scale = max(0.1, 0.5 ** p)\n        step = base_step * step_scale\n\n        for _ in range(evals_per_pass):\n            # pick a subset of coordinates to perturb\n            k = max(1, dim // 3)\n            idx = rng.choice(dim, size=k, replace=False)\n\n            candidate = current_x.copy()\n            candidate[idx] += rng.uniform(-step[idx], step[idx])\n            candidate = clip(candidate)\n\n            y = objective_function(candidate)\n            evals += 1\n\n            if y < best_y:\n                best_x, best_y = candidate, y\n                current_x, current_y = candidate, y\n\n            if evals >= budget:\n                return best_x.astype(float)\n\n    return best_x.astype(float)",
    "X": "0.4216188561825104 0.5783090255820071 0.35196717752390094 0.9978806227593856 0.3751630496261215 0.1673083206922319 1.0 0.3318754481616136"
}