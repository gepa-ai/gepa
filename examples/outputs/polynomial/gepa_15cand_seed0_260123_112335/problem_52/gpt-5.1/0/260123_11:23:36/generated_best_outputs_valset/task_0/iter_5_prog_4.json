{
    "score": 0.17685176931333482,
    "Input": "Sphere",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget-aware optimizer:\n      - Global sampling (low-discrepancy + random)\n      - Optional refinement around warm start\n      - Local search with adaptive step sizes and simple covariance adaptation.\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Degenerate / invalid config\n    if dim <= 0 or budget <= 0:\n        return (low + high) / 2.0\n\n    # Ensure span is non-zero to avoid division issues\n    safe_span = np.where(span > 0, span, 1.0)\n\n    # Phase allocation with explicit local and refine phases\n    if budget < 20:\n        global_frac = 0.8\n        refine_frac = 0.1\n    elif budget < 100:\n        global_frac = 0.6\n        refine_frac = 0.2\n    else:\n        global_frac = 0.5\n        refine_frac = 0.25\n    local_frac = max(0.0, 1.0 - global_frac - refine_frac)\n\n    global_budget = max(1, int(budget * global_frac))\n    refine_budget = max(0, int(budget * refine_frac))\n    local_budget = max(0, budget - global_budget - refine_budget)\n\n    total_alloc = global_budget + refine_budget + local_budget\n    if total_alloc < budget:\n        global_budget += budget - total_alloc\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # --- Helper: Sobol-like low-discrepancy using simple van-der-Corput per dim ---\n    def quasi_random_samples(n_samples, base_seed=None):\n        if n_samples <= 0:\n            return np.empty((0, dim), dtype=float)\n\n        primes = [2, 3, 5, 7, 11, 13, 17, 19, 23]\n        bases = [primes[i % len(primes)] for i in range(dim)]\n\n        if base_seed is None:\n            start = np.random.randint(0, 10000)\n        else:\n            start = int(base_seed)\n\n        def vdc(n, base):\n            v = 0.0\n            denom = 1.0\n            while n:\n                n, remainder = divmod(n, base)\n                denom *= base\n                v += remainder / denom\n            return v\n\n        xs = np.empty((n_samples, dim), dtype=float)\n        for i in range(n_samples):\n            idx = start + i\n            for d in range(dim):\n                xs[i, d] = vdc(idx, bases[d])\n\n        for d in range(dim):\n            perm = np.random.permutation(n_samples)\n            xs[:, d] = xs[perm, d]\n\n        xs = low + span * xs\n        return xs\n\n    # --- Warm start: evaluate prev_best_x if given ---\n    if prev_best_x is not None:\n        try:\n            prev_best_x_arr = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            prev_best_x_arr = np.clip(prev_best_x_arr, low, high)\n            y = objective_function(prev_best_x_arr)\n            evals_used += 1\n            best_x = prev_best_x_arr\n            best_y = y\n        except Exception:\n            best_x = None\n            best_y = np.inf\n\n    # --- Helper: safe evaluation respecting budget & best update ---\n    def try_eval(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        try:\n            y = objective_function(x)\n        except Exception:\n            return None\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x\n        return y\n\n    # Adjust global budget if we already consumed an eval (for warm start)\n    if evals_used > 0:\n        global_budget = max(0, global_budget - 1)\n\n    # --- Pure center evaluation for extremely tiny budgets ---\n    if budget <= 2 and best_x is None:\n        center = (low + high) / 2.0\n        try_eval(center)\n        if best_x is None:\n            best_x = center\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    # --- Global search: quasi-random + random ---\n    if global_budget > 0 and evals_used < budget:\n        n_qr = int(0.7 * global_budget)\n        n_qr = max(0, min(global_budget, n_qr))\n        n_rand = global_budget - n_qr\n\n        if n_qr > 0:\n            samples = quasi_random_samples(n_qr)\n            for i in range(n_qr):\n                if evals_used >= budget:\n                    break\n                try_eval(samples[i])\n\n        for _ in range(n_rand):\n            if evals_used >= budget:\n                break\n            x = low + span * np.random.rand(dim)\n            try_eval(x)\n\n    # If still nothing evaluated successfully, fall back to center\n    if best_x is None:\n        center = (low + high) / 2.0\n        if evals_used < budget:\n            try_eval(center)\n        if best_x is None:\n            best_x = center\n            best_y = np.inf\n\n    # --- Refine phase: concentrate samples around current best (small ellipsoid) ---\n    if refine_budget > 0 and evals_used < budget:\n        base_radius = 0.25 * safe_span\n        min_radius = 1e-3 * safe_span\n        for i in range(refine_budget):\n            if evals_used >= budget:\n                break\n            t = i / max(1, refine_budget - 1)\n            radius = base_radius * (0.5 ** t)\n            radius = np.maximum(radius, min_radius)\n\n            noise = np.random.randn(dim)\n            nrm = np.linalg.norm(noise)\n            if nrm == 0:\n                noise = np.ones(dim) / np.sqrt(dim)\n            else:\n                noise /= nrm\n            step = noise * radius\n            cand_x = np.clip(best_x + step, low, high)\n            try_eval(cand_x)\n\n    # --- Local search: adaptive Gaussian + coordinate search + covariance adaptation ---\n    if local_budget > 0 and evals_used < budget:\n        base_step = 0.3 * safe_span\n        step_floor = 1e-4 * safe_span\n\n        # Simple diagonal covariance for anisotropic search\n        cov_diag = (0.15 * safe_span) ** 2\n        success_counter = 0\n        total_counter = 0\n\n        for i in range(local_budget):\n            if evals_used >= budget:\n                break\n\n            t = i / max(1, local_budget - 1)\n            decay = 0.3 ** t\n            step = np.maximum(base_step * decay, step_floor)\n\n            mode = i % 5\n            if mode == 0:\n                # Full-dimensional Gaussian with diagonal covariance\n                z = np.random.randn(dim) * np.sqrt(cov_diag)\n                cand_x = best_x + z\n            elif mode == 1:\n                # Coordinate step (positive)\n                cand_x = best_x.copy()\n                coord = np.random.randint(dim)\n                cand_x[coord] += step[coord]\n            elif mode == 2:\n                # Coordinate step (negative)\n                cand_x = best_x.copy()\n                coord = np.random.randint(dim)\n                cand_x[coord] -= step[coord]\n            elif mode == 3:\n                # Small uniform box around best\n                u = (np.random.rand(dim) * 2.0 - 1.0) * step\n                cand_x = best_x + u\n            else:\n                # Narrow Gaussian exploiting current best\n                z = np.random.randn(dim) * (0.5 * step)\n                cand_x = best_x + z\n\n            cand_x = np.clip(cand_x, low, high)\n            prev_best_y = best_y\n            y = try_eval(cand_x)\n\n            if y is not None:\n                total_counter += 1\n                if best_y < prev_best_y - 1e-12:\n                    success_counter += 1\n                    # Slightly increase variance in successful direction\n                    diff = (best_x - cand_x)\n                    cov_diag = 0.9 * cov_diag + 0.1 * (diff * diff + 1e-12)\n                if total_counter >= 10:\n                    rate = success_counter / total_counter\n                    # Adaptive step: increase if too successful, decrease if not\n                    if rate > 0.4:\n                        cov_diag *= 1.2\n                    elif rate < 0.2:\n                        cov_diag *= 0.7\n                    cov_diag = np.clip(cov_diag, (1e-6 * safe_span) ** 2, (0.25 * safe_span) ** 2)\n                    success_counter = 0\n                    total_counter = 0\n\n    best_x = np.asarray(best_x, dtype=float).reshape(dim)\n    return best_x",
    "X": "0.27595052005329557 -0.04189582976852879 -0.038219490302042025 -0.026401062447422075 0.1655429863434596 -0.25254276804053255 0.07488486956169021"
}