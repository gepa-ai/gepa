{
    "score": 0.2646807655862595,
    "Input": "Sphere",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget-aware optimizer:\n      - Global sampling (Sobol-like low-discrepancy + random)\n      - Optional refinement around warm start\n      - Local search with adaptive step sizes.\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Degenerate / invalid config\n    if dim <= 0 or budget <= 0:\n        return (low + high) / 2.0\n\n    # Ensure span is non-zero to avoid division issues\n    safe_span = np.where(span > 0, span, 1.0)\n\n    # Phase allocation with explicit local and refine phases\n    # Small budgets: heavy on global; large budgets: more local\n    if budget < 20:\n        global_frac = 0.75\n        refine_frac = 0.15\n    elif budget < 100:\n        global_frac = 0.6\n        refine_frac = 0.2\n    else:\n        global_frac = 0.5\n        refine_frac = 0.25\n    local_frac = max(0.0, 1.0 - global_frac - refine_frac)\n\n    global_budget = max(1, int(budget * global_frac))\n    refine_budget = max(0, int(budget * refine_frac))\n    local_budget = max(0, budget - global_budget - refine_budget)\n\n    # Make sure we use full budget\n    total_alloc = global_budget + refine_budget + local_budget\n    if total_alloc < budget:\n        global_budget += budget - total_alloc\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # --- Helper: Sobol-like low-discrepancy using simple van-der-Corput per dim ---\n    def quasi_random_samples(n_samples, base_seed=None):\n        if n_samples <= 0:\n            return np.empty((0, dim), dtype=float)\n\n        # Use van der Corput sequences with different bases per dimension\n        # Bases: first few primes; repeat if dim > len(primes)\n        primes = [2, 3, 5, 7, 11, 13, 17]\n        bases = [primes[i % len(primes)] for i in range(dim)]\n\n        if base_seed is None:\n            start = np.random.randint(0, 10_000)\n        else:\n            start = int(base_seed)\n\n        def vdc(n, base):\n            v = 0.0\n            denom = 1.0\n            while n:\n                n, remainder = divmod(n, base)\n                denom *= base\n                v += remainder / denom\n            return v\n\n        xs = np.empty((n_samples, dim), dtype=float)\n        for i in range(n_samples):\n            idx = start + i\n            for d in range(dim):\n                xs[i, d] = vdc(idx, bases[d])\n\n        # scramble by random permutation of samples in each dimension\n        for d in range(dim):\n            perm = np.random.permutation(n_samples)\n            xs[:, d] = xs[perm, d]\n\n        # scale to bounds\n        xs = low + span * xs\n        return xs\n\n    # --- Warm start: evaluate prev_best_x if given ---\n    if prev_best_x is not None:\n        try:\n            prev_best_x_arr = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            prev_best_x_arr = np.clip(prev_best_x_arr, low, high)\n            y = objective_function(prev_best_x_arr)\n            evals_used += 1\n            best_x = prev_best_x_arr\n            best_y = y\n        except Exception:\n            best_x = None\n            best_y = np.inf\n\n    # --- Helper: safe evaluation respecting budget & best update ---\n    def try_eval(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return False\n        try:\n            y = objective_function(x)\n        except Exception:\n            return False\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x\n        return True\n\n    # Adjust global budget if we already consumed an eval (for warm start)\n    if evals_used > 0:\n        global_budget = max(0, global_budget - 1)\n\n    # --- Global search: quasi-random + random ---\n    if global_budget > 0 and evals_used < budget:\n        # Split into low-discrepancy and pure random\n        n_qr = int(0.7 * global_budget)\n        n_qr = max(0, min(global_budget, n_qr))\n        n_rand = global_budget - n_qr\n\n        if n_qr > 0:\n            samples = quasi_random_samples(n_qr)\n            for i in range(n_qr):\n                if evals_used >= budget:\n                    break\n                try_eval(samples[i])\n\n        for _ in range(n_rand):\n            if evals_used >= budget:\n                break\n            x = low + span * np.random.rand(dim)\n            try_eval(x)\n\n    # If still nothing evaluated successfully, fall back to center\n    if best_x is None:\n        center = (low + high) / 2.0\n        if evals_used < budget:\n            try_eval(center)\n        if best_x is None:\n            best_x = center\n            best_y = np.inf\n\n    # --- Refine phase: concentrate samples around current best (small ellipsoid) ---\n    if refine_budget > 0 and evals_used < budget:\n        # scale of refinement: start with moderate radius and shrink\n        base_radius = 0.2 * safe_span\n        min_radius = 1e-3 * safe_span\n        for i in range(refine_budget):\n            if evals_used >= budget:\n                break\n            t = i / max(1, refine_budget - 1)\n            radius = base_radius * (0.5 ** t)\n            radius = np.maximum(radius, min_radius)\n            # isotropic perturbation with truncated Gaussian\n            noise = np.random.randn(dim)\n            noise /= max(1e-12, np.linalg.norm(noise))\n            step = noise * radius\n            cand_x = np.clip(best_x + step, low, high)\n            try_eval(cand_x)\n\n    # --- Local search: adaptive Gaussian + coordinate search ---\n    if local_budget > 0 and evals_used < budget:\n        base_step = 0.3 * safe_span\n        step_floor = 1e-4 * safe_span\n\n        for i in range(local_budget):\n            if evals_used >= budget:\n                break\n\n            t = i / max(1, local_budget - 1)\n            decay = 0.4 ** t\n            step = np.maximum(base_step * decay, step_floor)\n\n            if i % 4 == 0:\n                # full-dimensional Gaussian perturbation\n                cand_x = best_x + np.random.randn(dim) * step\n            elif i % 4 == 1:\n                # coordinate step (positive)\n                cand_x = best_x.copy()\n                coord = np.random.randint(dim)\n                cand_x[coord] += step[coord]\n            elif i % 4 == 2:\n                # coordinate step (negative)\n                cand_x = best_x.copy()\n                coord = np.random.randint(dim)\n                cand_x[coord] -= step[coord]\n            else:\n                # small uniform box around best\n                u = (np.random.rand(dim) * 2.0 - 1.0) * step\n                cand_x = best_x + u\n\n            cand_x = np.clip(cand_x, low, high)\n            try_eval(cand_x)\n\n    best_x = np.asarray(best_x, dtype=float).reshape(dim)\n    return best_x",
    "X": "0.36614972127541656 -0.25157325309014783 -0.07166428023359643 -0.08208432629136694 0.04962298466181256 -0.12197355069808072 0.19522410754075392"
}