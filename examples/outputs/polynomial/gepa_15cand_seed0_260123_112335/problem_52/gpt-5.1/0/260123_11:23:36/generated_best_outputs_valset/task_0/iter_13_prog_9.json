{
    "score": 8.740973848829031e-05,
    "Input": "Sphere",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget-aware hybrid optimizer:\n      - Robust warm start from prev_best_x\n      - Global sampling (quasi-random + random)\n      - Adaptive population-based refinement (ES-style)\n      - Local search with adaptive Gaussian / coordinate steps\n      - Dimension- and budget-aware allocation\n\n    Returns: best x found as np.ndarray of shape (dim,)\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Degenerate config: return box center (or clipped prev_best_x)\n    if dim <= 0 or budget <= 0:\n        if prev_best_x is not None:\n            try:\n                prev_arr = np.asarray(prev_best_x, dtype=float).reshape(dim)\n                prev_arr = np.clip(prev_arr, low, high)\n                return prev_arr.astype(float).reshape(dim)\n            except Exception:\n                pass\n        center = (low + high) / 2.0\n        return center.astype(float).reshape(dim)\n\n    # Ensure span is non-zero; track degenerate dims (collapsed bounds)\n    safe_span = np.where(span > 0, span, 1.0)\n    free_dims = span > 0\n\n    # ---- Phase allocation: global / ES-refine / local ----\n    # Adjusted to put a bit more weight on global search and local search for many problems\n    if budget < 15:\n        global_frac = 0.8\n        refine_frac = 0.0\n    elif budget < 60:\n        global_frac = 0.65 if dim <= 10 else 0.75\n        refine_frac = 0.1\n    elif budget < 200:\n        global_frac = 0.55 if dim <= 10 else 0.65\n        refine_frac = 0.2\n    else:\n        global_frac = 0.45 if dim <= 10 else 0.6\n        refine_frac = 0.25\n\n    local_frac = max(0.0, 1.0 - global_frac - refine_frac)\n\n    global_budget = max(1, int(budget * global_frac))\n    refine_budget = max(0, int(budget * refine_frac))\n    local_budget = max(0, budget - global_budget - refine_budget)\n\n    # Fix rounding\n    total_alloc = global_budget + refine_budget + local_budget\n    if total_alloc < budget:\n        global_budget += budget - total_alloc\n    elif total_alloc > budget:\n        global_budget = max(0, global_budget - (total_alloc - budget))\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    rng = np.random.default_rng()\n\n    # -------- Helpers --------\n    def quasi_random_samples(n_samples, base_seed=None):\n        \"\"\"Simple van der Corput-based low-discrepancy sampler in [low, high].\"\"\"\n        if n_samples <= 0:\n            return np.empty((0, dim), dtype=float)\n\n        primes = [2, 3, 5, 7, 11, 13, 17, 19, 23]\n        bases = [primes[i % len(primes)] for i in range(dim)]\n\n        if base_seed is None:\n            start = rng.integers(0, 10000)\n        else:\n            start = int(base_seed)\n\n        def vdc(n, base):\n            v = 0.0\n            denom = 1.0\n            while n:\n                n, r = divmod(n, base)\n                denom *= base\n                v += r / denom\n            return v\n\n        xs = np.empty((n_samples, dim), dtype=float)\n        for i in range(n_samples):\n            idx = start + i\n            for d in range(dim):\n                xs[i, d] = vdc(idx, bases[d])\n\n        # Randomly permute each dimension to reduce structure\n        for d in range(dim):\n            perm = rng.permutation(n_samples)\n            xs[:, d] = xs[perm, d]\n\n        xs = low + span * xs\n        return xs\n\n    def try_eval(x):\n        \"\"\"Safe evaluation with budget check and best update.\"\"\"\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        x = np.asarray(x, dtype=float).reshape(dim)\n        x = np.clip(x, low, high)\n        x[~free_dims] = low[~free_dims]\n        try:\n            y = objective_function(x)\n        except Exception:\n            return None\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            # ensure we always store a copy to avoid unintentional mutation\n            best_x = x.copy()\n        return y\n\n    # ---------- Warm start handling ----------\n    if prev_best_x is not None and budget > 0:\n        try:\n            prev_arr = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            prev_arr = np.clip(prev_arr, low, high)\n            prev_arr[~free_dims] = low[~free_dims]\n            y = try_eval(prev_arr)\n            if y is None:\n                best_x, best_y = None, np.inf\n        except Exception:\n            best_x, best_y = None, np.inf\n\n    # Always evaluate the center early (robust baseline), unless budget is exhausted\n    center = (low + high) / 2.0\n    if evals_used < budget:\n        try_eval(center)\n\n    # Adjust allocation for any warm-start/center evaluations already used\n    # Deduct them from global budget first to keep refinement/local phases intact\n    if evals_used > 0:\n        deduct = min(evals_used, global_budget)\n        global_budget = max(0, global_budget - deduct)\n\n    # ---------- Tiny budgets: simplified logic ----------\n    if budget <= 3:\n        # One purely random sample if budget allows\n        remaining = budget - evals_used\n        if remaining > 0:\n            xr = low + span * rng.random(dim)\n            try_eval(xr)\n            remaining = budget - evals_used\n\n        # If still have budget, sample near current best (local exploitation)\n        if remaining > 0 and best_x is not None:\n            step = 0.2 * safe_span / np.sqrt(max(dim, 1))\n            noise = (rng.random(dim) * 2.0 - 1.0) * step\n            cand = best_x + noise\n            cand = np.clip(cand, low, high)\n            cand[~free_dims] = low[~free_dims]\n            try_eval(cand)\n\n        if best_x is None:\n            best_x = center\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    # ---------- Phase 1: Global search ----------\n    if global_budget > 0 and evals_used < budget:\n        # Mix quasi-random and random; in high dim rely more on pure random\n        if dim <= 15:\n            n_qr = int(0.7 * global_budget)\n        else:\n            n_qr = int(0.5 * global_budget)\n        n_qr = max(0, min(global_budget, n_qr))\n        n_rand = global_budget - n_qr\n\n        if n_qr > 0:\n            samples = quasi_random_samples(n_qr)\n            for i in range(n_qr):\n                if evals_used >= budget:\n                    break\n                try_eval(samples[i])\n\n        for _ in range(n_rand):\n            if evals_used >= budget:\n                break\n            x = low + span * rng.random(dim)\n            try_eval(x)\n\n    # Ensure at least one evaluation succeeded\n    if best_x is None:\n        try_eval(center)\n        if best_x is None:\n            best_x = center\n            best_y = np.inf\n\n    # ---------- Phase 2: ES-style population refinement around best ----------\n    if refine_budget > 0 and evals_used < budget:\n        # Choose number of generations and offspring per generation.\n        # Ensure enough population for meaningful selection.\n        max_generations = max(1, min(8, refine_budget // max(6, dim)))\n        lam = max(6, refine_budget // max_generations)\n        lam = int(min(lam, max(10 * dim, 80)))\n        mu = max(3, lam // 3)\n\n        mean = best_x.copy()\n        # Scale sigma per-dimension instead of scalar for better conditioning\n        sigma_vec = 0.2 * safe_span / np.sqrt(max(dim, 1))\n        sigma_vec[sigma_vec <= 0] = 1.0\n\n        sigma_min = 1e-6 * safe_span\n        sigma_max = 0.5 * safe_span\n\n        success_rate_target = 0.25\n        gen_evals = 0\n\n        for _ in range(max_generations):\n            if evals_used >= budget or gen_evals >= refine_budget:\n                break\n\n            remaining = min(refine_budget - gen_evals, budget - evals_used)\n            if remaining <= 0:\n                break\n            k = min(lam, remaining)\n\n            noise = rng.standard_normal((k, dim))\n            offspring = mean + noise * sigma_vec\n            offspring = np.clip(offspring, low, high)\n            offspring[:, ~free_dims] = low[~free_dims]\n\n            ys = np.empty(k, dtype=float)\n            for i in range(k):\n                if evals_used >= budget:\n                    ys[i] = np.inf\n                    continue\n                y = try_eval(offspring[i])\n                ys[i] = y if y is not None else np.inf\n            gen_evals += k\n\n            if not np.isfinite(ys).any():\n                continue\n\n            idx = np.argsort(ys)\n            ys_sorted = ys[idx]\n            xs_sorted = offspring[idx]\n\n            finite_mask = np.isfinite(ys_sorted)\n            if not finite_mask.any():\n                continue\n            finite_indices = np.where(finite_mask)[0]\n            use_mu = min(mu, len(finite_indices))\n            parents = xs_sorted[finite_indices[:use_mu]]\n\n            new_mean = np.mean(parents, axis=0)\n\n            prev_best = best_y\n            if ys_sorted[finite_indices[0]] < prev_best - 1e-12:\n                success_flag = 1.0\n            else:\n                success_flag = 0.0\n\n            # Per-dimension sigma adaptation\n            adjust = np.exp((success_flag - success_rate_target) * 0.5 / max(dim, 1))\n            sigma_vec *= adjust\n            sigma_vec = np.clip(sigma_vec, sigma_min, sigma_max)\n\n            mean = new_mean\n\n    # ---------- Phase 3: Local search ----------\n    if local_budget > 0 and evals_used < budget:\n        base_step = 0.3 * safe_span / np.sqrt(max(dim, 1))\n        step_floor = 1e-4 * safe_span\n\n        cov_diag = (0.12 * safe_span / np.sqrt(max(dim, 1))) ** 2\n        cov_min = (1e-6 * safe_span) ** 2\n        cov_max = (0.25 * safe_span) ** 2\n\n        success_counter = 0\n        total_counter = 0\n\n        cur_x = best_x.copy()\n        cur_y = best_y\n\n        for i in range(local_budget):\n            if evals_used >= budget:\n                break\n\n            if local_budget > 1:\n                t = i / (local_budget - 1)\n            else:\n                t = 0.0\n            decay = 0.2 ** t\n            step = np.maximum(base_step * decay, step_floor)\n\n            mode = i % 6\n            if mode == 0:\n                z = rng.standard_normal(dim) * np.sqrt(cov_diag)\n                cand_x = cur_x + z\n            elif mode == 1:\n                z = rng.standard_normal(dim) * (0.6 * np.sqrt(cov_diag))\n                cand_x = best_x + z\n            elif mode == 2:\n                coord = rng.integers(dim)\n                cand_x = cur_x.copy()\n                cand_x[coord] += step[coord]\n            elif mode == 3:\n                coord = rng.integers(dim)\n                cand_x = cur_x.copy()\n                cand_x[coord] -= step[coord]\n            elif mode == 4:\n                u = (rng.random(dim) * 2.0 - 1.0) * step\n                cand_x = cur_x + u\n            else:\n                z = rng.standard_normal(dim) * (0.3 * step)\n                cand_x = best_x + z\n\n            cand_x = np.clip(cand_x, low, high)\n            cand_x[~free_dims] = low[~free_dims]\n\n            prev_best_y = best_y\n            y = try_eval(cand_x)\n\n            if y is None:\n                continue\n\n            if y < cur_y:\n                cur_x, cur_y = cand_x, y\n\n            total_counter += 1\n            if best_y < prev_best_y - 1e-12:\n                success_counter += 1\n                diff = best_x - cand_x\n                cov_diag = 0.9 * cov_diag + 0.1 * (diff * diff + 1e-12)\n\n            if total_counter >= 10:\n                rate = success_counter / total_counter if total_counter > 0 else 0.0\n                if rate > 0.35:\n                    cov_diag *= 1.3\n                elif rate < 0.15:\n                    cov_diag *= 0.6\n                cov_diag = np.clip(cov_diag, cov_min, cov_max)\n                success_counter = 0\n                total_counter = 0\n\n    best_x = np.asarray(best_x, dtype=float).reshape(dim)\n    return best_x",
    "X": "-0.003191805449091742 -0.0007621740387074071 0.004490873281667421 -0.00021171434462464046 -0.006373790021221351 0.0017810653137085605 -0.003554018643188049"
}