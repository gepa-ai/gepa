{
    "score": 30.0,
    "Input": "Plateau",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Simple derivative-free optimizer: global random search +\n    local refinement around best-so-far (including warm start).\n    \"\"\"\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", len(bounds)))\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Helper: project to bounds\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n\n    # Initialize best solution\n    best_x = None\n    best_y = None\n\n    # Warm-start: evaluate prev_best_x if valid and budget allows\n    if prev_best_x is not None and budget > 0:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip_to_bounds(x0)\n            y0 = objective_function(x0)\n            evals_used += 1\n            best_x, best_y = x0, y0\n\n    # If we still have no incumbent, sample one random point\n    if best_x is None and budget > evals_used:\n        x0 = np.random.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Split budget between global exploration and local exploitation\n    # Favor global for small budgets, more local for larger budgets\n    global_frac = 0.6 if remaining >= 20 else 0.8\n    n_global = max(1, int(remaining * global_frac))\n    n_local = max(0, remaining - n_global)\n\n    # ---- Global random search ----\n    for _ in range(n_global):\n        x = np.random.uniform(low, high)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_x, best_y = x, y\n\n    remaining = budget - evals_used\n    if remaining <= 0 or n_local <= 0:\n        return best_x\n\n    # ---- Local search around best_x (Gaussian perturbations) ----\n    # Start with a moderate step relative to domain size\n    base_sigma = 0.2 * span\n    base_sigma[base_sigma == 0.0] = 1.0  # avoid zeros\n\n    # Split local evaluations into a few \"radius\" levels\n    n_levels = min(3, remaining)\n    per_level = [remaining // n_levels] * n_levels\n    for i in range(remaining % n_levels):\n        per_level[i] += 1\n\n    for level, n_evals in enumerate(per_level):\n        if n_evals <= 0:\n            continue\n        # Decrease radius over levels\n        scale = 0.5 ** level\n        sigma = base_sigma * scale\n\n        for _ in range(n_evals):\n            noise = np.random.normal(loc=0.0, scale=sigma, size=dim)\n            x = best_x + noise\n            x = clip_to_bounds(x)\n            y = objective_function(x)\n            evals_used += 1\n            if y < best_y:\n                best_x, best_y = x, y\n            if evals_used >= budget:\n                return best_x\n\n    return best_x",
    "X": "0.3419289382804438 0.9202583753430873"
}