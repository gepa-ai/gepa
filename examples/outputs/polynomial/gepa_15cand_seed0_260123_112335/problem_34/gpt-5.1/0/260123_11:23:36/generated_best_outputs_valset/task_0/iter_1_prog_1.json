{
    "score": -7.692372748513917,
    "Input": "McCourt28",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization using a simple hybrid global-local search.\n\n    Strategy:\n    1. Global search with quasi-random samples (Sobol-like via scrambling of linspace)\n       plus random samples across the full domain.\n    2. Local search (Gaussian perturbations) around the best point(s) found.\n    3. Warm start from prev_best_x if provided and inside bounds.\n\n    Uses the full evaluation budget and returns the best point found.\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    assert bounds.shape == (dim, 2)\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n\n    def clip_to_bounds(x):\n        return np.clip(x, lower, upper)\n\n    eval_count = 0\n    best_x = None\n    best_y = np.inf\n\n    def evaluate(x):\n        nonlocal eval_count, best_x, best_y\n        if eval_count >= budget:\n            return np.inf\n        y = objective_function(x)\n        eval_count += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    if budget <= 0:\n        # Return a feasible point (midpoint of bounds) when no budget\n        return (lower + upper) / 2.0\n\n    # Warm start if available and valid\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip_to_bounds(x0)\n            evaluate(x0)\n\n    remaining = budget - eval_count\n    if remaining <= 0:\n        # If we already spent budget on warm start\n        if best_x is None:\n            best_x = (lower + upper) / 2.0\n        return best_x\n\n    # Global search phase: use ~60% of remaining evaluations\n    global_evals = max(5 * dim, int(0.6 * remaining))\n    global_evals = min(global_evals, remaining)\n    if global_evals < 1:\n        global_evals = remaining\n\n    # Quasi-random (Sobol-like) initialization using scrambled linspace\n    n_qr = min(global_evals, max(2 * dim, 8))\n    base = np.linspace(0, 1, n_qr, endpoint=False)[:, None]  # (n_qr,1)\n    np.random.shuffle(base)\n    shifts = np.random.rand(1, dim)\n    qr_points = (base + shifts) % 1.0\n    qr_points = lower + qr_points * span\n\n    # Evaluate quasi-random points\n    for i in range(n_qr):\n        if eval_count >= budget:\n            break\n        evaluate(qr_points[i])\n\n    # Remaining global samples are uniform random\n    remaining_global = global_evals - n_qr\n    for _ in np.arange(remaining_global):\n        if eval_count >= budget:\n            break\n        x = np.random.uniform(lower, upper)\n        evaluate(x)\n\n    remaining = budget - eval_count\n    if remaining <= 0:\n        if best_x is None:\n            best_x = (lower + upper) / 2.0\n        return best_x\n\n    # Local search phase around current best\n    # Use progressively shrinking Gaussian perturbations\n    local_evals = remaining\n    if best_x is None:\n        # Fallback if somehow no evaluations occurred\n        best_x = np.random.uniform(lower, upper)\n        evaluate(best_x)\n        local_evals = budget - eval_count\n\n    if local_evals > 0:\n        # Initial step size as a fraction of span\n        base_sigma = 0.25 * span\n        base_sigma[base_sigma == 0] = 1.0\n\n        for i in range(local_evals):\n            if eval_count >= budget:\n                break\n            # Geometric cooling of step size\n            frac = 1.0 - (i / max(local_evals - 1, 1))\n            sigma = base_sigma * (0.1 + 0.9 * frac * frac)\n            perturb = np.random.normal(scale=sigma, size=dim)\n            x_new = clip_to_bounds(best_x + perturb)\n            evaluate(x_new)\n\n    if best_x is None:\n        best_x = (lower + upper) / 2.0\n    return best_x",
    "X": "0.45225769970189045 0.05340288605420181 0.9120831311806826 0.2693357847833488"
}