{
    "score": -7.6943042018376495,
    "Input": "McCourt28",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization using a hybrid global-local search with\n    adaptive step sizes and better use of warm starts.\n\n    Strategy:\n    1. Warm start from prev_best_x if provided and valid.\n    2. Global search with quasi-random (scrambled linspace) + uniform sampling.\n    3. Adaptive local search around the current best point using Gaussian\n       perturbations with step-size reduction on stagnation.\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    assert bounds.shape == (dim, 2)\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n\n    def clip_to_bounds(x):\n        return np.clip(x, lower, upper)\n\n    eval_count = 0\n    best_x = None\n    best_y = np.inf\n\n    def evaluate(x):\n        nonlocal eval_count, best_x, best_y\n        if eval_count >= budget:\n            return np.inf\n        x = clip_to_bounds(np.asarray(x, dtype=float).reshape(-1))\n        y = objective_function(x)\n        eval_count += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    if budget <= 0:\n        return (lower + upper) / 2.0\n\n    # Warm start if available and valid\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            evaluate(x0)\n\n    remaining = budget - eval_count\n    if remaining <= 0:\n        if best_x is None:\n            best_x = (lower + upper) / 2.0\n        return best_x\n\n    # Global search phase: allocate about 50% of remaining evaluations, but\n    # ensure a reasonable minimum depending on dimension.\n    global_evals = max(10 * dim, int(0.5 * remaining))\n    global_evals = min(global_evals, remaining)\n    if global_evals < 1:\n        global_evals = remaining\n\n    # Quasi-random (Sobol-like) initialization using scrambled linspace\n    n_qr = min(global_evals, max(4 * dim, 16))\n    base = np.linspace(0, 1, n_qr, endpoint=False)[:, None]  # (n_qr, 1)\n    np.random.shuffle(base)\n    shifts = np.random.rand(1, dim)\n    qr_points = (base + shifts) % 1.0\n    qr_points = lower + qr_points * span\n\n    for i in range(n_qr):\n        if eval_count >= budget:\n            break\n        evaluate(qr_points[i])\n\n    remaining_global = global_evals - n_qr\n    for _ in range(remaining_global):\n        if eval_count >= budget:\n            break\n        x = np.random.uniform(lower, upper)\n        evaluate(x)\n\n    remaining = budget - eval_count\n    if remaining <= 0:\n        if best_x is None:\n            best_x = (lower + upper) / 2.0\n        return best_x\n\n    # Local search phase with adaptive step size\n    if best_x is None:\n        best_x = np.random.uniform(lower, upper)\n        evaluate(best_x)\n        remaining = budget - eval_count\n        if remaining <= 0:\n            return best_x\n\n    local_evals = remaining\n    # Base step size relative to search span\n    base_sigma = 0.2 * span\n    base_sigma[base_sigma == 0] = 1.0\n    sigma = base_sigma.copy()\n\n    no_improve = 0\n    last_best_y = best_y\n\n    for i in range(local_evals):\n        if eval_count >= budget:\n            break\n\n        # Periodically reduce step size if no improvement\n        if i > 0 and i % max(5 * dim, 10) == 0:\n            if best_y >= last_best_y - 1e-12:\n                # Reduce sigma but keep it from collapsing completely\n                sigma *= 0.5\n                sigma = np.maximum(sigma, 0.01 * base_sigma)\n                no_improve += 1\n            else:\n                # If we improved, slightly increase sigma to allow exploration\n                sigma *= 1.1\n                sigma = np.minimum(sigma, base_sigma)\n                no_improve = 0\n            last_best_y = best_y\n\n        # Occasionally restart around a random point if stagnating badly\n        if no_improve >= 3 and i < local_evals - 1:\n            restart_x = np.random.uniform(lower, upper)\n            evaluate(restart_x)\n            no_improve = 0\n            continue\n\n        perturb = np.random.normal(scale=sigma, size=dim)\n        x_new = best_x + perturb\n        x_new = clip_to_bounds(x_new)\n        evaluate(x_new)\n\n    if best_x is None:\n        best_x = (lower + upper) / 2.0\n    return best_x",
    "X": "0.4498393670320332 0.06610439975600611 0.9085880665992848 0.27227923276540983"
}