{
    "score": 0.7852018071050009,
    "Input": "Easom",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Blackbox minimization with:\n    - robust initialization (incl. warm start)\n    - stronger global search (suited for narrow-basin problems like Easom)\n    - adaptive local search (CMA-ES\u2013like) for exploitation\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    bounds = np.array(bounds, dtype=float, copy=True)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config[\"budget\"])\n\n    # Ensure proper shape for bounds\n    if bounds.ndim != 2 or bounds.shape[0] != dim or bounds.shape[1] != 2:\n        bounds = np.reshape(bounds, (dim, 2))\n\n    lower = bounds[:, 0].astype(float).copy()\n    upper = bounds[:, 1].astype(float).copy()\n    span = (upper - lower).astype(float)\n    span = np.where(span <= 0, 1.0, span)\n\n    def clip(x):\n        x = np.asarray(x, dtype=float)\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n\n    # ----------------- Initialization -----------------\n    best_x = None\n    best_y = np.inf\n\n    # Use prev_best_x if available and valid\n    if prev_best_x is not None and evals_used < budget:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip(x0)\n            try:\n                y0 = float(objective_function(x0))\n                evals_used += 1\n                if np.isfinite(y0) and y0 < best_y:\n                    best_x, best_y = x0.copy(), y0\n            except Exception:\n                evals_used += 1  # counts toward budget\n\n    # Fallback: random start if we don't have a valid incumbent\n    if (best_x is None or not np.isfinite(best_y)) and evals_used < budget:\n        x0 = rng.uniform(lower, upper)\n        try:\n            y0 = float(objective_function(x0))\n        except Exception:\n            evals_used += 1\n            return np.asarray(clip(x0), dtype=float).reshape(dim)\n        evals_used += 1\n        best_x, best_y = x0.copy(), y0\n\n    if not np.isfinite(best_y):\n        return clip(lower + 0.5 * span).reshape(dim)\n\n    if evals_used >= budget:\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    # ----------------- Global exploration -----------------\n    remaining = budget - evals_used\n\n    # Increase global search share to better locate very narrow optima (e.g., Easom)\n    global_budget = max(1, int(0.7 * remaining))\n\n    def van_der_corput(n, base=2):\n        vdc = 0.0\n        denom = 1.0\n        while n:\n            n, remainder = divmod(n, base)\n            denom *= base\n            vdc += remainder / denom\n        return vdc\n\n    # Perturbation scales\n    base_scale_lowdim = 0.05  # a bit tighter for small-dim precision\n    base_scale_highdim = 0.02\n\n    # For extremely tight-basin problems, inject some direct probing around current best\n    local_probe_fraction = 0.15\n    local_probe_budget = int(local_probe_fraction * global_budget)\n\n    for i in range(global_budget):\n        if evals_used >= budget:\n            break\n\n        # Decide between quasi-random global point vs local probe around best\n        if i < local_probe_budget:\n            # Local probing around the incumbent best to refine narrow basins\n            if dim <= 5:\n                local_scale = 0.1\n            else:\n                local_scale = 0.05 / np.sqrt(max(1, dim))\n            perturb = rng.normal(scale=local_scale, size=dim) * span\n            x = clip(best_x + perturb)\n        else:\n            # Low-discrepancy global sample + perturbations\n            u = np.empty(dim, dtype=float)\n            for d in range(dim):\n                base = 2 + (d % 3)\n                u[d] = van_der_corput(i + 1 + d * 131, base=base)\n            x = lower + u * span\n\n            # Dimension-dependent perturbation\n            if dim <= 5:\n                base_scale = base_scale_lowdim\n            else:\n                base_scale = base_scale_highdim / np.sqrt(max(1, dim))\n            perturb = rng.normal(scale=base_scale, size=dim) * span\n\n            # Occasional large jump to escape local minima\n            if rng.rand() < 0.10:\n                large_scale = 0.5\n                perturb += rng.normal(scale=large_scale, size=dim) * span\n\n            x = clip(x + perturb)\n\n        try:\n            y = float(objective_function(x))\n        except Exception:\n            evals_used += 1\n            continue\n\n        evals_used += 1\n        if np.isfinite(y) and y < best_y:\n            best_x, best_y = x.copy(), y\n\n    if evals_used >= budget:\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    # ----------------- Local exploitation (CMA-ES\u2013like) -----------------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    center = np.asarray(best_x, dtype=float).copy()\n\n    # Population size: scale with dim but cap by remaining budget\n    lam = max(6, int(4 + 3 * np.log(dim + 1)))\n    lam = min(lam, max(4, remaining))  # ensure at least one generation\n\n    # Start with dimension-aware local scale to avoid overshooting in very narrow wells\n    sigma_start = 0.25 if dim <= 5 else 0.2 / np.sqrt(max(1, dim))\n    sigma_end = 0.02\n    C = np.eye(dim, dtype=float)\n\n    # CMA-like parameters\n    c_c = 2.0 / (dim + 2.0)\n    c_cov = 2.0 / (dim ** 1.5 + 6.0)\n    p_c = np.zeros(dim, dtype=float)\n\n    max_gens = max(1, remaining // max(1, lam))\n    gen = 0\n\n    span_scale = np.maximum(span, 1e-12)\n    min_eig = 1e-10\n\n    while evals_used < budget and gen < max_gens:\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n\n        if max_gens > 1:\n            frac = gen / (max_gens - 1)\n        else:\n            frac = 1.0\n        frac = np.clip(frac, 0.0, 1.0)\n        sigma = (1.0 - frac) * sigma_start + frac * sigma_end\n\n        try:\n            A = np.linalg.cholesky(C)\n        except np.linalg.LinAlgError:\n            try:\n                eigvals, eigvecs = np.linalg.eigh(C)\n                eigvals = np.maximum(eigvals, min_eig)\n                C = (eigvecs * eigvals) @ eigvecs.T\n            except Exception:\n                diag = np.maximum(min_eig, np.diag(C))\n                C = np.diag(diag)\n            A = np.linalg.cholesky(C + min_eig * np.eye(dim))\n\n        n_offspring = int(min(lam, remaining))\n        if n_offspring <= 0:\n            break\n\n        z = rng.randn(n_offspring, dim)\n        steps = (z @ A.T) * sigma\n\n        # Tightened step limit to better handle narrow global minima\n        step_norms = np.linalg.norm(steps, axis=1)\n        max_step = 3.0 if dim <= 5 else 2.5\n        mask = step_norms > max_step\n        if np.any(mask):\n            steps[mask] *= (max_step / step_norms[mask])[:, None]\n\n        X = center + steps * span_scale\n        X = clip(X)\n\n        Ys = []\n        valid_indices = []\n        for j in range(n_offspring):\n            if evals_used >= budget:\n                break\n            try:\n                y = float(objective_function(X[j]))\n            except Exception:\n                evals_used += 1\n                continue\n            evals_used += 1\n            if not np.isfinite(y):\n                continue\n            Ys.append(y)\n            valid_indices.append(j)\n\n        if not Ys:\n            gen += 1\n            continue\n\n        Ys = np.asarray(Ys, dtype=float)\n        X = X[np.asarray(valid_indices, dtype=int)]\n\n        idx = np.argsort(Ys)\n        X = X[idx]\n        Ys = Ys[idx]\n\n        if Ys[0] < best_y:\n            best_y = Ys[0]\n            best_x = X[0].copy()\n            center = best_x.copy()\n\n        mu = max(1, X.shape[0] // 2)\n        elite = X[:mu]\n        ranks = np.arange(1, mu + 1)\n        weights = np.log(mu + 0.5) - np.log(ranks)\n        weights = np.maximum(weights, 0.0)\n        if np.sum(weights) == 0.0:\n            weights = np.ones_like(weights)\n        weights /= np.sum(weights)\n\n        old_center = center.copy()\n        new_center = np.sum(elite * weights[:, None], axis=0)\n\n        norm_steps = ((elite - old_center) / span_scale) / max(1e-12, sigma)\n        mean_step = np.sum(norm_steps * weights[:, None], axis=0)\n\n        p_c = (1.0 - c_c) * p_c + np.sqrt(c_c * (2.0 - c_c)) * mean_step\n\n        rank_mu = np.zeros((dim, dim), dtype=float)\n        for w, s in zip(weights, norm_steps):\n            rank_mu += w * np.outer(s, s)\n\n        C = (1.0 - c_cov) * C + c_cov * (np.outer(p_c, p_c) + rank_mu)\n\n        C = 0.5 * (C + C.T)\n        diag = np.diag(C).copy()\n        diag[diag <= min_eig] = min_eig\n        C[np.diag_indices(dim)] = diag\n\n        center = new_center\n        gen += 1\n\n    return np.asarray(best_x, dtype=float).reshape(dim)",
    "X": "-0.1049568255928765 -0.0796212271966468"
}