{
    "score": 0.0722810863146397,
    "Input": "Easom",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Blackbox minimization with:\n    - robust initialization (incl. warm start)\n    - quasi-random global exploration tuned for narrow-basin problems (e.g., Easom)\n    - adaptive local CMA-ES\u2013like exploitation\n    - optional ultra-local refinement for very narrow minima\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    bounds = np.array(bounds, dtype=float, copy=True)\n    dim = int(config.get(\"dim\", bounds.shape[0]))\n    budget = int(config[\"budget\"])\n\n    # Ensure proper shape for bounds\n    if bounds.ndim != 2 or bounds.shape[0] != dim or bounds.shape[1] != 2:\n        bounds = np.reshape(bounds, (dim, 2))\n\n    lower = bounds[:, 0].astype(float).copy()\n    upper = bounds[:, 1].astype(float).copy()\n    span = (upper - lower).astype(float)\n    span = np.where(span <= 0, 1.0, span)\n\n    def clip(x):\n        x = np.asarray(x, dtype=float)\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n\n    # ----------------- Initialization -----------------\n    best_x = None\n    best_y = np.inf\n\n    # Use prev_best_x if available and valid\n    if prev_best_x is not None and evals_used < budget:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip(x0)\n            try:\n                y0 = float(objective_function(x0))\n                evals_used += 1\n                if np.isfinite(y0) and y0 < best_y:\n                    best_x, best_y = x0.copy(), y0\n            except Exception:\n                evals_used += 1  # counts toward budget\n\n    # Fallback: multiple random/quasi-random starts if we don't have a valid incumbent\n    # This helps for extremely narrow basins like Easom where a single random hit\n    # near the global optimum is unlikely.\n    if (best_x is None or not np.isfinite(best_y)) and evals_used < budget:\n        # Use up to 5% of budget (at least 3, at most 30) for diversified initial sampling\n        init_budget = min(budget - evals_used, max(3, int(0.05 * budget)))\n        init_budget = min(init_budget, 30)\n\n        # Halton-like sequence in [0,1]^dim\n        def van_der_corput(n, base=2):\n            vdc = 0.0\n            denom = 1.0\n            while n:\n                n, remainder = divmod(n, base)\n                denom *= base\n                vdc += remainder / denom\n            return vdc\n\n        for i in range(init_budget):\n            if evals_used >= budget:\n                break\n            u = np.empty(dim, dtype=float)\n            for d in range(dim):\n                base = 2 + (d % 5)\n                u[d] = van_der_corput(i + 1 + d * 131, base=base)\n            # Mild jitter to avoid exact lattice positions\n            u += rng.normal(scale=0.01, size=dim)\n            u = np.clip(u, 0.0, 1.0)\n            x0 = lower + u * span\n            x0 = clip(x0)\n            try:\n                y0 = float(objective_function(x0))\n            except Exception:\n                evals_used += 1\n                continue\n            evals_used += 1\n            if np.isfinite(y0) and y0 < best_y:\n                best_x, best_y = x0.copy(), y0\n\n    # Still no finite evaluation: return center of box\n    if best_x is None or not np.isfinite(best_y):\n        return clip(lower + 0.5 * span).reshape(dim)\n\n    if evals_used >= budget:\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    # ----------------- Global exploration -----------------\n    remaining = budget - evals_used\n\n    # Allocate about half evaluations to global search (slightly reduced vs previous\n    # to leave more budget for exploitation after a good hit in narrow basins).\n    global_budget = max(1, int(0.5 * remaining))\n\n    def van_der_corput(n, base=2):\n        vdc = 0.0\n        denom = 1.0\n        while n:\n            n, remainder = divmod(n, base)\n            denom *= base\n            vdc += remainder / denom\n        return vdc\n\n    # Perturbation scales\n    base_scale_lowdim = 0.05  # slightly more spread to increase chance hitting basin\n    base_scale_highdim = 0.02\n\n    # Local probing around best_x during global phase for refinement if we already\n    # found a promising point (important for warm-start or early hits).\n    local_probe_fraction = 0.25\n    local_probe_budget = int(local_probe_fraction * global_budget)\n    local_probe_budget = min(local_probe_budget, remaining)\n\n    narrow_hits = 0\n\n    for i in range(global_budget):\n        if evals_used >= budget:\n            break\n\n        # Decide between quasi-random global point vs local probe around best\n        if i < local_probe_budget:\n            # Local probing near the best to refine narrow basins\n            if dim <= 5:\n                local_scale = 0.1\n            else:\n                local_scale = 0.06 / np.sqrt(max(1, dim))\n            perturb = rng.normal(scale=local_scale, size=dim) * span\n            x = clip(best_x + perturb)\n        else:\n            # Low-discrepancy global sample + perturbations\n            u = np.empty(dim, dtype=float)\n            for d in range(dim):\n                base = 2 + (d % 3)\n                u[d] = van_der_corput(i + 1 + d * 131, base=base)\n            x = lower + u * span\n\n            # Dimension-dependent perturbation\n            if dim <= 5:\n                base_scale = base_scale_lowdim\n            else:\n                base_scale = base_scale_highdim / np.sqrt(max(1, dim))\n            perturb = rng.normal(scale=base_scale, size=dim) * span\n\n            # Occasional large jump to escape local minima\n            if rng.rand() < 0.1:\n                large_scale = 0.5\n                perturb += rng.normal(scale=large_scale, size=dim) * span\n\n            x = clip(x + perturb)\n\n        try:\n            y = float(objective_function(x))\n        except Exception:\n            evals_used += 1\n            continue\n\n        evals_used += 1\n        if np.isfinite(y) and y < best_y:\n            # Detect \"sudden\" large improvements as potential narrow-basin hits\n            if np.isfinite(best_y) and (best_y - y) > max(1e-12, abs(best_y) * 0.5):\n                narrow_hits += 1\n            best_x, best_y = x.copy(), y\n\n    if evals_used >= budget:\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    # ----------------- Local exploitation (CMA-ES\u2013like) -----------------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return np.asarray(best_x, dtype=float).reshape(dim)\n\n    center = np.asarray(best_x, dtype=float).copy()\n\n    # Population size: scale with dim but cap by remaining budget\n    lam = max(6, int(4 + 3 * np.log(dim + 1)))\n    lam = min(lam, max(4, remaining))  # ensure at least one generation\n\n    # Start with dimension-aware local scale\n    sigma_start = 0.25 if dim <= 5 else 0.18 / np.sqrt(max(1, dim))\n    sigma_end = 0.01\n    C = np.eye(dim, dtype=float)\n\n    # CMA-like parameters\n    c_c = 2.0 / (dim + 2.0)\n    c_cov = 2.0 / (dim ** 1.5 + 6.0)\n    p_c = np.zeros(dim, dtype=float)\n\n    max_gens = max(1, remaining // max(1, lam))\n    gen = 0\n\n    span_scale = np.maximum(span, 1e-12)\n    min_eig = 1e-10\n\n    best_y_before_local = best_y\n\n    while evals_used < budget and gen < max_gens:\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n\n        if max_gens > 1:\n            frac = gen / (max_gens - 1)\n        else:\n            frac = 1.0\n        frac = np.clip(frac, 0.0, 1.0)\n        sigma = (1.0 - frac) * sigma_start + frac * sigma_end\n\n        try:\n            A = np.linalg.cholesky(C)\n        except np.linalg.LinAlgError:\n            try:\n                eigvals, eigvecs = np.linalg.eigh(C)\n                eigvals = np.maximum(eigvals, min_eig)\n                C = (eigvecs * eigvals) @ eigvecs.T\n            except Exception:\n                diag = np.maximum(min_eig, np.diag(C))\n                C = np.diag(diag)\n            A = np.linalg.cholesky(C + min_eig * np.eye(dim))\n\n        n_offspring = int(min(lam, remaining))\n        if n_offspring <= 0:\n            break\n\n        z = rng.randn(n_offspring, dim)\n        steps = (z @ A.T) * sigma\n\n        # Limit step length in standardized space\n        step_norms = np.linalg.norm(steps, axis=1)\n        max_step = 3.0 if dim <= 5 else 2.5\n        mask = step_norms > max_step\n        if np.any(mask):\n            steps[mask] *= (max_step / step_norms[mask])[:, None]\n\n        X = center + steps * span_scale\n        X = clip(X)\n\n        Ys = []\n        valid_indices = []\n        for j in range(n_offspring):\n            if evals_used >= budget:\n                break\n            try:\n                y = float(objective_function(X[j]))\n            except Exception:\n                evals_used += 1\n                continue\n            evals_used += 1\n            if not np.isfinite(y):\n                continue\n            Ys.append(y)\n            valid_indices.append(j)\n\n        if not Ys:\n            gen += 1\n            continue\n\n        Ys = np.asarray(Ys, dtype=float)\n        X = X[np.asarray(valid_indices, dtype=int)]\n\n        idx = np.argsort(Ys)\n        X = X[idx]\n        Ys = Ys[idx]\n\n        if Ys[0] < best_y:\n            best_y = Ys[0]\n            best_x = X[0].copy()\n            center = best_x.copy()\n\n        mu = max(1, X.shape[0] // 2)\n        elite = X[:mu]\n        ranks = np.arange(1, mu + 1)\n        weights = np.log(mu + 0.5) - np.log(ranks)\n        weights = np.maximum(weights, 0.0)\n        if np.sum(weights) == 0.0:\n            weights = np.ones_like(weights)\n        weights /= np.sum(weights)\n\n        old_center = center.copy()\n        new_center = np.sum(elite * weights[:, None], axis=0)\n\n        norm_steps = ((elite - old_center) / span_scale) / max(1e-12, sigma)\n        mean_step = np.sum(norm_steps * weights[:, None], axis=0)\n\n        p_c = (1.0 - c_c) * p_c + np.sqrt(c_c * (2.0 - c_c)) * mean_step\n\n        rank_mu = np.zeros((dim, dim), dtype=float)\n        for w, s in zip(weights, norm_steps):\n            rank_mu += w * np.outer(s, s)\n\n        C = (1.0 - c_cov) * C + c_cov * (np.outer(p_c, p_c) + rank_mu)\n\n        C = 0.5 * (C + C.T)\n        diag = np.diag(C).copy()\n        diag[diag <= min_eig] = min_eig\n        C[np.diag_indices(dim)] = diag\n\n        center = new_center\n        gen += 1\n\n    # ----------------- Focused ultra-local refinement -----------------\n    remaining = budget - evals_used\n    if remaining > 0:\n        # If we saw strong hints of a narrow basin but local search did not improve much,\n        # spend remaining budget in a very tight neighborhood around best_x.\n        if narrow_hits > 0 and best_y_before_local - best_y < max(\n            1e-12, abs(best_y_before_local) * 0.01\n        ):\n            tight_scale = 0.01 if dim <= 5 else 0.005 / np.sqrt(max(1, dim))\n            for _ in range(remaining):\n                if evals_used >= budget:\n                    break\n                if rng.rand() < 0.85:\n                    scale = tight_scale\n                else:\n                    scale = tight_scale * 4.0\n                perturb = rng.normal(scale=scale, size=dim) * span\n                x = clip(best_x + perturb)\n                try:\n                    y = float(objective_function(x))\n                except Exception:\n                    evals_used += 1\n                    continue\n                evals_used += 1\n                if np.isfinite(y) and y < best_y:\n                    best_y = y\n                    best_x = x.copy()\n        else:\n            # If we did not get strong narrow-basin signals, still use any residual budget\n            # for moderate local refinement around best_x.\n            local_scale = 0.03 if dim <= 5 else 0.02 / np.sqrt(max(1, dim))\n            for _ in range(remaining):\n                if evals_used >= budget:\n                    break\n                perturb = rng.normal(scale=local_scale, size=dim) * span\n                x = clip(best_x + perturb)\n                try:\n                    y = float(objective_function(x))\n                except Exception:\n                    evals_used += 1\n                    continue\n                evals_used += 1\n                if np.isfinite(y) and y < best_y:\n                    best_y = y\n                    best_x = x.copy()\n\n    return np.asarray(best_x, dtype=float).reshape(dim)",
    "X": "0.003918597827144515 -0.020936075864173766"
}