{
    "score": -1.2277400799132916,
    "Input": "Shekel05",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config['bounds'], dtype=float)\n    dim = int(config.get('dim', len(bounds)))\n    budget = int(config.get('budget', 1))\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n\n    def clip_to_bounds(x):\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # Helper to evaluate a point (with bound handling)\n    def evaluate(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        x = clip_to_bounds(x)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # If no budget, return center of bounds\n    if budget <= 0:\n        return (lower + upper) / 2.0\n\n    # 1) Use prev_best_x if available as first evaluation\n    if prev_best_x is not None:\n        prev_best_x = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if prev_best_x.size == dim:\n            evaluate(prev_best_x)\n\n    # 2) Always ensure at least one evaluation\n    if evals_used == 0:\n        x0 = np.random.uniform(lower, upper)\n        evaluate(x0)\n        if evals_used >= budget:\n            return best_x\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Split remaining budget between global sampling and local search\n    # Favor more global samples when budget is small.\n    global_frac = 0.7 if budget >= 20 else 0.5\n    n_global = max(1, int(remaining * global_frac))\n    n_local = max(0, remaining - n_global)\n\n    # 3) Global random / LHS-like sampling\n    # Draw samples uniformly; slight stratification across dims\n    for i in range(n_global):\n        if evals_used >= budget:\n            break\n        # simple stratification over [0,1]^dim then scale\n        u = (np.random.rand(dim) + i / max(1, n_global)) % 1.0\n        x = lower + u * span\n        evaluate(x)\n\n    if evals_used >= budget or n_local <= 0:\n        return best_x\n\n    # 4) Local search around current best using random perturbations\n    # Step size shrinks over iterations\n    base_step = 0.2  # relative to span\n    for k in range(n_local):\n        if evals_used >= budget:\n            break\n        if best_x is None:\n            center = np.random.uniform(lower, upper)\n        else:\n            center = best_x\n\n        # Exponential decay of step size\n        frac = (k + 1) / (n_local + 1.0)\n        step_scale = base_step * (0.5 ** frac)\n        # Gaussian perturbation scaled by bounds\n        noise = np.random.randn(dim) * (span * step_scale)\n        cand = center + noise\n        evaluate(cand)\n\n    # Safety: if for some reason best_x is still None (shouldn't happen),\n    # return a random point.\n    if best_x is None:\n        best_x = np.random.uniform(lower, upper)\n\n    return best_x",
    "X": "7.915009077889205 7.81639763903312 8.123918256509956 8.788231732319051"
}