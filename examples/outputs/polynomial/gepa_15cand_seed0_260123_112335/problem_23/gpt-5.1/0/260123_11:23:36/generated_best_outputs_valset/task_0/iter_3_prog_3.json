{
    "score": 3.54280701683853,
    "Input": "McCourt12",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid derivative-free optimizer:\n    - Space-filling global exploration (Sobol-like + random fallback)\n    - Adaptive local search around current best (CMA-ES inspired diagonal Gaussian)\n    - Warm-start from prev_best_x when available\n    - Uses full evaluation budget\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = np.maximum(high - low, 1e-12)\n\n    # Degenerate budget: return center\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    # Helper: clip to bounds\n    def clip_to_bounds(x):\n        return np.minimum(high, np.maximum(low, x))\n\n    # Lightweight Sobol-like sequence with safeguards and per-dim continuity\n    def sobol_sequence(n, d, skip=0):\n        # For very high dimension or tiny n, fall back to random for robustness\n        if d > 32 or n <= 0:\n            return rng.rand(n, d)\n\n        max_bits = 30  # enough for up to ~1e9 points, keeps ints small\n        V = np.zeros((max_bits, d), dtype=np.uint32)\n\n        # Simple direction numbers, but build them once per dim with a stable scheme\n        # This is not a full Sobol implementation but gives low-discrepancy-ish spread\n        primitive_polys = [\n            0b11,      # x + 1\n            0b111,     # x^2 + x + 1\n            0b1011,    # x^3 + x + 1\n            0b10011,   # x^4 + x + 1\n            0b100101,  # x^5 + x^2 + 1\n            0b1000011, # x^6 + x + 1\n        ]\n\n        for j in range(d):\n            poly = primitive_polys[j % len(primitive_polys)]\n            degree = poly.bit_length() - 1\n            # Initial direction numbers: powers of 2 decreasing\n            for i in range(degree):\n                V[i, j] = 1 << (31 - i)\n            # Recurrence for remaining bits\n            for i in range(degree, max_bits):\n                val = V[i - degree, j]\n                val ^= val >> degree\n                for k in range(1, degree):\n                    if (poly >> k) & 1:\n                        val ^= V[i - k, j]\n                V[i, j] = val\n\n        x = np.zeros(d, dtype=np.uint32)\n        result = np.empty((n, d), dtype=float)\n        idx = 0\n        for i in range(skip, skip + n):\n            if i == 0:\n                # First point: center-like\n                result[idx] = 0.5\n                idx += 1\n                continue\n            c = (i & -i).bit_length() - 1\n            if c < max_bits:\n                x ^= V[c]\n            else:\n                # Safety: fall back to random bit flip if index too large\n                x ^= rng.randint(0, 2**31, size=d, dtype=np.uint32)\n            result[idx] = x / np.float32(2.0**32)\n            idx += 1\n        return result\n\n    evals_used = 0\n    best_x = None\n    best_y = None\n\n    # Robust evaluation wrapper to avoid rare crashes terminating search\n    def eval_point(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        try:\n            y = objective_function(x)\n        except Exception:\n            # On failure, penalize heavily but still count evaluation\n            y = np.inf\n        evals_used += 1\n        if best_y is None or (y is not None and y < best_y):\n            best_y = y\n            best_x = x\n        return y\n\n    # Try warm start\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float)\n        if x0.shape == (dim,):\n            x0 = clip_to_bounds(x0)\n            eval_point(x0)\n\n    # If no valid best yet, start at center\n    if best_x is None and evals_used < budget:\n        x0 = (low + high) / 2.0\n        eval_point(x0)\n\n    # If still no valid point, do one random evaluation\n    if best_x is None and evals_used < budget:\n        x0 = rng.uniform(low, high)\n        eval_point(x0)\n\n    if best_x is None:\n        # Objective always failing\n        return (low + high) / 2.0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Adaptive global/local allocation based on dimension and remaining budget\n    if dim <= 5:\n        global_fraction = 0.5\n    elif dim <= 15:\n        global_fraction = 0.6\n    else:\n        global_fraction = 0.7\n\n    global_budget = int(global_fraction * remaining)\n    global_budget = max(1, min(global_budget, remaining - 1))\n    local_budget = remaining - global_budget\n\n    # --- Global quasi-random exploration ---\n    if global_budget > 0:\n        # Generate candidates; for small n or large dim, mix Sobol and random\n        if global_budget >= 4 and dim <= 32:\n            sobol_n = int(0.7 * global_budget)\n            rand_n = global_budget - sobol_n\n            sobol_pts = sobol_sequence(sobol_n, dim, skip=1)\n            rand_pts = rng.rand(rand_n, dim) if rand_n > 0 else np.empty((0, dim))\n            pts = np.vstack([sobol_pts, rand_pts]) if rand_n > 0 else sobol_pts\n        else:\n            pts = rng.rand(global_budget, dim)\n\n        global_candidates = low + pts * span\n\n        for x in global_candidates:\n            if evals_used >= budget:\n                break\n            eval_point(x)\n\n    if evals_used >= budget:\n        return best_x\n\n    # --- Local adaptive search around current best (diagonal CMA-ES flavor) ---\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    local_budget = max(1, min(local_budget, remaining))\n\n    # Initial step size relative to bounds\n    sigma = 0.25 * span\n    sigma = np.where(sigma <= 0, 1.0, sigma)\n\n    # Population size and adaptation parameters\n    pop_size = max(4, min(8 + dim // 2, local_budget))\n    elite_frac = 0.25\n    elite_size = max(1, int(elite_frac * pop_size))\n\n    # Minimal step size (relative)\n    min_sigma = 1e-4 * span\n\n    center = best_x.copy()\n\n    for gen in range(max(1, local_budget // pop_size)):\n        if evals_used >= budget:\n            break\n\n        # Sample population around current center\n        xs = []\n        ys = []\n        for _ in range(pop_size):\n            if evals_used >= budget:\n                break\n            step = rng.normal(size=dim) * sigma\n            cand = clip_to_bounds(center + step)\n            y = eval_point(cand)\n            xs.append(cand)\n            ys.append(y)\n\n        if not xs:\n            break\n\n        xs = np.array(xs)\n        ys = np.array(ys)\n\n        # Filter finite values\n        finite_mask = np.isfinite(ys)\n        if not np.any(finite_mask):\n            # If everything is inf, shrink step size and continue\n            sigma *= 0.5\n            sigma = np.maximum(sigma, min_sigma)\n            continue\n\n        xs_f = xs[finite_mask]\n        ys_f = ys[finite_mask]\n\n        # Update center towards elite mean\n        elite_idx = np.argsort(ys_f)[:elite_size]\n        elite_pts = xs_f[elite_idx]\n        new_center = elite_pts.mean(axis=0)\n\n        # Step-size adaptation: compare new center improvement\n        prev_best = best_y\n        center = new_center\n        if best_x is not None:\n            # Evaluate center explicitly if not already\n            if evals_used < budget:\n                eval_point(center)\n\n        # If improvement observed, slightly increase sigma, else decrease\n        if best_y is not None and prev_best is not None and best_y < prev_best:\n            sigma *= 1.1\n        else:\n            sigma *= 0.7\n\n        sigma = np.clip(sigma, min_sigma, 0.5 * span)\n\n        if evals_used >= budget:\n            break\n\n    # Use any leftover budget for a final tightening around best_x\n    remaining = budget - evals_used\n    if remaining > 0 and best_x is not None:\n        tight_sigma = np.maximum(0.05 * span, min_sigma)\n        for _ in range(remaining):\n            step = rng.normal(size=dim) * tight_sigma\n            cand = clip_to_bounds(best_x + step)\n            eval_point(cand)\n            if evals_used >= budget:\n                break\n\n    return best_x if best_x is not None else (low + high) / 2.0",
    "X": "0.44842287164759853 0.45292403214044263 0.0035349899814539226 1.0 0.37671549290324413 0.30931646201191887 0.6165140595997421"
}