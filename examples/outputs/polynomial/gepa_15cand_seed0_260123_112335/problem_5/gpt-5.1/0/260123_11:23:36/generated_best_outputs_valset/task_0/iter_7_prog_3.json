{
    "score": 6.8575528348114365e-43,
    "Input": "Csendes",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global-local blackbox minimization.\n\n    Strategy:\n    - Careful initialization (uses prev_best_x if available, plus a few randoms)\n    - Global search with quasi-random Sobol-like exploration + some refinement\n    - Local search via adaptive random search around the current best\n\n    All evaluations strictly respect config[\"budget\"].\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config.get(\"dim\", len(bounds)))\n    budget = int(config.get(\"budget\", 1))\n\n    if dim <= 0 or budget <= 0:\n        # Degenerate cases: just return middle of the box\n        mid = bounds[:, 0] + 0.5 * (bounds[:, 1] - bounds[:, 0])\n        return np.asarray(mid, dtype=float)\n\n    lower = bounds[:, 0].astype(float)\n    upper = bounds[:, 1].astype(float)\n    span = upper - lower\n    # Avoid zero-span dimensions: keep point fixed in that dimension\n    fixed_mask = span <= 0.0\n    span[fixed_mask] = 1.0\n\n    def clamp(x):\n        return np.clip(x, lower, upper)\n\n    def eval_point(x):\n        return objective_function(x)\n\n    evals_used = 0\n\n    # ---- Initialization: use warm start if compatible, otherwise random ----\n    best_x = None\n    best_y = None\n\n    # Helper for safe update of best\n    def update_best(x, y, bx, by):\n        if bx is None or y < by:\n            return np.array(x, copy=True), float(y)\n        return bx, by\n\n    # 1) Try prev_best_x first if dimension matches\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float)\n        if x0.shape[0] == dim:\n            x0 = clamp(x0)\n            y0 = eval_point(x0)\n            evals_used += 1\n            best_x, best_y = update_best(x0, y0, best_x, best_y)\n\n    # 2) If still nothing, or if budget permits, sample a few random restarts\n    if evals_used < budget:\n        # small fraction of budget, at least 1, at most 5\n        init_trials = min(max(1, budget // 50), 5)\n        for _ in range(init_trials):\n            if evals_used >= budget:\n                break\n            xr = np.random.uniform(lower, upper)\n            yr = eval_point(xr)\n            evals_used += 1\n            best_x, best_y = update_best(xr, yr, best_x, best_y)\n\n    # If budget exhausted by initialization\n    if evals_used >= budget:\n        return best_x\n\n    remaining = budget - evals_used\n\n    # ---- Budget split: global vs local ----\n    # More global search for high-dim or small total budget.\n    if remaining < 30 or dim > 20:\n        global_frac = 0.7\n    else:\n        global_frac = 0.55\n\n    global_budget = max(1, int(global_frac * remaining))\n    local_budget = max(0, remaining - global_budget)\n\n    # ---- Global search: quasi-random (Sobol-like) + jitter ----\n    # Use a simple low-discrepancy sequence based on Van der Corput and permutations\n    def van_der_corput(n, base=2):\n        seq = np.empty(n, dtype=float)\n        for i in range(n):\n            v, denom, x = i, 1.0, 0.0\n            while v > 0:\n                v, r = divmod(v, base)\n                denom *= base\n                x += r / denom\n            seq[i] = x\n        return seq\n\n    def quasi_random_points(n_points, dim_):\n        # Generate independent permutations of a 1D Van der Corput sequence\n        base_sequence = van_der_corput(n_points + 10, 2)[10:]  # skip first few points\n        pts = np.empty((n_points, dim_), dtype=float)\n        for d in range(dim_):\n            perm = np.random.permutation(n_points)\n            pts[:, d] = base_sequence[perm]\n        # Map to bounds and add small jitter for diversity\n        jitter = (np.random.rand(n_points, dim_) - 0.5) / (10.0 * n_points)\n        u = np.clip(pts + jitter, 0.0, 1.0)\n        return lower + u * span\n\n    n_global = min(global_budget, max(1, global_budget))\n    # Reserve a small portion for focused refinement around current best\n    refine_budget = max(0, int(0.15 * n_global))\n    pure_explore_budget = max(0, n_global - refine_budget)\n\n    # 1) Pure exploration over the whole box\n    if pure_explore_budget > 0:\n        xs = quasi_random_points(pure_explore_budget, dim)\n        for i in range(pure_explore_budget):\n            if evals_used >= budget:\n                break\n            x = xs[i]\n            y = eval_point(x)\n            evals_used += 1\n            best_x, best_y = update_best(x, y, best_x, best_y)\n\n    # 2) Refine around current best with Gaussian sampling\n    if refine_budget > 0 and evals_used < budget and best_x is not None:\n        # exploration radius ~ 20% of box initially\n        base_sigma = 0.2 * span\n        base_sigma[fixed_mask] = 0.0\n        for _ in range(refine_budget):\n            if evals_used >= budget:\n                break\n            noise = np.random.randn(dim) * base_sigma\n            cand = clamp(best_x + noise)\n            y = eval_point(cand)\n            evals_used += 1\n            best_x, best_y = update_best(cand, y, best_x, best_y)\n\n    if evals_used >= budget or local_budget <= 0:\n        return best_x\n\n    # ---- Local search: adaptive stochastic search around best_x ----\n    remaining = budget - evals_used\n    # Starting step size: smaller if many evaluations left to allow gradual refinement\n    if remaining < 30:\n        step_frac = 0.25\n    else:\n        step_frac = 0.15\n    step = step_frac * span\n    step[fixed_mask] = 0.0\n    min_step = 1e-8 * np.maximum(span, 1.0)\n\n    # Number of iterations of local search, each using about 'dim * k' evaluations\n    # Keep it simple: each iteration ~ 3*dim evals\n    max_iters = max(1, min(25, local_budget // max(3 * dim, 1)))\n    it = 0\n\n    while evals_used < budget and it < max_iters and np.any(step > min_step):\n        it += 1\n        improved = False\n        # For each dimension, try plus and minus steps and one random perturbation\n        order = np.arange(dim)\n        np.random.shuffle(order)\n        for j in order:\n            if evals_used >= budget:\n                break\n            if fixed_mask[j]:\n                continue\n\n            # Deterministic directions\n            for direction in (-1.0, 1.0):\n                if evals_used >= budget:\n                    break\n                cand = np.array(best_x, copy=True)\n                cand[j] = cand[j] + direction * step[j]\n                cand = clamp(cand)\n                y = eval_point(cand)\n                evals_used += 1\n                if y < best_y:\n                    best_x, best_y = cand, y\n                    improved = True\n\n            if evals_used >= budget:\n                break\n\n            # Random perturbation along this coordinate\n            rnd = (2.0 * np.random.rand() - 1.0) * step[j]\n            cand = np.array(best_x, copy=True)\n            cand[j] = cand[j] + rnd\n            cand = clamp(cand)\n            y = eval_point(cand)\n            evals_used += 1\n            if y < best_y:\n                best_x, best_y = cand, y\n                improved = True\n\n        # Occasional full-dimensional Gaussian step to escape local basin\n        if evals_used < budget:\n            full_noise = (np.random.randn(dim) * (0.5 * step))\n            full_noise[fixed_mask] = 0.0\n            cand = clamp(best_x + full_noise)\n            y = eval_point(cand)\n            evals_used += 1\n            if y < best_y:\n                best_x, best_y = cand, y\n                improved = True\n\n        # Adapt step size\n        if not improved:\n            step *= 0.5\n        else:\n            # Slightly enlarge step size to keep exploring\n            step *= 1.05\n        step = np.maximum(step, min_step)\n\n    return best_x",
    "X": "-1.240442269103377e-08 -7.861981091531005e-08"
}