{
    "score": 0.0049009082507502424,
    "Input": "HelicalValley",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid black-box optimizer with warm start support.\n\n    Strategy:\n    - Robust initialization using warm start (if valid) plus diversified sampling.\n    - Global search using quasi-random sampling.\n    - Local search using adaptive Gaussian steps and coordinate-wise perturbations.\n    - Dynamic reallocation between global and local based on observed improvements.\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # No/negative budget: return center of box\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    # Utility: clip into bounds\n    def clip_to_bounds(x):\n        return np.minimum(high, np.maximum(low, x))\n\n    rng = np.random.default_rng()\n\n    evals_used = 0\n    best_x = None\n    best_y = None\n\n    # --- Warm start if available and valid ---\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n            if x0.size == dim:\n                x0 = clip_to_bounds(x0)\n                y0 = objective_function(x0)\n                evals_used += 1\n                best_x, best_y = x0, y0\n        except Exception:\n            best_x, best_y = None, None\n\n    # --- Always include at least one random initialization for robustness ---\n    if evals_used < budget:\n        x_rand = rng.uniform(low, high)\n        y_rand = objective_function(x_rand)\n        evals_used += 1\n        if best_x is None or y_rand < best_y:\n            best_x, best_y = x_rand, y_rand\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Initial global exploration: a few more diverse samples ---\n    # Up to dim*2 or 10 samples, but not exceeding budget\n    init_global = min(remaining, max(2, min(10, 2 * dim)))\n    for _ in range(init_global):\n        x = rng.uniform(low, high)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_x, best_y = x, y\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Decide initial budget split between global and local ---\n    # Start with more global for larger budgets, otherwise 50/50.\n    if remaining >= 40:\n        global_budget = int(0.6 * remaining)\n    else:\n        global_budget = int(0.5 * remaining)\n    global_budget = max(1, min(global_budget, remaining - 1))\n    local_budget = remaining - global_budget\n\n    # --- Global search: quasi-random (low-discrepancy style) sampling ---\n    base = rng.random(dim)\n    step = (np.sqrt(5.0) - 1.0) / 2.0  # golden ratio conjugate\n    step_vec = (step * np.arange(1, dim + 1)) % 1.0\n\n    global_improvements = 0\n    g_evals = 0\n    while g_evals < global_budget and evals_used < budget:\n        u = (base + g_evals * step_vec) % 1.0\n        x = low + u * span\n        y = objective_function(x)\n        evals_used += 1\n        g_evals += 1\n        if y < best_y:\n            best_x, best_y = x, y\n            global_improvements += 1\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Optionally reallocate: if global search was very successful,\n    # keep some budget for additional global samples later.\n    # Otherwise, favor local search.\n    if global_improvements == 0:\n        extra_global = 0\n    else:\n        extra_global = min(remaining // 4, global_improvements)\n\n    local_budget = max(1, remaining - extra_global)\n    global_tail_budget = remaining - local_budget\n\n    # --- Local search parameters ---\n    base_sigma = 0.2 * span\n    base_sigma[base_sigma == 0] = 1.0\n\n    # Multi-phase decay for sigma\n    phases = min(5, max(1, int(np.log2(local_budget + 2))))\n    steps_per_phase = max(1, local_budget // phases)\n    sigmas = [base_sigma * (0.5 ** p) for p in range(phases)]\n\n    no_improve_streak = 0\n    local_improvements = 0\n\n    # --- Local search loop ---\n    for phase in range(phases):\n        if evals_used >= budget:\n            break\n        sigma = sigmas[phase]\n        phase_steps = min(steps_per_phase, budget - evals_used)\n        for _ in range(phase_steps):\n            if evals_used >= budget:\n                break\n\n            # Mixture of full-dimensional and coordinate-wise perturbations\n            if rng.random() < 0.7:\n                noise = rng.normal(0.0, sigma, size=dim)\n            else:\n                noise = np.zeros(dim)\n                idx = rng.integers(0, dim)\n                noise[idx] = rng.normal(0.0, sigma[idx])\n\n            x = clip_to_bounds(best_x + noise)\n            y = objective_function(x)\n            evals_used += 1\n\n            if y < best_y:\n                best_x, best_y = x, y\n                no_improve_streak = 0\n                local_improvements += 1\n            else:\n                no_improve_streak += 1\n\n            # If stuck, inject a random global jump\n            if no_improve_streak >= 12 and evals_used < budget:\n                x_jump = rng.uniform(low, high)\n                y_jump = objective_function(x_jump)\n                evals_used += 1\n                if y_jump < best_y:\n                    best_x, best_y = x_jump, y_jump\n                    local_improvements += 1\n                no_improve_streak = 0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Tail global search if budget remains and was allocated ---\n    tail_budget = min(global_tail_budget, remaining)\n    if tail_budget > 0:\n        # Use a fresh quasi-random sequence starting from current best\n        base_tail = rng.random(dim)\n        for i in range(tail_budget):\n            if evals_used >= budget:\n                break\n            u = (base_tail + i * step_vec) % 1.0\n            x = low + u * span\n            y = objective_function(x)\n            evals_used += 1\n            if y < best_y:\n                best_x, best_y = x, y\n\n    return best_x",
    "X": "0.9946151637924188 0.030428310914573896 0.04703732756765519"
}