{
    "score": 2.5266072403130693,
    "Input": "Tripod",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n    Strategy: global random search (Latin-hypercube-like) + local refinement\n    around the best point, with optional warm-start from prev_best_x.\n    \"\"\"\n    rng = np.random.default_rng()\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n    span[span <= 0] = 1.0  # avoid zero-width issues\n\n    # Helper to project into bounds\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # Warm start from prev_best_x if provided\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip_to_bounds(x0)\n            try:\n                y0 = objective_function(x0)\n                evals_used += 1\n                if np.isfinite(y0) and y0 < best_y:\n                    best_y = y0\n                    best_x = x0\n            except Exception:\n                pass\n\n    # If no valid best yet, take one random point\n    if best_x is None and evals_used < budget:\n        x0 = rng.uniform(low, high)\n        try:\n            y0 = objective_function(x0)\n            evals_used += 1\n            if np.isfinite(y0):\n                best_y = y0\n                best_x = x0\n        except Exception:\n            # fall back to center\n            best_x = (low + high) / 2.0\n            best_y = np.inf\n\n    if best_x is None:\n        # Degenerate case: cannot evaluate\n        return (low + high) / 2.0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Split budget: 60% global, 40% local (at least a few each)\n    global_evals = max(remaining * 6 // 10, 2)\n    global_evals = min(global_evals, remaining)\n    local_evals = remaining - global_evals\n\n    # --- Global exploration: stratified random sampling ---\n    if global_evals > 0:\n        # Latin-hypercube-like: stratify per dimension\n        n = global_evals\n        # Generate base samples in [0, 1]\n        u = (rng.random((n, dim)) + rng.permutation(n).reshape(-1, 1)) / n\n        u = np.mod(u, 1.0)\n        Xg = low + u * span\n\n        for i in range(n):\n            if evals_used >= budget:\n                break\n            x = Xg[i]\n            try:\n                y = objective_function(x)\n                evals_used += 1\n            except Exception:\n                continue\n            if np.isfinite(y) and y < best_y:\n                best_y = y\n                best_x = x\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    local_evals = remaining\n\n    # --- Local refinement: decreasing-radius random search around best_x ---\n    if local_evals > 0:\n        # start radius: a fraction of domain size\n        base_radius = 0.25\n        for k in range(local_evals):\n            if evals_used >= budget:\n                break\n            # geometric decay of radius\n            frac = (k + 1) / (local_evals + 1)\n            radius = base_radius * (0.5 ** frac)\n            step = rng.normal(size=dim)\n            step /= np.linalg.norm(step) + 1e-12\n            step *= radius * span\n            x = clip_to_bounds(best_x + step)\n            try:\n                y = objective_function(x)\n                evals_used += 1\n            except Exception:\n                continue\n            if np.isfinite(y) and y < best_y:\n                best_y = y\n                best_x = x\n\n    return best_x",
    "X": "49.747952385969086 49.725440373717845"
}