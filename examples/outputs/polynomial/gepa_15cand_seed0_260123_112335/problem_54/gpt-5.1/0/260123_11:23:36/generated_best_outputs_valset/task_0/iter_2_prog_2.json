{
    "score": 0.0,
    "Input": "Tripod",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n    Strategy: Sobol-sequence global search + adaptive local refinement\n    around the best point, with optional warm-start from prev_best_x.\n    \"\"\"\n\n    rng = np.random.default_rng()\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n    # Avoid degenerate ranges\n    span[span <= 0] = 1.0\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # --- Helper: safe evaluation with bookkeeping ---\n    def eval_point(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        try:\n            y = objective_function(x)\n        except Exception:\n            evals_used += 1  # still count against budget\n            return None\n        evals_used += 1\n        if np.isfinite(y) and y < best_y:\n            best_y = y\n            best_x = x\n        return y\n\n    # --- Warm start from previous best if available ---\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip_to_bounds(x0)\n            eval_point(x0)\n\n    # If still no valid best, sample a single random point\n    if best_x is None and evals_used < budget:\n        x0 = rng.uniform(low, high)\n        eval_point(x0)\n\n    # Fallback if evaluation always fails\n    if best_x is None:\n        return (low + high) / 2.0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # --- Budget split: slightly more global early, but adaptive ---\n    # Default split 70% global, 30% local, but ensure both get at least a few evals\n    global_evals = int(0.7 * remaining)\n    global_evals = min(max(global_evals, min(5, remaining)), remaining)\n    local_evals = remaining - global_evals\n\n    # --- Sobol sequence generator (simple implementation) ---\n    # Precomputed direction numbers for up to dim=16 (sufficient for many benchmarks).\n    # Falls back to random for higher dimensions.\n    def sobol_sequence(n_points, dim, seed=0):\n        if dim > 16:\n            return rng.random((n_points, dim))\n\n        # Primitive polynomials and initial direction numbers for first 16 dims\n        # Source: Joe & Kuo (2008) initial segments (shortened for simplicity)\n        # For robustness we keep a small, fixed-capability implementation.\n        mmax = 30  # up to 2^30 points\n        # Direction numbers for first dimension\n        V = np.zeros((dim, mmax), dtype=np.uint32)\n        for j in range(mmax):\n            V[0, j] = 1 << (31 - j)\n\n        # Parameters for dimensions 2..16 (s, a, m)\n        params = [\n            (1, 0, [1]),\n            (2, 1, [1, 3]),\n            (3, 1, [1, 3, 1]),\n            (3, 2, [1, 1, 1]),\n            (4, 1, [1, 3, 5, 13]),\n            (4, 4, [1, 1, 5, 5]),\n            (5, 2, [1, 1, 3, 3, 9]),\n            (5, 4, [1, 3, 5, 11, 27]),\n            (5, 7, [1, 1, 5, 5, 17]),\n            (5, 11, [1, 1, 7, 9, 29]),\n            (5, 13, [1, 3, 3, 9, 7]),\n            (5, 14, [1, 3, 5, 3, 3]),\n            (5, 16, [1, 1, 1, 15, 21]),\n            (5, 19, [1, 1, 7, 11, 19]),\n            (5, 22, [1, 3, 3, 1, 13]),\n        ]\n\n        for k in range(1, dim):\n            s, a, m = params[k - 1]\n            # Initialize first s direction numbers\n            for j in range(s):\n                V[k, j] = m[j] << (31 - (j + 1))\n            # Compute remaining direction numbers\n            for j in range(s, mmax):\n                v = V[k, j - s] >> s\n                for i in range(1, s):\n                    if (a >> (s - 1 - i)) & 1:\n                        v ^= V[k, j - i]\n                V[k, j] = v\n\n        # Generate sequence\n        X = np.zeros((n_points, dim), dtype=np.float64)\n        x_int = np.zeros(dim, dtype=np.uint32)\n        for i in range(n_points):\n            if i == 0:\n                g = 0\n            else:\n                g = (i & -i).bit_length() - 1  # index of rightmost set bit\n            if i > 0:\n                for k in range(dim):\n                    x_int[k] ^= V[k, g]\n            # Convert to float\n            X[i] = x_int / float(1 << 32)\n\n        # Optional scrambling with seed for variation across runs\n        if seed is not None:\n            # Simple Owen-style digital shift\n            shift = rng.random(dim)\n            X = np.mod(X + shift, 1.0)\n        return X\n\n    # --- Global exploration using quasi-random samples ---\n    if global_evals > 0:\n        # Generate Sobol points in [0,1]^dim then scale to bounds\n        u_global = sobol_sequence(global_evals, dim, seed=None)\n        Xg = low + u_global * span\n\n        for i in range(global_evals):\n            if evals_used >= budget:\n                break\n            x = Xg[i]\n            eval_point(x)\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    local_evals = remaining\n\n    # --- Local refinement: adaptive radius, anisotropic steps ---\n    if local_evals > 0:\n        # Initial radius based on domain size and dimension\n        # Smaller in higher dimensions to avoid too-large jumps\n        base_radius = 0.3 / max(1.0, np.sqrt(dim))\n        min_radius = 1e-3 / max(1.0, np.sqrt(dim))\n\n        no_improve_streak = 0\n        last_best_y = best_y\n\n        for k in range(local_evals):\n            if evals_used >= budget:\n                break\n\n            frac = (k + 1) / (local_evals + 1)\n            # Combine global schedule (decaying) with adaptive reduction\n            radius = base_radius * (0.5 ** frac)\n\n            # If stuck, shrink more aggressively\n            if best_y >= last_best_y:\n                no_improve_streak += 1\n                if no_improve_streak > 5:\n                    radius *= 0.5\n            else:\n                no_improve_streak = 0\n                last_best_y = best_y\n\n            radius = max(radius, min_radius)\n\n            # Anisotropic step: normal scaled by span and radius\n            step = rng.normal(size=dim)\n            norm = np.linalg.norm(step)\n            if norm > 0:\n                step /= norm\n            # Scale step per-dimension based on span\n            step *= radius * span\n            x = clip_to_bounds(best_x + step)\n            eval_point(x)\n\n    return best_x",
    "X": "0.0 -50.0"
}