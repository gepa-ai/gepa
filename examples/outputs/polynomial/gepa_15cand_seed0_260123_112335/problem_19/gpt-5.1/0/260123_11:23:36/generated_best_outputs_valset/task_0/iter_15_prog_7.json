{
    "score": -3.4518610882293563,
    "Input": "McCourt08",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget-aware black-box minimization with hybrid global + local search\n    and warm-start support.\n\n    Strategy:\n    - Always respect config['budget'] evaluations and try to use all of them.\n    - Use prev_best_x if provided and refine it.\n    - Robust initialization: local search around warm start + diversified\n      global sampling (low-discrepancy-like + random).\n    - Maintain an elite set; run adaptive local search around elites with\n      step-size control and occasional larger jumps.\n    - Adaptive budget allocation based on total budget and dimension.\n\n    This version:\n    - Keeps the core hybrid / elite-based strategy.\n    - Simplifies and stabilizes local adaptation logic.\n    - Strengthens use of prev_best_x via slightly more focused early refinement.\n    - Uses a mild, default seed if none provided, but allows overriding via\n      config[\"seed\"].\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    # Handle degenerate or zero budget\n    if budget <= 0:\n        if prev_best_x is not None:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n            if x0.size == dim:\n                lower = bounds[:, 0]\n                upper = bounds[:, 1]\n                x0 = np.minimum(upper, np.maximum(lower, x0))\n                return x0\n        # Fallback: mid-point of bounds\n        lower = bounds[:, 0]\n        upper = bounds[:, 1]\n        return (lower + upper) / 2.0\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n    span[span <= 0] = 1.0\n\n    # Reproducible but varied RNG\n    if \"seed\" in config:\n        seed = int(config[\"seed\"])\n    else:\n        # Mild default seeding based on dimension and budget\n        seed = (dim * 73856093 + budget * 19349663) & 0xFFFFFFFF\n    rng = np.random.RandomState(seed)\n\n    def project(x):\n        return np.minimum(upper, np.maximum(lower, x))\n\n    def halton_like(n, d, rng_local):\n        \"\"\"Cheap low-discrepancy-like sampler; Halton-style with scrambling.\"\"\"\n        if n <= 0:\n            return np.empty((0, d), dtype=float)\n        primes = [2, 3, 5, 7, 11, 13, 17, 19, 23, 29,\n                  31, 37, 41, 43, 47, 53, 59, 61, 67, 71]\n        bases = primes[: min(d, len(primes))]\n        start = rng_local.randint(0, 10000)\n        pts = np.empty((n, d), dtype=float)\n        for j, b in enumerate(bases):\n            i = np.arange(start, start + n)\n            f = 1.0\n            x = np.zeros(n, dtype=float)\n            while True:\n                f /= b\n                i, r = divmod(i, b)\n                x += f * r\n                if not i.any():\n                    break\n            x = (x + rng_local.rand()) % 1.0\n            pts[:, j] = x\n        if d > len(bases):\n            pts[:, len(bases):] = rng_local.rand(n, d - len(bases))\n        return pts\n\n    evals_used = 0\n\n    # ---------- Initialization with optional warm start ----------\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = project(x0)\n        else:\n            x0 = rng.uniform(lower, upper)\n    else:\n        x0 = rng.uniform(lower, upper)\n\n    best_x = x0.copy()\n    best_y = objective_function(best_x)\n    evals_used += 1\n    if evals_used >= budget:\n        return best_x\n\n    # ---------- Early local refinement of warm-start / initial guess ----------\n    remaining_budget = budget - evals_used\n    if remaining_budget > 0:\n        if budget <= 20:\n            refine_steps = min(5, remaining_budget)\n        elif budget <= 60:\n            refine_steps = min(10, remaining_budget // 2)\n        else:\n            refine_steps = min(max(6, budget // 60), remaining_budget // 2)\n\n        if refine_steps > 0:\n            local_sigma0 = 0.06 * span\n            local_sigma0[local_sigma0 == 0] = 0.06\n            for _ in range(refine_steps):\n                if evals_used >= budget:\n                    return best_x\n                cand = best_x + rng.normal(0.0, local_sigma0, size=dim)\n                cand = project(cand)\n                y = objective_function(cand)\n                evals_used += 1\n                if y < best_y:\n                    best_y = y\n                    best_x = cand\n\n    # ---------- Global exploration ----------\n    remaining_budget = budget - evals_used\n    if remaining_budget <= 0:\n        return best_x\n\n    # Adaptive global vs local split based on total budget and dimension\n    if budget <= 30:\n        global_frac = 0.45\n    elif budget <= 100:\n        global_frac = 0.4\n    elif dim <= 5:\n        global_frac = 0.35\n    else:\n        global_frac = 0.5\n\n    global_budget_target = int(budget * global_frac)\n    global_budget = max(3, min(global_budget_target, remaining_budget))\n\n    elite_size = max(3, min(25, global_budget // 2 if global_budget >= 6 else 3))\n    elites_x = [best_x.copy()]\n    elites_y = [best_y]\n\n    if global_budget > 0:\n        n_halton = int(0.6 * global_budget)\n        n_rand = global_budget - n_halton\n\n        if n_halton > 0:\n            u_hd = halton_like(n_halton, dim, rng)\n            samples_hd = lower + u_hd * span\n        else:\n            samples_hd = np.empty((0, dim), dtype=float)\n\n        if n_rand > 0:\n            samples_rand = rng.uniform(lower, upper, size=(n_rand, dim))\n            samples = np.vstack([samples_hd, samples_rand])\n        else:\n            samples = samples_hd\n\n        idxs = np.arange(samples.shape[0])\n        rng.shuffle(idxs)\n        samples = samples[idxs]\n\n        for x in samples:\n            if evals_used >= budget:\n                return best_x\n            y = objective_function(x)\n            evals_used += 1\n\n            if y < best_y:\n                best_y = y\n                best_x = x\n\n            if len(elites_x) < elite_size:\n                elites_x.append(x)\n                elites_y.append(y)\n            else:\n                worst_idx = int(np.argmax(elites_y))\n                if y < elites_y[worst_idx]:\n                    elites_x[worst_idx] = x\n                    elites_y[worst_idx] = y\n\n    # ---------- Local exploitation around elites ----------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    elites_x = [project(e) for e in elites_x]\n    elites_y = [float(v) for v in elites_y]\n    order = np.argsort(elites_y)\n    elites_x = [elites_x[i] for i in order]\n    elites_y = [elites_y[i] for i in order]\n\n    base_sigma = 0.12 * span\n    base_sigma[base_sigma == 0] = 0.12\n\n    n_elites = len(elites_x)\n    step_factors = np.ones(n_elites, dtype=float)\n    cov_scales = np.ones((n_elites, dim), dtype=float)\n\n    # For extremely tiny remaining budgets, just sample around global best\n    if remaining <= n_elites:\n        sigma_small = np.maximum(0.025 * span, 1e-6)\n        for _ in range(remaining):\n            if evals_used >= budget:\n                break\n            cand = best_x + rng.normal(0.0, sigma_small, size=dim)\n            cand = project(cand)\n            y = objective_function(cand)\n            evals_used += 1\n            if y < best_y:\n                best_y = y\n                best_x = cand\n        return best_x\n\n    # Determine a simple schedule for exploration vs exploitation\n    # Early iterations: more exploratory (larger sigma)\n    # Later iterations: smaller sigma\n    for i in range(remaining):\n        if evals_used >= budget:\n            break\n\n        t = i / max(1.0, remaining - 1)\n        # Exploration factor decays from 1.0 to about 0.35\n        decay = 0.35 + 0.65 * (1.0 - t)\n        sigma_base_t = base_sigma * decay\n        sigma_base_t = np.maximum(sigma_base_t, 0.015 * span)\n\n        if (i % 40) == 0:\n            sigma_base_t = base_sigma\n\n        # Rank-based selection of elite centers (bias to best)\n        if n_elites > 1:\n            ranks = np.arange(n_elites)\n            probs = (0.55 ** ranks).astype(float)\n            probs /= probs.sum()\n            idx = rng.choice(n_elites, p=probs)\n        else:\n            idx = 0\n\n        center = elites_x[idx]\n        sigma = sigma_base_t * step_factors[idx] * cov_scales[idx]\n\n        # Occasional larger jumps from the best elite to escape basins\n        if (i % 45) == 0 and idx == 0:\n            sigma = np.maximum(sigma, 0.25 * span)\n\n        candidate = center + rng.normal(0.0, sigma, size=dim)\n        candidate = project(candidate)\n\n        y = objective_function(candidate)\n        evals_used += 1\n\n        improved_global = False\n\n        if y < best_y:\n            best_y = y\n            best_x = candidate\n            improved_global = True\n\n        worst_idx = int(np.argmax(elites_y))\n        replaced_center = False\n        if y < elites_y[worst_idx]:\n            elites_x[worst_idx] = candidate\n            elites_y[worst_idx] = y\n            replaced_center = worst_idx == idx\n\n        # Simple step-size adaptation: enlarge if improved, shrink otherwise\n        if replaced_center or improved_global:\n            step_factors[idx] *= 1.05\n            diff = np.abs(candidate - center)\n            if np.any(diff > 0):\n                rel = diff / np.maximum(np.abs(span), 1e-8)\n                cov_scales[idx] = 0.9 * cov_scales[idx] + 0.1 * (1.0 + rel)\n        else:\n            step_factors[idx] *= 0.97\n            cov_scales[idx] = 0.97 * cov_scales[idx] + 0.03\n\n        step_factors = np.clip(step_factors, 0.15, 4.0)\n        cov_scales = np.clip(cov_scales, 0.3, 3.0)\n\n        # Keep elites ordered\n        order = np.argsort(elites_y)\n        elites_x = [elites_x[j] for j in order]\n        elites_y = [elites_y[j] for j in order]\n        step_factors = step_factors[order]\n        cov_scales = cov_scales[order]\n\n    return best_x",
    "X": "0.5070580569190942 1.0 0.5925617592719737 0.08469481662689933"
}