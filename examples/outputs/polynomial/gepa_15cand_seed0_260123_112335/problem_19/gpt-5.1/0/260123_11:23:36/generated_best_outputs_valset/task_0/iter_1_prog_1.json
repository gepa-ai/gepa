{
    "score": -3.4504502411931455,
    "Input": "McCourt08",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization using a simple hybrid of random search and local search.\n\n    Strategy:\n    1. Use prev_best_x as a starting point if available and inside bounds.\n    2. Use ~30% of the budget for global random search over bounds.\n    3. Use remaining budget for local Gaussian search around the current best.\n    \"\"\"\n    rng = np.random.RandomState()  # isolated RNG\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n    span[span <= 0] = 1.0  # prevent degenerate ranges\n\n    def project(x):\n        return np.minimum(upper, np.maximum(lower, x))\n\n    evals_used = 0\n\n    # Initialize best solution\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = project(x0)\n        else:\n            x0 = rng.uniform(lower, upper)\n    else:\n        x0 = rng.uniform(lower, upper)\n\n    best_x = x0\n    best_y = objective_function(best_x)\n    evals_used += 1\n\n    if evals_used >= budget:\n        return best_x\n\n    # Global random search\n    global_frac = 0.3\n    global_budget = max(1, int(budget * global_frac))\n    global_budget = min(global_budget, budget - evals_used)\n\n    for _ in range(global_budget):\n        x = rng.uniform(lower, upper)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x\n        if evals_used >= budget:\n            return best_x\n\n    # Local search around best_x\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Initial step size proportional to bounds\n    base_sigma = 0.2 * span\n    base_sigma[base_sigma == 0] = 0.1\n\n    # Adaptive local search: mix of exploration and exploitation\n    for i in range(remaining):\n        # Exponentially decay step size over iterations\n        decay = 0.5 ** (i / max(1.0, remaining - 1))\n        sigma = base_sigma * decay\n\n        # Occasionally try larger jumps to escape local minima\n        if (i % 10) == 0:\n            sigma = base_sigma\n\n        candidate = best_x + rng.normal(0.0, sigma, size=dim)\n        candidate = project(candidate)\n        y = objective_function(candidate)\n        evals_used += 1\n\n        if y < best_y:\n            best_y = y\n            best_x = candidate\n\n        if evals_used >= budget:\n            break\n\n    return best_x",
    "X": "0.5185361440697375 1.0 0.6257809768053072 0.07302980584389292"
}