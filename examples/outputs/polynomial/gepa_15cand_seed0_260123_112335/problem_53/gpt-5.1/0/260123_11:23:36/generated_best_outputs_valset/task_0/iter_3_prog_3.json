{
    "score": -195.8247305050572,
    "Input": "StyblinskiTang",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Derivative-free optimizer: hybrid global + local search with warm start.\n\n    Strategy:\n    1. Use a CMA-ES\u2013like evolutionary global search for ~60\u201380% of the budget.\n    2. Use remaining budget for local stochastic hill-climbing around best point.\n    3. If prev_best_x is provided and inside bounds, inject and seed search.\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    width = upper - lower\n    width = np.where(width <= 0, 1.0, width)  # guard degenerate bounds\n\n    def clamp(x):\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    def evaluate(x):\n        nonlocal best_x, best_y, evals_used\n        if evals_used >= budget:\n            return best_y\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y or best_x is None:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # Decide split between global and local search based on dimension\n    if dim <= 5:\n        global_frac = 0.6\n    elif dim <= 20:\n        global_frac = 0.7\n    else:\n        global_frac = 0.8\n\n    global_budget = int(budget * global_frac)\n    local_budget = budget - global_budget\n\n    # Warm start from previous best if provided\n    if prev_best_x is not None and evals_used < budget:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clamp(x0)\n            evaluate(x0)\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x if best_x is not None else clamp(lower)\n\n    global_budget = min(global_budget, remaining)\n    local_budget = max(0, budget - evals_used - global_budget)\n\n    # ----------------- Global evolutionary search (CMA-ES like) -----------------\n    if global_budget > 0:\n        # Population size scaling with dimension and budget\n        # \u03bb ~ 4 + floor(3 * ln(dim)) is common; cap by budget\n        if dim > 0:\n            lam = int(4 + np.floor(3 * np.log(dim)))\n        else:\n            lam = 4\n        lam = max(4, lam)\n        # Ensure at least a few generations\n        max_generations = max(2, global_budget // lam)\n        lam = min(lam, max(10, global_budget // 2)) if global_budget >= 20 else min(lam, global_budget)\n\n        if lam <= 0:\n            lam = min(4, global_budget)\n\n        mu = lam // 2\n        # recombination weights\n        weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n        weights = weights / np.sum(weights)\n        mueff = 1.0 / np.sum(weights ** 2)\n\n        # Step size initialisation\n        sigma = 0.3  # relative to width; we scale later per dimension\n\n        # CMA-ES learning rates (slightly simplified & robustified)\n        cc = (4 + mueff / dim) / (dim + 4 + 2 * mueff / dim)\n        c1 = 2 / ((dim + 1.3) ** 2 + mueff)\n        cmu = min(1 - c1, 2 * (mueff - 2 + 1 / mueff) / ((dim + 2) ** 2 + mueff))\n        damps = 1 + 2 * max(0, np.sqrt((mueff - 1) / (dim + 1)) - 1) + cc\n\n        pc = np.zeros(dim)\n        ps = np.zeros(dim)\n        C = np.eye(dim)\n\n        # Initial mean: from warm start if available, else random in bounds\n        if best_x is not None:\n            mean = best_x.copy()\n        else:\n            mean = lower + rng.rand(dim) * width\n\n        # Ensure mean is inside bounds\n        mean = clamp(mean)\n\n        # Use diagonal covariance in sampling for robustness (full C used in adaptation)\n        diagC = np.ones(dim)\n\n        counteval_start = evals_used\n        chi_n = np.sqrt(dim) * (1 - 1. / (4 * dim) + 1. / (21 * dim ** 2))\n\n        # Reserve some evaluations for local search: adapt local_budget if global ends early\n        generation = 0\n        while evals_used < budget and evals_used - counteval_start < global_budget:\n            remaining_global = global_budget - (evals_used - counteval_start)\n            if remaining_global <= 0:\n                break\n\n            # Sample \u03bb offspring\n            lam_actual = min(lam, remaining_global)\n            arz = rng.randn(lam_actual, dim)\n            # anisotropic sampling using diagC and sigma\n            steps = arz * (sigma * np.sqrt(diagC))\n            arx = mean + steps * width  # scale with bounds width\n            arx = clamp(arx)\n\n            # Evaluate\n            fitness = np.empty(lam_actual)\n            for k in range(lam_actual):\n                if evals_used >= budget:\n                    fitness[k] = np.inf\n                else:\n                    fitness[k] = evaluate(arx[k])\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            arx = arx[idx]\n            arz = arz[idx]\n            fitness = fitness[idx]\n\n            # If we evaluated nothing useful, break\n            if lam_actual == 0:\n                break\n\n            # Update mean using top mu individuals\n            xold = mean.copy()\n            mu_eff = min(mu, lam_actual)\n            w = weights[:mu_eff]\n            w = w / w.sum()\n            mean = np.sum(arx[:mu_eff] * w[:, None], axis=0)\n\n            # Evolution paths\n            z_mean = np.sum(arz[:mu_eff] * w[:, None], axis=0)\n            ps = (1 - cc) * ps + np.sqrt(cc * (2 - cc) * mueff) * z_mean\n\n            # Heuristic conjugate evolution path for covariance\n            hsig = int(np.linalg.norm(ps) / np.sqrt(1 - (1 - cc) ** (2 * (generation + 1))) / chi_n < (1.4 + 2 / (dim + 1)))\n            pc = (1 - cc) * pc + hsig * np.sqrt(cc * (2 - cc) * mueff) * (mean - xold) / (sigma * width + 1e-12)\n\n            # Rank-1 and rank-\u03bc update to covariance (diagonalised)\n            # Use only diagonal for efficiency / robustness\n            delta_hsig = (1 - hsig) * cc * (2 - cc)\n            C = (1 + c1 * delta_hsig - c1 - cmu * np.sum(w)) * C\n            C += c1 * np.outer(pc, pc)\n            for i in range(mu_eff):\n                yi = (arx[i] - xold) / (sigma * width + 1e-12)\n                C += cmu * w[i] * np.outer(yi, yi)\n\n            # Extract diagonal for sampling\n            diagC = np.maximum(np.diag(C), 1e-12)\n\n            # Step-size control\n            sigma = sigma * np.exp((np.linalg.norm(ps) / chi_n - 1) * cc / damps)\n            sigma = np.clip(sigma, 1e-3, 2.0)\n\n            generation += 1\n\n            if evals_used >= budget:\n                break\n\n        # Ensure best_x evaluated\n        if best_x is None and evals_used < budget:\n            x = lower + rng.rand(dim) * width\n            evaluate(x)\n\n    if evals_used >= budget:\n        return best_x if best_x is not None else clamp(lower)\n\n    # ----------------- Local stochastic hill-climbing -----------------\n    if best_x is None:\n        x = lower + rng.rand(dim) * width\n        evaluate(x)\n        if evals_used >= budget:\n            return best_x\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    x_current = best_x.copy()\n    # Local step size: smaller than before, to refine CMA output\n    step = 0.1 * width\n    min_step = 1e-6 * np.maximum(1.0, np.abs(width))\n    max_step = width\n\n    no_improve_count = 0\n\n    while evals_used < budget:\n        perturb = rng.randn(dim) * step\n        x_candidate = clamp(x_current + perturb)\n        y_candidate = evaluate(x_candidate)\n\n        if y_candidate < best_y:\n            x_current = x_candidate\n            step = np.minimum(step * 1.3, max_step)\n            no_improve_count = 0\n        else:\n            step = np.maximum(step * 0.7, min_step)\n            no_improve_count += 1\n\n            if no_improve_count >= 10 and evals_used < budget:\n                # Occasional long jump from global best to escape local basin\n                long_step = 0.4 * width\n                x_try = clamp(best_x + rng.randn(dim) * long_step)\n                y_try = evaluate(x_try)\n                if y_try < best_y:\n                    x_current = x_try\n                    step = np.maximum(step, 0.2 * width)\n                else:\n                    step = np.maximum(step, 0.05 * width)\n                no_improve_count = 0\n\n    return best_x if best_x is not None else clamp(lower)",
    "X": "-2.902125291015756 -2.9124278067256175 -2.891120691339314 -2.8957228217667885 -2.911076656693962"
}