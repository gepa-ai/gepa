{
    "score": -195.82927512653083,
    "Input": "StyblinskiTang",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Derivative-free optimizer: hybrid global + local search with warm start.\n\n    Strategy:\n    1. Robust CMA-ES\u2013like global search (diagonal covariance) for ~60\u201380% budget.\n    2. Adaptive local stochastic search for remaining budget.\n    3. Proper use of prev_best_x to seed search when available.\n    4. Handles very low budgets and small dimensions gracefully.\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    width = upper - lower\n    width = np.where(width <= 0, 1.0, width)  # guard degenerate bounds / zero width\n\n    def clamp(x):\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    def evaluate(x):\n        nonlocal best_x, best_y, evals_used\n        if evals_used >= budget:\n            return best_y\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y or best_x is None:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # Early exit for zero or negative budget\n    if budget <= 0:\n        return clamp(lower)\n\n    # Decide split between global and local search based on dimension\n    if dim <= 5:\n        global_frac = 0.6\n    elif dim <= 20:\n        global_frac = 0.7\n    else:\n        global_frac = 0.8\n\n    global_budget = int(budget * global_frac)\n    global_budget = max(0, min(global_budget, budget - 1))  # keep at least 1 eval for safety\n    local_budget = budget - global_budget\n\n    # Warm start from previous best if provided\n    if prev_best_x is not None and evals_used < budget:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clamp(x0)\n            evaluate(x0)\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x if best_x is not None else clamp(lower)\n\n    global_budget = min(global_budget, remaining)\n    local_budget = max(0, budget - evals_used - global_budget)\n\n    # ----------------- Global evolutionary search (CMA-ES like) -----------------\n    if global_budget > 0:\n        # Robust population size selection\n        if dim > 0:\n            lam = int(4 + np.floor(3 * np.log(dim)))\n        else:\n            lam = 4\n        lam = max(4, lam)\n        # Cap lambda by available global_budget to allow several generations\n        if global_budget < 4:\n            lam = global_budget\n        else:\n            lam = min(lam, max(6, global_budget // 3))\n        lam = max(1, lam)\n\n        # Number of parents\n        mu = max(1, lam // 2)\n\n        # Recombination weights\n        weights = np.log(np.arange(1, mu + 1) + 0.5)\n        weights = weights[::-1]  # decreasing\n        weights = weights / np.sum(weights)\n        mueff = 1.0 / np.sum(weights ** 2)\n\n        # CMA-ES hyperparameters (slightly simplified & robustified)\n        # Guard against dim=0 (degenerate) or very small dims\n        eff_dim = max(dim, 1)\n        cc = (4 + mueff / eff_dim) / (eff_dim + 4 + 2 * mueff / eff_dim)\n        c1 = 2 / ((eff_dim + 1.3) ** 2 + mueff)\n        cmu = min(1 - c1, 2 * (mueff - 2 + 1 / mueff) / ((eff_dim + 2) ** 2 + mueff))\n        damps = 1 + 2 * max(0, np.sqrt((mueff - 1) / (eff_dim + 1)) - 1) + cc\n\n        pc = np.zeros(dim)\n        ps = np.zeros(dim)\n\n        # Use diagonal covariance for robustness; store as vector\n        diagC = np.ones(dim)\n\n        # Initial mean: from warm start best_x if available, else center of bounds, else random\n        if best_x is not None:\n            mean = best_x.copy()\n        else:\n            center = lower + 0.5 * width\n            # Slight randomization around center to avoid symmetry degeneracy\n            mean = clamp(center + 0.1 * width * rng.randn(dim))\n\n        # Step size relative to bounds width (slightly conservative)\n        sigma = 0.25\n\n        counteval_start = evals_used\n        chi_n = np.sqrt(eff_dim) * (1 - 1. / (4 * eff_dim) + 1. / (21 * eff_dim ** 2))\n\n        generation = 0\n        while evals_used < budget and (evals_used - counteval_start) < global_budget:\n            remaining_global = global_budget - (evals_used - counteval_start)\n            if remaining_global <= 0:\n                break\n\n            # Sample \u03bb offspring (limited by remaining evaluations)\n            lam_actual = min(lam, remaining_global)\n            if lam_actual <= 0:\n                break\n\n            # Generate samples\n            arz = rng.randn(lam_actual, dim)\n            steps = arz * (sigma * np.sqrt(diagC))\n            arx = mean + steps * width\n            arx = clamp(arx)\n\n            # Evaluate offspring\n            fitness = np.empty(lam_actual)\n            for k in range(lam_actual):\n                if evals_used >= budget:\n                    fitness[k] = np.inf\n                else:\n                    fitness[k] = evaluate(arx[k])\n\n            # If all evaluations are exhausted\n            if lam_actual == 0:\n                break\n\n            # Sort by fitness\n            idx = np.argsort(fitness)\n            arx = arx[idx]\n            arz = arz[idx]\n            fitness = fitness[idx]\n\n            # Update mean using top mu individuals\n            mu_eff = min(mu, lam_actual)\n            w = weights[:mu_eff]\n            w = w / w.sum()\n            xold = mean.copy()\n            mean = np.sum(arx[:mu_eff] * w[:, None], axis=0)\n\n            # Evolution paths (safeguarded against zero-dim)\n            if eff_dim > 0:\n                z_mean = np.sum(arz[:mu_eff] * w[:, None], axis=0)\n                ps = (1 - cc) * ps + np.sqrt(cc * (2 - cc) * mueff) * z_mean\n\n                norm_ps = np.linalg.norm(ps)\n                hsig_cond = norm_ps / np.sqrt(1 - (1 - cc) ** (2 * (generation + 1)))\n                hsig = 1 if hsig_cond / chi_n < (1.4 + 2 / (eff_dim + 1)) else 0\n\n                diff = (mean - xold) / (sigma * width + 1e-12)\n                pc = (1 - cc) * pc + hsig * np.sqrt(cc * (2 - cc) * mueff) * diff\n\n                # Diagonal covariance update\n                delta_hsig = (1 - hsig) * cc * (2 - cc)\n                # Rank-one update\n                diagC = (1 + c1 * delta_hsig - c1 - cmu * np.sum(w)) * diagC\n                diagC += c1 * pc ** 2\n                # Rank-mu update\n                for i in range(mu_eff):\n                    yi = (arx[i] - xold) / (sigma * width + 1e-12)\n                    diagC += cmu * w[i] * yi ** 2\n\n                # Enforce positive covariance and numeric stability\n                diagC = np.clip(diagC, 1e-12, 1e6)\n\n                # Step-size control\n                sigma = sigma * np.exp((norm_ps / chi_n - 1) * cc / damps)\n                sigma = np.clip(sigma, 1e-3, 2.0)\n\n            generation += 1\n\n            if evals_used >= budget:\n                break\n\n        # Ensure at least one random evaluation if nothing was evaluated\n        if best_x is None and evals_used < budget:\n            x = lower + rng.rand(dim) * width\n            evaluate(x)\n\n    if evals_used >= budget:\n        return best_x if best_x is not None else clamp(lower)\n\n    # ----------------- Local stochastic hill-climbing -----------------\n    if best_x is None and evals_used < budget:\n        x = lower + rng.rand(dim) * width\n        evaluate(x)\n        if evals_used >= budget:\n            return best_x if best_x is not None else clamp(lower)\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x if best_x is not None else clamp(lower)\n\n    x_current = best_x.copy()\n\n    # Local step size: dimension-aware; start modestly to refine CMA output\n    step = 0.05 * width\n    min_step = 1e-6 * np.maximum(1.0, np.abs(width))\n    max_step = 0.5 * width\n\n    # For very small budgets, avoid wasteful restarts\n    no_improve_count = 0\n    long_jump_threshold = 12\n\n    while evals_used < budget:\n        perturb = rng.randn(dim) * step\n        x_candidate = clamp(x_current + perturb)\n        y_candidate = evaluate(x_candidate)\n\n        if y_candidate < best_y:\n            x_current = x_candidate\n            # Increase step size (but stay within bounds) to keep exploring\n            step = np.minimum(step * 1.5, max_step)\n            no_improve_count = 0\n        else:\n            # Decrease step size for finer search\n            step = np.maximum(step * 0.6, min_step)\n            no_improve_count += 1\n\n            # Occasional longer jump to escape local basins\n            if no_improve_count >= long_jump_threshold and evals_used < budget:\n                long_step = 0.3 * width\n                x_try = clamp(best_x + rng.randn(dim) * long_step)\n                y_try = evaluate(x_try)\n                if y_try < best_y:\n                    x_current = x_try\n                    step = np.maximum(step, 0.15 * width)\n                else:\n                    step = np.maximum(step, 0.05 * width)\n                no_improve_count = 0\n\n    return best_x if best_x is not None else clamp(lower)",
    "X": "-2.911425203391004 -2.903635166711855 -2.8991933872667848 -2.9006108477494603 -2.9033362065284516"
}