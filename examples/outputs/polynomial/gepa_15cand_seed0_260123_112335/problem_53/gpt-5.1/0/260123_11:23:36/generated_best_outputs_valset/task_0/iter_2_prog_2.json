{
    "score": -195.8040836970048,
    "Input": "StyblinskiTang",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Derivative-free optimizer: population-based global search + local refinement.\n\n    Strategy:\n    1. Use ~60\u201380% of the budget for a small population evolutionary search\n       (mutation + crossover + occasional global restarts).\n    2. Use the remaining budget for local stochastic hill-climbing around the\n       best point found.\n    3. If prev_best_x is provided and inside bounds, inject it into the\n       initial population and seed local search.\n    \"\"\"\n    rng = np.random.RandomState()  # independent RNG\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    width = upper - lower\n\n    def clamp(x):\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n\n    # Helper: evaluate point and track best\n    best_x = None\n    best_y = np.inf\n\n    def evaluate(x):\n        nonlocal best_x, best_y, evals_used\n        if evals_used >= budget:\n            # Should not happen if used correctly, but guard anyway\n            return best_y\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # Decide split between global and local search based on dimension\n    if dim <= 5:\n        global_frac = 0.6\n    elif dim <= 20:\n        global_frac = 0.7\n    else:\n        global_frac = 0.8\n\n    # Will adapt these after possible prev_best_x evaluation\n    global_budget = int(budget * global_frac)\n    local_budget = budget - global_budget\n\n    # Use prev_best_x if available and valid (counts against budget)\n    if prev_best_x is not None and evals_used < budget:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clamp(x0)\n            evaluate(x0)\n\n    # Recompute budgets after any warm-start evaluation\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x if best_x is not None else clamp(lower)\n\n    global_budget = min(global_budget, remaining)\n    local_budget = max(0, budget - evals_used - global_budget)\n\n    # ---------- Global evolutionary search ----------\n    if global_budget > 0:\n        # Population size adapts to dimension and budget\n        # Aim for enough generations while keeping diversity\n        base_pop = 10 if dim <= 5 else (15 if dim <= 20 else 20)\n        max_pop = max(4, min(base_pop, global_budget // 2))\n        pop_size = max(4, max_pop)\n\n        # We'll use (\u00b5+\u03bb) style evolution: parents + offspring selection\n        # Reserve at least one evaluation per individual for initialization\n        # and ensure some generations (>1) if possible\n        min_gens = 3\n        max_gens = max(1, global_budget // pop_size)\n        gens = max(1, min(max_gens, global_budget // pop_size))\n        if gens < min_gens and global_budget >= min_gens * pop_size:\n            gens = min_gens\n        # If still only one gen possible, just do a one-shot population search\n        total_needed = gens * pop_size\n        if total_needed > global_budget:\n            gens = max(1, global_budget // pop_size)\n            total_needed = gens * pop_size\n\n        # Mutation parameters (scale with search space)\n        mut_scale = 0.2 * width\n        min_mut_scale = 1e-6 * np.maximum(1.0, np.abs(width))\n\n        # Initialize population uniformly\n        pop = lower + rng.rand(pop_size, dim) * width\n        pop_y = np.empty(pop_size)\n\n        # Inject warm start into population if available\n        if best_x is not None:\n            # Replace a random individual with prev best\n            idx = rng.randint(pop_size)\n            pop[idx] = best_x\n        # Evaluate initial population\n        for i in range(pop_size):\n            if evals_used >= budget or evals_used >= global_budget:\n                break\n            pop_y[i] = evaluate(pop[i])\n\n        # Update remaining global budget after initialization\n        remaining_global = min(global_budget, budget - evals_used)\n        if remaining_global <= 0:\n            # No budget left for evolution; fall through to possibly local\n            global_budget = 0\n        else:\n            # Adaptive crossover rate and mutation decay\n            crossover_rate = 0.7\n            # ensure we know current best (already tracked by evaluate)\n\n            for g in range(gens):\n                if evals_used >= budget:\n                    break\n                # Sort population by fitness (ascending)\n                order = np.argsort(pop_y)\n                pop = pop[order]\n                pop_y = pop_y[order]\n\n                # Keep elites (top fraction)\n                elite_frac = 0.25\n                elite_count = max(1, int(elite_frac * pop_size))\n                elites = pop[:elite_count]\n\n                # Generate offspring\n                new_pop = [elites[0].copy()]  # always carry best\n                while len(new_pop) < pop_size and evals_used < budget and evals_used < global_budget:\n                    # Parent selection: tournament between 2 random\n                    i1, i2 = rng.randint(pop_size, size=2)\n                    p1 = pop[i1]\n                    p2 = pop[i2]\n                    if rng.rand() < crossover_rate:\n                        # Blend crossover\n                        alpha = rng.rand(dim)\n                        child = alpha * p1 + (1 - alpha) * p2\n                    else:\n                        # Clone best of the two\n                        child = p1 if pop_y[i1] < pop_y[i2] else p2\n                        child = child.copy()\n\n                    # Gaussian mutation\n                    noise = rng.randn(dim) * mut_scale\n                    child = clamp(child + noise)\n\n                    new_pop.append(child)\n\n                # Evaluate offspring\n                new_pop = np.asarray(new_pop[:pop_size])\n                new_pop_y = np.empty(pop_size)\n                for i in range(pop_size):\n                    if evals_used >= budget or evals_used >= global_budget:\n                        # Truncate population if we can't evaluate further\n                        new_pop = new_pop[:i]\n                        new_pop_y = new_pop_y[:i]\n                        break\n                    new_pop_y[i] = evaluate(new_pop[i])\n\n                if new_pop.shape[0] == 0:\n                    break\n\n                # (\u00b5+\u03bb): combine parents and offspring, keep best pop_size\n                combined = np.vstack([pop, new_pop])\n                combined_y = np.concatenate([pop_y, new_pop_y])\n                order = np.argsort(combined_y)\n                pop = combined[order[:pop_size]]\n                pop_y = combined_y[order[:pop_size]]\n\n                # Slightly reduce mutation scale over generations, but not below minimum\n                mut_scale = np.maximum(mut_scale * 0.9, min_mut_scale)\n\n                if evals_used >= budget or evals_used >= global_budget:\n                    break\n\n        # finished global phase; best_x, best_y already updated\n\n    if evals_used >= budget:\n        return best_x if best_x is not None else clamp(lower)\n\n    # ---------- Ensure at least one point evaluated ----------\n    if best_x is None:\n        x = lower + rng.rand(dim) * width\n        evaluate(x)\n        if evals_used >= budget:\n            return best_x\n\n    # ---------- Local stochastic hill climbing ----------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Use remaining budget fully for local search\n    # Adaptive step size based on bounds and amplification with history\n    initial_step = 0.15 * width\n    min_step = 1e-6 * np.maximum(1.0, np.abs(width))\n\n    x_current = best_x.copy()\n    step = initial_step.copy()\n\n    # Track unsuccessful moves to decide occasional re-expansion\n    no_improve_count = 0\n\n    while evals_used < budget:\n        perturb = rng.randn(dim) * step\n        x_candidate = clamp(x_current + perturb)\n        y_candidate = evaluate(x_candidate)\n\n        if y_candidate < best_y:\n            # Improvement: move center to candidate, slightly expand steps\n            x_current = x_candidate\n            step = np.minimum(step * 1.2, width)\n            no_improve_count = 0\n        else:\n            # No improvement: shrink step sizes\n            step = np.maximum(step * 0.7, min_step)\n            no_improve_count += 1\n\n            # If we haven't improved for a while, try a larger jump from global best\n            if no_improve_count >= 10:\n                large_step = 0.5 * width\n                perturb_large = rng.randn(dim) * large_step\n                x_try = clamp(best_x + perturb_large)\n                y_try = evaluate(x_try)\n                if y_try < best_y:\n                    x_current = x_try\n                    step = np.maximum(initial_step, step)\n                    no_improve_count = 0\n                else:\n                    # Reset only the most promising dimensions (smaller width)\n                    step = np.maximum(step, 0.05 * width)\n                    no_improve_count = 0\n\n        if evals_used >= budget:\n            break\n\n    return best_x",
    "X": "-2.90677631394976 -2.8790729773345536 -2.8788442577330153 -2.914688526670374 -2.8888929523134683"
}