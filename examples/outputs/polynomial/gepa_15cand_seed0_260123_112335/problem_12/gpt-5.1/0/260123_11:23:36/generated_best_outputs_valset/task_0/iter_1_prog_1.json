{
    "score": -3.2,
    "Input": "Hartmann6",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budget-aware hybrid search:\n    - Warm-start from prev_best_x if available and feasible\n    - Global search via randomized search / coordinate perturbations\n    - Local refinement around current best\n    \"\"\"\n    rng = np.random.RandomState()  # use local RNG\n\n    bounds = np.array(config['bounds'], dtype=float)\n    dim = int(config.get('dim', bounds.shape[0]))\n    budget = int(config.get('budget', 1))\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n\n    def clip_to_bounds(x):\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # Helper to evaluate a candidate with budget tracking\n    def evaluate(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return np.inf\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # 1) Initialize from prev_best_x if provided and feasible\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip_to_bounds(x0)\n            evaluate(x0)\n\n    # If no valid prev_best or still no evaluation, sample a fresh point\n    if best_x is None:\n        x0 = lower + span * rng.rand(dim)\n        evaluate(x0)\n\n    # If budget already exhausted, return best found\n    if evals_used >= budget:\n        return best_x\n\n    # Remaining evaluations\n    remaining = budget - evals_used\n\n    # Strategy:\n    # - Use ~60% of remaining for global exploration\n    # - Use ~40% of remaining for local refinement around best\n    if remaining < 4:\n        # Too few evaluations: just do simple random search\n        for _ in range(remaining):\n            x = lower + span * rng.rand(dim)\n            evaluate(x)\n        return best_x\n\n    global_evals = int(0.6 * remaining)\n    global_evals = max(2, min(global_evals, remaining - 2))\n    local_evals = remaining - global_evals\n\n    # 2) Global exploration\n    # Mix: half uniform random, half perturbations around current best\n    for i in range(global_evals):\n        if best_x is None or i < global_evals // 2:\n            # pure random sample\n            x = lower + span * rng.rand(dim)\n        else:\n            # perturb best_x with moderately large noise\n            step_scale = 0.3  # 30% of range\n            noise = rng.randn(dim) * (step_scale * span)\n            x = clip_to_bounds(best_x + noise)\n        evaluate(x)\n        if evals_used >= budget:\n            return best_x\n\n    # 3) Local refinement around best_x using coordinate-wise and full-vector perturbations\n    if best_x is None or local_evals <= 0:\n        return best_x\n\n    current = best_x.copy()\n\n    # Local step sizes shrink over iterations\n    for k in range(local_evals):\n        frac = (k + 1) / (local_evals + 1)\n        # Exponential decay of step size from 10% to 1% of range\n        base_scale = 0.1 * (0.1 ** frac)\n        # Alternate between full-dimensional and single-coordinate moves\n        if k % 2 == 0:\n            # full-vector small Gaussian step\n            noise = rng.randn(dim) * (base_scale * span)\n            candidate = clip_to_bounds(current + noise)\n        else:\n            # coordinate-wise step\n            candidate = current.copy()\n            j = rng.randint(dim)\n            step = rng.randn() * (base_scale * span[j])\n            candidate[j] = np.clip(candidate[j] + step, lower[j], upper[j])\n\n        old_best_y = best_y\n        evaluate(candidate)\n        if best_y < old_best_y:\n            current = best_x.copy()  # best_x updated in evaluate\n\n        if evals_used >= budget:\n            break\n\n    return best_x",
    "X": "0.4073643056670225 0.886420106862347 0.9199462974383964 0.6067183984733151 0.5400765174614611 0.037239654595969195"
}