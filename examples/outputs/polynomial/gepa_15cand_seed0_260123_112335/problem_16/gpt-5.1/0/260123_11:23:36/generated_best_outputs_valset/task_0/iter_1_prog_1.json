{
    "score": -3.023786075678408,
    "Input": "McCourt03",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Simple derivative-free optimizer using adaptive random search with\n    warm-start support and basic local refinement.\n\n    Strategy:\n    - Start from prev_best_x if provided, otherwise a random point.\n    - Use a sequence of Gaussian perturbations with decreasing scale.\n    - Always respect bounds and budget.\n    \"\"\"\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    lower, upper = bounds[:, 0], bounds[:, 1]\n    width = upper - lower\n\n    # Handle degenerate cases\n    if budget <= 0:\n        # Just return a bounded version of prev_best_x or a random point\n        if prev_best_x is not None:\n            x0 = np.clip(np.asarray(prev_best_x, dtype=float), lower, upper)\n        else:\n            x0 = np.random.uniform(lower, upper, size=dim)\n        return x0.astype(float)\n\n    # Initialize starting point\n    if prev_best_x is not None:\n        x_best = np.clip(np.asarray(prev_best_x, dtype=float), lower, upper)\n    else:\n        x_best = np.random.uniform(lower, upper, size=dim)\n\n    # Evaluate initial point\n    y_best = objective_function(x_best)\n    evals_used = 1\n\n    # If budget is 1 we must stop here\n    if budget == 1:\n        return x_best.astype(float)\n\n    # Adaptive random search parameters\n    # Number of candidate moves per \"iteration\" is modest to keep it cheap\n    base_step = 0.25  # fraction of domain width for initial std\n    min_step = 1e-3   # minimum relative step size\n    n_candidates = 4  # candidates per iteration\n\n    # Derive a schedule for step sizes based on remaining budget\n    # Larger budgets allow more gradual decay.\n    n_iters = max(1, budget // n_candidates)\n    # Precompute step sizes (geometric decay from base_step to min_step)\n    step_scales = np.geomspace(base_step, max(min_step, base_step * 1e-3), num=n_iters)\n\n    it = 0\n    while evals_used < budget:\n        if it >= n_iters:\n            # If we used more iterations than precomputed, keep the last scale\n            step_scale = step_scales[-1]\n        else:\n            step_scale = step_scales[it]\n        it += 1\n\n        # Candidate generation around current best\n        # Scale per-dimension by width to adapt to box size\n        std = step_scale * width\n        # Guard against zero-width dimensions\n        std = np.where(std > 0, std, (upper - lower + 1e-9) * step_scale)\n\n        # Try n_candidates perturbations or until budget exhausted\n        for _ in range(n_candidates):\n            if evals_used >= budget:\n                break\n\n            # Gaussian perturbation around best\n            x_trial = x_best + np.random.normal(loc=0.0, scale=std, size=dim)\n            # Project back to bounds\n            x_trial = np.clip(x_trial, lower, upper)\n\n            y_trial = objective_function(x_trial)\n            evals_used += 1\n\n            if y_trial < y_best:\n                x_best, y_best = x_trial, y_trial\n\n    return x_best.astype(float)",
    "X": "0.9311724490517149 0.19089924060821772 0.24981419400014407 0.3647656916814001 0.16207781714297406 0.9830857555921723 0.039089041072755334 0.3264789509497023 0.6516344038496978"
}