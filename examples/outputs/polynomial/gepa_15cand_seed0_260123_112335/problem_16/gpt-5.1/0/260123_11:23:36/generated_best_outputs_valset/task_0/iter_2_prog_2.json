{
    "score": -3.02379581813292,
    "Input": "McCourt03",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid optimizer: combines warm-started local search with opportunistic\n    global restarts under a strict evaluation budget.\n\n    Main ideas:\n    - Start from prev_best_x if available, otherwise several random points.\n    - Maintain a global best across all starts.\n    - Local search: adaptive Gaussian random search with shrinking step size.\n    - Occasional larger exploratory moves even late in the search.\n    - Full budget use and strict bound compliance.\n    \"\"\"\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    lower, upper = bounds[:, 0], bounds[:, 1]\n    width = upper - lower\n\n    # Handle degenerate cases quickly\n    if budget <= 0:\n        if prev_best_x is not None:\n            x0 = np.clip(np.asarray(prev_best_x, dtype=float), lower, upper)\n        else:\n            x0 = np.random.uniform(lower, upper, size=dim)\n        return x0.astype(float)\n\n    # Helper: single local search run starting from x0\n    def local_search(x0, remaining_budget, y0=None):\n        # Ensure feasible start\n        x_best = np.clip(np.asarray(x0, dtype=float), lower, upper)\n        evals_used = 0\n\n        # Evaluate if not already evaluated\n        if y0 is None:\n            y_best = objective_function(x_best)\n            evals_used += 1\n        else:\n            y_best = float(y0)\n\n        if remaining_budget <= evals_used:\n            return x_best, y_best, evals_used\n\n        # Local search hyperparameters\n        # Relative step size schedule\n        base_step = 0.25\n        min_step = 1e-4\n        n_candidates = 6\n\n        # Conservative estimate of iterations for remaining budget\n        max_iters = max(1, (remaining_budget - evals_used) // n_candidates)\n        step_scales = np.geomspace(base_step, max(min_step, base_step * 1e-3), num=max_iters)\n\n        it = 0\n        no_improve_streak = 0\n        max_no_improve = 8  # early shrink of step size when stuck\n\n        while evals_used < remaining_budget:\n            if it >= max_iters:\n                step_scale = step_scales[-1]\n            else:\n                step_scale = step_scales[it]\n            it += 1\n\n            # Basic std based on domain width\n            std = step_scale * width\n            std = np.where(std > 0, std, (upper - lower + 1e-9) * step_scale)\n\n            improved_in_iter = False\n\n            for _ in range(n_candidates):\n                if evals_used >= remaining_budget:\n                    break\n\n                # With small probability, do a larger exploratory move\n                if np.random.rand() < 0.1:\n                    exp_scale = min(1.0, step_scale * 4.0)\n                    std_exp = exp_scale * width\n                    std_exp = np.where(std_exp > 0, std_exp, (upper - lower + 1e-9) * exp_scale)\n                    x_trial = x_best + np.random.normal(0.0, std_exp, size=dim)\n                else:\n                    x_trial = x_best + np.random.normal(0.0, std, size=dim)\n\n                x_trial = np.clip(x_trial, lower, upper)\n                y_trial = objective_function(x_trial)\n                evals_used += 1\n\n                if y_trial < y_best:\n                    x_best, y_best = x_trial, y_trial\n                    improved_in_iter = True\n\n            if improved_in_iter:\n                no_improve_streak = 0\n            else:\n                no_improve_streak += 1\n                # If stuck, advance step schedule faster (shrink step size)\n                if no_improve_streak >= max_no_improve:\n                    no_improve_streak = 0\n                    it = min(it + 3, max_iters - 1)\n\n        return x_best.astype(float), float(y_best), evals_used\n\n    # Global bookkeeping\n    evals_total = 0\n    x_global_best = None\n    y_global_best = None\n\n    # 1) Mandatory evaluation of warm start if provided\n    if prev_best_x is not None:\n        x0 = np.clip(np.asarray(prev_best_x, dtype=float), lower, upper)\n        y0 = objective_function(x0)\n        evals_total += 1\n        x_global_best = x0\n        y_global_best = float(y0)\n    else:\n        x_global_best = None\n        y_global_best = None\n\n    if evals_total >= budget:\n        # Budget exhausted by warm start evaluation\n        return x_global_best.astype(float)\n\n    remaining = budget - evals_total\n\n    # 2) Decide number of additional starting points\n    # Use more restarts for larger budgets and when no warm start\n    if prev_best_x is None:\n        max_starts = 4\n    else:\n        max_starts = 3\n\n    # Ensure at least one local search run\n    n_starts = min(max_starts, max(1, remaining // 5))\n\n    # Allocate budget: keep a small reserve for a final intensification\n    reserve = max(0, remaining // 8)\n    budget_for_starts = max(1, remaining - reserve)\n\n    # Distribute approximately evenly across starts\n    per_start_budget = max(3, budget_for_starts // n_starts)\n\n    # 3) First run: from warm start if available, otherwise random\n    starts_done = 0\n    if prev_best_x is not None:\n        run_budget = min(per_start_budget, remaining)\n        x_ls, y_ls, used = local_search(x_global_best, run_budget, y_global_best)\n        evals_total += used\n        remaining -= used\n        x_global_best, y_global_best = x_ls, y_ls\n        starts_done += 1\n\n    # 4) Additional restarts from random points\n    while starts_done < n_starts and remaining > 0:\n        x0 = np.random.uniform(lower, upper, size=dim)\n        run_budget = min(per_start_budget, remaining)\n        x_ls, y_ls, used = local_search(x0, run_budget)\n        evals_total += used\n        remaining -= used\n        starts_done += 1\n\n        if (y_global_best is None) or (y_ls < y_global_best):\n            x_global_best, y_global_best = x_ls, y_ls\n\n    # 5) Final intensification around global best with any leftover budget\n    if remaining > 0 and x_global_best is not None:\n        x_ls, y_ls, used = local_search(x_global_best, remaining, y_global_best)\n        evals_total += used\n        if y_ls < y_global_best:\n            x_global_best, y_global_best = x_ls, y_ls\n\n    # Fallback if, for some reason, we never evaluated anything (extreme edge)\n    if x_global_best is None:\n        x_global_best = np.random.uniform(lower, upper, size=dim)\n\n    return x_global_best.astype(float)",
    "X": "0.9319334213571011 0.18906209218857728 0.25055685702864905 0.3645631697184768 0.16011679724208783 0.9823743223857494 0.03913509770551985 0.3263435377973915 0.6522905741231709"
}