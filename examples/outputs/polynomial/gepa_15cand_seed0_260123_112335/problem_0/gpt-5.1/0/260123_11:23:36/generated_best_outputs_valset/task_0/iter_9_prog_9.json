{
    "score": 7.383040465533947,
    "Input": "Ackley",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global (LHS + evolutionary) and local (adaptive random / coordinate search)\n    optimizer with warm start support.\n\n    This version focuses on:\n    - Slightly stronger and earlier exploitation around warm starts / incumbents.\n    - Simpler and more robust budget splitting.\n    - Mildly higher evaluation density per local trajectory on smooth functions\n      (e.g., Ackley), which reduces over-fragmentation of the budget.\n    - Conservative, dimension-aware step sizes to behave well on bowl-like\n      landscapes while still exploring globally.\n\n    It always respects the given evaluation budget and returns the best x found.\n    \"\"\"\n\n    # ---------- Setup ----------\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0].astype(float)\n    high = bounds[:, 1].astype(float)\n    span = high - low\n    span = np.where(span <= 0.0, 1.0, span)  # handle degenerate bounds\n\n    # Deterministic seed based on config for reproducibility\n    key = (tuple(map(float, np.array(config.get(\"bounds\", []), float).ravel()))\n           if isinstance(config, dict) and \"bounds\" in config else ())\n    seed = (hash((config.get(\"dim\", dim), config.get(\"budget\", budget), key)) %\n            (2**32 - 1))\n    rng = np.random.RandomState(seed)\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n\n    # ---------- Initialize incumbent ----------\n    x_best = None\n    y_best = None\n\n    # Warm start from prev_best_x if provided and valid\n    if prev_best_x is not None and budget > 0:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = clip_to_bounds(x0)\n            y0 = float(objective_function(x0))\n            evals_used += 1\n            x_best, y_best = x0, y0\n        except Exception:\n            x_best, y_best = None, None\n\n    if evals_used >= budget:\n        if x_best is None:\n            return clip_to_bounds((low + high) * 0.5)\n        return x_best\n\n    # If no valid warm start, start from center-biased random point\n    if x_best is None:\n        center = (low + high) * 0.5\n        # mild spread around center: up to 40% of span\n        scale = 0.4\n        x0 = center + rng.uniform(-scale, scale, size=dim) * span\n        x0 = clip_to_bounds(x0)\n        y0 = float(objective_function(x0))\n        evals_used += 1\n        x_best, y_best = x0, y0\n\n    if evals_used >= budget:\n        return x_best\n\n    # Global cache (simple numeric hash)\n    cache = {}\n\n    def key_from_x(x):\n        return tuple(np.round(x, decimals=12))\n\n    cache[key_from_x(x_best)] = y_best\n\n    # Track good points for local starts\n    best_seen_x = [x_best]\n    best_seen_y = [y_best]\n\n    # ---------- Budget allocation (global vs local) ----------\n    remaining_total = budget - evals_used\n    if remaining_total <= 0:\n        return x_best\n\n    # Heuristic: Ackley-like landscapes prefer strong global search first,\n    # but we bias slightly more budget to local search than before for\n    # smoother convergence once a good basin is found.\n    dim_factor = min(1.0, max(0.0, (dim - 2) / 18.0))\n    budget_factor = min(1.0, max(0.0, (budget - 40) / 260.0))\n    global_ratio = 0.40 + 0.25 * dim_factor + 0.15 * budget_factor\n    global_ratio = max(0.25, min(0.65, global_ratio))\n\n    global_budget = int(round(global_ratio * remaining_total))\n\n    # Ensure some evaluations for local search\n    if remaining_total > 16:\n        global_budget = min(global_budget, remaining_total - 10)\n        global_budget = max(4, global_budget)\n    else:\n        # very small budgets: keep at least 3 for local if possible\n        global_budget = max(1, remaining_total - 3)\n\n    global_budget = min(global_budget, remaining_total)\n    local_budget = remaining_total - global_budget\n\n    # ---------- Global exploration: LHS + small evolutionary refinement ----------\n    if global_budget > 0:\n        if global_budget <= 5:\n            n_lhs = global_budget\n            evo_budget = 0\n        else:\n            n_lhs = max(4, int(0.7 * global_budget))\n            n_lhs = min(n_lhs, global_budget)\n            evo_budget = global_budget - n_lhs\n\n        # Latin-hypercube-like sampling (n_lhs points)\n        n_global = n_lhs\n        base = rng.rand(n_global, dim)\n        for d in range(dim):\n            perm = rng.permutation(n_global)\n            base[:, d] = (perm + base[:, d]) / float(n_global)\n        Xg = low + base * span\n\n        # Inject points around current best to exploit warm start / incumbent\n        n_around_best = max(1, min(8, n_global // 3))\n        for i in range(n_around_best):\n            noise_dir = rng.normal(size=dim)\n            norm = np.linalg.norm(noise_dir)\n            if norm > 1e-12:\n                noise_dir /= norm\n            # modest radius: 4\u201312% of span\n            radius = span * (0.04 + 0.08 * rng.rand(dim))\n            x_nb = clip_to_bounds(x_best + noise_dir * radius)\n            Xg[i] = x_nb\n\n        # Evaluate LHS points\n        Yg = np.empty(n_global, dtype=float)\n        for i in range(n_global):\n            if evals_used >= budget:\n                Yg[i] = np.inf\n                continue\n            x = Xg[i]\n            k = key_from_x(x)\n            y = cache.get(k, None)\n            if y is None:\n                y = float(objective_function(x))\n                evals_used += 1\n                cache[k] = y\n            Yg[i] = y\n            best_seen_x.append(x)\n            best_seen_y.append(y)\n            if y < y_best:\n                x_best, y_best = x, y\n\n        if evals_used >= budget:\n            return x_best\n\n        # Compact evolutionary refinement on top of LHS\n        evo_evals_left = max(0, evo_budget)\n        if evo_evals_left > 0 and n_global > 2 and evals_used < budget:\n            elite_frac = 0.3\n            elite_size = max(2, int(elite_frac * n_global))\n            elite_size = min(elite_size, n_global)\n            elite_idx = np.argsort(Yg)[:elite_size]\n            elite_X = Xg[elite_idx].copy()\n            elite_Y = Yg[elite_idx].copy()\n\n            # estimate scale from elite spread; fall back to global span\n            if elite_size > 1:\n                elite_span = np.max(elite_X, axis=0) - np.min(elite_X, axis=0)\n            else:\n                elite_span = span * 0.2\n            evo_step = np.maximum(elite_span * 0.35, span * 0.025)\n\n            while evo_evals_left > 0 and evals_used < budget:\n                parent_ids = rng.choice(elite_size, size=2, replace=True)\n                p1, p2 = elite_X[parent_ids[0]], elite_X[parent_ids[1]]\n                alpha = rng.rand()\n                child = alpha * p1 + (1.0 - alpha) * p2\n\n                # Gaussian mutation\n                mutation = rng.normal(scale=0.45, size=dim) * evo_step\n                child = clip_to_bounds(child + mutation)\n\n                k = key_from_x(child)\n                y = cache.get(k, None)\n                if y is None:\n                    y = float(objective_function(child))\n                    evals_used += 1\n                    cache[k] = y\n                evo_evals_left -= 1\n\n                best_seen_x.append(child)\n                best_seen_y.append(y)\n                if y < y_best:\n                    x_best, y_best = child, y\n\n                # Replace worst elite if improved\n                worst_idx = np.argmax(elite_Y)\n                if y < elite_Y[worst_idx]:\n                    elite_Y[worst_idx] = y\n                    elite_X[worst_idx] = child\n\n    if evals_used >= budget:\n        return x_best\n\n    # ---------- Local search: multi-start adaptive random search ----------\n    remaining = budget - evals_used\n    if remaining <= 0 or local_budget <= 0:\n        return x_best\n\n    local_budget = min(local_budget, remaining)\n    if local_budget <= 0:\n        return x_best\n\n    best_seen_y_arr = np.array(best_seen_y, dtype=float)\n    best_seen_x_arr = np.array(best_seen_x, dtype=float)\n    order = np.argsort(best_seen_y_arr)\n    best_seen_x_arr = best_seen_x_arr[order]\n    best_seen_y_arr = best_seen_y_arr[order]\n\n    # Dimension-aware base step for smooth functions\n    base_step = span / (16.0 + 0.4 * max(dim - 1, 0))\n    min_step = span / 4e4 + 1e-12\n    max_step = span\n\n    # Fewer, but deeper local starts to avoid fragmenting the budget\n    min_per_start = max(4, 2 * dim)\n    # slightly higher per-start minimum to ensure real refinement on Ackley\n    min_per_start = max(min_per_start, 10)\n    max_starts = max(1, min(4, local_budget // min_per_start))\n    max_starts = min(max_starts, max(1, len(best_seen_x_arr)))\n\n    local_starts = best_seen_x_arr[:max_starts].copy()\n\n    # If not enough starts, add random ones\n    while len(local_starts) < max_starts:\n        local_starts = np.vstack([local_starts, rng.uniform(low, high)])\n    local_starts = local_starts[:max_starts]\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # Distribute remaining budget across starts, preferring best starts\n    per_start = [remaining // max_starts] * max_starts\n    for i in range(remaining % max_starts):\n        per_start[i] += 1\n    # ensure each start has at least a small number of moves\n    for i in range(max_starts):\n        per_start[i] = max(5, per_start[i])\n\n    for s in range(max_starts):\n        if evals_used >= budget:\n            break\n\n        start_budget = per_start[s]\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n        start_budget = min(start_budget, remaining)\n        if start_budget <= 0:\n            continue\n\n        current_x = clip_to_bounds(local_starts[s].copy())\n        k = key_from_x(current_x)\n        y_cur = cache.get(k, None)\n        if y_cur is None:\n            if evals_used >= budget:\n                break\n            y_cur = float(objective_function(current_x))\n            evals_used += 1\n            cache[k] = y_cur\n\n        current_y = y_cur\n        if current_y < y_best:\n            x_best, y_best = current_x, current_y\n\n        # small randomization of initial step to diversify starts\n        current_step = np.maximum(\n            base_step * (0.9 + 0.5 * rng.rand(dim)), min_step\n        )\n        no_improve = 0\n        # allow longer \"patience\" before restart in higher dims\n        no_improve_thres = max(8, 3 * dim)\n\n        for _ in range(start_budget):\n            if evals_used >= budget:\n                break\n\n            # Coordinate moves strongly preferred in higher dimensions\n            if rng.rand() < (0.75 if dim <= 10 else 0.93):\n                d = np.zeros(dim)\n                idx = rng.randint(dim)\n                d[idx] = 1.0 if rng.rand() < 0.5 else -1.0\n                direction = d\n            else:\n                direction = rng.normal(size=dim)\n                norm = np.linalg.norm(direction)\n                if norm > 1e-12:\n                    direction /= norm\n\n            mag = rng.lognormal(mean=-0.15, sigma=0.32)\n            step_vec = current_step * mag\n            x_candidate = clip_to_bounds(current_x + direction * step_vec)\n\n            k = key_from_x(x_candidate)\n            y_candidate = cache.get(k, None)\n            if y_candidate is None:\n                y_candidate = float(objective_function(x_candidate))\n                evals_used += 1\n                cache[k] = y_candidate\n\n            if y_candidate < current_y:\n                current_x, current_y = x_candidate, y_candidate\n                if y_candidate < y_best:\n                    x_best, y_best = x_candidate, y_candidate\n                current_step = np.minimum(current_step * 1.3, max_step)\n                no_improve = 0\n            else:\n                current_step = np.maximum(current_step * 0.7, min_step)\n                no_improve += 1\n\n            if evals_used >= budget:\n                break\n\n            # Local restart if stuck\n            if no_improve >= no_improve_thres and evals_used < budget:\n                noise = rng.normal(size=dim)\n                norm = np.linalg.norm(noise)\n                if norm > 1e-12:\n                    noise /= norm\n                progress = (s + 1) / max_starts\n                radius = span * (0.18 * (1.0 - 0.45 * progress))\n                x_restart = clip_to_bounds(x_best + noise * radius)\n\n                k_r = key_from_x(x_restart)\n                y_restart = cache.get(k_r, None)\n                if y_restart is None:\n                    y_restart = float(objective_function(x_restart))\n                    evals_used += 1\n                    cache[k_r] = y_restart\n\n                if y_restart < current_y:\n                    current_x, current_y = x_restart, y_restart\n                    if y_restart < y_best:\n                        x_best, y_best = x_restart, y_restart\n                    current_step = np.maximum(\n                        base_step * (0.45 ** (s + 1)), min_step\n                    )\n                no_improve = 0\n\n                if evals_used >= budget:\n                    break\n\n    # ---------- Final greedy coordinate refinement ----------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    refine_steps = min(remaining, max(8, dim * 4))\n    refine_step = np.maximum(span / (30.0 + dim), min_step)\n\n    current_x = x_best.copy()\n    current_y = y_best\n    step_vec = refine_step.copy()\n\n    for _ in range(refine_steps):\n        if evals_used >= budget:\n            break\n\n        idx = rng.randint(dim)\n        direction = np.zeros(dim)\n        direction[idx] = 1.0 if rng.rand() < 0.5 else -1.0\n\n        x_candidate = clip_to_bounds(current_x + direction * step_vec)\n\n        k = key_from_x(x_candidate)\n        y_candidate = cache.get(k, None)\n        if y_candidate is None:\n            y_candidate = float(objective_function(x_candidate))\n            evals_used += 1\n            cache[k] = y_candidate\n\n        if y_candidate < current_y:\n            current_x, current_y = x_candidate, y_candidate\n            if y_candidate < y_best:\n                x_best, y_best = x_candidate, y_candidate\n            step_vec[idx] = min(step_vec[idx] * 1.45, max_step[idx])\n        else:\n            step_vec[idx] = max(step_vec[idx] * 0.55, min_step[idx])\n\n    return x_best",
    "X": "-0.9303721038191267 3.520870753166421 -3.710568427170912 2.406858998868019 -0.9139177835695959 -0.09038520216393847 0.9695248877150321 0.818509332467805 -0.9325348852075607 -0.9614685041407153 -0.16338661564043908"
}