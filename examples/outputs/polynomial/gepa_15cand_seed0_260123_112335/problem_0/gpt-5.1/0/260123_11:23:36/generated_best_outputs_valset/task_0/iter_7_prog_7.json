{
    "score": 10.1134772189362,
    "Input": "Ackley",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global (LHS + evolutionary) and local (adaptive random search) optimizer\n    with warm start support.\n\n    This version keeps the core structure of the previous solver but:\n    - Uses the actual remaining budget for the global phase (no off\u2011by\u2011error).\n    - Ensures the evolutionary phase actually receives evaluations (not zero).\n    - Slightly simplifies/refines budget splitting and step sizing.\n    \"\"\"\n\n    # ---------- Setup ----------\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0].astype(float)\n    high = bounds[:, 1].astype(float)\n    span = high - low\n    span = np.where(span <= 0.0, 1.0, span)  # handle degenerate bounds\n\n    # Deterministic seed based on config for reproducibility\n    key = (tuple(map(float, np.array(config.get(\"bounds\", []), float).ravel()))\n           if isinstance(config, dict) and \"bounds\" in config else ())\n    seed = (hash((config.get(\"dim\", dim), config.get(\"budget\", budget), key)) %\n            (2**32 - 1))\n    rng = np.random.RandomState(seed)\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n\n    # ---------- Initialize incumbent ----------\n    x_best = None\n    y_best = None\n\n    # Warm start from prev_best_x if provided and valid\n    if prev_best_x is not None and budget > 0:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x0 = clip_to_bounds(x0)\n            y0 = float(objective_function(x0))\n            evals_used += 1\n            x_best, y_best = x0, y0\n        except Exception:\n            x_best, y_best = None, None\n\n    if evals_used >= budget:\n        if x_best is None:\n            return clip_to_bounds((low + high) * 0.5)\n        return x_best\n\n    # If no valid warm start, start from center-biased random point\n    if x_best is None:\n        center = (low + high) * 0.5\n        scale = 0.6\n        x0 = center + rng.uniform(-scale, scale, size=dim) * span\n        x0 = clip_to_bounds(x0)\n        y0 = float(objective_function(x0))\n        evals_used += 1\n        x_best, y_best = x0, y0\n\n    if evals_used >= budget:\n        return x_best\n\n    # Containers for global cache of all evaluations\n    best_seen_x = [x_best]\n    best_seen_y = [y_best]\n\n    # Simple numeric hash for caching to avoid duplicates\n    cache = {}\n\n    def key_from_x(x):\n        # Round to 1e-10 precision for hash key\n        return tuple(np.round(x, decimals=10))\n\n    cache[key_from_x(x_best)] = y_best\n\n    # ---------- Budget allocation (global vs local) ----------\n    remaining_total = budget - evals_used\n    if remaining_total <= 0:\n        return x_best\n\n    # More global search for high dim / large budget, but always reserve local\n    dim_factor = min(1.0, max(0.0, (dim - 2) / 18.0))          # grows with dim\n    budget_factor = min(1.0, max(0.0, (budget - 30) / 270.0))  # grows with budget\n    global_ratio = 0.35 + 0.3 * dim_factor + 0.2 * budget_factor\n    global_ratio = max(0.25, min(0.8, global_ratio))\n\n    # Raw allocation\n    global_budget = int(round(global_ratio * remaining_total))\n\n    # Ensure some room for local search\n    if remaining_total > 10:\n        global_budget = min(global_budget, remaining_total - 10)\n        global_budget = max(5, global_budget)\n    else:\n        # Very small budgets: keep at least 2 for local if possible\n        global_budget = max(1, remaining_total - 2)\n\n    global_budget = min(global_budget, remaining_total)\n    local_budget = remaining_total - global_budget\n\n    # ---------- Global exploration: LHS + compact evolutionary phase ----------\n    if global_budget > 0:\n        # Decide mix of LHS vs evo within the global budget\n        # At least a small evo phase (unless global_budget is tiny)\n        if global_budget <= 6:\n            n_lhs = global_budget\n            evo_budget = 0\n        else:\n            n_lhs = max(4, int(0.7 * global_budget))\n            n_lhs = min(n_lhs, global_budget)       # cannot exceed global_budget\n            evo_budget = global_budget - n_lhs      # remaining for evo\n\n        # Latin-hypercube-like initial sampling (n_lhs points)\n        n_global = n_lhs\n        base = rng.rand(n_global, dim)\n        for d in range(dim):\n            perm = rng.permutation(n_global)\n            base[:, d] = (perm + base[:, d]) / float(n_global)\n        Xg = low + base * span\n\n        # Inject several points around current best to exploit warm start\n        n_around_best = max(1, min(6, n_global // 4))\n        for i in range(n_around_best):\n            noise_dir = rng.normal(size=dim)\n            norm = np.linalg.norm(noise_dir)\n            if norm > 1e-12:\n                noise_dir /= norm\n            radius = span * (0.1 + 0.15 * rng.rand(dim))  # 10\u201325% of span\n            x_nb = clip_to_bounds(x_best + noise_dir * radius)\n            Xg[i] = x_nb\n\n        # Evaluate LHS population\n        Yg = np.empty(n_global, dtype=float)\n        for i in range(n_global):\n            if evals_used >= budget:\n                Yg[i] = np.inf\n                continue\n            x = Xg[i]\n            k = key_from_x(x)\n            y = cache.get(k, None)\n            if y is None:\n                y = float(objective_function(x))\n                evals_used += 1\n                cache[k] = y\n            Yg[i] = y\n            best_seen_x.append(x)\n            best_seen_y.append(y)\n            if y < y_best:\n                x_best, y_best = x, y\n\n        if evals_used >= budget:\n            best_seen_y_arr = np.array(best_seen_y, dtype=float)\n            best_seen_x_arr = np.array(best_seen_x, dtype=float)\n            order = np.argsort(best_seen_y_arr)\n            return best_seen_x_arr[order[0]]\n\n        # Compact evolutionary phase on top of LHS samples\n        evo_evals_left = max(0, evo_budget)\n        if evo_evals_left > 0 and n_global > 2 and evals_used < budget:\n            # Take a small elite set\n            elite_frac = 0.3\n            elite_size = max(2, int(elite_frac * n_global))\n            elite_size = min(elite_size, n_global)\n            elite_idx = np.argsort(Yg)[:elite_size]\n            elite_X = Xg[elite_idx].copy()\n            elite_Y = Yg[elite_idx].copy()\n\n            # Estimate typical scale from elite spread\n            if elite_size > 1:\n                elite_span = np.max(elite_X, axis=0) - np.min(elite_X, axis=0)\n            else:\n                elite_span = span * 0.2\n            evo_step = np.maximum(elite_span * 0.5, span * 0.05)\n\n            while evo_evals_left > 0 and evals_used < budget:\n                parent_ids = rng.choice(elite_size, size=2, replace=True)\n                p1, p2 = elite_X[parent_ids[0]], elite_X[parent_ids[1]]\n                alpha = rng.rand()\n                child = alpha * p1 + (1.0 - alpha) * p2\n\n                # Gaussian mutation\n                mutation = rng.normal(scale=0.5, size=dim) * evo_step\n                child = clip_to_bounds(child + mutation)\n\n                k = key_from_x(child)\n                y = cache.get(k, None)\n                if y is None:\n                    y = float(objective_function(child))\n                    evals_used += 1\n                    cache[k] = y\n                # Count toward evo budget regardless of cache hit\n                evo_evals_left -= 1\n\n                best_seen_x.append(child)\n                best_seen_y.append(y)\n                if y < y_best:\n                    x_best, y_best = child, y\n\n                # Replace worst elite if improvement\n                worst_idx = np.argmax(elite_Y)\n                if y < elite_Y[worst_idx]:\n                    elite_Y[worst_idx] = y\n                    elite_X[worst_idx] = child\n\n    # Sort evaluated points for better local-start selection\n    best_seen_y_arr = np.array(best_seen_y, dtype=float)\n    best_seen_x_arr = np.array(best_seen_x, dtype=float)\n    order = np.argsort(best_seen_y_arr)\n    best_seen_x_arr = best_seen_x_arr[order]\n    best_seen_y_arr = best_seen_y_arr[order]\n\n    if evals_used >= budget:\n        return x_best\n\n    # ---------- Local search: multi-start adaptive random search ----------\n    remaining = budget - evals_used\n    if remaining <= 0 or local_budget <= 0:\n        return x_best\n\n    # Use actual remaining for local (may be slightly different from local_budget)\n    local_budget = min(local_budget, remaining)\n    if local_budget <= 0:\n        return x_best\n\n    # Dimension-aware base step\n    base_step = span / (12.0 + 0.6 * max(dim - 1, 0))\n    min_step = span / 2e4 + 1e-12\n    max_step = span\n\n    # Number of local starts\n    max_starts = max(1, min(6, local_budget // max(4, 2 * dim)))\n    max_starts = min(max_starts, max(1, len(best_seen_x_arr)))\n\n    local_starts = best_seen_x_arr[:max_starts].copy()\n\n    # If not enough starts, add random ones\n    while len(local_starts) < max_starts:\n        local_starts = np.vstack([local_starts, rng.uniform(low, high)])\n    local_starts = local_starts[:max_starts]\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # Redistribute remaining budget across starts\n    per_start = [remaining // max_starts] * max_starts\n    for i in range(remaining % max_starts):\n        per_start[i] += 1\n\n    for s in range(max_starts):\n        if evals_used >= budget:\n            break\n\n        start_budget = per_start[s]\n        if start_budget <= 0:\n            continue\n\n        current_x = clip_to_bounds(local_starts[s].copy())\n        k = key_from_x(current_x)\n        y_cur = cache.get(k, None)\n        if y_cur is None:\n            if evals_used >= budget:\n                break\n            y_cur = float(objective_function(current_x))\n            evals_used += 1\n            cache[k] = y_cur\n            best_seen_x_arr = np.vstack([best_seen_x_arr, current_x])\n            best_seen_y_arr = np.concatenate([best_seen_y_arr, [y_cur]])\n\n        current_y = y_cur\n        if current_y < y_best:\n            x_best, y_best = current_x, current_y\n\n        current_step = np.maximum(\n            base_step * (0.7 + 0.6 * rng.rand(dim)), min_step\n        )\n        no_improve = 0\n\n        for _ in range(start_budget):\n            if evals_used >= budget:\n                break\n\n            # Coordinate moves are preferred, more so in high dimensions\n            if rng.rand() < (0.7 if dim <= 10 else 0.9):\n                d = np.zeros(dim)\n                idx = rng.randint(dim)\n                d[idx] = 1.0 if rng.rand() < 0.5 else -1.0\n                direction = d\n            else:\n                direction = rng.normal(size=dim)\n                norm = np.linalg.norm(direction)\n                if norm > 1e-12:\n                    direction /= norm\n\n            mag = rng.lognormal(mean=-0.1, sigma=0.35)\n            step_vec = current_step * mag\n            x_candidate = clip_to_bounds(current_x + direction * step_vec)\n\n            k = key_from_x(x_candidate)\n            y_candidate = cache.get(k, None)\n            if y_candidate is None:\n                y_candidate = float(objective_function(x_candidate))\n                evals_used += 1\n                cache[k] = y_candidate\n\n            if y_candidate < current_y:\n                current_x, current_y = x_candidate, y_candidate\n                if y_candidate < y_best:\n                    x_best, y_best = x_candidate, y_candidate\n                current_step = np.minimum(current_step * 1.3, max_step)\n                no_improve = 0\n            else:\n                current_step = np.maximum(current_step * 0.6, min_step)\n                no_improve += 1\n\n            if evals_used >= budget:\n                break\n\n            # Local restart if stuck\n            if no_improve >= max(8, 3 * dim) and evals_used < budget:\n                noise = rng.normal(size=dim)\n                norm = np.linalg.norm(noise)\n                if norm > 1e-12:\n                    noise /= norm\n                progress = (s + 1) / max_starts\n                radius = span * (0.25 * (1.0 - 0.5 * progress))\n                x_restart = clip_to_bounds(x_best + noise * radius)\n\n                k_r = key_from_x(x_restart)\n                y_restart = cache.get(k_r, None)\n                if y_restart is None:\n                    y_restart = float(objective_function(x_restart))\n                    evals_used += 1\n                    cache[k_r] = y_restart\n\n                if y_restart < current_y:\n                    current_x, current_y = x_restart, y_restart\n                    if y_restart < y_best:\n                        x_best, y_best = x_restart, y_restart\n                    current_step = np.maximum(\n                        base_step * (0.5 ** (s + 1)), min_step\n                    )\n                no_improve = 0\n\n                if evals_used >= budget:\n                    break\n\n    # ---------- Final greedy refinement around best ----------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # Small-step greedy coordinate search\n    refine_steps = min(remaining, max(7, dim * 4))\n    refine_step = np.maximum(span / (25.0 + dim), min_step)\n\n    current_x = x_best.copy()\n    current_y = y_best\n    step_vec = refine_step.copy()\n\n    for _ in range(refine_steps):\n        if evals_used >= budget:\n            break\n\n        idx = rng.randint(dim)\n        direction = np.zeros(dim)\n        direction[idx] = 1.0 if rng.rand() < 0.5 else -1.0\n\n        x_candidate = clip_to_bounds(current_x + direction * step_vec)\n\n        k = key_from_x(x_candidate)\n        y_candidate = cache.get(k, None)\n        if y_candidate is None:\n            y_candidate = float(objective_function(x_candidate))\n            evals_used += 1\n            cache[k] = y_candidate\n\n        if y_candidate < current_y:\n            current_x, current_y = x_candidate, y_candidate\n            if y_candidate < y_best:\n                x_best, y_best = x_candidate, y_candidate\n            step_vec[idx] = min(step_vec[idx] * 1.5, max_step[idx])\n        else:\n            step_vec[idx] = max(step_vec[idx] * 0.5, min_step[idx])\n\n    return x_best",
    "X": "0.001986273215697449 7.955327658608972 -6.960193638554886 1.9911133722612624 -0.0003406994735220195 3.9936253066838643 0.9942643740424739 0.025109108227777416 0.9946609669939874 -0.9185572853577281 -0.001202039970301773"
}