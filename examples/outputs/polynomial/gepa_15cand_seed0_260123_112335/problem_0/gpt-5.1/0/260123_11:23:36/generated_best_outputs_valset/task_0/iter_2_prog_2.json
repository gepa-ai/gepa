{
    "score": 10.522368515348731,
    "Input": "Ackley",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid global-local derivative-free optimizer with warm start support.\n\n    Strategy:\n    - Use a portion of the budget for quasi-random global exploration.\n    - Maintain and refine the best incumbent.\n    - Use multiple local-search phases with adaptive step sizes.\n    - Warm start from prev_best_x if available and feasible.\n    \"\"\"\n\n    rng = np.random.RandomState()\n\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Handle degenerate bounds\n    span = np.where(span <= 0, 1.0, span)\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n\n    # Initialize incumbent\n    x_best = None\n    y_best = None\n\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(dim)\n        x0 = clip_to_bounds(x0)\n        y0 = objective_function(x0)\n        evals_used += 1\n        x_best, y_best = x0, y0\n\n    if evals_used >= budget:\n        return x_best\n\n    if x_best is None:\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        x_best, y_best = x0, y0\n\n        if evals_used >= budget:\n            return x_best\n\n    # Budget split: global ~45%, local ~55%\n    remaining = budget - evals_used\n    global_budget = int(0.45 * budget) - evals_used\n    if global_budget < 0:\n        global_budget = 0\n    if global_budget > remaining:\n        global_budget = remaining\n\n    # Global exploration: Sobol-like jittered sampling via scrambled uniform\n    # (simple stratification instead of pure random)\n    if global_budget > 0:\n        # Number of strata per dimension (keep small to avoid curse of dimensionality)\n        grid_per_dim = max(2, min(6, int(np.floor(global_budget ** (1.0 / max(1, dim))))))\n        total_cells = grid_per_dim ** dim\n\n        # We will sample at most one point per cell index until we exhaust global_budget\n        # Generate a random ordering of cell indices using base grid_per_dim representation\n        # for first min(global_budget, total_cells) points.\n        num_points = min(global_budget, total_cells)\n        # Draw random integer codes and decode to per-dim coords\n        # This avoids building the full grid in high dimensions.\n        used_codes = set()\n        points_generated = 0\n        while points_generated < num_points and evals_used < budget:\n            code = rng.randint(0, total_cells)\n            if code in used_codes:\n                continue\n            used_codes.add(code)\n            coords = []\n            tmp = code\n            for _ in range(dim):\n                coords.append(tmp % grid_per_dim)\n                tmp //= grid_per_dim\n            coords = np.array(coords, dtype=float)\n            # jitter inside each cell\n            jitter = rng.uniform(size=dim)\n            frac = (coords + jitter) / grid_per_dim\n            x = low + frac * span\n            y = objective_function(x)\n            evals_used += 1\n            points_generated += 1\n            if y < y_best:\n                x_best, y_best = x, y\n            if evals_used >= budget:\n                return x_best\n\n        # If budget remains for global, fill with uniform random\n        remaining_global = global_budget - points_generated\n        for _ in range(max(0, remaining_global)):\n            if evals_used >= budget:\n                break\n            x = rng.uniform(low, high)\n            y = objective_function(x)\n            evals_used += 1\n            if y < y_best:\n                x_best, y_best = x, y\n\n    if evals_used >= budget:\n        return x_best\n\n    # Local search: multi-phase adaptive random search\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # Step sizes: start moderate, shrink across phases\n    base_step = span / 3.0\n    min_step = span / 1e5 + 1e-12\n\n    # Number of local phases capped by dimension and budget\n    phases = min(4, max(1, remaining // max(4, dim)))\n\n    # Distribute remaining budget across phases\n    per_phase = [remaining // phases] * phases\n    for i in range(remaining % phases):\n        per_phase[i] += 1\n\n    for phase in range(phases):\n        if evals_used >= budget:\n            break\n\n        phase_budget = per_phase[phase]\n        if phase_budget <= 0:\n            continue\n\n        # Phase-specific step size: geometric decay with phase index\n        step = base_step * (0.5 ** phase)\n        step = np.maximum(step, min_step)\n\n        # Directional search probability\n        # Occasionally sample coordinate-aligned directions for robustness.\n        for _ in range(phase_budget):\n            if evals_used >= budget:\n                break\n\n            if rng.rand() < 0.4:\n                # Coordinate direction\n                d = np.zeros(dim)\n                idx = rng.randint(dim)\n                d[idx] = 1.0 if rng.rand() < 0.5 else -1.0\n                noise = d\n            else:\n                # Isotropic Gaussian\n                noise = rng.normal(size=dim)\n                norm = np.linalg.norm(noise)\n                if norm > 1e-12:\n                    noise /= norm\n\n            magnitude = rng.lognormal(mean=0.0, sigma=0.6)\n            x_candidate = x_best + noise * step * magnitude\n            x_candidate = clip_to_bounds(x_candidate)\n\n            y_candidate = objective_function(x_candidate)\n            evals_used += 1\n\n            if y_candidate < y_best:\n                x_best, y_best = x_candidate, y_candidate\n                step = np.minimum(step * 1.3, span)\n            else:\n                step = np.maximum(step * 0.65, min_step)\n\n    return x_best",
    "X": "0.04660309731966702 7.9496832506492 -6.968151465638024 1.9834914312382528 1.9999492713602842 4.049685764287979 0.9787578518082626 -2.9366708032400077 1.007392865810687 -1.9905252535217686 -0.013267450516073094"
}