{
    "score": -4.999999999999586,
    "Input": "McCourt14",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Derivative-free optimizer combining:\n    - Space-filling global search (LHS-style)\n    - Warm start from prev_best_x if provided\n    - Two-phase search: global exploration + local refinement\n    - Adaptive step size and covariance for local search\n\n    Always respects the evaluation budget and returns the best point seen.\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n\n    def project(x):\n        return np.clip(x, lower, upper)\n\n    # Handle degenerate budget\n    if budget <= 0:\n        return project(lower + rng.rand(dim) * np.where(span > 0, span, 1.0))\n\n    evals_used = 0\n\n    # --- Initialization with warm start and random backup ---\n    if prev_best_x is not None:\n        try:\n            x_best = np.asarray(prev_best_x, dtype=float).reshape(dim)\n            x_best = project(x_best)\n        except Exception:\n            x_best = lower + rng.rand(dim) * np.where(span > 0, span, 1.0)\n    else:\n        x_best = lower + rng.rand(dim) * np.where(span > 0, span, 1.0)\n\n    y_best = objective_function(x_best)\n    evals_used += 1\n    if evals_used >= budget:\n        return x_best\n\n    # --- Global exploration (LHS-like) ---\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # Use ~50% of remaining for global search for stronger exploration\n    global_budget = max(1, int(0.5 * remaining))\n    global_budget = min(global_budget, budget - evals_used)\n\n    if global_budget > 0:\n        # LHS-style sampling\n        u_base = (np.arange(global_budget) + rng.rand(global_budget)) / global_budget\n        global_points = np.empty((global_budget, dim), dtype=float)\n        for d in range(dim):\n            rng.shuffle(u_base)\n            global_points[:, d] = lower[d] + u_base * span[d]\n\n        for i in range(global_budget):\n            if evals_used >= budget:\n                break\n            x = global_points[i]\n            y = objective_function(x)\n            evals_used += 1\n            if y < y_best:\n                x_best, y_best = x, y\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return x_best\n\n    # --- Local search: adaptive Gaussian with covariance-like adaptation ---\n    # Scale with box; fall back to 1.0 if zero-span\n    eff_span = np.where(span > 0, span, 1.0)\n\n    # Initial step: moderate fraction of box; smaller in high dim\n    base_scale = 0.2 / np.sqrt(max(1, dim))\n    sigma = (base_scale * eff_span).astype(float)\n\n    # Minimal step size\n    min_sigma = 1e-6 * eff_span\n    max_sigma = eff_span\n\n    # Offspring per iteration depending on dim and remaining budget\n    # Larger for higher dim, but keep modest for budget efficiency\n    offspring_per_iter = int(np.clip(4 + dim // 3, 4, max(4, remaining // 2)))\n    offspring_per_iter = max(3, min(20, offspring_per_iter))\n    if offspring_per_iter <= 0:\n        return x_best\n\n    max_iters = max(1, remaining // offspring_per_iter)\n\n    # Track a simple diagonal covariance via per-dimension success history\n    success_history = np.zeros(dim, dtype=float) + 1e-8\n    attempt_history = np.zeros(dim, dtype=float) + 1e-8\n\n    for _ in range(max_iters):\n        if evals_used >= budget:\n            break\n\n        improved_any = False\n\n        for _ in range(offspring_per_iter):\n            if evals_used >= budget:\n                break\n\n            # Draw anisotropic Gaussian noise scaled by sigma\n            z = rng.randn(dim)\n            step = z * sigma\n            x_new = project(x_best + step)\n            y_new = objective_function(x_new)\n            evals_used += 1\n\n            # Update best\n            if y_new < y_best:\n                # Dimension-wise success statistics\n                improved_any = True\n                mask = np.abs(step) > 0\n                success_history[mask] += 1.0\n                attempt_history[mask] += 1.0\n\n                x_best, y_best = x_new, y_new\n            else:\n                mask = np.abs(step) > 0\n                attempt_history[mask] += 1.0\n\n        # Adapt step sizes based on success rate per dimension\n        # Target success rate ~ 0.2\n        if np.any(attempt_history > 0):\n            success_rate = success_history / attempt_history\n            # Increase where success > target, decrease where lower\n            factor = np.where(success_rate > 0.25, 1.2,\n                              np.where(success_rate < 0.15, 0.8, 1.0))\n            sigma *= factor\n            sigma = np.clip(sigma, min_sigma, max_sigma)\n            # Lightly forget the past to stay adaptive\n            success_history *= 0.7\n            attempt_history *= 0.7\n\n        # Global shrink if no improvements recently\n        if not improved_any:\n            sigma *= 0.5\n            sigma = np.clip(sigma, min_sigma, max_sigma)\n\n    return x_best",
    "X": "0.10000008524135284 0.7999999985058753 0.29999990364838564"
}