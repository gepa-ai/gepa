{
    "score": 2.32305286118617e-10,
    "Input": "Easom",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config['bounds'], dtype=float)\n    dim = int(config['dim'])\n    budget = int(config['budget'])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    def clip_to_bounds(x):\n        return np.minimum(np.maximum(x, low), high)\n\n    rng = np.random.RandomState()\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # ---- Warm start from previous run if available ----\n    if prev_best_x is not None and budget > 0:\n        x0 = clip_to_bounds(np.asarray(prev_best_x, dtype=float))\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        if best_x is None:\n            # degenerate case: zero budget and no warm start\n            return clip_to_bounds(np.zeros(dim))\n        return np.asarray(best_x, dtype=float)\n\n    # ---- Initial sampling: mix of random and local perturbations ----\n    # Allocate up to 20% of budget (min 5, max 40) to global initialization\n    n_initial = min(max(5, int(0.2 * budget)), 40)\n    n_initial = min(n_initial, remaining)\n\n    # If we have a warm start, also sample perturbations around it\n    n_local_around_best = 0\n    if best_x is not None and n_initial >= 4:\n        n_local_around_best = min(n_initial // 3, 10)\n    n_random = n_initial - n_local_around_best\n\n    # Pure random samples\n    for _ in range(n_random):\n        if remaining <= 0:\n            break\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        remaining -= 1\n        if y0 < best_y:\n            best_x, best_y = x0, y0\n\n    # Local Gaussian perturbations around current best (if any)\n    if best_x is not None:\n        base = best_x.copy()\n        # Start with moderate spread (10% of range)\n        sigma = 0.1 * span\n        sigma[sigma == 0.0] = 1.0  # avoid zeros in degenerate bounds\n        for _ in range(n_local_around_best):\n            if remaining <= 0:\n                break\n            x0 = base + rng.randn(dim) * sigma\n            x0 = clip_to_bounds(x0)\n            y0 = objective_function(x0)\n            evals_used += 1\n            remaining -= 1\n            if y0 < best_y:\n                best_x, best_y = x0, y0\n\n    # Fallback if still no evaluated point (e.g., very tiny budget)\n    if best_x is None:\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        remaining -= 1\n        best_x, best_y = x0, y0\n\n    if remaining <= 0:\n        return np.asarray(best_x, dtype=float)\n\n    # ---- Hybrid search: coordinate local search + occasional global jumps ----\n    x = best_x.copy()\n\n    # Start with 25% of range per dimension, will shrink adaptively\n    step = np.maximum(span * 0.25, 1e-12 * np.maximum(1.0, np.abs(span)))\n\n    # Track stagnation to trigger global moves\n    no_improve_sweeps = 0\n\n    # Fraction of remaining budget we allow for global random jumps\n    global_jump_prob = 0.15\n\n    while remaining > 0 and np.any(step > 1e-12 * np.maximum(1.0, np.abs(span))):\n        improved = False\n\n        # Coordinate-wise exploration with random order\n        coord_order = np.arange(dim)\n        rng.shuffle(coord_order)\n\n        for i in coord_order:\n            if remaining <= 0:\n                break\n\n            # Try positive step\n            xp = x.copy()\n            xp[i] = np.clip(xp[i] + step[i], low[i], high[i])\n            if xp[i] != x[i]:  # avoid wasting eval when clipped to same point\n                yp = objective_function(xp)\n                remaining -= 1\n                if yp < best_y:\n                    best_x, best_y = xp, yp\n                    x = xp\n                    improved = True\n                    if remaining <= 0:\n                        break\n                    # Optionally try another positive move in same direction\n                    continue\n\n            if remaining <= 0:\n                break\n\n            # Try negative step\n            xn = x.copy()\n            xn[i] = np.clip(xn[i] - step[i], low[i], high[i])\n            if xn[i] != x[i]:\n                yn = objective_function(xn)\n                remaining -= 1\n                if yn < best_y:\n                    best_x, best_y = xn, yn\n                    x = xn\n                    improved = True\n                    if remaining <= 0:\n                        break\n\n            if remaining <= 0:\n                break\n\n        if improved:\n            no_improve_sweeps = 0\n            # Slightly increase step size to speed convergence along good directions\n            step *= 1.05\n            step = np.minimum(step, span)\n        else:\n            no_improve_sweeps += 1\n            # Reduce step size more aggressively after several non-improving sweeps\n            factor = 0.5 if no_improve_sweeps < 3 else 0.3\n            step *= factor\n\n            # Occasional global random restart / large perturbation to escape local minima\n            if remaining > dim and rng.rand() < global_jump_prob:\n                # With 50% chance, pure random; otherwise, large perturbation of best\n                if rng.rand() < 0.5:\n                    xr = rng.uniform(low, high)\n                else:\n                    # Large perturbation: 30% of span\n                    sigma_global = 0.3 * span\n                    sigma_global[sigma_global == 0.0] = 1.0\n                    xr = best_x + rng.randn(dim) * sigma_global\n                    xr = clip_to_bounds(xr)\n\n                yr = objective_function(xr)\n                remaining -= 1\n                if yr < best_y:\n                    best_x, best_y = xr, yr\n                    x = xr\n                    # Reset step size around new point to moderate value\n                    step = np.maximum(span * 0.2,\n                                      1e-12 * np.maximum(1.0, np.abs(span)))\n                    no_improve_sweeps = 0\n\n    return np.asarray(best_x, dtype=float)",
    "X": "-4.8835134234315405e-11 4.166432336124201e-11 -1.7744338993850622e-11 -7.76768075752682e-11 -7.996887068050677e-11"
}