{
    "score": 1.6394752222481657e-10,
    "Input": "Easom",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n    span_safe = np.where(span == 0.0, 1.0, span)\n\n    def clip_to_bounds(x):\n        return np.minimum(np.maximum(x, low), high)\n\n    rng = np.random.RandomState()\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # --- Warm start ---\n    if prev_best_x is not None and budget > 0:\n        x0 = clip_to_bounds(np.asarray(prev_best_x, dtype=float))\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        if best_x is None:\n            return clip_to_bounds(np.zeros(dim))\n        return np.asarray(best_x, dtype=float)\n\n    # --- Initial design: mix of global LHS and local perturbations ---\n    # Use up to 30% of total budget (min 5, max 60) for initialization\n    n_initial = min(max(5, int(0.3 * budget)), 60)\n    n_initial = min(n_initial, remaining)\n\n    n_local_around_best = 0\n    if best_x is not None and n_initial >= 4:\n        n_local_around_best = min(n_initial // 3, 15)\n    n_global = n_initial - n_local_around_best\n\n    # Global: Latin Hypercube-like sampling for better coverage (cheap approximation)\n    if n_global > 0:\n        # For each dim: divide [0,1] into n_global strata and permute\n        u = (np.arange(n_global) + rng.rand(n_global)) / float(n_global)\n        X_global = np.empty((n_global, dim))\n        for j in range(dim):\n            rng.shuffle(u)\n            X_global[:, j] = low[j] + u * span[j]\n        for k in range(n_global):\n            if remaining <= 0:\n                break\n            x0 = X_global[k]\n            y0 = objective_function(x0)\n            evals_used += 1\n            remaining -= 1\n            if y0 < best_y:\n                best_x, best_y = x0.copy(), y0\n\n    # Local perturbations around best_x\n    if best_x is not None and n_local_around_best > 0 and remaining > 0:\n        base = best_x.copy()\n        sigma = 0.15 * span_safe\n        for _ in range(n_local_around_best):\n            if remaining <= 0:\n                break\n            x0 = base + rng.randn(dim) * sigma\n            x0 = clip_to_bounds(x0)\n            y0 = objective_function(x0)\n            evals_used += 1\n            remaining -= 1\n            if y0 < best_y:\n                best_x, best_y = x0.copy(), y0\n                base = best_x.copy()\n\n    if best_x is None:\n        # fallback if nothing evaluated for some reason\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        remaining -= 1\n        best_x, best_y = x0, y0\n\n    if remaining <= 0:\n        return np.asarray(best_x, dtype=float)\n\n    # --- Pattern search with restarts (robust local search) ---\n    x = best_x.copy()\n\n    # Initial step: moderate fraction of range\n    step = 0.25 * span_safe\n\n    # Adaptive thresholds\n    min_step = 1e-12 * np.maximum(1.0, np.abs(span_safe))\n    no_improve_sweeps = 0\n    global_jump_prob = 0.2\n\n    while remaining > 0 and np.any(step > min_step):\n        improved = False\n\n        # Shuffle coordinates\n        coord_order = np.arange(dim)\n        rng.shuffle(coord_order)\n\n        for i in coord_order:\n            if remaining <= 0:\n                break\n\n            # Try positive and negative moves, pick best\n            candidates = []\n\n            xp = x.copy()\n            xp[i] = np.clip(xp[i] + step[i], low[i], high[i])\n            if xp[i] != x[i]:\n                candidates.append(xp)\n\n            xn = x.copy()\n            xn[i] = np.clip(xn[i] - step[i], low[i], high[i])\n            if xn[i] != x[i]:\n                candidates.append(xn)\n\n            for xc in candidates:\n                if remaining <= 0:\n                    break\n                yc = objective_function(xc)\n                remaining -= 1\n                if yc < best_y:\n                    best_x, best_y = xc.copy(), yc\n                    x = xc.copy()\n                    improved = True\n\n            if remaining <= 0:\n                break\n\n        if improved:\n            no_improve_sweeps = 0\n            # Slightly enlarge step for faster progress but cap by span\n            step = np.minimum(step * 1.1, span_safe)\n        else:\n            no_improve_sweeps += 1\n            # Shrink step; more aggressively after multiple non-improving sweeps\n            factor = 0.6 if no_improve_sweeps < 3 else 0.35\n            step = np.maximum(step * factor, min_step)\n\n            # Occasional global restart / large perturbation\n            if remaining > dim and rng.rand() < global_jump_prob:\n                # 50% pure random, 50% large perturbation\n                if rng.rand() < 0.5:\n                    xr = rng.uniform(low, high)\n                else:\n                    sigma_global = 0.4 * span_safe\n                    xr = clip_to_bounds(best_x + rng.randn(dim) * sigma_global)\n                yr = objective_function(xr)\n                remaining -= 1\n                if yr < best_y:\n                    best_x, best_y = xr.copy(), yr\n                    x = xr.copy()\n                    # Reset step around new incumbent\n                    step = 0.2 * span_safe\n                    no_improve_sweeps = 0\n\n    return np.asarray(best_x, dtype=float)",
    "X": "-4.8835134234315405e-11 4.166432336124201e-11 -1.7744338993850622e-11 4.564980983909388e-11 4.33577467338553e-11"
}