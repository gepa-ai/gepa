{
    "score": -6.072248679805178,
    "Input": "Michalewicz",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    bounds = np.array(config['bounds'], dtype=float)\n    dim = int(config.get('dim', bounds.shape[0]))\n    budget = int(config.get('budget', 1))\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n    span_safe = span.copy()\n    span_safe[span_safe == 0.0] = 1.0\n\n    def clamp(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n\n    def eval_point(x):\n        nonlocal evals_used\n        if evals_used >= budget:\n            return np.inf\n        fx = objective_function(x)\n        evals_used += 1\n        return fx\n\n    best_x = None\n    best_y = np.inf\n\n    # Use prev_best_x if available and valid\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float)\n        if x0.shape == (dim,):\n            x0 = clamp(x0)\n            y0 = eval_point(x0)\n            if y0 < best_y:\n                best_x, best_y = x0, y0\n\n    # If nothing evaluated yet, sample a first random point\n    if best_x is None and evals_used < budget:\n        x0 = np.random.uniform(low, high)\n        y0 = eval_point(x0)\n        best_x, best_y = x0, y0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Very small remaining budget: perform purely local search around best_x\n    if remaining <= 5:\n        base_step = 0.25 * span_safe\n        for _ in range(remaining):\n            if evals_used >= budget:\n                break\n            step = base_step * np.exp(np.random.uniform(-1.5, 0.0, size=dim))\n            perturb = np.random.standard_cauchy(size=dim) * step\n            candidate = clamp(best_x + perturb)\n            y = eval_point(candidate)\n            if y < best_y:\n                best_x, best_y = candidate, y\n        return best_x\n\n    # Global seeding: mix of uniform and local samples\n    remaining = budget - evals_used\n    n_seed = max(3, min(20, remaining // 6))\n    for i in range(n_seed):\n        if evals_used >= budget:\n            break\n        if i == 0 and best_x is not None:\n            step = 0.2 * span_safe\n            perturb = np.random.uniform(-1.0, 1.0, size=dim) * step\n            x = clamp(best_x + perturb)\n        else:\n            x = np.random.uniform(low, high)\n        y = eval_point(x)\n        if y < best_y:\n            best_x, best_y = x, y\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Adaptive diagonal CMA-ES-like strategy with restarts and increasing population\n    base_lam = max(6, int(4 + 3 * np.log(dim + 1)))\n    mean = best_x.copy()\n    sigma = 0.25 * np.mean(span_safe)\n    if not np.isfinite(sigma) or sigma <= 0:\n        sigma = 0.25\n\n    C_diag = (0.5 * span_safe) ** 2\n    C_diag = np.maximum(C_diag, 1e-20)\n\n    pc = np.zeros(dim)\n    ps = np.zeros(dim)\n\n    def cma_es_loop(mean_init, sigma_init, C_diag_init, lam, budget_left):\n        nonlocal evals_used, best_x, best_y\n\n        mean = mean_init.copy()\n        sigma = float(sigma_init)\n        C_diag = C_diag_init.copy()\n\n        mu = max(2, lam // 2)\n        weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n        weights /= np.sum(weights)\n        mueff = 1.0 / np.sum(weights ** 2)\n\n        cc = (4 + mueff / dim) / (dim + 4 + 2 * mueff / dim)\n        cs = (mueff + 2) / (dim + mueff + 5)\n        c1 = 2 / ((dim + 1.3) ** 2 + mueff)\n        cmu = min(1 - c1, 2 * (mueff - 2 + 1 / mueff) / ((dim + 2) ** 2 + mueff))\n        damps = 1 + 2 * max(0.0, np.sqrt((mueff - 1) / (dim + 1)) - 1) + cs\n\n        max_generations = max(1, budget_left // lam)\n        no_improve_count = 0\n        last_best = best_y\n\n        for _ in range(max_generations):\n            if evals_used >= budget:\n                break\n\n            std = np.sqrt(np.maximum(C_diag, 1e-30))\n            z = np.random.randn(lam, dim) * std\n            pop = clamp(mean + sigma * z)\n\n            fitness = np.empty(lam)\n            for i in range(lam):\n                if evals_used >= budget:\n                    fitness[i] = np.inf\n                else:\n                    fitness[i] = eval_point(pop[i])\n\n            idx_best = np.argmin(fitness)\n            if fitness[idx_best] < best_y:\n                best_x, best_y = pop[idx_best].copy(), fitness[idx_best]\n\n            if best_y < last_best - 1e-12:\n                last_best = best_y\n                no_improve_count = 0\n            else:\n                no_improve_count += 1\n\n            valid_mask = np.isfinite(fitness)\n            if not np.any(valid_mask):\n                break\n\n            idx = np.argsort(fitness[valid_mask])\n            valid_pop = pop[valid_mask][idx]\n            max_parents = min(mu, valid_pop.shape[0])\n            parents = valid_pop[:max_parents]\n            w = weights[:max_parents]\n            w /= np.sum(w)\n\n            old_mean = mean.copy()\n            mean = np.sum(parents * w[:, None], axis=0)\n\n            y_vec = (mean - old_mean) / max(1e-12, sigma)\n            ps_new = (1 - cs) * ps + np.sqrt(cs * (2 - cs) * mueff) * y_vec\n            ps[:] = ps_new\n\n            norm_ps = np.linalg.norm(ps)\n            expected_norm = np.sqrt(dim) * (1 - 1 / (4 * dim) + 1 / (21 * dim ** 2))\n            hsig = int(\n                norm_ps /\n                np.sqrt(1 - (1 - cs) ** (2 * (evals_used / max(1, lam) + 1))) /\n                (1.4 + 2 / (dim + 1))\n                < 2 + 4 / (dim + 1)\n            )\n\n            pc[:] = (1 - cc) * pc + hsig * np.sqrt(cc * (2 - cc) * mueff) * (mean - old_mean)\n\n            diff = parents - old_mean\n            C_mu = np.sum(w[:, None] * (diff ** 2), axis=0)\n            C_diag = (\n                (1 - c1 - cmu) * C_diag\n                + c1 * (pc ** 2)\n                + cmu * C_mu\n            )\n            C_diag = np.maximum(C_diag, 1e-30)\n\n            sigma *= np.exp((cs / damps) * (norm_ps / expected_norm - 1))\n\n            avg_span = float(np.mean(span_safe))\n            if not np.isfinite(avg_span) or avg_span <= 0:\n                avg_span = 1.0\n            sigma = float(np.clip(sigma, 1e-6 * avg_span, 0.5 * avg_span))\n\n            if no_improve_count >= 5:\n                break\n\n            if evals_used >= budget:\n                break\n\n        return mean, sigma, C_diag\n\n    # Restart strategy with increasing population size\n    remaining = budget - evals_used\n    lam = base_lam\n    restart_factor = 2\n\n    while remaining > 0 and evals_used < budget:\n        per_restart_budget = max(lam * 3, remaining // 2)\n        per_restart_budget = min(per_restart_budget, remaining)\n        if per_restart_budget < lam:\n            break\n\n        mean, sigma, C_diag = cma_es_loop(mean, sigma, C_diag, lam, per_restart_budget)\n\n        remaining = budget - evals_used\n        lam = int(lam * restart_factor)\n        sigma = max(sigma * 0.5, 1e-8 * np.mean(span_safe))\n        mean = best_x.copy() if best_x is not None else clamp(np.random.uniform(low, high))\n        C_diag = np.maximum(C_diag, 1e-20)\n\n    return best_x",
    "X": "2.2347167701447694 1.5952286397979716 1.261072374360002 1.246537308402931 1.7231851164083518 0.9039512215391542 2.515825952407067 2.0811156874291"
}