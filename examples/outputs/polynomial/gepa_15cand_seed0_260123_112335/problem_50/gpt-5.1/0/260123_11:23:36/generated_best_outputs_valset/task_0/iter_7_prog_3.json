{
    "score": -3456.0000000000005,
    "Input": "Schwefel36",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Budget-aware black-box minimization with:\n      - optional warm start from prev_best_x\n      - global search (scrambled Halton sequence + uniform fallback for very high dim)\n      - followed by coordinate-wise local search with adaptive step sizes\n\n    Strategy:\n    1. Use prev_best_x if available (counts as one eval).\n    2. Use a fraction of remaining budget for global exploration\n       (Halton in low/moderate dim, uniform otherwise).\n    3. Use remaining budget for local search around current best with\n       coordinate-wise perturbations and step-size adaptation.\n    \"\"\"\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    # Degenerate or infeasible cases\n    if dim <= 0 or budget <= 0 or bounds.size == 0:\n        # Return a simple feasible point: midpoint of bounds or zeros\n        if bounds.size == 0:\n            return np.zeros(dim, dtype=float)\n        return np.mean(bounds, axis=1)\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    # Ensure bounds are valid; if not, swap\n    invalid = low > high\n    if np.any(invalid):\n        tmp_low = low.copy()\n        low[invalid] = high[invalid]\n        high[invalid] = tmp_low[invalid]\n        span = high - low\n\n    evals_used = 0\n    best_x = None\n    best_y = np.inf\n\n    # ---------- helper: evaluation with budget tracking ----------\n    def eval_point(x):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None\n        x = np.asarray(x, dtype=float).reshape(-1)\n        if x.size != dim:\n            # Attempt to repair; if impossible, skip\n            if x.size == 0:\n                return None\n            if x.size > dim:\n                x = x[:dim]\n            else:\n                # pad with midpoints\n                mid = (low + high) * 0.5\n                padded = np.full(dim, mid, dtype=float)\n                padded[:x.size] = x\n                x = padded\n        x = np.clip(x, low, high)\n        try:\n            y = float(objective_function(x))\n        except Exception:\n            # If objective crashes, skip this point and do not count it\n            return None\n        evals_used += 1\n        if y < best_y:\n            best_y = y\n            best_x = x.copy()\n        return y\n\n    # ---------- helper: simple scrambled Halton sequence ----------\n    def halton_sequence(size, d, seed=None):\n        \"\"\"\n        Generate 'size' points of a Halton sequence in [0,1]^d.\n        For very large d, fall back to uniform since prime list is limited.\n        \"\"\"\n        # First primes, enough for moderate dimension\n        primes = [\n            2, 3, 5, 7, 11, 13, 17, 19, 23, 29,\n            31, 37, 41, 43, 47, 53, 59, 61, 67, 71,\n            73, 79, 83, 89, 97, 101, 103, 107, 109, 113\n        ]\n        if d <= 0 or size <= 0:\n            return np.empty((0, d), dtype=float)\n\n        if d > len(primes):\n            # Fallback: uniform sampling; Halton would repeat bases otherwise\n            rng = np.random.RandomState(seed)\n            return rng.rand(size, d)\n\n        base_list = primes[:d]\n        rng = np.random.RandomState(seed)\n\n        # Prepare per-base scramble permutations\n        scramble_map = {}\n        for b in base_list:\n            perm = np.arange(b)\n            rng.shuffle(perm)\n            scramble_map[b] = perm\n\n        def van_der_corput(n, base):\n            vdc, denom = 0.0, 1.0\n            while n:\n                n, remainder = divmod(n, base)\n                digit = scramble_map[base][remainder]\n                denom *= base\n                vdc += digit / denom\n            return vdc\n\n        seq = np.empty((size, d), dtype=float)\n        for di, base in enumerate(base_list):\n            for i in range(size):\n                seq[i, di] = van_der_corput(i + 1, base)\n        return seq\n\n    # ---------- 1) Warm-start from prev_best_x ----------\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = np.clip(x0, low, high)\n            eval_point(x0)\n\n    if evals_used >= budget:\n        if best_x is None:\n            best_x = np.clip((low + high) * 0.5, low, high)\n        return best_x\n\n    # ---------- 2) Global exploration ----------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        if best_x is None:\n            best_x = np.clip((low + high) * 0.5, low, high)\n        return best_x\n\n    # Allocate about 50% of remaining evaluations to global search\n    global_budget = max(1, int(0.5 * remaining))\n\n    # Low/moderate dimension: use Halton; high dimension: use uniform\n    if dim <= 30:\n        u_points = halton_sequence(global_budget, dim, seed=12345)\n    else:\n        rng = np.random.RandomState(12345)\n        u_points = rng.rand(global_budget, dim)\n\n    for i in range(global_budget):\n        if evals_used >= budget:\n            break\n        u = u_points[i]\n        x = low + u * span\n        x = np.where(span > 0, x, low)\n        eval_point(x)\n\n    # ---------- 3) Coordinate-wise local search ----------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        if best_x is None:\n            best_x = np.clip((low + high) * 0.5, low, high)\n        return best_x\n\n    if best_x is None:\n        # No valid evaluation yet, sample once at midpoint\n        x_init = np.clip((low + high) * 0.5, low, high)\n        eval_point(x_init)\n        remaining = budget - evals_used\n        if remaining <= 0:\n            return best_x\n\n    # Initial step sizes: fraction of span, with fallback where span==0\n    base_step_scale = 0.2\n    step = np.where(span > 0, base_step_scale * span, 0.1)\n\n    # Coordinate-wise adaptive search: random coordinate per iteration\n    # Use a simple 1+1 ES style adaptation per coordinate\n    rng_local = np.random.RandomState(98765)\n    success_window = max(10, 3 * dim)\n    success_count = 0\n    it_local = 0\n\n    while evals_used < budget:\n        # Select a random coordinate to mutate\n        coord = rng_local.randint(0, dim)\n        direction = rng_local.randn()  # standard normal\n        candidate = best_x.copy()\n        candidate[coord] += direction * step[coord]\n        candidate = np.clip(candidate, low, high)\n\n        old_best_y = best_y\n        eval_point(candidate)\n\n        improved = best_y < old_best_y\n        if improved:\n            success_count += 1\n\n        it_local += 1\n        if it_local % success_window == 0:\n            if success_window > 0:\n                success_rate = success_count / float(success_window)\n            else:\n                success_rate = 0.0\n            # Target success rate about 0.2-0.3\n            if success_rate > 0.35:\n                step *= 1.5\n            elif success_rate < 0.15:\n                step *= 0.5\n            # Keep step sizes within reasonable bounds\n            step = np.clip(step, 1e-12, np.where(span > 0, span, 1.0))\n            success_count = 0\n\n    if best_x is None:\n        best_x = np.clip((low + high) * 0.5, low, high)\n    return best_x",
    "X": "12.000000045274634 11.999999865972057"
}