{
    "score": 0.15791258505252598,
    "Input": "RosenbrockLog",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Hybrid derivative-free optimizer combining:\n    - Diagonal CMA-ES style global search (robust, exploration-oriented)\n    - Adaptive coordinate / pattern local search (exploitation / refinement)\n    - Optional Nelder\u2013Mead-style simplex refinement for very low dimensions\n\n    This version is tuned to:\n    - Use the full evaluation budget more reliably\n    - Improve performance on ill-scaled / curved problems (e.g., Rosenbrock-like)\n    - Better exploit warm starts while maintaining global exploration\n    \"\"\"\n\n    # --- RNG / configuration ---\n    seed = int(config.get(\"seed\", 0)) if \"seed\" in config else None\n    rng = np.random.RandomState(seed)\n\n    bounds = np.array(config[\"bounds\"], dtype=float)\n    dim_cfg = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    if budget <= 0:\n        return np.mean(bounds, axis=1)\n\n    # --- Dimension / bounds handling ---\n    if bounds.ndim != 2 or bounds.shape[1] != 2:\n        raise ValueError(\"bounds must be of shape (dim, 2)\")\n    dim_bounds = bounds.shape[0]\n    dim = dim_bounds if dim_cfg != dim_bounds else dim_cfg\n\n    lower = bounds[:, 0]\n    upper = bounds[:, 1]\n    span = upper - lower\n    span_safe = span.copy()\n    span_safe[span_safe == 0.0] = 1.0\n\n    def clip_to_bounds(x):\n        return np.clip(x, lower, upper)\n\n    evals_used = 0\n\n    def eval_point(x):\n        nonlocal evals_used\n        if evals_used >= budget:\n            return np.inf\n        x = np.asarray(x, dtype=float).reshape(-1)\n        if x.size != dim:\n            return np.inf\n        fx = objective_function(x)\n        evals_used += 1\n        return fx\n\n    # --- Initialization & warm start handling ---\n    best_x = None\n    best_y = np.inf\n\n    # Warm start: evaluate provided point and a small cloud around it\n    if prev_best_x is not None and budget > 0:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n            if x0.size == dim:\n                x0 = clip_to_bounds(x0)\n                y0 = eval_point(x0)\n                if y0 < best_y:\n                    best_x, best_y = x0, y0\n\n                remaining = budget - evals_used\n                if remaining > 2 * dim:\n                    n_perturb = min(8, remaining // max(1, dim // 2))\n                    local_sigma = 0.05 * span_safe / max(1.0, np.sqrt(dim))\n                    for _ in range(n_perturb):\n                        cand = x0 + rng.randn(dim) * local_sigma\n                        cand = clip_to_bounds(cand)\n                        fy = eval_point(cand)\n                        if fy < best_y:\n                            best_x, best_y = cand, fy\n        except Exception:\n            pass\n\n    if evals_used >= budget:\n        if best_x is None:\n            return (lower + upper) / 2.0\n        return best_x\n\n    # Ensure at least one evaluated point exists\n    if best_x is None:\n        x_mid = (lower + upper) / 2.0\n        y_mid = eval_point(x_mid)\n        best_x, best_y = x_mid, y_mid\n\n        if evals_used < budget:\n            x_rand = rng.uniform(lower, upper)\n            y_rand = eval_point(x_rand)\n            if y_rand < best_y:\n                best_x, best_y = x_rand, y_rand\n\n    if evals_used >= budget:\n        return best_x\n\n    remaining = budget - evals_used\n\n    # --- Budget split: global vs local search ---\n    # Make global search a bit stronger on curved problems\n    if budget < 20 * dim:\n        global_frac = 0.85\n    else:\n        global_frac = 0.7\n    global_evals = max(1, int(remaining * global_frac))\n    local_evals = max(0, remaining - global_evals)\n\n    # ----------------- GLOBAL SEARCH: diagonal CMA-ES variant -----------------\n    lam = int(4 + np.floor(3 * np.log(dim + 1)))\n    lam = max(4, lam)\n    mu = lam // 2\n\n    weights = np.log(mu + 0.5) - np.log(np.arange(1, mu + 1))\n    weights /= np.sum(weights)\n    mueff = (np.sum(weights) ** 2) / np.sum(weights ** 2)\n\n    # Step-size control (slightly more conservative to avoid premature shrink)\n    cs = (mueff + 3) / (dim + mueff + 5)\n    ds = 1.0 + cs + 2 * max(0.0, np.sqrt((mueff - 1) / (dim + 1)) - 1)\n\n    x_mean = best_x.copy()\n    # Slightly smaller initial sigma to better handle narrow valleys but not too small\n    sigma = 0.2 * np.mean(span_safe)\n\n    ps = np.zeros(dim)\n\n    diag_C = (0.5 * span_safe) ** 2\n    min_diag_C = (1e-12 * span_safe) ** 2\n    max_diag_C = (5.0 * span_safe) ** 2\n\n    evals_before_global = evals_used\n    max_generations = max(1, global_evals // lam)\n\n    rand_inject_prob = 0.1\n    # Occasional sigma reset for stagnation handling\n    stagnation_generations = 0\n    last_improvement_eval = evals_used\n\n    for gen in range(max_generations):\n        if evals_used >= budget:\n            break\n        remaining_evals = budget - evals_used\n        if remaining_evals <= 0:\n            break\n\n        cur_lambda = min(lam, remaining_evals)\n        if cur_lambda <= 0:\n            break\n\n        arz = rng.randn(cur_lambda, dim)\n        ary = np.sqrt(diag_C)[None, :] * arz\n        arx = x_mean[None, :] + sigma * ary\n\n        inject_mask = rng.rand(cur_lambda) < rand_inject_prob\n        if np.any(inject_mask):\n            arx[inject_mask] = rng.uniform(lower, upper, size=(inject_mask.sum(), dim))\n\n        arx = clip_to_bounds(arx)\n\n        fitness = np.empty(cur_lambda, dtype=float)\n        improved_in_gen = False\n        for k in range(cur_lambda):\n            fitness[k] = eval_point(arx[k])\n            if fitness[k] < best_y:\n                best_x, best_y = arx[k].copy(), fitness[k]\n                improved_in_gen = True\n                last_improvement_eval = evals_used\n\n        if evals_used >= budget:\n            break\n\n        if improved_in_gen:\n            stagnation_generations = 0\n        else:\n            stagnation_generations += 1\n\n        idx = np.argsort(fitness)\n        x_selected = arx[idx[:mu]]\n        old_mean = x_mean.copy()\n        x_mean = np.sum(weights[:, None] * x_selected, axis=0)\n\n        y_mean = (x_mean - old_mean) / max(1e-12, sigma)\n        ps = (1 - cs) * ps + np.sqrt(cs * (2 - cs) * mueff) * (\n            y_mean / np.maximum(np.sqrt(diag_C), 1e-12)\n        )\n\n        norm_ps = np.linalg.norm(ps)\n        expected_norm = np.sqrt(dim) * (1 - 1.0 / (4 * dim) + 1.0 / (21 * dim ** 2))\n        sigma *= np.exp((cs / ds) * (norm_ps / (expected_norm + 1e-12) - 1.0))\n\n        dy = x_selected - old_mean\n        if dy.shape[0] > 0:\n            cov_update = np.sum(weights[:, None] * (dy ** 2), axis=0)\n            diag_C = 0.9 * diag_C + 0.1 * cov_update\n            diag_C = np.clip(diag_C, min_diag_C, max_diag_C)\n\n        # Guard against too small sigma: instead of breaking, reset for exploration\n        tiny_sigma_threshold = 1e-14 * np.mean(span_safe)\n        if sigma < tiny_sigma_threshold:\n            sigma = 0.1 * np.mean(span_safe)\n            diag_C = (0.5 * span_safe) ** 2\n            ps[:] = 0.0\n\n        # If many generations pass without improvement, increase randomness\n        if stagnation_generations > 8:\n            rand_inject_prob = min(0.4, rand_inject_prob + 0.05)\n            sigma = min(sigma * 1.5, 0.5 * np.mean(span_safe))\n        else:\n            rand_inject_prob = max(0.05, rand_inject_prob * 0.98)\n\n    global_used = evals_used - evals_before_global\n\n    remaining = budget - evals_used\n    if remaining <= 0 or best_x is None:\n        return best_x\n\n    # Ensure a non-trivial local budget, but keep some flexibility\n    if global_used < max(3, global_evals // 4):\n        remaining = budget - evals_used\n        if remaining <= 0:\n            return best_x\n        local_evals = max(local_evals, remaining // 2)\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # ----------------- LOCAL SEARCH: coordinate / pattern search -----------------\n    # Recompute local_evals with remaining, ensuring a few sweeps\n    min_local_evals = min(6 * dim, remaining)\n    local_evals = max(local_evals, min_local_evals)\n\n    x_curr = best_x.copy()\n    y_curr = best_y\n\n    # Step sizes: moderate but allow adaptation to CMA-ES spread\n    base_step = 0.06 * span_safe\n    if np.isfinite(sigma) and sigma > 0:\n        base_step = np.minimum(base_step, 0.4 * sigma * np.ones(dim))\n    step = base_step\n    min_step = np.maximum(span_safe * 1e-5, 1e-8)\n\n    no_improve_sweeps = 0\n    max_no_improve_sweeps = 15\n\n    avg_evals_per_coord = 3\n    approx_evals_per_sweep = max(dim * avg_evals_per_coord, 1)\n    max_sweeps_by_budget = max(1, min(local_evals, budget - evals_used) // approx_evals_per_sweep)\n    max_sweeps = max_sweeps_by_budget\n\n    sweeps_done = 0\n    while (\n        evals_used < budget\n        and np.any(step > min_step)\n        and sweeps_done < max_sweeps\n        and no_improve_sweeps < max_no_improve_sweeps\n    ):\n        sweeps_done += 1\n        improved = False\n\n        coord_order = np.arange(dim)\n        rng.shuffle(coord_order)\n\n        for idx_i in coord_order:\n            if evals_used >= budget:\n                break\n            i = int(idx_i)\n            if step[i] <= min_step[i]:\n                continue\n\n            base_val = x_curr[i]\n\n            # Positive direction\n            cand = x_curr.copy()\n            cand[i] = base_val + step[i]\n            cand = clip_to_bounds(cand)\n            fy = eval_point(cand)\n            if fy < y_curr:\n                x_curr, y_curr = cand, fy\n                if y_curr < best_y:\n                    best_x, best_y = x_curr.copy(), y_curr\n                improved = True\n                continue\n\n            if evals_used >= budget:\n                break\n\n            # Negative direction\n            cand = x_curr.copy()\n            cand[i] = base_val - step[i]\n            cand = clip_to_bounds(cand)\n            fy = eval_point(cand)\n            if fy < y_curr:\n                x_curr, y_curr = cand, fy\n                if y_curr < best_y:\n                    best_x, best_y = x_curr.copy(), y_curr\n                improved = True\n\n        # Occasional small random perturbation around current point\n        remaining = budget - evals_used\n        if not improved and remaining > dim:\n            perturb_scale = 0.01 * span_safe\n            cand = x_curr + rng.randn(dim) * perturb_scale\n            cand = clip_to_bounds(cand)\n            fy = eval_point(cand)\n            if fy < y_curr:\n                x_curr, y_curr = cand, fy\n                if y_curr < best_y:\n                    best_x, best_y = x_curr.copy(), y_curr\n                improved = True\n\n        if not improved:\n            step *= 0.5\n            no_improve_sweeps += 1\n        else:\n            no_improve_sweeps = 0\n            step = np.minimum(step * 1.4, 0.3 * span_safe)\n\n    # ----------------- OPTIONAL SIMPLEX REFINEMENT FOR LOW DIMENSION -----------------\n    remaining = budget - evals_used\n    if remaining > dim + 1 and dim <= 2:\n        simplex = [best_x.copy()]\n        for j in range(dim):\n            v = best_x.copy()\n            v[j] = clip_to_bounds(v[j] + 0.05 * span_safe[j])\n            simplex.append(v)\n        simplex = np.array(simplex[: dim + 1])\n        fvals = np.array([eval_point(p) for p in simplex])\n\n        for _ in range(25):\n            if evals_used >= budget:\n                break\n            idx = np.argsort(fvals)\n            simplex = simplex[idx]\n            fvals = fvals[idx]\n            if fvals[0] < best_y:\n                best_x, best_y = simplex[0].copy(), fvals[0]\n\n            centroid = np.mean(simplex[:-1], axis=0)\n            worst = simplex[-1]\n\n            xr = centroid + (centroid - worst)\n            xr = clip_to_bounds(xr)\n            fr = eval_point(xr)\n            if fr < fvals[0]:\n                xe = centroid + 2 * (xr - centroid)\n                xe = clip_to_bounds(xe)\n                fe = eval_point(xe)\n                if fe < fr:\n                    simplex[-1] = xe\n                    fvals[-1] = fe\n                else:\n                    simplex[-1] = xr\n                    fvals[-1] = fr\n            elif fr < fvals[-2]:\n                simplex[-1] = xr\n                fvals[-1] = fr\n            else:\n                xc = centroid + 0.5 * (worst - centroid)\n                xc = clip_to_bounds(xc)\n                fc = eval_point(xc)\n                if fc < fvals[-1]:\n                    simplex[-1] = xc\n                    fvals[-1] = fc\n                else:\n                    for i in range(1, dim + 1):\n                        simplex[i] = simplex[0] + 0.5 * (simplex[i] - simplex[0])\n                        simplex[i] = clip_to_bounds(simplex[i])\n                        fvals[i] = eval_point(simplex[i])\n            if np.min(fvals) < best_y:\n                best_x = simplex[np.argmin(fvals)].copy()\n                best_y = np.min(fvals)\n\n    return best_x",
    "X": "0.9992518725313362 0.9937645924614781 0.9937249999999999 0.9917642356469363 0.98627 0.9719918819086967 0.9534786797396899 0.9045221215965467 0.8229799999999999 0.6746828827616286 0.45643881296732436"
}