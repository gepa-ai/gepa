{
    "score": 2.8072026325305064,
    "Input": "McCourt06",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Derivative-free optimizer: hybrid global evolutionary search + local refinement\n    with tighter budget handling and more adaptive allocation.\n\n    Strategy:\n      1. Warm start: if prev_best_x is valid, include/evaluate it.\n      2. Global phase (~60% of remaining after warm start):\n         - small/medium-size evolutionary algorithm in normalized [0,1]^d\n         - tournament selection, blend crossover, adaptive mutation\n      3. Local phase (~40% of remaining): coordinate search + random anisotropic\n         perturbations around best point.\n      4. Always try to use the full evaluation budget (never exceed).\n    \"\"\"\n    rng = np.random.default_rng()\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    # Safety reshape\n    if bounds.shape != (dim, 2):\n        bounds = bounds.reshape(dim, 2)\n    low, high = bounds[:, 0], bounds[:, 1]\n    span = high - low\n    # Avoid zero-span issues\n    zero_span_mask = span == 0.0\n    if np.any(zero_span_mask):\n        span[zero_span_mask] = 1.0\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    # Normalize to [0,1]^dim for evolutionary operations\n    def to_unit(x):\n        return (x - low) / span\n\n    def from_unit(u):\n        return clip_to_bounds(low + u * span)\n\n    evals_used = 0\n\n    # --- Initialization with optional warm start ---\n    best_x = None\n    best_y = np.inf\n\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip_to_bounds(x0)\n            y0 = objective_function(x0)\n            evals_used += 1\n            best_x, best_y = x0, y0\n\n    # If no warm start or invalid, seed with random point\n    if best_x is None:\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    if evals_used >= budget:\n        return best_x\n\n    # Recompute remaining budget and split between phases\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # ----------------- Global Evolutionary Phase -----------------\n    # Allocate ~60% of remaining evaluations to EA\n    global_fraction = 0.6\n    global_budget = int(remaining * global_fraction)\n    global_budget = max(0, min(global_budget, remaining))\n\n    # Population size based on dimension and global_budget:\n    # small for tiny budgets/dims, up to 40.\n    if global_budget > 0:\n        min_pop = 4\n        max_pop = 40\n        base_pop = 4 * dim\n        pop_size = int(np.clip(base_pop, min_pop, max_pop))\n        # ensure at least 2 generations if possible\n        if global_budget >= 2 * pop_size:\n            pass\n        else:\n            pop_size = max(4, global_budget // 3)\n        pop_size = max(4, min(pop_size, global_budget))  # always >= 4 and <= global_budget\n    else:\n        pop_size = 0\n\n    if pop_size > 0 and evals_used < budget:\n        # Initialize population in unit cube\n        pop_u = rng.uniform(0.0, 1.0, size=(pop_size, dim))\n        # Inject warm-start point into population\n        pop_u[0] = to_unit(best_x)\n        pop_y = np.empty(pop_size, dtype=float)\n\n        # Evaluate initial population, but do not exceed global_budget or total budget\n        init_evals = min(pop_size, global_budget, budget - evals_used)\n        for i in range(init_evals):\n            if evals_used >= budget:\n                break\n            x = from_unit(pop_u[i])\n            y = objective_function(x)\n            evals_used += 1\n            pop_y[i] = y\n            if y < best_y:\n                best_x, best_y = x, y\n\n        # If less than pop_size was evaluated due to budget, truncate arrays\n        if init_evals < pop_size:\n            pop_u = pop_u[:init_evals]\n            pop_y = pop_y[:init_evals]\n            pop_size = init_evals\n\n        # If we could not evaluate any population individuals, skip EA\n        if pop_size > 0 and evals_used < budget:\n            tournament_k = 3\n            crossover_prob = 0.7\n            mutation_prob = 0.5\n            coord_mut_prob = 0.6\n            base_sigma = 0.2 / np.sqrt(max(1, dim))\n\n            def tournament_select():\n                idxs = rng.integers(0, pop_size, size=tournament_k)\n                best_idx = idxs[0]\n                best_val = pop_y[best_idx]\n                for j in idxs[1:]:\n                    if pop_y[j] < best_val:\n                        best_val = pop_y[j]\n                        best_idx = j\n                return best_idx\n\n            remaining_global = min(global_budget - init_evals, budget - evals_used)\n            if pop_size > 0:\n                max_gens = max(1, remaining_global // pop_size) if remaining_global > 0 else 0\n            else:\n                max_gens = 0\n\n            for _ in range(max_gens):\n                if evals_used >= budget:\n                    break\n                # If remaining_global is almost exhausted, stop\n                if evals_used >= budget or (budget - evals_used) <= 0:\n                    break\n\n                new_pop_u = np.empty_like(pop_u)\n                new_pop_y = np.empty_like(pop_y)\n\n                # Elitism: carry over best individual\n                elite_idx = np.argmin(pop_y)\n                new_pop_u[0] = pop_u[elite_idx]\n                new_pop_y[0] = pop_y[elite_idx]\n                elite_x = from_unit(new_pop_u[0])\n                if new_pop_y[0] < best_y:\n                    best_x, best_y = elite_x, new_pop_y[0]\n                else:\n                    new_pop_y[0] = best_y\n                    new_pop_u[0] = to_unit(best_x)\n\n                # Remaining individuals\n                for i in range(1, pop_size):\n                    if evals_used >= budget:\n                        # carry elite to keep arrays valid\n                        new_pop_u[i] = new_pop_u[0]\n                        new_pop_y[i] = new_pop_y[0]\n                        continue\n\n                    p1 = pop_u[tournament_select()]\n                    if rng.random() < crossover_prob:\n                        p2 = pop_u[tournament_select()]\n                        alpha = rng.uniform(-0.25, 1.25, size=dim)\n                        child = np.clip(alpha * p1 + (1 - alpha) * p2, 0.0, 1.0)\n                    else:\n                        child = p1.copy()\n\n                    if rng.random() < mutation_prob:\n                        if rng.random() < coord_mut_prob:\n                            num_coords = rng.integers(1, max(2, dim // 3 + 1))\n                            idxs = rng.choice(dim, size=num_coords, replace=False)\n                            child[idxs] += rng.normal(scale=base_sigma, size=num_coords)\n                        else:\n                            child += rng.normal(scale=base_sigma, size=dim)\n                        child = np.clip(child, 0.0, 1.0)\n\n                    x_child = from_unit(child)\n                    y_child = objective_function(x_child)\n                    evals_used += 1\n                    new_pop_u[i] = child\n                    new_pop_y[i] = y_child\n                    if y_child < best_y:\n                        best_x, best_y = x_child, y_child\n\n                    if evals_used >= budget:\n                        # Fill rest with best so far\n                        for j in range(i + 1, pop_size):\n                            new_pop_u[j] = new_pop_u[0]\n                            new_pop_y[j] = new_pop_y[0]\n                        break\n\n                pop_u, pop_y = new_pop_u, new_pop_y\n\n    if evals_used >= budget:\n        return best_x\n\n    # ----------------- Local Search Phase -----------------\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Allocate all remaining to an adaptive local / refined global mix\n    local_budget = remaining\n\n    # Initial step sizes: fraction of span\n    base_step = np.maximum(span * 0.05, span * 1e-3)\n    step = base_step.copy()\n    min_step = span * 1e-5\n\n    no_improve_sweeps = 0\n\n    def local_eval_trial(x_center, coord, step_size):\n        nonlocal evals_used, best_x, best_y\n        if evals_used >= budget:\n            return None, None\n        trial = x_center.copy()\n        trial[coord] += step_size\n        trial = clip_to_bounds(trial)\n        y = objective_function(trial)\n        evals_used += 1\n        if y < best_y:\n            best_x, best_y = trial, y\n        return trial, y\n\n    # Coordinate search uses up to ~60% of local_budget\n    remaining_local = budget - evals_used\n    coord_budget = int(0.6 * remaining_local)\n    coord_budget = max(0, min(coord_budget, remaining_local))\n\n    if coord_budget > 0 and evals_used < budget:\n        evals_per_coord = 2  # +/- directions\n        evals_per_sweep = max(1, dim * evals_per_coord)\n        max_sweeps = max(1, coord_budget // evals_per_sweep)\n\n        for _ in range(max_sweeps):\n            if evals_used >= budget:\n                break\n            improved_any = False\n            coords = rng.permutation(dim)\n\n            for d in coords:\n                if evals_used >= budget:\n                    break\n                curr_best_y = best_y\n                curr_best_x = best_x\n                s = step[d]\n\n                dirs = [-1.0, 1.0]\n                rng.shuffle(dirs)\n                for direction in dirs:\n                    if evals_used >= budget:\n                        break\n                    scaled_step = direction * s * rng.uniform(0.5, 1.5)\n                    trial, y = local_eval_trial(curr_best_x, d, scaled_step)\n                    if trial is None:\n                        break\n                    if y < curr_best_y:\n                        curr_best_y = y\n                        curr_best_x = trial\n\n                if curr_best_y < best_y:\n                    best_x, best_y = curr_best_x, curr_best_y\n                    improved_any = True\n\n            if improved_any:\n                no_improve_sweeps = 0\n            else:\n                no_improve_sweeps += 1\n                step *= 0.5\n                if np.all(step <= min_step) or no_improve_sweeps >= 3:\n                    break\n\n            if evals_used >= budget:\n                break\n\n    if evals_used >= budget:\n        return best_x\n\n    # ----------------- Final Diversified / Anisotropic Refinement -----------------\n    while evals_used < budget:\n        remaining = budget - evals_used\n        if remaining <= 0:\n            break\n\n        # Probability of global vs local perturbation depends on remaining budget\n        # and dimension: more global early, more local near the end.\n        frac_remaining = remaining / max(1.0, budget)\n        p_global = 0.2 + 0.5 * frac_remaining  # in [0.2, 0.7]\n\n        if rng.random() < p_global:\n            # Global sampling biased around best_x but still exploring the box\n            if rng.random() < 0.5:\n                x = rng.uniform(low, high)\n            else:\n                # mixture of global and local: wide Gaussian around best\n                scale_factor = 0.3 * max(0.1, frac_remaining)\n                noise = rng.normal(scale=scale_factor, size=dim) * span\n                x = clip_to_bounds(best_x + noise)\n        else:\n            # Local anisotropic perturbation around best_x, decaying with remaining\n            # Emphasize coordinates with larger span\n            scale_factor = 0.08 * max(0.05, frac_remaining)\n            coord_noise = rng.normal(scale=scale_factor, size=dim) * span\n            x = clip_to_bounds(best_x + coord_noise)\n\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_x, best_y = x, y\n\n    return best_x",
    "X": "1.0 1.0 0.7635442770876775 0.5268638936855237 0.9999999999999998"
}