{
    "score": 2.8072033519613413,
    "Input": "McCourt06",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Derivative-free optimizer: adaptive global search + focused local search\n    with optional warm start from prev_best_x.\n\n    Strategy overview:\n      1. Warm start: if prev_best_x is valid, start from it; otherwise random.\n      2. Global phase (~50% budget): low-discrepancy random search with\n         occasional local refinement from improving points.\n      3. Local phase (~50% budget): adaptive coordinate-wise search around\n         best point with step-size control.\n      4. Use full budget and always respect bounds.\n    \"\"\"\n    rng = np.random.default_rng()\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    # Safety checks and normalization of bounds\n    if bounds.shape != (dim, 2):\n        bounds = bounds.reshape(dim, 2)\n    low, high = bounds[:, 0], bounds[:, 1]\n    span = high - low\n    span[span == 0.0] = 1.0  # avoid zero span issues in step size\n\n    def clip_to_bounds(x):\n        return np.clip(x, low, high)\n\n    evals_used = 0\n\n    # --- Initialization with optional warm start ---\n    best_x = None\n    best_y = np.inf\n\n    if prev_best_x is not None:\n        x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n        if x0.size == dim:\n            x0 = clip_to_bounds(x0)\n            y0 = objective_function(x0)\n            evals_used += 1\n            best_x, best_y = x0, y0\n\n    if best_x is None:\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    if evals_used >= budget:\n        return best_x\n\n    # --- Global search phase ---\n    remaining = budget - evals_used\n    global_fraction = 0.5\n    n_global = max(1, int(remaining * global_fraction))\n    n_global = min(n_global, remaining)\n\n    # Global step size: moderate fraction of range to allow broad moves\n    global_step = 0.25 * span\n\n    # Helper: one small local improvement attempt around a given point\n    def small_local_refine(x_start, y_start, eval_budget):\n        nonlocal evals_used, best_x, best_y\n        x_curr, y_curr = x_start, y_start\n        if eval_budget <= 0:\n            return x_curr, y_curr\n\n        # Try a few coordinate perturbations, limited by eval_budget\n        max_trials = min(dim, eval_budget)\n        for _ in range(max_trials):\n            if evals_used >= budget:\n                break\n            d = rng.integers(0, dim)\n            direction = rng.choice([-1.0, 1.0])\n            trial = x_curr.copy()\n            step_mag = global_step[d] * rng.uniform(0.25, 1.0)\n            trial[d] += direction * step_mag\n            trial = clip_to_bounds(trial)\n            y_trial = objective_function(trial)\n            evals_used += 1\n            if y_trial < y_curr:\n                x_curr, y_curr = trial, y_trial\n                if y_trial < best_y:\n                    best_x, best_y = trial, y_trial\n        return x_curr, y_curr\n\n    # Perform global sampling\n    for i in range(n_global):\n        if evals_used >= budget:\n            break\n\n        x = rng.uniform(low, high)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_x, best_y = x, y\n            # Occasionally perform a short local refinement when we find an improvement\n            remaining_now = budget - evals_used\n            if remaining_now > 0 and (i % 3 == 0):\n                small_local_refine(best_x, best_y, min(3, remaining_now))\n\n    if evals_used >= budget:\n        return best_x\n\n    # --- Local search phase (coordinate-wise, adaptive step sizes) ---\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Initial step sizes: moderate fraction of span, with lower bound\n    base_step = np.maximum(span * 0.05, span * 1e-3)\n    step = base_step.copy()\n    min_step = span * 1e-4\n\n    # Number of sweeps heuristics: ensure at least a few passes\n    evals_per_sweep = max(1, dim)\n    max_sweeps = max(2, remaining // evals_per_sweep)\n\n    no_improve_sweeps = 0\n    for _ in range(max_sweeps):\n        if evals_used >= budget:\n            break\n\n        improved_any = False\n\n        # Randomized coordinate order to avoid bias\n        coords = rng.permutation(dim)\n        for d in coords:\n            if evals_used >= budget:\n                break\n\n            # Try both directions; pick the best of the two\n            best_coord_y = best_y\n            best_coord_x = best_x\n\n            for direction in (-1.0, 1.0):\n                if evals_used >= budget:\n                    break\n                trial = best_x.copy()\n                trial[d] += direction * step[d] * rng.uniform(0.5, 1.5)\n                trial = clip_to_bounds(trial)\n                y = objective_function(trial)\n                evals_used += 1\n                if y < best_coord_y:\n                    best_coord_y = y\n                    best_coord_x = trial\n\n            if best_coord_y < best_y:\n                best_x, best_y = best_coord_x, best_coord_y\n                improved_any = True\n\n        if improved_any:\n            no_improve_sweeps = 0\n        else:\n            no_improve_sweeps += 1\n            step *= 0.5\n            # If steps too small or repeated non-improvement, break to random exploration\n            if np.all(step <= min_step) or no_improve_sweeps >= 3:\n                break\n\n    # --- Use any remaining budget for diversified random search around best_x ---\n    while evals_used < budget:\n        # Mix between global uniform and local Gaussian around best_x\n        if rng.random() < 0.5:\n            x = rng.uniform(low, high)\n        else:\n            # Localized random search around best_x\n            noise = rng.normal(scale=0.1, size=dim) * span\n            x = clip_to_bounds(best_x + noise)\n        y = objective_function(x)\n        evals_used += 1\n        if y < best_y:\n            best_x, best_y = x, y\n\n    return best_x",
    "X": "1.0 1.0 0.7620586975112699 0.5257436881322579 1.0"
}