{
    "score": -10.171332855762179,
    "Input": "McCourt09",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n\n    Hybrid strategy:\n    - Robust warm start from prev_best_x (if valid).\n    - Space-filling global exploration (Sobol-like / stratified fallback).\n    - Greedy selection of global samples to form a local candidate set.\n    - Focused local search around multiple promising points with adaptive radii.\n    - Simple coordinatewise local search to replace fragile covariance adaptation.\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    def clip_to_bounds(x):\n        return np.minimum(high, np.maximum(low, x))\n\n    evals_used = 0\n    best_x = None\n    best_y = None\n\n    # Warm start from prev_best_x if valid\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n            if x0.size == dim:\n                x0 = clip_to_bounds(x0)\n                y0 = objective_function(x0)\n                evals_used += 1\n                best_x, best_y = x0, y0\n        except Exception:\n            best_x, best_y = None, None\n\n    # If no incumbent yet, use a random point\n    if best_x is None and evals_used < budget:\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Split budget: more global on tiny budgets, more local on larger ones\n    if budget < 40:\n        global_budget = max(1, int(0.65 * remaining))\n    else:\n        global_budget = max(3, int(0.4 * remaining))\n    if remaining > 1:\n        global_budget = min(global_budget, remaining - 1)\n    else:\n        global_budget = remaining\n    local_budget = remaining - global_budget\n\n    # Global exploration: Sobol-like / stratified low-discrepancy sampling\n    global_points = []\n    if global_budget > 0:\n        n = global_budget\n\n        def van_der_corput(i, base=2):\n            vdc, denom = 0.0, 1.0\n            while i:\n                i, remainder = divmod(i, base)\n                denom *= base\n                vdc += remainder / denom\n            return vdc\n\n        indices = np.arange(1, n + 1)\n        u = np.empty((n, dim), dtype=float)\n\n        for d in range(dim):\n            base = 2 + (d % 5)\n            for k, idx in enumerate(indices):\n                u[k, d] = van_der_corput(idx + d + 1, base=base)\n\n        X_global = low + u * span\n\n        # Jitter and clip to avoid grid-like patterns in high dim\n        if dim > 5:\n            jitter_scale = 0.01\n            X_global = clip_to_bounds(\n                X_global + rng.normal(0.0, jitter_scale, size=X_global.shape) * span\n            )\n\n        for i in range(n):\n            if evals_used >= budget:\n                break\n            xg = X_global[i]\n            yg = objective_function(xg)\n            evals_used += 1\n            global_points.append((yg, xg))\n            if best_y is None or yg < best_y:\n                best_x, best_y = xg, yg\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Select promising points for local search\n    local_starts = [best_x]\n    if global_points:\n        global_points.sort(key=lambda t: t[0])\n        for _, xg in global_points[:5]:\n            if len(local_starts) >= 6:\n                break\n            if not np.allclose(xg, best_x):\n                local_starts.append(xg)\n\n    m = len(local_starts)\n    if m == 0 or local_budget <= 0:\n        return best_x\n\n    # Distribute local_budget across starting points\n    per_start = max(1, local_budget // m)\n    extra = local_budget - per_start * m\n\n    base_radius = 0.2 * np.maximum(span, 1e-8)\n    min_radius = 0.01 * np.maximum(span, 1e-8)\n\n    # Replace fragile covariance adaptation with more robust pattern search / coordinate descent\n    for i, x_center_init in enumerate(local_starts):\n        if evals_used >= budget:\n            break\n\n        steps_here = per_start + (1 if i < extra else 0)\n        if steps_here <= 0:\n            continue\n\n        x_center = x_center_init.copy()\n        y_center = None  # lazy evaluation\n\n        radius = base_radius.copy()\n\n        for k in range(steps_here):\n            if evals_used >= budget:\n                break\n\n            # Ensure current value known\n            if y_center is None:\n                y_center = objective_function(x_center)\n                evals_used += 1\n                if y_center < best_y:\n                    best_x, best_y = x_center, y_center\n\n                if evals_used >= budget:\n                    break\n\n            improved = False\n\n            # Coordinate-wise exploratory moves\n            for d in range(dim):\n                if evals_used >= budget:\n                    break\n\n                step_size = radius[d]\n                if step_size < min_radius[d]:\n                    continue\n\n                # Try positive direction\n                x_try = x_center.copy()\n                x_try[d] = np.clip(x_try[d] + step_size, low[d], high[d])\n                if x_try[d] != x_center[d]:\n                    y_try = objective_function(x_try)\n                    evals_used += 1\n                    if y_try < best_y:\n                        best_x, best_y = x_try, y_try\n                    if y_try < y_center:\n                        x_center, y_center = x_try, y_try\n                        improved = True\n                        continue  # move to next coordinate\n\n                if evals_used >= budget:\n                    break\n\n                # Try negative direction\n                x_try = x_center.copy()\n                x_try[d] = np.clip(x_try[d] - step_size, low[d], high[d])\n                if x_try[d] != x_center[d]:\n                    y_try = objective_function(x_try)\n                    evals_used += 1\n                    if y_try < best_y:\n                        best_x, best_y = x_try, y_try\n                    if y_try < y_center:\n                        x_center, y_center = x_try, y_try\n                        improved = True\n\n            # Adaptive radius: shrink if no coord improved, mildly expand otherwise\n            if improved:\n                radius = np.maximum(radius * 1.05, min_radius)\n            else:\n                radius = np.maximum(radius * 0.5, min_radius)\n\n            # Occasionally inject a random local perturbation to escape shallow basins\n            if evals_used < budget and (k % max(1, dim) == 0):\n                jitter = rng.normal(0.0, 0.3, size=dim) * radius\n                x_try = clip_to_bounds(x_center + jitter)\n                y_try = objective_function(x_try)\n                evals_used += 1\n                if y_try < best_y:\n                    best_x, best_y = x_try, y_try\n                if y_center is None or y_try < y_center:\n                    x_center, y_center = x_try, y_try\n\n    return best_x",
    "X": "0.5945573067639194 1.0 0.2034396209274547"
}