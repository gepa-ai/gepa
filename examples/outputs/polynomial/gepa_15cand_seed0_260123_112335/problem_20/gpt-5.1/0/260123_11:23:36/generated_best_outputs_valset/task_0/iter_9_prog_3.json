{
    "score": -10.171298926755416,
    "Input": "McCourt09",
    "Prints": "",
    "Logs": "",
    "Error": "",
    "code": "import numpy as np\n\ndef solve(objective_function, config, prev_best_x=None):\n    \"\"\"\n    Black-box minimization with budgeted evaluations.\n\n    Hybrid strategy:\n    - Robust warm start from prev_best_x (if valid).\n    - Space-filling global exploration (Sobol-like / stratified fallback).\n    - Greedy selection of global samples to form a local candidate set.\n    - Focused local search around multiple promising points with adaptive radii.\n    - Simple covariance adaptation for local search when budget allows.\n    \"\"\"\n    rng = np.random.RandomState()\n\n    bounds = np.asarray(config[\"bounds\"], dtype=float)\n    dim = int(config[\"dim\"])\n    budget = int(config[\"budget\"])\n\n    low = bounds[:, 0]\n    high = bounds[:, 1]\n    span = high - low\n\n    if budget <= 0:\n        return (low + high) / 2.0\n\n    def clip_to_bounds(x):\n        return np.minimum(high, np.maximum(low, x))\n\n    evals_used = 0\n    best_x = None\n    best_y = None\n\n    # Warm start from prev_best_x if valid\n    if prev_best_x is not None:\n        try:\n            x0 = np.asarray(prev_best_x, dtype=float).reshape(-1)\n            if x0.size == dim:\n                x0 = clip_to_bounds(x0)\n                y0 = objective_function(x0)\n                evals_used += 1\n                best_x, best_y = x0, y0\n        except Exception:\n            best_x, best_y = None, None\n\n    # If no incumbent yet, use a random point\n    if best_x is None and evals_used < budget:\n        x0 = rng.uniform(low, high)\n        y0 = objective_function(x0)\n        evals_used += 1\n        best_x, best_y = x0, y0\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Split budget: more global on tiny budgets, more local on larger ones\n    if budget < 40:\n        global_budget = max(1, int(0.65 * remaining))\n    else:\n        global_budget = max(3, int(0.4 * remaining))\n    if remaining > 1:\n        global_budget = min(global_budget, remaining - 1)\n    else:\n        global_budget = remaining\n    local_budget = remaining - global_budget\n\n    # Global exploration: Sobol-like / stratified low-discrepancy sampling\n    global_points = []\n    if global_budget > 0:\n        n = global_budget\n\n        def van_der_corput(i, base=2):\n            vdc, denom = 0.0, 1.0\n            while i:\n                i, remainder = divmod(i, base)\n                denom *= base\n                vdc += remainder / denom\n            return vdc\n\n        indices = np.arange(1, n + 1)\n        u = np.empty((n, dim), dtype=float)\n\n        # Use scrambled-like offsets for diversity\n        for d in range(dim):\n            base = 2 + (d % 5)\n            for k, idx in enumerate(indices):\n                u[k, d] = van_der_corput(idx + d + 1, base=base)\n\n        X_global = low + u * span\n\n        # Jitter and clip to avoid grid-like patterns in high dim\n        if dim > 5:\n            jitter_scale = 0.01\n            X_global = clip_to_bounds(\n                X_global + rng.normal(0.0, jitter_scale, size=X_global.shape) * span\n            )\n\n        for i in range(n):\n            if evals_used >= budget:\n                break\n            xg = X_global[i]\n            yg = objective_function(xg)\n            evals_used += 1\n            global_points.append((yg, xg))\n            if best_y is None or yg < best_y:\n                best_x, best_y = xg, yg\n\n    remaining = budget - evals_used\n    if remaining <= 0:\n        return best_x\n\n    # Select promising points for local search\n    local_starts = [best_x]\n    if global_points:\n        global_points.sort(key=lambda t: t[0])\n        for _, xg in global_points[:5]:\n            if len(local_starts) >= 6:\n                break\n            if not np.allclose(xg, best_x):\n                local_starts.append(xg)\n\n    m = len(local_starts)\n    if m == 0 or local_budget <= 0:\n        return best_x\n\n    # Distribute local_budget across starting points\n    per_start = max(1, local_budget // m)\n    extra = local_budget - per_start * m\n\n    base_radius = 0.2 * np.maximum(span, 1e-8)\n\n    # Simple per-start covariance (diagonal) adaptation when enough steps\n    for i, x_center_init in enumerate(local_starts):\n        if evals_used >= budget:\n            break\n\n        steps_here = per_start + (1 if i < extra else 0)\n        if steps_here <= 0:\n            continue\n\n        x_center = x_center_init.copy()\n\n        # Initialize per-dimension scales\n        scale = base_radius.copy()\n        min_scale = 0.02 * np.maximum(span, 1e-8)\n\n        for k in range(steps_here):\n            if evals_used >= budget:\n                break\n\n            frac = 1.0 - (k / max(1, steps_here - 1))\n            radius = scale * (0.1 + 0.7 * frac)\n\n            step = rng.normal(loc=0.0, scale=radius, size=dim)\n            xc = clip_to_bounds(x_center + step)\n            yc = objective_function(xc)\n            evals_used += 1\n\n            if yc < best_y:\n                best_x, best_y = xc, yc\n\n            # Local move acceptance and simple scale adaptation\n            if yc < objective_function(x_center) if False else yc < best_y + 1e-12:\n                x_center = xc\n                scale = np.maximum(scale * 1.05, min_scale)\n            else:\n                scale = np.maximum(scale * 0.95, min_scale)\n\n    return best_x",
    "X": "0.5955199118540555 1.0 0.20389116462507104"
}