{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Using EvolveAdapter with OpenEvolve Projects\n",
    "\n",
    "This tutorial demonstrates how to adapt an existing OpenEvolve project to work with GEPA's `EvolveAdapter`. The key changes required are providing a batch of training data and modifying your `evaluate` function to accept a **single data instance** and return an `EvaluationResult` for that data instance. The adapter then calls your evaluate function for each instance in the batch.\n",
    "\n",
    "> **Note:** This tutorial is also available as a standalone Python script: `tutorial.py`. You can run it directly instead of using this notebook.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To run this tutorial, you need to:\n",
    "\n",
    "1. **Clone the GEPA repository** to get the tutorial files:\n",
    "   ```bash\n",
    "   git clone https://github.com/gepa-ai/gepa.git\n",
    "   cd gepa\n",
    "   ```\n",
    "\n",
    "2. TODO: **Install GEPA in editable mode from the root (gepa)** (required since EvolveAdapter is not in PyPI):\n",
    "   ```bash\n",
    "   pip install -e \".[full]\"\n",
    "   ```\n",
    "\n",
    "3. **Install dependencies and input API key** using the setup cell the start of **Step 5: Using EvolveAdapter** below.\n",
    "\n",
    "4. **Run this notebook from:** `src/gepa/examples/evolve_adapter/function_minimization/`\n",
    "\n",
    "   This tutorial uses example files located in `src/gepa/examples/evolve_adapter/function_minimization/`:\n",
    "   - `tutorial.ipynb` (this notebook)\n",
    "   - `tutorial.py` (standalone Python script)\n",
    "   - `tutorial_example/` (example OpenEvolve project containing `config.yaml`, `evaluator.py`, and `initial_program.py`)\n",
    "   \n",
    "   The `tutorial_example/` directory contains a complete, working example that demonstrates the required changes.\n",
    "\n",
    "## Why This Change?\n",
    "\n",
    "GEPA's optimization engine works with batches of data to:\n",
    "- Provide per-instance feedback for better program refinement\n",
    "- Support minibatch-based optimization strategies\n",
    "\n",
    "## Example Project: Function Minimization\n",
    "\n",
    "We'll use the **function minimization** example from OpenEvolve [examples/function_minimization](https://github.com/algorithmicsuperintelligence/openevolve/tree/main/examples/function_minimization)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Key Changes Required\n",
    "\n",
    "Here are the **two main changes** you need to make to your `evaluate` function:\n",
    "\n",
    "### Change 1: Function Signature\n",
    "**Before:**\n",
    "```python\n",
    "def evaluate(program_path: str) -> EvaluationResult:\n",
    "```\n",
    "\n",
    "**After:**\n",
    "```python\n",
    "def evaluate(program_path: str, data_instance: Any) -> EvaluationResult:\n",
    "```\n",
    "- Add `data_instance` parameter (can be any type - dict, string, custom object, etc.)\n",
    "- For the function minimization example, we use a `dict`, but you can use whatever type best suits your original OpenEvolve project\n",
    "\n",
    "### Change 2: Extract Parameters from Data Instance\n",
    "**Before:** Hard-coded problem parameters (e.g., `GLOBAL_MIN_X = -1.704`)\n",
    "\n",
    "**After:** Extract parameters from the data instance. The exact way you extract parameters depends on the type of `data_instance`:\n",
    "```python\n",
    "# If data_instance is a dict (as in our function minimization example):\n",
    "GLOBAL_MIN_X = data_instance.get(\"global_min_x\", -1.704)\n",
    "GLOBAL_MIN_Y = data_instance.get(\"global_min_y\", 0.678)\n",
    "# ... etc\n",
    "```\n",
    "\n",
    "## Complete Modified Evaluate Function\n",
    "\n",
    "Here's the complete modified evaluate function with all changes applied. For this function minimization project example, each data instance represents a different function minimization problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified evaluator.py for EvolveAdapter\n",
    "# For this example, each data instance represents a different function minimization problem\n",
    "#\n",
    "# KEY CHANGES MADE:\n",
    "# 1. Added 'data_instance' parameter to function signature (can be any type)\n",
    "#    For this example, we use a dict, but you can use whatever type suits your project\n",
    "# 2. Extract parameters from data_instance instead of hard-coding\n",
    "\n",
    "import concurrent.futures\n",
    "import importlib.util\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "import numpy as np\n",
    "from openevolve.evaluation_result import EvaluationResult\n",
    "\n",
    "\n",
    "def run_with_timeout(func, args=(), kwargs={}, timeout_seconds=5):\n",
    "    \"\"\"\n",
    "    Run a function with a timeout using concurrent.futures\n",
    "\n",
    "    Args:\n",
    "        func: Function to run\n",
    "        args: Arguments to pass to the function\n",
    "        kwargs: Keyword arguments to pass to the function\n",
    "        timeout_seconds: Timeout in seconds\n",
    "\n",
    "    Returns:\n",
    "        Result of the function or raises TimeoutError\n",
    "    \"\"\"\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:\n",
    "        future = executor.submit(func, *args, **kwargs)\n",
    "        try:\n",
    "            return future.result(timeout=timeout_seconds)\n",
    "        except concurrent.futures.TimeoutError:\n",
    "            raise TimeoutError(f\"Function timed out after {timeout_seconds} seconds\")\n",
    "\n",
    "\n",
    "def safe_float(value):\n",
    "    \"\"\"Convert a value to float safely.\"\"\"\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (TypeError, ValueError):\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "# CHANGE 1: Added 'data_instance' parameter\n",
    "# Note: data_instance can be of any type - use whatever best suits your original project.\n",
    "# For this function minimization example, we use a dict containing problem parameters\n",
    "def evaluate(program_path: str, data_instance: dict) -> EvaluationResult:\n",
    "    \"\"\"\n",
    "    Evaluate the program on a single function minimization problem.\n",
    "\n",
    "    Args:\n",
    "        program_path: Path to the program file to evaluate\n",
    "        data_instance: Dict containing problem parameters:\n",
    "            - 'global_min_x': Target x coordinate\n",
    "            - 'global_min_y': Target y coordinate\n",
    "            - 'global_min_value': Target function value\n",
    "            - 'bounds': Tuple of (min, max) bounds for search space\n",
    "            - 'function_name': Optional name for the function\n",
    "\n",
    "    Returns:\n",
    "        EvaluationResult for this data instance\n",
    "    \"\"\"\n",
    "    # Load the program\n",
    "    try:\n",
    "        spec = importlib.util.spec_from_file_location(\"program\", program_path)\n",
    "        program = importlib.util.module_from_spec(spec)\n",
    "        spec.loader.exec_module(program)\n",
    "\n",
    "        if not hasattr(program, \"run_search\"):\n",
    "            return EvaluationResult(\n",
    "                metrics={\"combined_score\": 0.0, \"error\": 1.0}, artifacts={\"error\": \"Missing run_search function\"}\n",
    "            )\n",
    "    except Exception as e:\n",
    "        return EvaluationResult(\n",
    "            metrics={\"combined_score\": 0.0, \"error\": 1.0},\n",
    "            artifacts={\"error\": str(e), \"traceback\": traceback.format_exc()},\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        # CHANGE 2: Extract problem parameters from data_instance instead of hard-coding\n",
    "        # In the original, these were hard-coded constants like:\n",
    "        #   GLOBAL_MIN_X = -1.704\n",
    "        # Now we get them from the data instance:\n",
    "        GLOBAL_MIN_X = data_instance.get(\"global_min_x\", -1.704)\n",
    "        GLOBAL_MIN_Y = data_instance.get(\"global_min_y\", 0.678)\n",
    "        GLOBAL_MIN_VALUE = data_instance.get(\"global_min_value\", -1.519)\n",
    "        bounds = data_instance.get(\"bounds\", (-5, 5))\n",
    "\n",
    "        # Run multiple trials for this specific problem\n",
    "        num_trials = 10\n",
    "        x_values = []\n",
    "        y_values = []\n",
    "        values = []\n",
    "        distances = []\n",
    "        times = []\n",
    "        success_count = 0\n",
    "\n",
    "        for trial in range(num_trials):\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Run the program (it should use the bounds from data_instance)\n",
    "                # Note: The program may need to be modified to accept bounds as parameter\n",
    "                result = run_with_timeout(program.run_search, timeout_seconds=5)\n",
    "\n",
    "                # Handle different result formats\n",
    "                if isinstance(result, tuple):\n",
    "                    if len(result) == 3:\n",
    "                        x, y, value = result\n",
    "                    elif len(result) == 2:\n",
    "                        x, y = result\n",
    "                        # Calculate function value\n",
    "                        value = np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n",
    "                    else:\n",
    "                        continue\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "                end_time = time.time()\n",
    "\n",
    "                # Validate results\n",
    "                x = safe_float(x)\n",
    "                y = safe_float(y)\n",
    "                value = safe_float(value)\n",
    "\n",
    "                if np.isnan(x) or np.isnan(y) or np.isnan(value) or np.isinf(x) or np.isinf(y) or np.isinf(value):\n",
    "                    continue\n",
    "\n",
    "                # Calculate metrics for this trial\n",
    "                x_diff = x - GLOBAL_MIN_X\n",
    "                y_diff = y - GLOBAL_MIN_Y\n",
    "                distance_to_global = np.sqrt(x_diff**2 + y_diff**2)\n",
    "\n",
    "                x_values.append(x)\n",
    "                y_values.append(y)\n",
    "                values.append(value)\n",
    "                distances.append(distance_to_global)\n",
    "                times.append(end_time - start_time)\n",
    "                success_count += 1\n",
    "\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # If all trials failed, return error result\n",
    "        if success_count == 0:\n",
    "            return EvaluationResult(\n",
    "                metrics={\n",
    "                    \"value_score\": 0.0,\n",
    "                    \"distance_score\": 0.0,\n",
    "                    \"reliability_score\": 0.0,\n",
    "                    \"combined_score\": 0.0,\n",
    "                    \"error\": 1.0,\n",
    "                },\n",
    "                artifacts={\"error\": \"All trials failed\"},\n",
    "            )\n",
    "\n",
    "        # Calculate aggregated metrics for this instance\n",
    "        avg_value = float(np.mean(values))\n",
    "        avg_distance = float(np.mean(distances))\n",
    "\n",
    "        # Convert to scores (higher is better)\n",
    "        value_score = float(1.0 / (1.0 + abs(avg_value - GLOBAL_MIN_VALUE)))\n",
    "        distance_score = float(1.0 / (1.0 + avg_distance))\n",
    "        reliability_score = float(success_count / num_trials)\n",
    "\n",
    "        # Calculate combined score\n",
    "        base_score = 0.5 * value_score + 0.3 * distance_score + 0.2 * reliability_score\n",
    "\n",
    "        # Apply solution quality multiplier\n",
    "        if avg_distance < 0.5:\n",
    "            solution_quality_multiplier = 1.5\n",
    "        elif avg_distance < 1.5:\n",
    "            solution_quality_multiplier = 1.2\n",
    "        elif avg_distance < 3.0:\n",
    "            solution_quality_multiplier = 1.0\n",
    "        else:\n",
    "            solution_quality_multiplier = 0.7\n",
    "\n",
    "        combined_score = float(base_score * solution_quality_multiplier)\n",
    "\n",
    "        # Create artifacts\n",
    "        artifacts = {\n",
    "            \"convergence_info\": f\"Converged in {num_trials} trials with {success_count} successes\",\n",
    "            \"best_position\": f\"Final position: x={x_values[-1]:.4f}, y={y_values[-1]:.4f}\",\n",
    "            \"average_distance_to_global\": f\"{avg_distance:.4f}\",\n",
    "            \"search_efficiency\": f\"Success rate: {reliability_score:.2%}\",\n",
    "        }\n",
    "\n",
    "        return EvaluationResult(\n",
    "            metrics={\n",
    "                \"value_score\": value_score,\n",
    "                \"distance_score\": distance_score,\n",
    "                \"reliability_score\": reliability_score,\n",
    "                \"combined_score\": combined_score,\n",
    "            },\n",
    "            artifacts=artifacts,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        # Return error result for this instance\n",
    "        return EvaluationResult(\n",
    "            metrics={\"combined_score\": 0.0, \"error\": 1.0},\n",
    "            artifacts={\"error\": str(e), \"traceback\": traceback.format_exc()},\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Changes\n",
    "\n",
    "Here's a quick reference of what changed:\n",
    "\n",
    "| Aspect | Original | Modified for EvolveAdapter |\n",
    "|--------|----------|---------------------------|\n",
    "| **Function signature** | `evaluate(program_path: str)` | `evaluate(program_path: str, data_instance: Any)` |\n",
    "| **Structure** | Single evaluation | Single evaluation on an explicit data instance from a larger batch of training data |\n",
    "| **Parameters** | Hard-coded constants | Extracted from `data_instance` (type depends on your project) |\n",
    "\n",
    "## Step 2: Modifying Cascade Evaluation Functions\n",
    "\n",
    "If your project uses cascade evaluation, you must also modify your cascade evaluation functions (`evaluate_stage1`, `evaluate_stage2`, `evaluate_stage3`) to accept a single data instance and return a single EvaluationResult for that data instance, just like the main `evaluate` function.\n",
    "\n",
    "### Example: Modified `evaluate_stage1`\n",
    "\n",
    "**Before:**\n",
    "```python\n",
    "def evaluate_stage1(program_path: str) -> EvaluationResult:\n",
    "    # ... evaluation logic for single instance ...\n",
    "    return EvaluationResult(metrics={...}, artifacts={...})\n",
    "```\n",
    "\n",
    "**After:**\n",
    "```python\n",
    "def evaluate_stage1(program_path: str, data_instance: Any) -> EvaluationResult:\n",
    "    # Extract parameters from data_instance if needed\n",
    "    # (Extraction method depends on the type of data_instance, e.g. dict for our \n",
    "    # function minimization example)\n",
    "    GLOBAL_MIN_X = data_instance.get(\"global_min_x\", -1.704) # if dict\n",
    "    # ... evaluation logic for this data instance ...\n",
    "    return EvaluationResult(metrics={...}, artifacts={...})\n",
    "```\n",
    "\n",
    "### Example: Modified `evaluate_stage2`\n",
    "\n",
    "**Before:**\n",
    "```python\n",
    "def evaluate_stage2(program_path: str) -> EvaluationResult:\n",
    "    # Full evaluation as in the main evaluate function\n",
    "    return evaluate(program_path)\n",
    "```\n",
    "\n",
    "**After:**\n",
    "```python\n",
    "def evaluate_stage2(program_path: str, data_instance: Any) -> EvaluationResult:\n",
    "    # Full evaluation as in the main evaluate function\n",
    "    return evaluate(program_path, data_instance)\n",
    "```\n",
    "\n",
    "### Key Points for Cascade Functions:\n",
    "\n",
    "1. **Same signature pattern**: All stage functions should follow the same pattern as `evaluate`:\n",
    "   - Add `data_instance` parameter (can be any type)\n",
    "   - Process the single data instance and return a single `EvaluationResult` for it\n",
    "\n",
    "2. **Error handling**: If a stage fails for a specific data instance, return an error `EvaluationResult` for that instance rather than raising an exception\n",
    "\n",
    "## Step 3: (Optional) Modify Config System Message\n",
    "\n",
    "You may need to modify the `system_message` in your `config.yaml` to match your newly-modified evaluation setup. For example, if your original OpenEvolve project had a hard-coded problem in the system prompt, you should remove or generalize it.\n",
    "\n",
    "**Example for function minimization:**\n",
    "- **Before (hard-coded)**: `\"You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. The function is f(x, y) = sin(x) * cos(y) + sin(x*y) + (x^2 + y^2)/20. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.\"`\n",
    "- **After (generalized)**: `\"You are an expert programmer specializing in optimization algorithms. Your task is to improve a function minimization algorithm to find the global minimum of a complex function with many local minima. Focus on improving the search_algorithm function to reliably find the global minimum, escaping local minima that might trap simple algorithms.\"`\n",
    "\n",
    "## Step 4: Defining Training Dataset\n",
    "\n",
    "Before using `EvolveAdapter`, you need to define your training dataset. The dataset is a list of data instances, where each instance represents a problem to evaluate your program on.\n",
    "\n",
    "Data instances can be of any type - use whatever type best suits your original OpenEvolve project setup. The adapter simply passes each data instance to your `evaluate` function as-is.\n",
    "\n",
    "> **Note:** You can use just one data instance in your trainset if that's more analogous to your original OpenEvolve project setup. For example, the original function minimization project evolved on one fixed problem, so using a single data instance mimics that setup.\n",
    "\n",
    "For the function minimization example, we use dicts where each data instance contains the problem parameters:\n",
    "- `global_min_x`, `global_min_y`: The target coordinates of the global minimum\n",
    "- `global_min_value`: The target function value at the global minimum\n",
    "- `bounds`: The search space bounds\n",
    "- `function_name`: Optional name for the function\n",
    "\n",
    "## Step 5: Using EvolveAdapter\n",
    "\n",
    "Here is how to use `EvolveAdapter` with GEPA's optimization engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/angelahe/Desktop/gepa\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: litellm>=1.64.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from gepa==0.0.24) (1.80.16)\n",
      "Requirement already satisfied: datasets>=2.14.6 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from gepa==0.0.24) (4.5.0)\n",
      "Requirement already satisfied: mlflow>=3.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from gepa==0.0.24) (3.8.1)\n",
      "Requirement already satisfied: wandb in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from gepa==0.0.24) (0.24.0)\n",
      "Requirement already satisfied: tqdm>=4.66.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from gepa==0.0.24) (4.67.1)\n",
      "Requirement already satisfied: filelock in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (3.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (2.4.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (0.4.0)\n",
      "Requirement already satisfied: pandas in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets>=2.14.6->gepa==0.0.24) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (1.3.2)\n",
      "Requirement already satisfied: packaging in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from datasets>=2.14.6->gepa==0.0.24) (6.0.3)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (3.13.3)\n",
      "Requirement already satisfied: click in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (1.76.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (4.26.0)\n",
      "Requirement already satisfied: openai>=2.8.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (2.15.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm>=1.64.0->gepa==0.0.24) (0.22.2)\n",
      "Requirement already satisfied: mlflow-skinny==3.8.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (3.8.1)\n",
      "Requirement already satisfied: mlflow-tracing==3.8.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (3.8.1)\n",
      "Requirement already satisfied: Flask-CORS<7 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (6.0.2)\n",
      "Requirement already satisfied: Flask<4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (3.1.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (1.18.1)\n",
      "Requirement already satisfied: cryptography<47,>=43.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (46.0.3)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (3.4.3)\n",
      "Requirement already satisfied: gunicorn<24 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (23.0.0)\n",
      "Requirement already satisfied: huey<3,>=2.5.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (2.6.0)\n",
      "Requirement already satisfied: matplotlib<4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (3.10.8)\n",
      "Requirement already satisfied: scikit-learn<2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (1.8.0)\n",
      "Requirement already satisfied: scipy<2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (1.17.0)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow>=3.0.0->gepa==0.0.24) (2.0.45)\n",
      "Requirement already satisfied: cachetools<7,>=5.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (6.2.4)\n",
      "Requirement already satisfied: cloudpickle<4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (3.1.2)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.78.0)\n",
      "Requirement already satisfied: fastapi<1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.128.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (3.1.46)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (1.39.1)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (1.39.1)\n",
      "Requirement already satisfied: protobuf<7,>=3.12.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (6.33.4)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.5.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (4.15.0)\n",
      "Requirement already satisfied: uvicorn<1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.40.0)\n",
      "Requirement already satisfied: platformdirs in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from wandb->gepa==0.0.24) (4.5.1)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from wandb->gepa==0.0.24) (2.49.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->gepa==0.0.24) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->gepa==0.0.24) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->gepa==0.0.24) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->gepa==0.0.24) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->gepa==0.0.24) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->gepa==0.0.24) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm>=1.64.0->gepa==0.0.24) (1.22.0)\n",
      "Requirement already satisfied: Mako in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from alembic!=1.10.0,<2->mlflow>=3.0.0->gepa==0.0.24) (1.3.10)\n",
      "Requirement already satisfied: cffi>=2.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from cryptography<47,>=43.0.0->mlflow>=3.0.0->gepa==0.0.24) (2.0.0)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from docker<8,>=4.0.0->mlflow>=3.0.0->gepa==0.0.24) (2.6.3)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from Flask<4->mlflow>=3.0.0->gepa==0.0.24) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from Flask<4->mlflow>=3.0.0->gepa==0.0.24) (2.2.0)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from Flask<4->mlflow>=3.0.0->gepa==0.0.24) (3.0.3)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from Flask<4->mlflow>=3.0.0->gepa==0.0.24) (3.1.5)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (4.0.12)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from graphene<4->mlflow>=3.0.0->gepa==0.0.24) (3.2.7)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from graphene<4->mlflow>=3.0.0->gepa==0.0.24) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from graphene<4->mlflow>=3.0.0->gepa==0.0.24) (2.9.0.post0)\n",
      "Requirement already satisfied: anyio in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.14.6->gepa==0.0.24) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.14.6->gepa==0.0.24) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.14.6->gepa==0.0.24) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.14.6->gepa==0.0.24) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.14.6->gepa==0.0.24) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->gepa==0.0.24) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->gepa==0.0.24) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets>=2.14.6->gepa==0.0.24) (0.21.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->gepa==0.0.24) (3.23.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.64.0->gepa==0.0.24) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.64.0->gepa==0.0.24) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm>=1.64.0->gepa==0.0.24) (0.30.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0.0->gepa==0.0.24) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0.0->gepa==0.0.24) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0.0->gepa==0.0.24) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0.0->gepa==0.0.24) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0.0->gepa==0.0.24) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from matplotlib<4->mlflow>=3.0.0->gepa==0.0.24) (3.3.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openai>=2.8.0->litellm>=1.64.0->gepa==0.0.24) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openai>=2.8.0->litellm>=1.64.0->gepa==0.0.24) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openai>=2.8.0->litellm>=1.64.0->gepa==0.0.24) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pandas->datasets>=2.14.6->gepa==0.0.24) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pandas->datasets>=2.14.6->gepa==0.0.24) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.64.0->gepa==0.0.24) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.64.0->gepa==0.0.24) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm>=1.64.0->gepa==0.0.24) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from requests>=2.32.2->datasets>=2.14.6->gepa==0.0.24) (3.4.4)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from scikit-learn<2->mlflow>=3.0.0->gepa==0.0.24) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from scikit-learn<2->mlflow>=3.0.0->gepa==0.0.24) (3.6.0)\n",
      "Requirement already satisfied: greenlet>=1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from sqlalchemy<3,>=1.4.0->mlflow>=3.0.0->gepa==0.0.24) (3.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm>=1.64.0->gepa==0.0.24) (2026.1.15)\n",
      "Requirement already satisfied: pycparser in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow>=3.0.0->gepa==0.0.24) (2.23)\n",
      "Requirement already satisfied: google-auth~=2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (2.47.0)\n",
      "Requirement already satisfied: starlette<0.51.0,>=0.40.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.50.0)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from fastapi<1->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.0.4)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (5.0.2)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.60b1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.60b1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow>=3.0.0->gepa==0.0.24) (1.17.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (4.9.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.8.1->mlflow>=3.0.0->gepa==0.0.24) (0.6.2)\n",
      "Building wheels for collected packages: gepa\n",
      "  Building editable for gepa (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gepa: filename=gepa-0.0.24-0.editable-py3-none-any.whl size=13500 sha256=2b96b0772dbd0c9be0606b40014b80c75670b258d32ae91fd0488c52bab7eb94\n",
      "  Stored in directory: /private/var/folders/l_/glwc3twx7yd30d436jfkk3_00000gn/T/pip-ephem-wheel-cache-xo3azext/wheels/bd/67/b3/b2d0d0c35bae524180c6a7cd56189ab7e2aee9c47a79c049a9\n",
      "Successfully built gepa\n",
      "Installing collected packages: gepa\n",
      "  Attempting uninstall: gepa\n",
      "    Found existing installation: gepa 0.0.24\n",
      "    Uninstalling gepa-0.0.24:\n",
      "      Successfully uninstalled gepa-0.0.24\n",
      "Successfully installed gepa-0.0.24\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e \"../../../../../[full]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gepa in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (0.0.24)\n",
      "Requirement already satisfied: openevolve in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (0.2.25)\n",
      "Requirement already satisfied: numpy in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (2.4.1)\n",
      "Requirement already satisfied: scipy in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (1.17.0)\n",
      "Requirement already satisfied: pyyaml in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (6.0.3)\n",
      "Requirement already satisfied: litellm in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (1.80.16)\n",
      "Requirement already satisfied: openai>=1.0.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openevolve) (2.15.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openevolve) (4.67.1)\n",
      "Requirement already satisfied: flask in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openevolve) (3.1.2)\n",
      "Requirement already satisfied: dacite>=1.9.2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openevolve) (1.9.2)\n",
      "Requirement already satisfied: aiohttp>=3.10 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (3.13.3)\n",
      "Requirement already satisfied: click in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (8.3.1)\n",
      "Requirement already satisfied: fastuuid>=0.13.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (0.14.0)\n",
      "Requirement already satisfied: grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (1.76.0)\n",
      "Requirement already satisfied: httpx>=0.23.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (0.28.1)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (8.7.1)\n",
      "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (3.1.6)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.23.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (4.26.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (2.12.5)\n",
      "Requirement already satisfied: python-dotenv>=0.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (1.2.1)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (0.12.0)\n",
      "Requirement already satisfied: tokenizers in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from litellm) (0.22.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from aiohttp>=3.10->litellm) (1.22.0)\n",
      "Requirement already satisfied: typing-extensions~=4.12 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from grpcio!=1.68.*,!=1.69.*,!=1.70.*,!=1.71.0,!=1.71.1,!=1.72.0,!=1.72.1,!=1.73.0,>=1.62.3->litellm) (4.15.0)\n",
      "Requirement already satisfied: anyio in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (4.12.1)\n",
      "Requirement already satisfied: certifi in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (1.0.9)\n",
      "Requirement already satisfied: idna in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpx>=0.23.0->litellm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.16.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.25.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from jsonschema<5.0.0,>=4.23.0->litellm) (0.30.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openai>=1.0.0->openevolve) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openai>=1.0.0->openevolve) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from openai>=1.0.0->openevolve) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.0->litellm) (0.4.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2026.1.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from tiktoken>=0.7.0->litellm) (2.32.5)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from flask->openevolve) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from flask->openevolve) (2.2.0)\n",
      "Requirement already satisfied: werkzeug>=3.1.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from flask->openevolve) (3.1.5)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from tokenizers->litellm) (1.3.2)\n",
      "Requirement already satisfied: filelock in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (3.20.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (25.0)\n",
      "Requirement already satisfied: shellingham in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm) (0.21.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/angelahe/Desktop/gepa/myenv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.6.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required dependencies\n",
    "%pip install gepa openevolve numpy scipy pyyaml litellm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below and input your API key when prompted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = input(\"API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from gepa import optimize\n",
    "from gepa.adapters.evolve_adapter.evolve_adapter import EvolveAdapter\n",
    "\n",
    "# Path to your modified OpenEvolve project directory\n",
    "# This should contain: config.yaml, evaluator.py, initial_program.py\n",
    "# For this example, we use the tutorial_example directory in the same folder as this notebook\n",
    "project_path = Path(\"tutorial_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the adapter\n",
    "adapter = EvolveAdapter(path=project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training data (for this example, function minimization problems)\n",
    "# Each item represents a different problem instance\n",
    "# The adapter will call your evaluate function for each instance in the batch\n",
    "#\n",
    "# NOTE: You can use just one data instance if that's more analogous to your original\n",
    "# OpenEvolve project setup. For example, the original function minimization project\n",
    "# evolved on one fixed problem, so using a single data instance mimics that setup.\n",
    "trainset = [\n",
    "    {\n",
    "        \"global_min_x\": -1.704,\n",
    "        \"global_min_y\": 0.678,\n",
    "        \"global_min_value\": -1.519,\n",
    "        \"bounds\": (-5, 5),\n",
    "        \"function_name\": \"sin_cos_function\",\n",
    "    },\n",
    "    # Uncomment the following to add more problem instances:\n",
    "    # {\n",
    "    #     \"global_min_x\": 0.0,\n",
    "    #     \"global_min_y\": 0.0,\n",
    "    #     \"global_min_value\": 0.0,\n",
    "    #     \"bounds\": (-3, 3),\n",
    "    #     \"function_name\": \"quadratic_function\"\n",
    "    # },\n",
    "    # Add more problem instances as needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read initial program\n",
    "with open(project_path / \"initial_program.py\") as f:\n",
    "    initial_program = f.read()\n",
    "\n",
    "# Define seed candidate (the program to evolve)\n",
    "seed_candidate = {\"program\": initial_program}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Base program full valset score: 1.4079332968094032 over 1 / 1 examples\n",
      "Iteration 1: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 1: All subsample scores perfect. Skipping.\n",
      "Iteration 1: Reflective mutation did not propose a new candidate\n",
      "Iteration 2: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 2: All subsample scores perfect. Skipping.\n",
      "Iteration 2: Reflective mutation did not propose a new candidate\n",
      "Iteration 3: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3: All subsample scores perfect. Skipping.\n",
      "Iteration 3: Reflective mutation did not propose a new candidate\n",
      "Iteration 4: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4: All subsample scores perfect. Skipping.\n",
      "Iteration 4: Reflective mutation did not propose a new candidate\n",
      "Iteration 5: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 5: All subsample scores perfect. Skipping.\n",
      "Iteration 5: Reflective mutation did not propose a new candidate\n",
      "Iteration 6: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 6: Proposed new text for program: \"\"\"Function minimization example for OpenEvolve\"\"\"\n",
      "import numpy as np\n",
      "import random\n",
      "\n",
      "\n",
      "def search_algorithm(iterations=10000, bounds=(-5, 5), population_size=50, mutation_rate=0.1, crossover_rate=0.7):\n",
      "    \"\"\"\n",
      "    An improved search algorithm using concepts from evolutionary computation,\n",
      "    specifically a form of Genetic Algorithm with a population-based approach\n",
      "    to escape local minima.\n",
      "\n",
      "    Args:\n",
      "        iterations: Number of generations to run\n",
      "        bounds: Bounds for the search space (min, max)\n",
      "        population_size: Number of individuals in the population\n",
      "        mutation_rate: Probability of an individual's gene mutating\n",
      "        crossover_rate: Probability of two individuals crossing over their genes\n",
      "\n",
      "    Returns:\n",
      "        Tuple of (best_x, best_y, best_value)\n",
      "    \"\"\"\n",
      "\n",
      "    def create_individual():\n",
      "        x = np.random.uniform(bounds[0], bounds[1])\n",
      "        y = np.random.uniform(bounds[0], bounds[1])\n",
      "        return (x, y, evaluate_function(x, y))\n",
      "\n",
      "    def mutate(individual):\n",
      "        x, y, _ = individual\n",
      "        if random.random() < mutation_rate:\n",
      "            # Mutate x\n",
      "            x += np.random.normal(0, (bounds[1] - bounds[0]) * 0.05) # Small Gaussian perturbation\n",
      "            x = np.clip(x, bounds[0], bounds[1])\n",
      "        if random.random() < mutation_rate:\n",
      "            # Mutate y\n",
      "            y += np.random.normal(0, (bounds[1] - bounds[0]) * 0.05)\n",
      "            y = np.clip(y, bounds[0], bounds[1])\n",
      "        return (x, y, evaluate_function(x, y))\n",
      "\n",
      "    def crossover(parent1, parent2):\n",
      "        x1, y1, _ = parent1\n",
      "        x2, y2, _ = parent2\n",
      "\n",
      "        if random.random() < crossover_rate:\n",
      "            # Simple arithmetic crossover\n",
      "            alpha = random.random()\n",
      "            child_x = alpha * x1 + (1 - alpha) * x2\n",
      "            child_y = alpha * y1 + (1 - alpha) * y2\n",
      "        else:\n",
      "            # If no crossover, pick one parent randomly\n",
      "            child_x, child_y = random.choice([parent1[:2], parent2[:2]])\n",
      "\n",
      "        child_x = np.clip(child_x, bounds[0], bounds[1])\n",
      "        child_y = np.clip(child_y, bounds[0], bounds[1])\n",
      "        return (child_x, child_y, evaluate_function(child_x, child_y))\n",
      "\n",
      "    # Initialize population\n",
      "    population = [create_individual() for _ in range(population_size)]\n",
      "    population.sort(key=lambda item: item[2]) # Sort by fitness (lower value is better)\n",
      "    best_x, best_y, best_value = population[0]\n",
      "\n",
      "    for generation in range(iterations):\n",
      "        new_population = []\n",
      "\n",
      "        # Elitism: Keep the best individual from the previous generation\n",
      "        new_population.append(population[0])\n",
      "\n",
      "        # Generate offspring\n",
      "        while len(new_population) < population_size:\n",
      "            # Select parents (tournament selection or roulette wheel could be used,\n",
      "            # but for simplicity, we'll use simple selection and crossover/mutate)\n",
      "            parent1 = random.choice(population[:population_size//2]) # Select from fitter half\n",
      "            parent2 = random.choice(population[:population_size//2])\n",
      "\n",
      "            child = crossover(parent1, parent2)\n",
      "            mutated_child = mutate(child)\n",
      "            new_population.append(mutated_child)\n",
      "\n",
      "        population = new_population\n",
      "        population.sort(key=lambda item: item[2])\n",
      "\n",
      "        # Update global best\n",
      "        if population[0][2] < best_value:\n",
      "            best_x, best_y, best_value = population[0]\n",
      "\n",
      "        # Optional: Introduce some random exploration periodically to jump out of plateaus\n",
      "        if generation % (iterations // 10) == 0 and generation > 0:\n",
      "            random_x = np.random.uniform(bounds[0], bounds[1])\n",
      "            random_y = np.random.uniform(bounds[0], bounds[1])\n",
      "            random_val = evaluate_function(random_x, random_y)\n",
      "            if random_val < best_value:\n",
      "                best_x, best_y, best_value = random_x, random_y, random_val\n",
      "                # Add this random point to the population to ensure it's not lost\n",
      "                population.append((random_x, random_y, random_val))\n",
      "                population.sort(key=lambda item: item[2])\n",
      "                population = population[:population_size] # Trim if it exceeds size\n",
      "\n",
      "    return best_x, best_y, best_value\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6: New subsample score 0.0 is not better than old score 3.347516077054268, skipping\n",
      "Iteration 7: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7: All subsample scores perfect. Skipping.\n",
      "Iteration 7: Reflective mutation did not propose a new candidate\n",
      "Iteration 8: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 8: All subsample scores perfect. Skipping.\n",
      "Iteration 8: Reflective mutation did not propose a new candidate\n",
      "Iteration 9: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9: All subsample scores perfect. Skipping.\n",
      "Iteration 9: Reflective mutation did not propose a new candidate\n",
      "Iteration 10: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 10: All subsample scores perfect. Skipping.\n",
      "Iteration 10: Reflective mutation did not propose a new candidate\n",
      "Iteration 11: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 11: All subsample scores perfect. Skipping.\n",
      "Iteration 11: Reflective mutation did not propose a new candidate\n",
      "Iteration 12: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 12: All subsample scores perfect. Skipping.\n",
      "Iteration 12: Reflective mutation did not propose a new candidate\n",
      "Iteration 13: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 13: Proposed new text for program: \"\"\"Function minimization example for OpenEvolve\"\"\"\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def search_algorithm(iterations=1000, bounds=(-5, 5), population_size=50, mutation_rate=0.1, crossover_rate=0.7):\n",
      "    \"\"\"\n",
      "    An improved search algorithm incorporating elements of a Genetic Algorithm\n",
      "    and Simulated Annealing to escape local minima.\n",
      "\n",
      "    Args:\n",
      "        iterations: Number of iterations to run\n",
      "        bounds: Bounds for the search space (min, max)\n",
      "        population_size: Number of individuals in the population\n",
      "        mutation_rate: Probability of a gene mutating\n",
      "        crossover_rate: Probability of two parents crossing over\n",
      "\n",
      "    Returns:\n",
      "        Tuple of (best_x, best_y, best_value)\n",
      "    \"\"\"\n",
      "\n",
      "    def initialize_population(size, bounds):\n",
      "        population_x = np.random.uniform(bounds[0], bounds[1], size)\n",
      "        population_y = np.random.uniform(bounds[0], bounds[1], size)\n",
      "        return population_x, population_y\n",
      "\n",
      "    def evaluate_population(pop_x, pop_y):\n",
      "        return np.array([evaluate_function(x, y) for x, y in zip(pop_x, pop_y)])\n",
      "\n",
      "    def select_parents(pop_x, pop_y, fitness, num_parents):\n",
      "        # Tournament selection\n",
      "        parents_indices = []\n",
      "        for _ in range(num_parents):\n",
      "            tournament_size = max(2, int(len(fitness) * 0.1))\n",
      "            competitor_indices = np.random.choice(len(fitness), tournament_size, replace=False)\n",
      "            winner_index = competitor_indices[np.argmin(fitness[competitor_indices])]\n",
      "            parents_indices.append(winner_index)\n",
      "        return pop_x[parents_indices], pop_y[parents_indices]\n",
      "\n",
      "    def crossover(parent_x, parent_y, child_x, child_y, crossover_rate):\n",
      "        if np.random.rand() < crossover_rate:\n",
      "            # One-point crossover\n",
      "            crossover_point = np.random.randint(1, len(parent_x))\n",
      "            child_x[:crossover_point] = parent_x[:crossover_point]\n",
      "            child_x[crossover_point:] = parent_y[crossover_point:]\n",
      "            child_y[:crossover_point] = parent_y[:crossover_point]\n",
      "            child_y[crossover_point:] = parent_x[crossover_point:]\n",
      "        else:\n",
      "            child_x[:] = parent_x[:]\n",
      "            child_y[:] = parent_y[:]\n",
      "        return child_x, child_y\n",
      "\n",
      "    def mutate(individual_x, individual_y, mutation_rate, bounds):\n",
      "        for i in range(len(individual_x)):\n",
      "            if np.random.rand() < mutation_rate:\n",
      "                # Add Gaussian noise for exploration\n",
      "                mutation_strength = (bounds[1] - bounds[0]) * 0.05  # Adjust strength as needed\n",
      "                individual_x[i] += np.random.normal(0, mutation_strength)\n",
      "                individual_y[i] += np.random.normal(0, mutation_strength)\n",
      "                # Clamp to bounds\n",
      "                individual_x[i] = np.clip(individual_x[i], bounds[0], bounds[1])\n",
      "                individual_y[i] = np.clip(individual_y[i], bounds[0], bounds[1])\n",
      "        return individual_x, individual_y\n",
      "\n",
      "    # Initialize population\n",
      "    pop_x, pop_y = initialize_population(population_size, bounds)\n",
      "    values = evaluate_population(pop_x, pop_y)\n",
      "\n",
      "    best_x = pop_x[np.argmin(values)]\n",
      "    best_y = pop_y[np.argmin(values)]\n",
      "    best_value = np.min(values)\n",
      "\n",
      "    for _ in range(iterations):\n",
      "        # Evaluate current population\n",
      "        values = evaluate_population(pop_x, pop_y)\n",
      "\n",
      "        # Update overall best\n",
      "        current_best_idx = np.argmin(values)\n",
      "        if values[current_best_idx] < best_value:\n",
      "            best_value = values[current_best_idx]\n",
      "            best_x = pop_x[current_best_idx]\n",
      "            best_y = pop_y[current_best_idx]\n",
      "\n",
      "        # Selection\n",
      "        parents_x, parents_y = select_parents(pop_x, pop_y, values, population_size // 2)\n",
      "\n",
      "        # Crossover and Mutation to create next generation\n",
      "        next_pop_x = np.zeros(population_size)\n",
      "        next_pop_y = np.zeros(population_size)\n",
      "\n",
      "        # Keep some of the best individuals (elitism)\n",
      "        elite_count = max(1, int(population_size * 0.05))\n",
      "        elite_indices = np.argsort(values)[:elite_count]\n",
      "        next_pop_x[:elite_count] = pop_x[elite_indices]\n",
      "        next_pop_y[:elite_count] = pop_y[elite_indices]\n",
      "\n",
      "        for i in range(elite_count, population_size, 2):\n",
      "            # Select two parents randomly from the selected parents\n",
      "            parent1_idx = np.random.randint(len(parents_x))\n",
      "            parent2_idx = np.random.randint(len(parents_x))\n",
      "            parent_x1, parent_y1 = parents_x[parent1_idx], parents_y[parent1_idx]\n",
      "            parent_x2, parent_y2 = parents_x[parent2_idx], parents_y[parent2_idx]\n",
      "\n",
      "            child_x1, child_y1 = np.copy(parent_x1), np.copy(parent_y1)\n",
      "            child_x2, child_y2 = np.copy(parent_x2), np.copy(parent_y2)\n",
      "\n",
      "            # Crossover\n",
      "            child_x1, child_y1 = crossover(parent_x1, parent_y1, child_x1, child_y1, crossover_rate)\n",
      "            child_x2, child_y2 = crossover(parent_x2, parent_y2, child_x2, child_y2, crossover_rate)\n",
      "\n",
      "            # Mutation\n",
      "            child_x1, child_y1 = mutate(child_x1, child_y1, mutation_rate, bounds)\n",
      "            child_x2, child_y2 = mutate(child_x2, child_y2, mutation_rate, bounds)\n",
      "\n",
      "            next_pop_x[i] = child_x1\n",
      "            next_pop_y[i] = child_y1\n",
      "            if i + 1 < population_size:\n",
      "                next_pop_x[i+1] = child_x2\n",
      "                next_pop_y[i+1] = child_y2\n",
      "\n",
      "        pop_x, pop_y = next_pop_x, next_pop_y\n",
      "\n",
      "        # Simulated Annealing-like cooling schedule for mutation rate\n",
      "        # This allows for more exploration early on and more exploitation later.\n",
      "        # The exact cooling function might need tuning.\n",
      "        current_iter_ratio = _ / iterations\n",
      "        # Example: Exponential decay\n",
      "        # temperature = initial_temp * np.exp(-cooling_rate * _)\n",
      "        # mutation_rate = base_mutation_rate * (temperature / initial_temp)\n",
      "        # Or a simpler linear decrease\n",
      "        mutation_rate = 0.1 * (1 - current_iter_ratio) + 0.01 * current_iter_ratio # Range from 0.1 to 0.01\n",
      "\n",
      "\n",
      "    return best_x, best_y, best_value\n",
      "Iteration 13: New subsample score 0.0 is not better than old score 3.3257625585707022, skipping\n",
      "Iteration 14: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 14: All subsample scores perfect. Skipping.\n",
      "Iteration 14: Reflective mutation did not propose a new candidate\n",
      "Iteration 15: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 15: All subsample scores perfect. Skipping.\n",
      "Iteration 15: Reflective mutation did not propose a new candidate\n",
      "Iteration 16: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 16: All subsample scores perfect. Skipping.\n",
      "Iteration 16: Reflective mutation did not propose a new candidate\n",
      "Iteration 17: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 17: All subsample scores perfect. Skipping.\n",
      "Iteration 17: Reflective mutation did not propose a new candidate\n",
      "Iteration 18: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 18: All subsample scores perfect. Skipping.\n",
      "Iteration 18: Reflective mutation did not propose a new candidate\n",
      "Iteration 19: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 19: All subsample scores perfect. Skipping.\n",
      "Iteration 19: Reflective mutation did not propose a new candidate\n",
      "Iteration 20: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 20: All subsample scores perfect. Skipping.\n",
      "Iteration 20: Reflective mutation did not propose a new candidate\n",
      "Iteration 21: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 21: All subsample scores perfect. Skipping.\n",
      "Iteration 21: Reflective mutation did not propose a new candidate\n",
      "Iteration 22: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 22: All subsample scores perfect. Skipping.\n",
      "Iteration 22: Reflective mutation did not propose a new candidate\n",
      "Iteration 23: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 23: All subsample scores perfect. Skipping.\n",
      "Iteration 23: Reflective mutation did not propose a new candidate\n",
      "Iteration 24: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 24: All subsample scores perfect. Skipping.\n",
      "Iteration 24: Reflective mutation did not propose a new candidate\n",
      "Iteration 25: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25: All subsample scores perfect. Skipping.\n",
      "Iteration 25: Reflective mutation did not propose a new candidate\n",
      "Iteration 26: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 26: All subsample scores perfect. Skipping.\n",
      "Iteration 26: Reflective mutation did not propose a new candidate\n",
      "Iteration 27: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 27: All subsample scores perfect. Skipping.\n",
      "Iteration 27: Reflective mutation did not propose a new candidate\n",
      "Iteration 28: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 28: All subsample scores perfect. Skipping.\n",
      "Iteration 28: Reflective mutation did not propose a new candidate\n",
      "Iteration 29: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 29: All subsample scores perfect. Skipping.\n",
      "Iteration 29: Reflective mutation did not propose a new candidate\n",
      "Iteration 30: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 30: All subsample scores perfect. Skipping.\n",
      "Iteration 30: Reflective mutation did not propose a new candidate\n",
      "Iteration 31: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 31: All subsample scores perfect. Skipping.\n",
      "Iteration 31: Reflective mutation did not propose a new candidate\n",
      "Iteration 32: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 32: Proposed new text for program: \"\"\"Function minimization example for OpenEvolve\"\"\"\n",
      "import numpy as np\n",
      "\n",
      "\n",
      "def search_algorithm(iterations=5000, bounds=(-5, 5), population_size=50, mutation_rate=0.1, crossover_rate=0.8):\n",
      "    \"\"\"\n",
      "    An improved search algorithm that uses a combination of population-based search\n",
      "    (like a genetic algorithm) and local search to escape local minima.\n",
      "\n",
      "    Args:\n",
      "        iterations: Number of generations to run\n",
      "        bounds: Bounds for the search space (min, max)\n",
      "        population_size: Number of individuals in the population\n",
      "        mutation_rate: Probability of mutating an individual\n",
      "        crossover_rate: Probability of performing crossover between parents\n",
      "\n",
      "    Returns:\n",
      "        Tuple of (best_x, best_y, best_value)\n",
      "    \"\"\"\n",
      "\n",
      "    def initialize_population(size, bounds):\n",
      "        population_x = np.random.uniform(bounds[0], bounds[1], size)\n",
      "        population_y = np.random.uniform(bounds[0], bounds[1], size)\n",
      "        values = evaluate_function(population_x, population_y)\n",
      "        return population_x, population_y, values\n",
      "\n",
      "    def select_parents(population_x, population_y, values, num_parents):\n",
      "        # Tournament selection\n",
      "        indices = np.random.randint(0, len(values), size=(num_parents, 5))\n",
      "        parent_indices = np.argmin(values[indices], axis=1)\n",
      "        selected_indices = indices[np.arange(num_parents), parent_indices]\n",
      "        return population_x[selected_indices], population_y[selected_indices]\n",
      "\n",
      "    def crossover(parent1_x, parent1_y, parent2_x, parent2_y, crossover_rate):\n",
      "        if np.random.rand() < crossover_rate:\n",
      "            # One-point crossover\n",
      "            child1_x, child2_x = np.split(np.random.permutation([parent1_x, parent2_x]), 1)\n",
      "            child1_y, child2_y = np.split(np.random.permutation([parent1_y, parent2_y]), 1)\n",
      "            return child1_x[0], child1_y[0], child2_x[0], child2_y[0]\n",
      "        else:\n",
      "            return parent1_x, parent1_y, parent2_x, parent2_y\n",
      "\n",
      "    def mutate(individual_x, individual_y, mutation_rate, bounds):\n",
      "        if np.random.rand() < mutation_rate:\n",
      "            # Add Gaussian noise for mutation\n",
      "            mutation_strength = (bounds[1] - bounds[0]) * 0.1 # Adjust mutation strength\n",
      "            individual_x += np.random.normal(0, mutation_strength)\n",
      "            individual_y += np.random.normal(0, mutation_strength)\n",
      "            # Clamp values to bounds\n",
      "            individual_x = np.clip(individual_x, bounds[0], bounds[1])\n",
      "            individual_y = np.clip(individual_y, bounds[0], bounds[1])\n",
      "        return individual_x, individual_y\n",
      "\n",
      "    def local_search(x, y, evaluate_func, bounds, steps=5):\n",
      "        # Simple gradient descent-like local search\n",
      "        step_size = (bounds[1] - bounds[0]) * 0.05\n",
      "        for _ in range(steps):\n",
      "            grad_x = (evaluate_func(x + step_size, y) - evaluate_func(x - step_size, y)) / (2 * step_size)\n",
      "            grad_y = (evaluate_func(x, y + step_size) - evaluate_func(x, y - step_size)) / (2 * step_size)\n",
      "            x -= grad_x * step_size * 0.5 # Smaller step for local search\n",
      "            y -= grad_y * step_size * 0.5\n",
      "            x = np.clip(x, bounds[0], bounds[1])\n",
      "            y = np.clip(y, bounds[0], bounds[1])\n",
      "        return x, y\n",
      "\n",
      "    # Initialize population\n",
      "    population_x, population_y, values = initialize_population(population_size, bounds)\n",
      "\n",
      "    # Keep track of the overall best\n",
      "    best_idx = np.argmin(values)\n",
      "    best_x, best_y = population_x[best_idx], population_y[best_idx]\n",
      "    best_value = values[best_idx]\n",
      "\n",
      "    for generation in range(iterations):\n",
      "        # Select parents\n",
      "        parents_x, parents_y = select_parents(population_x, population_y, values, population_size // 2)\n",
      "\n",
      "        # Create next generation\n",
      "        next_population_x = np.zeros(population_size)\n",
      "        next_population_y = np.zeros(population_size)\n",
      "        next_values = np.zeros(population_size)\n",
      "\n",
      "        for i in range(0, population_size, 2):\n",
      "            # Crossover\n",
      "            parent1_idx = np.random.randint(0, len(parents_x))\n",
      "            parent2_idx = np.random.randint(0, len(parents_x))\n",
      "            child1_x, child1_y, child2_x, child2_y = crossover(\n",
      "                parents_x[parent1_idx], parents_y[parent1_idx],\n",
      "                parents_x[parent2_idx], parents_y[parent2_idx],\n",
      "                crossover_rate\n",
      "            )\n",
      "\n",
      "            # Mutation\n",
      "            child1_x, child1_y = mutate(child1_x, child1_y, mutation_rate, bounds)\n",
      "            child2_x, child2_y = mutate(child2_x, child2_y, mutation_rate, bounds)\n",
      "\n",
      "            # Add to next generation\n",
      "            next_population_x[i] = child1_x\n",
      "            next_population_y[i] = child1_y\n",
      "            next_population_x[i+1] = child2_x\n",
      "            next_population_y[i+1] = child2_y\n",
      "\n",
      "        # Evaluate new individuals\n",
      "        next_values[:population_size] = evaluate_function(next_population_x, next_population_y)\n",
      "\n",
      "        # Apply local search to a subset of the new population to exploit promising areas\n",
      "        num_local_search = int(population_size * 0.2) # Apply local search to 20% of the new population\n",
      "        local_search_indices = np.random.choice(population_size, num_local_search, replace=False)\n",
      "        for idx in local_search_indices:\n",
      "            next_population_x[idx], next_population_y[idx] = local_search(\n",
      "                next_population_x[idx], next_population_y[idx], evaluate_function, bounds\n",
      "            )\n",
      "            next_values[idx] = evaluate_function(next_population_x[idx], next_population_y[idx])\n",
      "\n",
      "\n",
      "        # Elitism: keep the best individual from the previous generation\n",
      "        elite_idx = np.argmin(values)\n",
      "        next_population_x[0] = population_x[elite_idx]\n",
      "        next_population_y[0] = population_y[elite_idx]\n",
      "        next_values[0] = values[elite_idx]\n",
      "\n",
      "        population_x, population_y, values = next_population_x, next_population_y, next_values\n",
      "\n",
      "        # Update overall best\n",
      "        current_best_idx = np.argmin(values)\n",
      "        if values[current_best_idx] < best_value:\n",
      "            best_value = values[current_best_idx]\n",
      "            best_x = population_x[current_best_idx]\n",
      "            best_y = population_y[current_best_idx]\n",
      "\n",
      "    return best_x, best_y, best_value\n",
      "Iteration 32: New subsample score 0.0 is not better than old score 3.4073028926604865, skipping\n",
      "Iteration 33: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 33: All subsample scores perfect. Skipping.\n",
      "Iteration 33: Reflective mutation did not propose a new candidate\n",
      "Iteration 34: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 34: All subsample scores perfect. Skipping.\n",
      "Iteration 34: Reflective mutation did not propose a new candidate\n",
      "Iteration 35: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 35: All subsample scores perfect. Skipping.\n",
      "Iteration 35: Reflective mutation did not propose a new candidate\n",
      "Iteration 36: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 36: All subsample scores perfect. Skipping.\n",
      "Iteration 36: Reflective mutation did not propose a new candidate\n",
      "Iteration 37: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 37: All subsample scores perfect. Skipping.\n",
      "Iteration 37: Reflective mutation did not propose a new candidate\n",
      "Iteration 38: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 38: All subsample scores perfect. Skipping.\n",
      "Iteration 38: Reflective mutation did not propose a new candidate\n",
      "Iteration 39: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 39: All subsample scores perfect. Skipping.\n",
      "Iteration 39: Reflective mutation did not propose a new candidate\n",
      "Iteration 40: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 40: All subsample scores perfect. Skipping.\n",
      "Iteration 40: Reflective mutation did not propose a new candidate\n",
      "Iteration 41: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 41: All subsample scores perfect. Skipping.\n",
      "Iteration 41: Reflective mutation did not propose a new candidate\n",
      "Iteration 42: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 42: All subsample scores perfect. Skipping.\n",
      "Iteration 42: Reflective mutation did not propose a new candidate\n",
      "Iteration 43: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 43: All subsample scores perfect. Skipping.\n",
      "Iteration 43: Reflective mutation did not propose a new candidate\n",
      "Iteration 44: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 44: All subsample scores perfect. Skipping.\n",
      "Iteration 44: Reflective mutation did not propose a new candidate\n",
      "Iteration 45: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 45: All subsample scores perfect. Skipping.\n",
      "Iteration 45: Reflective mutation did not propose a new candidate\n",
      "Iteration 46: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 46: All subsample scores perfect. Skipping.\n",
      "Iteration 46: Reflective mutation did not propose a new candidate\n",
      "Iteration 47: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 47: All subsample scores perfect. Skipping.\n",
      "Iteration 47: Reflective mutation did not propose a new candidate\n",
      "Iteration 48: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 48: All subsample scores perfect. Skipping.\n",
      "Iteration 48: Reflective mutation did not propose a new candidate\n",
      "Iteration 49: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 49: All subsample scores perfect. Skipping.\n",
      "Iteration 49: Reflective mutation did not propose a new candidate\n",
      "Iteration 50: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 50: All subsample scores perfect. Skipping.\n",
      "Iteration 50: Reflective mutation did not propose a new candidate\n",
      "Iteration 51: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 51: All subsample scores perfect. Skipping.\n",
      "Iteration 51: Reflective mutation did not propose a new candidate\n",
      "Iteration 52: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 52: All subsample scores perfect. Skipping.\n",
      "Iteration 52: Reflective mutation did not propose a new candidate\n",
      "Iteration 53: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 53: All subsample scores perfect. Skipping.\n",
      "Iteration 53: Reflective mutation did not propose a new candidate\n",
      "Iteration 54: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 54: All subsample scores perfect. Skipping.\n",
      "Iteration 54: Reflective mutation did not propose a new candidate\n",
      "Iteration 55: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 55: All subsample scores perfect. Skipping.\n",
      "Iteration 55: Reflective mutation did not propose a new candidate\n",
      "Iteration 56: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 56: All subsample scores perfect. Skipping.\n",
      "Iteration 56: Reflective mutation did not propose a new candidate\n",
      "Iteration 57: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 57: All subsample scores perfect. Skipping.\n",
      "Iteration 57: Reflective mutation did not propose a new candidate\n",
      "Iteration 58: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 58: Proposed new text for program: # EVOLVE-BLOCK-START\n",
      "\"\"\"Function minimization example for OpenEvolve\"\"\"\n",
      "import numpy as np\n",
      "import random\n",
      "\n",
      "\n",
      "def search_algorithm(iterations=1000, bounds=(-5, 5)):\n",
      "    \"\"\"\n",
      "    An enhanced search algorithm that uses a combination of random search,\n",
      "    gradient-based local search (simplified), and a wider initial exploration\n",
      "    to escape local minima and find the global minimum more reliably.\n",
      "\n",
      "    Args:\n",
      "        iterations: Number of iterations to run\n",
      "        bounds: Bounds for the search space (min, max)\n",
      "\n",
      "    Returns:\n",
      "        Tuple of (best_x, best_y, best_value)\n",
      "    \"\"\"\n",
      "    # Parameters for diversification and exploitation\n",
      "    exploration_factor = 0.3  # Probability of exploring new random regions\n",
      "    local_search_steps = 5    # Number of steps for local refinement\n",
      "    step_size = 0.1           # Step size for local search\n",
      "\n",
      "    # Initialize with a point from a wider initial exploration\n",
      "    # This helps in finding a good starting region\n",
      "    initial_x = np.random.uniform(bounds[0] * 1.5, bounds[1] * 1.5)\n",
      "    initial_y = np.random.uniform(bounds[0] * 1.5, bounds[1] * 1.5)\n",
      "    # Clamp to bounds if initial exploration goes out\n",
      "    initial_x = np.clip(initial_x, bounds[0], bounds[1])\n",
      "    initial_y = np.clip(initial_y, bounds[0], bounds[1])\n",
      "\n",
      "    best_x = initial_x\n",
      "    best_y = initial_y\n",
      "    best_value = evaluate_function(best_x, best_y)\n",
      "\n",
      "    for i in range(iterations):\n",
      "        if random.random() < exploration_factor or i < iterations * 0.1: # More exploration early on\n",
      "            # Explore a new random region\n",
      "            x = np.random.uniform(bounds[0], bounds[1])\n",
      "            y = np.random.uniform(bounds[0], bounds[1])\n",
      "        else:\n",
      "            # Perform a simplified local search around the current best\n",
      "            # This is a form of hill-climbing or gradient descent approximation\n",
      "            # We perturb the current best and see if we can improve it.\n",
      "            # This would ideally be replaced by a proper gradient-based optimizer\n",
      "            # if gradients were available.\n",
      "            current_x = best_x\n",
      "            current_y = best_y\n",
      "            x = current_x + np.random.uniform(-step_size, step_size)\n",
      "            y = current_y + np.random.uniform(-step_size, step_size)\n",
      "            # Ensure we stay within bounds\n",
      "            x = np.clip(x, bounds[0], bounds[1])\n",
      "            y = np.clip(y, bounds[0], bounds[1])\n",
      "\n",
      "        value = evaluate_function(x, y)\n",
      "\n",
      "        if value < best_value:\n",
      "            # If we found a better point, update the best\n",
      "            best_value = value\n",
      "            best_x, best_y = x, y\n",
      "\n",
      "            # Optionally, perform a few local search steps from this new best point\n",
      "            # to quickly refine it.\n",
      "            for _ in range(local_search_steps):\n",
      "                local_x = best_x + np.random.uniform(-step_size/2, step_size/2)\n",
      "                local_y = best_y + np.random.uniform(-step_size/2, step_size/2)\n",
      "                local_x = np.clip(local_x, bounds[0], bounds[1])\n",
      "                local_y = np.clip(local_y, bounds[0], bounds[1])\n",
      "                local_value = evaluate_function(local_x, local_y)\n",
      "                if local_value < best_value:\n",
      "                    best_value = local_value\n",
      "                    best_x, best_y = local_x, local_y\n",
      "\n",
      "    return best_x, best_y, best_value\n",
      "# EVOLVE-BLOCK-END\n",
      "Iteration 58: New subsample score 4.358218255035094 is better than old score 3.3028160684883345. Continue to full eval and add to candidate pool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 58: Valset score for new program: 1.3635279918593164 (coverage 1 / 1)\n",
      "Iteration 58: Val aggregate for new program: 1.3635279918593164\n",
      "Iteration 58: Individual valset scores for new program: {0: 1.3635279918593164}\n",
      "Iteration 58: New valset pareto front scores: {0: 1.4079332968094032}\n",
      "Iteration 58: Valset pareto front aggregate score: 1.4079332968094032\n",
      "Iteration 58: Updated valset pareto front programs: {0: {0}}\n",
      "Iteration 58: Best valset aggregate score so far: 1.4079332968094032\n",
      "Iteration 58: Best program as per aggregate score on valset: 0\n",
      "Iteration 58: Best score on valset: 1.4079332968094032\n",
      "Iteration 58: Linear pareto front program index: 0\n",
      "Iteration 58: New program candidate index: 1\n",
      "Iteration 59: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 59: All subsample scores perfect. Skipping.\n",
      "Iteration 59: Reflective mutation did not propose a new candidate\n",
      "Iteration 60: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 60: All subsample scores perfect. Skipping.\n",
      "Iteration 60: Reflective mutation did not propose a new candidate\n",
      "Iteration 61: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 61: All subsample scores perfect. Skipping.\n",
      "Iteration 61: Reflective mutation did not propose a new candidate\n",
      "Iteration 62: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 62: All subsample scores perfect. Skipping.\n",
      "Iteration 62: Reflective mutation did not propose a new candidate\n",
      "Iteration 63: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 63: All subsample scores perfect. Skipping.\n",
      "Iteration 63: Reflective mutation did not propose a new candidate\n",
      "Iteration 64: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 64: All subsample scores perfect. Skipping.\n",
      "Iteration 64: Reflective mutation did not propose a new candidate\n",
      "Iteration 65: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 65: All subsample scores perfect. Skipping.\n",
      "Iteration 65: Reflective mutation did not propose a new candidate\n",
      "Iteration 66: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 66: All subsample scores perfect. Skipping.\n",
      "Iteration 66: Reflective mutation did not propose a new candidate\n",
      "Iteration 67: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 67: All subsample scores perfect. Skipping.\n",
      "Iteration 67: Reflective mutation did not propose a new candidate\n",
      "Iteration 68: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 68: All subsample scores perfect. Skipping.\n",
      "Iteration 68: Reflective mutation did not propose a new candidate\n",
      "Iteration 69: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 69: All subsample scores perfect. Skipping.\n",
      "Iteration 69: Reflective mutation did not propose a new candidate\n",
      "Iteration 70: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 70: All subsample scores perfect. Skipping.\n",
      "Iteration 70: Reflective mutation did not propose a new candidate\n",
      "Iteration 71: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 71: All subsample scores perfect. Skipping.\n",
      "Iteration 71: Reflective mutation did not propose a new candidate\n",
      "Iteration 72: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 72: All subsample scores perfect. Skipping.\n",
      "Iteration 72: Reflective mutation did not propose a new candidate\n",
      "Iteration 73: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 1 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 73: All subsample scores perfect. Skipping.\n",
      "Iteration 73: Reflective mutation did not propose a new candidate\n",
      "Iteration 74: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 74: All subsample scores perfect. Skipping.\n",
      "Iteration 74: Reflective mutation did not propose a new candidate\n",
      "Iteration 75: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n",
      "WARNING:root:Batch item 2 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 75: All subsample scores perfect. Skipping.\n",
      "Iteration 75: Reflective mutation did not propose a new candidate\n",
      "Iteration 76: Selected program 0 score: 1.4079332968094032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Batch item 0 failed to meet stage 1 threshold\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 76: All subsample scores perfect. Skipping.\n",
      "Iteration 76: Reflective mutation did not propose a new candidate\n",
      "Iteration 77: Selected program 0 score: 1.4079332968094032\n",
      "Iteration 77: Proposed new text for program: \"\"\"Function minimization example for OpenEvolve\"\"\"\n",
      "import numpy as np\n",
      "import random\n",
      "\n",
      "\n",
      "def search_algorithm(iterations=5000, bounds=(-5, 5)):\n",
      "    \"\"\"\n",
      "    An improved search algorithm combining random search with a form of simulated annealing\n",
      "    and a local search to escape local minima and find the global minimum.\n",
      "\n",
      "    Args:\n",
      "        iterations: Number of iterations to run\n",
      "        bounds: Bounds for the search space (min, max)\n",
      "\n",
      "    Returns:\n",
      "        Tuple of (best_x, best_y, best_value)\n",
      "    \"\"\"\n",
      "    # Initialize with a random point\n",
      "    best_x = np.random.uniform(bounds[0], bounds[1])\n",
      "    best_y = np.random.uniform(bounds[0], bounds[1])\n",
      "    best_value = evaluate_function(best_x, best_y)\n",
      "\n",
      "    # Parameters for a simplified simulated annealing approach\n",
      "    temperature = 1.0\n",
      "    cooling_rate = 0.995\n",
      "    num_local_search_steps = 10\n",
      "\n",
      "    for i in range(iterations):\n",
      "        # Introduce exploration by sometimes taking a worse step based on temperature\n",
      "        if random.random() < temperature and best_value != -np.inf:\n",
      "            # Perturb existing best solution\n",
      "            x = best_x + np.random.normal(0, (bounds[1] - bounds[0]) / 10)\n",
      "            y = best_y + np.random.normal(0, (bounds[1] - bounds[0]) / 10)\n",
      "            x = np.clip(x, bounds[0], bounds[1])\n",
      "            y = np.clip(y, bounds[0], bounds[1])\n",
      "        else:\n",
      "            # Standard random exploration\n",
      "            x = np.random.uniform(bounds[0], bounds[1])\n",
      "            y = np.random.uniform(bounds[0], bounds[1])\n",
      "\n",
      "        value = evaluate_function(x, y)\n",
      "\n",
      "        # Decide whether to accept the new point\n",
      "        if value < best_value:\n",
      "            best_value = value\n",
      "            best_x, best_y = x, y\n",
      "\n",
      "        # Local search to refine the current best solution\n",
      "        if i % (iterations // (iterations // num_local_search_steps + 1)) == 0 and best_value != -np.inf:\n",
      "            local_best_x, local_best_y = best_x, best_y\n",
      "            local_best_value = best_value\n",
      "            for _ in range(num_local_search_steps):\n",
      "                # Small random step for local refinement\n",
      "                step_size = (bounds[1] - bounds[0]) / 20 * temperature\n",
      "                lx = local_best_x + np.random.normal(0, step_size)\n",
      "                ly = local_best_y + np.random.normal(0, step_size)\n",
      "                lx = np.clip(lx, bounds[0], bounds[1])\n",
      "                ly = np.clip(ly, bounds[0], bounds[1])\n",
      "                lvalue = evaluate_function(lx, ly)\n",
      "\n",
      "                if lvalue < local_best_value:\n",
      "                    local_best_value = lvalue\n",
      "                    local_best_x, local_best_y = lx, ly\n",
      "\n",
      "            if local_best_value < best_value:\n",
      "                best_value = local_best_value\n",
      "                best_x, best_y = local_best_x, local_best_y\n",
      "\n",
      "        # Cool down the temperature\n",
      "        temperature *= cooling_rate\n",
      "\n",
      "    return best_x, best_y, best_value\n",
      "Iteration 77: New subsample score 4.498619901343968 is better than old score 3.3720183427253145. Continue to full eval and add to candidate pool.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 77: Found a better program on the valset with score 1.4995399671550813.\n",
      "Iteration 77: Valset score for new program: 1.4995399671550813 (coverage 1 / 1)\n",
      "Iteration 77: Val aggregate for new program: 1.4995399671550813\n",
      "Iteration 77: Individual valset scores for new program: {0: 1.4995399671550813}\n",
      "Iteration 77: New valset pareto front scores: {0: 1.4995399671550813}\n",
      "Iteration 77: Valset pareto front aggregate score: 1.4995399671550813\n",
      "Iteration 77: Updated valset pareto front programs: {0: {2}}\n",
      "Iteration 77: Best valset aggregate score so far: 1.4995399671550813\n",
      "Iteration 77: Best program as per aggregate score on valset: 2\n",
      "Iteration 77: Best score on valset: 1.4995399671550813\n",
      "Iteration 77: Linear pareto front program index: 2\n",
      "Iteration 77: New program candidate index: 2\n",
      "Iteration 78: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 78: All subsample scores perfect. Skipping.\n",
      "Iteration 78: Reflective mutation did not propose a new candidate\n",
      "Iteration 79: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 79: All subsample scores perfect. Skipping.\n",
      "Iteration 79: Reflective mutation did not propose a new candidate\n",
      "Iteration 80: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 80: All subsample scores perfect. Skipping.\n",
      "Iteration 80: Reflective mutation did not propose a new candidate\n",
      "Iteration 81: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 81: All subsample scores perfect. Skipping.\n",
      "Iteration 81: Reflective mutation did not propose a new candidate\n",
      "Iteration 82: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 82: All subsample scores perfect. Skipping.\n",
      "Iteration 82: Reflective mutation did not propose a new candidate\n",
      "Iteration 83: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 83: All subsample scores perfect. Skipping.\n",
      "Iteration 83: Reflective mutation did not propose a new candidate\n",
      "Iteration 84: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 84: All subsample scores perfect. Skipping.\n",
      "Iteration 84: Reflective mutation did not propose a new candidate\n",
      "Iteration 85: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 85: All subsample scores perfect. Skipping.\n",
      "Iteration 85: Reflective mutation did not propose a new candidate\n",
      "Iteration 86: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 86: All subsample scores perfect. Skipping.\n",
      "Iteration 86: Reflective mutation did not propose a new candidate\n",
      "Iteration 87: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 87: All subsample scores perfect. Skipping.\n",
      "Iteration 87: Reflective mutation did not propose a new candidate\n",
      "Iteration 88: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 88: All subsample scores perfect. Skipping.\n",
      "Iteration 88: Reflective mutation did not propose a new candidate\n",
      "Iteration 89: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 89: All subsample scores perfect. Skipping.\n",
      "Iteration 89: Reflective mutation did not propose a new candidate\n",
      "Iteration 90: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 90: All subsample scores perfect. Skipping.\n",
      "Iteration 90: Reflective mutation did not propose a new candidate\n",
      "Iteration 91: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 91: All subsample scores perfect. Skipping.\n",
      "Iteration 91: Reflective mutation did not propose a new candidate\n",
      "Iteration 92: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 92: All subsample scores perfect. Skipping.\n",
      "Iteration 92: Reflective mutation did not propose a new candidate\n",
      "Iteration 93: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 93: All subsample scores perfect. Skipping.\n",
      "Iteration 93: Reflective mutation did not propose a new candidate\n",
      "Iteration 94: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 94: All subsample scores perfect. Skipping.\n",
      "Iteration 94: Reflective mutation did not propose a new candidate\n",
      "Iteration 95: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 95: All subsample scores perfect. Skipping.\n",
      "Iteration 95: Reflective mutation did not propose a new candidate\n",
      "Iteration 96: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 96: All subsample scores perfect. Skipping.\n",
      "Iteration 96: Reflective mutation did not propose a new candidate\n",
      "Iteration 97: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 97: All subsample scores perfect. Skipping.\n",
      "Iteration 97: Reflective mutation did not propose a new candidate\n",
      "Iteration 98: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 98: All subsample scores perfect. Skipping.\n",
      "Iteration 98: Reflective mutation did not propose a new candidate\n",
      "Iteration 99: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 99: All subsample scores perfect. Skipping.\n",
      "Iteration 99: Reflective mutation did not propose a new candidate\n",
      "Iteration 100: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100: All subsample scores perfect. Skipping.\n",
      "Iteration 100: Reflective mutation did not propose a new candidate\n",
      "Iteration 101: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 101: All subsample scores perfect. Skipping.\n",
      "Iteration 101: Reflective mutation did not propose a new candidate\n",
      "Iteration 102: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 102: All subsample scores perfect. Skipping.\n",
      "Iteration 102: Reflective mutation did not propose a new candidate\n",
      "Iteration 103: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 103: All subsample scores perfect. Skipping.\n",
      "Iteration 103: Reflective mutation did not propose a new candidate\n",
      "Iteration 104: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 104: All subsample scores perfect. Skipping.\n",
      "Iteration 104: Reflective mutation did not propose a new candidate\n",
      "Iteration 105: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 105: All subsample scores perfect. Skipping.\n",
      "Iteration 105: Reflective mutation did not propose a new candidate\n",
      "Iteration 106: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 106: All subsample scores perfect. Skipping.\n",
      "Iteration 106: Reflective mutation did not propose a new candidate\n",
      "Iteration 107: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 107: All subsample scores perfect. Skipping.\n",
      "Iteration 107: Reflective mutation did not propose a new candidate\n",
      "Iteration 108: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 108: All subsample scores perfect. Skipping.\n",
      "Iteration 108: Reflective mutation did not propose a new candidate\n",
      "Iteration 109: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 109: All subsample scores perfect. Skipping.\n",
      "Iteration 109: Reflective mutation did not propose a new candidate\n",
      "Iteration 110: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 110: All subsample scores perfect. Skipping.\n",
      "Iteration 110: Reflective mutation did not propose a new candidate\n",
      "Iteration 111: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 111: All subsample scores perfect. Skipping.\n",
      "Iteration 111: Reflective mutation did not propose a new candidate\n",
      "Iteration 112: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 112: All subsample scores perfect. Skipping.\n",
      "Iteration 112: Reflective mutation did not propose a new candidate\n",
      "Iteration 113: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 113: All subsample scores perfect. Skipping.\n",
      "Iteration 113: Reflective mutation did not propose a new candidate\n",
      "Iteration 114: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 114: All subsample scores perfect. Skipping.\n",
      "Iteration 114: Reflective mutation did not propose a new candidate\n",
      "Iteration 115: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 115: All subsample scores perfect. Skipping.\n",
      "Iteration 115: Reflective mutation did not propose a new candidate\n",
      "Iteration 116: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 116: All subsample scores perfect. Skipping.\n",
      "Iteration 116: Reflective mutation did not propose a new candidate\n",
      "Iteration 117: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 117: All subsample scores perfect. Skipping.\n",
      "Iteration 117: Reflective mutation did not propose a new candidate\n",
      "Iteration 118: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 118: All subsample scores perfect. Skipping.\n",
      "Iteration 118: Reflective mutation did not propose a new candidate\n",
      "Iteration 119: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 119: All subsample scores perfect. Skipping.\n",
      "Iteration 119: Reflective mutation did not propose a new candidate\n",
      "Iteration 120: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 120: All subsample scores perfect. Skipping.\n",
      "Iteration 120: Reflective mutation did not propose a new candidate\n",
      "Iteration 121: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 121: All subsample scores perfect. Skipping.\n",
      "Iteration 121: Reflective mutation did not propose a new candidate\n",
      "Iteration 122: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 122: All subsample scores perfect. Skipping.\n",
      "Iteration 122: Reflective mutation did not propose a new candidate\n",
      "Iteration 123: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 123: All subsample scores perfect. Skipping.\n",
      "Iteration 123: Reflective mutation did not propose a new candidate\n",
      "Iteration 124: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 124: All subsample scores perfect. Skipping.\n",
      "Iteration 124: Reflective mutation did not propose a new candidate\n",
      "Iteration 125: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 125: All subsample scores perfect. Skipping.\n",
      "Iteration 125: Reflective mutation did not propose a new candidate\n",
      "Iteration 126: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 126: All subsample scores perfect. Skipping.\n",
      "Iteration 126: Reflective mutation did not propose a new candidate\n",
      "Iteration 127: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 127: All subsample scores perfect. Skipping.\n",
      "Iteration 127: Reflective mutation did not propose a new candidate\n",
      "Iteration 128: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 128: All subsample scores perfect. Skipping.\n",
      "Iteration 128: Reflective mutation did not propose a new candidate\n",
      "Iteration 129: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 129: All subsample scores perfect. Skipping.\n",
      "Iteration 129: Reflective mutation did not propose a new candidate\n",
      "Iteration 130: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 130: All subsample scores perfect. Skipping.\n",
      "Iteration 130: Reflective mutation did not propose a new candidate\n",
      "Iteration 131: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 131: All subsample scores perfect. Skipping.\n",
      "Iteration 131: Reflective mutation did not propose a new candidate\n",
      "Iteration 132: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 132: All subsample scores perfect. Skipping.\n",
      "Iteration 132: Reflective mutation did not propose a new candidate\n",
      "Iteration 133: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 133: All subsample scores perfect. Skipping.\n",
      "Iteration 133: Reflective mutation did not propose a new candidate\n",
      "Iteration 134: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 134: All subsample scores perfect. Skipping.\n",
      "Iteration 134: Reflective mutation did not propose a new candidate\n",
      "Iteration 135: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 135: All subsample scores perfect. Skipping.\n",
      "Iteration 135: Reflective mutation did not propose a new candidate\n",
      "Iteration 136: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 136: All subsample scores perfect. Skipping.\n",
      "Iteration 136: Reflective mutation did not propose a new candidate\n",
      "Iteration 137: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 137: All subsample scores perfect. Skipping.\n",
      "Iteration 137: Reflective mutation did not propose a new candidate\n",
      "Iteration 138: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 138: All subsample scores perfect. Skipping.\n",
      "Iteration 138: Reflective mutation did not propose a new candidate\n",
      "Iteration 139: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 139: All subsample scores perfect. Skipping.\n",
      "Iteration 139: Reflective mutation did not propose a new candidate\n",
      "Iteration 140: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 140: All subsample scores perfect. Skipping.\n",
      "Iteration 140: Reflective mutation did not propose a new candidate\n",
      "Iteration 141: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 141: All subsample scores perfect. Skipping.\n",
      "Iteration 141: Reflective mutation did not propose a new candidate\n",
      "Iteration 142: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 142: All subsample scores perfect. Skipping.\n",
      "Iteration 142: Reflective mutation did not propose a new candidate\n",
      "Iteration 143: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 143: All subsample scores perfect. Skipping.\n",
      "Iteration 143: Reflective mutation did not propose a new candidate\n",
      "Iteration 144: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 144: All subsample scores perfect. Skipping.\n",
      "Iteration 144: Reflective mutation did not propose a new candidate\n",
      "Iteration 145: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 145: All subsample scores perfect. Skipping.\n",
      "Iteration 145: Reflective mutation did not propose a new candidate\n",
      "Iteration 146: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 146: All subsample scores perfect. Skipping.\n",
      "Iteration 146: Reflective mutation did not propose a new candidate\n",
      "Iteration 147: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 147: All subsample scores perfect. Skipping.\n",
      "Iteration 147: Reflective mutation did not propose a new candidate\n",
      "Iteration 148: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 148: All subsample scores perfect. Skipping.\n",
      "Iteration 148: Reflective mutation did not propose a new candidate\n",
      "Iteration 149: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 149: All subsample scores perfect. Skipping.\n",
      "Iteration 149: Reflective mutation did not propose a new candidate\n",
      "Iteration 150: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 150: All subsample scores perfect. Skipping.\n",
      "Iteration 150: Reflective mutation did not propose a new candidate\n",
      "Iteration 151: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 151: All subsample scores perfect. Skipping.\n",
      "Iteration 151: Reflective mutation did not propose a new candidate\n",
      "Iteration 152: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 152: All subsample scores perfect. Skipping.\n",
      "Iteration 152: Reflective mutation did not propose a new candidate\n",
      "Iteration 153: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 153: All subsample scores perfect. Skipping.\n",
      "Iteration 153: Reflective mutation did not propose a new candidate\n",
      "Iteration 154: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 154: All subsample scores perfect. Skipping.\n",
      "Iteration 154: Reflective mutation did not propose a new candidate\n",
      "Iteration 155: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 155: All subsample scores perfect. Skipping.\n",
      "Iteration 155: Reflective mutation did not propose a new candidate\n",
      "Iteration 156: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 156: All subsample scores perfect. Skipping.\n",
      "Iteration 156: Reflective mutation did not propose a new candidate\n",
      "Iteration 157: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 157: All subsample scores perfect. Skipping.\n",
      "Iteration 157: Reflective mutation did not propose a new candidate\n",
      "Iteration 158: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 158: All subsample scores perfect. Skipping.\n",
      "Iteration 158: Reflective mutation did not propose a new candidate\n",
      "Iteration 159: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 159: All subsample scores perfect. Skipping.\n",
      "Iteration 159: Reflective mutation did not propose a new candidate\n",
      "Iteration 160: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 160: All subsample scores perfect. Skipping.\n",
      "Iteration 160: Reflective mutation did not propose a new candidate\n",
      "Iteration 161: Selected program 2 score: 1.4995399671550813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization: 100%|| 498/500 [06:26<00:01,  1.29rollouts/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 161: All subsample scores perfect. Skipping.\n",
      "Iteration 161: Reflective mutation did not propose a new candidate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Run GEPA optimization\n",
    "result = optimize(\n",
    "    seed_candidate=seed_candidate,\n",
    "    trainset=trainset,\n",
    "    adapter=adapter,\n",
    "    max_metric_calls=500,  # Budget for evaluation calls -  adjust as needed\n",
    "    display_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 1.4995399671550813\n",
      "Best candidate index: 2\n",
      "Total candidates evaluated: 3\n",
      "Total metric calls: 501\n",
      "\n",
      "Best candidate program:\n",
      "\"\"\"Function minimization example for OpenEvolve\"\"\"\n",
      "import numpy as np\n",
      "import random\n",
      "\n",
      "\n",
      "def search_algorithm(iterations=5000, bounds=(-5, 5)):\n",
      "    \"\"\"\n",
      "    An improved search algorithm combining random search with a form of simulated annealing\n",
      "    and a local search to escape local minima and find the global minimum.\n",
      "\n",
      "    Args:\n",
      "        iterations: Number of iterations to run\n",
      "        bounds: Bounds for the search space (min, max)\n",
      "\n",
      "    Returns:\n",
      "        Tuple of (best_x, best_y, best_value)\n",
      "    \"\"\"\n",
      "    # Initialize with a random point\n",
      "    best_x = np.random.uniform(bounds[0], bounds[1])\n",
      "    best_y = np.random.uniform(bounds[0], bounds[1])\n",
      "    best_value = evaluate_function(best_x, best_y)\n",
      "\n",
      "    # Parameters for a simplified simulated annealing approach\n",
      "    temperature = 1.0\n",
      "    cooling_rate = 0.995\n",
      "    num_local_search_steps = 10\n",
      "\n",
      "    for i in range(iterations):\n",
      "        # Introduce exploration by sometimes taking a worse step based on temperature\n",
      "        if random.random() < temperature and best_value != -np.inf:\n",
      "            # Perturb existing best solution\n",
      "            x = best_x + np.random.normal(0, (bounds[1] - bounds[0]) / 10)\n",
      "            y = best_y + np.random.normal(0, (bounds[1] - bounds[0]) / 10)\n",
      "            x = np.clip(x, bounds[0], bounds[1])\n",
      "            y = np.clip(y, bounds[0], bounds[1])\n",
      "        else:\n",
      "            # Standard random exploration\n",
      "            x = np.random.uniform(bounds[0], bounds[1])\n",
      "            y = np.random.uniform(bounds[0], bounds[1])\n",
      "\n",
      "        value = evaluate_function(x, y)\n",
      "\n",
      "        # Decide whether to accept the new point\n",
      "        if value < best_value:\n",
      "            best_value = value\n",
      "            best_x, best_y = x, y\n",
      "\n",
      "        # Local search to refine the current best solution\n",
      "        if i % (iterations // (iterations // num_local_search_steps + 1)) == 0 and best_value != -np.inf:\n",
      "            local_best_x, local_best_y = best_x, best_y\n",
      "            local_best_value = best_value\n",
      "            for _ in range(num_local_search_steps):\n",
      "                # Small random step for local refinement\n",
      "                step_size = (bounds[1] - bounds[0]) / 20 * temperature\n",
      "                lx = local_best_x + np.random.normal(0, step_size)\n",
      "                ly = local_best_y + np.random.normal(0, step_size)\n",
      "                lx = np.clip(lx, bounds[0], bounds[1])\n",
      "                ly = np.clip(ly, bounds[0], bounds[1])\n",
      "                lvalue = evaluate_function(lx, ly)\n",
      "\n",
      "                if lvalue < local_best_value:\n",
      "                    local_best_value = lvalue\n",
      "                    local_best_x, local_best_y = lx, ly\n",
      "\n",
      "            if local_best_value < best_value:\n",
      "                best_value = local_best_value\n",
      "                best_x, best_y = local_best_x, local_best_y\n",
      "\n",
      "        # Cool down the temperature\n",
      "        temperature *= cooling_rate\n",
      "\n",
      "    return best_x, best_y, best_value\n"
     ]
    }
   ],
   "source": [
    "# Get the best score\n",
    "best_score = result.val_aggregate_scores[result.best_idx]\n",
    "print(f\"Best score: {best_score}\")\n",
    "print(f\"Best candidate index: {result.best_idx}\")\n",
    "print(f\"Total candidates evaluated: {len(result.candidates)}\")\n",
    "print(f\"Total metric calls: {result.total_metric_calls}\")\n",
    "\n",
    "# The evolved program is in result.best_candidate[\"program\"]\n",
    "print(\"\\nBest candidate program:\")\n",
    "print(result.best_candidate.get(\"program\", \"N/A\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Results Comparison with OpenEvolve\n",
    "\n",
    "Let's compare GEPA's results with the original OpenEvolve results from their function minimization example. We'll visualize the evolution of metrics over iterations and compare the final performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Score: 1.4079\n",
      "Best Score: 1.4995\n",
      "Improvement: 6.51%\n",
      "Total Candidates Evaluated: 3\n",
      "Total Metric Calls: 501\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract score progression over iterations\n",
    "eval_counts = result.discovery_eval_counts\n",
    "scores = result.val_aggregate_scores\n",
    "\n",
    "# Sort by evaluation count to show progression\n",
    "sorted_indices = sorted(range(len(eval_counts)), key=lambda i: eval_counts[i])\n",
    "sorted_eval_counts = [eval_counts[i] for i in sorted_indices]\n",
    "sorted_scores = [scores[i] for i in sorted_indices]\n",
    "\n",
    "# Create visualization of evolution\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Plot: Score progression over metric calls\n",
    "ax.plot(sorted_eval_counts, sorted_scores, \"o-\", linewidth=2, markersize=6, color=\"#2E86AB\", label=\"GEPA Evolution\")\n",
    "ax.axhline(y=sorted_scores[0], color=\"r\", linestyle=\"--\", alpha=0.5, label=\"Initial Score\")\n",
    "ax.axhline(y=sorted_scores[-1], color=\"g\", linestyle=\"--\", alpha=0.5, label=\"Best Score\")\n",
    "ax.set_xlabel(\"Metric Calls\", fontsize=12)\n",
    "ax.set_ylabel(\"Combined Score\", fontsize=12)\n",
    "ax.set_title(\"GEPA Score Evolution Over Iterations\", fontsize=14, fontweight=\"bold\")\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, max(sorted_scores) * 1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Initial Score: {sorted_scores[0]:.4f}\")\n",
    "print(f\"Best Score: {sorted_scores[-1]:.4f}\")\n",
    "improvement = ((sorted_scores[-1] - sorted_scores[0]) / sorted_scores[0] * 100) if sorted_scores[0] > 0 else 0\n",
    "print(f\"Improvement: {improvement:.2f}%\")\n",
    "print(f\"Total Candidates Evaluated: {len(result.candidates)}\")\n",
    "print(f\"Total Metric Calls: {result.total_metric_calls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEPA Best Candidate Detailed Metrics:\n",
      "==================================================\n",
      "value_score: 0.9997\n",
      "distance_score: 0.9995\n",
      "reliability_score: 1.0000\n",
      "combined_score: 1.4995\n"
     ]
    }
   ],
   "source": [
    "# Re-evaluate the best candidate to get detailed metrics for comparison\n",
    "evaluator_path = project_path / \"evaluator.py\"\n",
    "spec = importlib.util.spec_from_file_location(\"evaluator\", evaluator_path)\n",
    "evaluator_module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(evaluator_module)\n",
    "evaluate = evaluator_module.evaluate\n",
    "\n",
    "# Use the adapter's _construct_complete_program method to ensure\n",
    "# the full program is constructed (including run_search() and other fixed code)\n",
    "# (as best_candidate[\"program\"] may only contain the evolved block)\n",
    "best_program_text = result.best_candidate.get(\"program\", \"\")\n",
    "complete_program = adapter._construct_complete_program(best_program_text)\n",
    "\n",
    "with tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".py\", delete=False) as f:\n",
    "    f.write(complete_program)\n",
    "    temp_program_path = f.name\n",
    "\n",
    "best_result = evaluate(temp_program_path, trainset[0])\n",
    "gepa_metrics = best_result.metrics\n",
    "\n",
    "gepa_detailed = {\n",
    "    \"value_score\": gepa_metrics.get(\"value_score\", 0.0),\n",
    "    \"distance_score\": gepa_metrics.get(\"distance_score\", 0.0),\n",
    "    \"reliability_score\": gepa_metrics.get(\"reliability_score\", 0.0),\n",
    "    \"combined_score\": gepa_metrics.get(\"combined_score\", 0.0),\n",
    "}\n",
    "\n",
    "os.unlink(temp_program_path)\n",
    "\n",
    "print(\"GEPA Best Candidate Detailed Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in gepa_detailed.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this to the metrics as given by the OpenEvolve README.md for function minimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenEvolve Best Candidate Detailed Metrics:\n",
      "==================================================\n",
      "value_score: 0.9900\n",
      "distance_score: 0.9210\n",
      "reliability_score: 1.0000\n",
      "combined_score: 0.9220\n"
     ]
    }
   ],
   "source": [
    "openevolve_metrics = {\n",
    "    \"value_score\": 0.990,\n",
    "    \"distance_score\": 0.921,\n",
    "    \"reliability_score\": 1.000,\n",
    "    \"combined_score\": 0.922,\n",
    "}\n",
    "print(\"OpenEvolve Best Candidate Detailed Metrics:\")\n",
    "print(\"=\" * 50)\n",
    "for metric, value in openevolve_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Reference: Before vs After\n",
    "\n",
    "### Original OpenEvolve Evaluate Function:\n",
    "```python\n",
    "def evaluate(program_path: str) -> EvaluationResult:\n",
    "    # Hard-coded problem parameters\n",
    "    GLOBAL_MIN_X = -1.704\n",
    "    GLOBAL_MIN_Y = 0.678\n",
    "    GLOBAL_MIN_VALUE = -1.519\n",
    "    \n",
    "    # Run program multiple times (trials) and aggregate\n",
    "    x_values = []\n",
    "    y_values = []\n",
    "    values = []\n",
    "    for trial in range(num_trials):  # e.g., 10 trials\n",
    "        result = program.run_search()\n",
    "        x, y, value = result\n",
    "        x_values.append(x)\n",
    "        y_values.append(y)\n",
    "        values.append(value)\n",
    "    \n",
    "    # Aggregate across all trials\n",
    "    avg_value = np.mean(values)\n",
    "    avg_distance = np.mean(distances)\n",
    "    # ... calculate aggregated metrics ...\n",
    "    \n",
    "    # Return single aggregated result\n",
    "    return EvaluationResult(metrics={...}, artifacts={...})\n",
    "```\n",
    "\n",
    "### Modified for EvolveAdapter:\n",
    "```python\n",
    "def evaluate(program_path: str, data_instance: dict) -> EvaluationResult:\n",
    "    # Extract parameters from data instance\n",
    "    # (Extraction method depends on the type of data_instance, e.g. dict for our function minimization example)\n",
    "    GLOBAL_MIN_X = data_instance.get(\"global_min_x\", -1.704)\n",
    "    GLOBAL_MIN_Y = data_instance.get(\"global_min_y\", 0.678)\n",
    "    GLOBAL_MIN_VALUE = data_instance.get(\"global_min_value\", -1.519)\n",
    "    \n",
    "    # Run program multiple times for this data instance\n",
    "    for trial in range(num_trials):\n",
    "        result = program.run_search()\n",
    "        # ... aggregate results for this data instance ...\n",
    "    \n",
    "    # Return single result for this data instance\n",
    "    return EvaluationResult(metrics={...}, artifacts={...})\n",
    "```\n",
    "\n",
    "## Notes:\n",
    "\n",
    "1. **Data Instance Structure**: Each item in the batch (trainset) should represent a distinct evaluation instance. `data_instance` can be any type. Use whatever type suits your original project setup.\n",
    "\n",
    "2. **Error Handling**: If evaluation fails for a specific data instance, return an `EvaluationResult` with error metrics rather than raising an exception.\n",
    "\n",
    "4. **Metrics**: The `EvaluationResult` should include a `\"combined_score\"` metric in its `metrics` dict, as this is used by GEPA for optimization.\n",
    "\n",
    "5. **Artifacts**: Use the `artifacts` field to store additional information. The adapter automatically uses these artifacts to create feedback for program improvement.\n",
    "\n",
    "6. **Cascade Evaluation**: If your project uses cascade evaluation, remember to modify **all** stage functions (`evaluate_stage1`, `evaluate_stage2`, etc.) to accept `data_instance` and return a single `EvaluationResult` for that data instance. See Step 2 for details.\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. Modify your `evaluator.py` to accept `data_instance` parameter and return a single `EvaluationResult` for that data instance\n",
    "2. **If using cascade evaluation**: Modify all stage functions (`evaluate_stage1`, `evaluate_stage2`, etc.) to accept `data_instance` and return a single `EvaluationResult` for that data instance\n",
    "3. Test with a small batch to ensure everything works\n",
    "4. Run GEPA optimization with your adapted project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
