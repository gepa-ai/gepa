{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "outline",
   "metadata": {},
   "source": [
    "# `optimize_anything`: A Universal API for Text-Based Optimization\n",
    "\n",
    "**TL;DR**: We introduce `optimize_anything`, a single, declarative API that uses LLMs as intelligent proposers to optimize *anything* representable as text—code, prompts, configurations, agent architectures. The key insight: if it can be serialized to text, an LLM can reason about it and propose improvements. The secret sauce? **A**uxiliary **S**ide **I**nformation (ASI).\n",
    "\n",
    "---\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Unified Interface**: Whether you're optimizing prompts, code, hyperparameters, or agent architectures, the API is the same—just provide a `seed_candidate` (starting point) and a `fitness_fn` (how good are we doing?).\n",
    "\n",
    "2. **The Convex Hull of Optimization**: `optimize_anything` is designed to be the \"convex hull\" of all text-based optimization problems. Different libraries optimize different things (Optuna for hyperparameters, evolutionary strategies for algorithms, gradient descent for neural networks). We unify them under one abstraction.\n",
    "\n",
    "3. **Side Information is Key**: Unlike traditional optimizers that only see scalar scores, GEPA's LLM-based reflection can understand *why* a candidate performed poorly through rich diagnostic information—error messages, execution traces, partial results.\n",
    "\n",
    "4. **Emergent Capabilities**: GEPA can discover sophisticated strategies (like self-refinement) that weren't explicitly programmed—they emerge from the optimization process itself.\n",
    "\n",
    "---\n",
    "\n",
    "## Results Summary\n",
    "\n",
    "| Domain | Task | Baseline | Optimized | Improvement |\n",
    "|--------|------|----------|-----------|-------------|\n",
    "| **Mathematical Optimization** | EvalSet Benchmark | Optuna TPE | GEPA | Outperforms Optuna |\n",
    "| **Prompt Engineering** | AIME 2025 (GPT-4.1 Mini) | 46.67% | 60.00% | +13.33% absolute |\n",
    "| **Agent Evolution** | ARC-AGI (GPT-5) | 56.5% | 68.0% | +11.5% absolute |\n",
    "| **Algorithmic Discovery** | Circle Packing (N=26) | 0.9798 | 2.6359 | Exceeds AlphaEvolve |\n",
    "| **Systems: Scheduling** | Can't Be Late | Cost 96.48 | Cost 89.86 | **6.9% savings** |\n",
    "| **Systems: Networking** | Cloudcast | $191 | $120 | **37.3% savings** |\n",
    "\n",
    "---\n",
    "\n",
    "## Outline\n",
    "\n",
    "1. **[The Landscape of Optimization (The \"Old\" Way)](#section-1)** — The fragmented world of optimization libraries\n",
    "2. **[The Unifying Abstraction: `optimize_anything`](#section-2)** — One API to rule them all\n",
    "3. **[The Secret Weapon: Auxiliary Side Information (ASI)](#section-3)** — Why GEPA outperforms traditional optimizers\n",
    "4. **[Example 1: Mathematical Optimization](#section-4)** — Evolving code to beat Optuna on EvalSet\n",
    "5. **[Example 2: Prompt Engineering](#section-5)** — Optimizing prompts for AIME 2025\n",
    "6. **[Example 3: Agent Program Evolution](#section-6)** — Evolving DSPy programs for ARC-AGI\n",
    "7. **[Example 4: Algorithmic Discovery](#section-7)** — Circle packing that matches AlphaEvolve\n",
    "8. **[Example 5: Systems Optimization](#section-adrs)** — Cloud infrastructure cost reduction\n",
    "9. **[How It Works Under the Hood](#section-8)** — The GEPA engine\n",
    "10. **[Conclusion](#section-9)** — From imperative to declarative optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-1\"></a>\n",
    "# 1. The Landscape of Optimization (The \"Old\" Way)\n",
    "\n",
    "The world of optimization is **fragmented**. Each problem domain has its own specialized library with its own API, paradigm, and learning curve. Let's look at the major categories:\n",
    "\n",
    "### Hyperparameter/Black-Box Optimization (Optuna)\n",
    "\n",
    "For hyperparameter tuning, you use Bayesian optimization or Tree-structured Parzen Estimators (TPE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optuna-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 5)\n",
    "    \n",
    "    # Train model and return validation score\n",
    "    model = build_model(lr, n_layers)\n",
    "    return train_and_evaluate(model)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scipy-intro",
   "metadata": {},
   "source": [
    "### Mathematical Optimization (SciPy)\n",
    "\n",
    "For continuous optimization of mathematical functions, you use classical algorithms like L-BFGS-B or SLSQP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ab70cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def rosenbrock(x):\n",
    "    return sum(100*(x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)\n",
    "\n",
    "result = minimize(\n",
    "    rosenbrock, \n",
    "    x0=[0, 0, 0, 0],\n",
    "    method='L-BFGS-B',\n",
    "    bounds=[(-5, 5)] * 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dcea18",
   "metadata": {},
   "source": [
    "### Evolutionary Algorithms (DEAP)\n",
    "\n",
    "For evolving programs or complex structures, you use genetic algorithms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scipy-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools, algorithms\n",
    "\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, 100)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", eval_func)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "population = toolbox.population(n=300)\n",
    "algorithms.eaSimple(population, toolbox, cxpb=0.5, mutpb=0.2, ngen=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deap-intro",
   "metadata": {},
   "source": [
    "### The Problem: Fragmentation\n",
    "\n",
    "**A user needs to learn 3 different paradigms to solve 3 different optimization problems.**\n",
    "\n",
    "| Library | Domain | Paradigm | What You Must Know |\n",
    "|---------|--------|----------|-------------------|\n",
    "| Optuna | Hyperparameters | Bayesian/TPE | Samplers, pruners, search space definition |\n",
    "| SciPy | Mathematical Functions | Classical Methods | Algorithm selection (L-BFGS, SLSQP, etc.) |\n",
    "| DEAP | Evolutionary | Genetic Algorithms | Crossover, mutation, selection operators |\n",
    "\n",
    "Each library has:\n",
    "- **Different APIs and abstractions** — you can't just swap one for another\n",
    "- **Different optimization strategies** hard-coded into the implementation\n",
    "- **Different assumptions** about what can be optimized (differentiable? discrete? continuous?)\n",
    "\n",
    "### The Insight: Text is the Universal Representation\n",
    "\n",
    "Here's the key insight: **if something can be represented as text, an LLM can reason about it and propose improvements**.\n",
    "\n",
    "- **Code** is text → LLMs can write and improve code\n",
    "- **Prompts** are text → LLMs can refine instructions\n",
    "- **Configurations** are text → LLMs can tune JSON/YAML\n",
    "- **Agent architectures** are text → LLMs can evolve program structure\n",
    "\n",
    "What if we had **one API** that could optimize all of them—by leveraging the LLM's ability to understand and generate text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fragmentation-problem",
   "metadata": {},
   "source": [
    "<!-- This cell intentionally left empty - placeholder for removal -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-2\"></a>\n",
    "# 2. The Unifying Abstraction: `optimize_anything`\n",
    "\n",
    "We introduce `optimize_anything`—a single entry point for optimizing any text-representable artifact. It's designed to be the **\"Convex Hull\"** of all optimization problems: every point in the space of text-based optimization can be reached through this API.\n",
    "\n",
    "## The API Signature\n",
    "\n",
    "The API is intentionally minimal. You need only two things:\n",
    "1. **A seed candidate** — your starting point\n",
    "2. **A fitness function** — how to measure success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "api-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gepa.optimize_anything import optimize_anything, GEPAConfig\n",
    "\n",
    "def optimize_anything(\n",
    "    # === REQUIRED ===\n",
    "    seed_candidate: dict[str, str],           # Your starting point (text parameters to optimize)\n",
    "    fitness_fn: FitnessFn,                    # How to measure success\n",
    "    \n",
    "    # === OPTIONAL: Data ===\n",
    "    dataset: list[DataInst] | None = None,   # Examples to optimize on (for example, multiple related tasks)\n",
    "    valset: list[DataInst] | None = None,    # Held-out set for ensuring generalization if required\n",
    "    \n",
    "    # === OPTIONAL: Natural Language Guidance ===\n",
    "    objective: str | None = None,            # What you're trying to achieve (e.g. \"Find a prompt that maximizes accuracy\")\n",
    "    background: str | None = None,           # Domain knowledge, constraints, strategies (e.g. Domain knowledge about the framework which the candidate is written in)\n",
    "    \n",
    "    # === OPTIONAL: Fine-Grained Control ===\n",
    "    config: GEPAConfig | None = None,        # Engine, reflection, tracking settings\n",
    ") -> GEPAResult:\n",
    "    \"\"\"\n",
    "    Optimize any parameterized system using evolutionary algorithms with LLM-based reflection.\n",
    "    \n",
    "    Returns:\n",
    "        GEPAResult containing best_candidate, optimization history, and metrics.\n",
    "    \"\"\"\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "api-philosophy",
   "metadata": {},
   "source": [
    "## The Philosophy: Declare, Don't Implement\n",
    "\n",
    "With `optimize_anything`, the user **declares** the optimization problem:\n",
    "\n",
    "| You Provide | Example | Purpose |\n",
    "|-------------|---------|---------|\n",
    "| `seed_candidate` | `{\"prompt\": \"Solve this math problem:\"}` | Your starting point |\n",
    "| `fitness_fn` | Returns (score, output, side_info) | How to measure success |\n",
    "| `dataset` (optional) | List of test cases | Multi-instance generalization |\n",
    "| `objective` (optional) | \"Find a prompt that maximizes accuracy\" | Natural language guidance |\n",
    "| `background` (optional) | \"Solutions must handle edge cases\" | Domain knowledge |\n",
    "\n",
    "GEPA handles the **how**: proposing mutations, reflecting on failures, selecting candidates, and tracking the optimization trajectory.\n",
    "\n",
    "## Two Modes of Operation\n",
    "\n",
    "### Per-Instance Mode (with `dataset`)\n",
    "\n",
    "For problems where you want parameters that **generalize** across examples:\n",
    "- **Prompt optimization**: The same prompt should work on many math problems\n",
    "- **Agent architecture search**: The same agent should solve many tasks\n",
    "\n",
    "```python\n",
    "# dataset is a list of examples\n",
    "result = optimize_anything(\n",
    "    seed_candidate={\"prompt\": \"Solve:\"},\n",
    "    fitness_fn=evaluate_prompt,\n",
    "    dataset=math_problems,  # ← Optimize across these\n",
    "    valset=held_out_problems,  # ← Test generalization\n",
    ")\n",
    "```\n",
    "\n",
    "### Single-Instance Mode (without `dataset`)\n",
    "\n",
    "For problems defined by a **single optimization target**:\n",
    "- **Circle packing**: Maximize sum of radii for N circles\n",
    "- **Code evolution**: Minimize a mathematical function\n",
    "\n",
    "```python\n",
    "# dataset=None triggers single-instance mode\n",
    "result = optimize_anything(\n",
    "    seed_candidate={\"code\": \"def solve(): ...\"},\n",
    "    fitness_fn=evaluate_code,\n",
    "    dataset=None,  # ← Single optimization target\n",
    ")\n",
    "```\n",
    "\n",
    "## The Fitness Function: Your Optimization Signal\n",
    "\n",
    "The fitness function is where you define *what* you're optimizing for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitness-fn-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "\n",
    "def fitness_fn(\n",
    "    candidate: dict[str, str],  # The parameters being optimized\n",
    "    example: Any | None = None  # A single data instance (None for single-instance mode)\n",
    ") -> tuple[float, Any, dict]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        score: Higher is better\n",
    "        output: The actual output produced (for tracking)\n",
    "        side_info: Diagnostic information for LLM reflection\n",
    "    \"\"\"\n",
    "    # Run your system with the candidate parameters\n",
    "    output = run_my_system(candidate, example)\n",
    "    \n",
    "    # Compute a score (higher is better)\n",
    "    score = compute_score(output, example)\n",
    "    \n",
    "    # Collect diagnostic info for LLM reflection\n",
    "    side_info = {\n",
    "        \"Input\": example[\"input\"],\n",
    "        \"Output\": output,\n",
    "        \"Expected\": example[\"expected\"],\n",
    "        \"Error\": get_error_message(output),\n",
    "    }\n",
    "    \n",
    "    return score, output, side_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "side-info-power",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-3\"></a>\n",
    "# 3. The Secret Weapon: Auxiliary Side Information (ASI)\n",
    "\n",
    "The `side_info` dictionary is GEPA's secret weapon—we call it **ASI** (**A**uxiliary **S**ide **I**nformation). \n",
    "\n",
    "> *While the AI community debates when we'll achieve ASI (Artificial Superintelligence), you can achieve **your** ASI today—just return rich diagnostic information from your fitness function.*\n",
    "\n",
    "## Why ASI Matters\n",
    "\n",
    "Traditional optimizers only see a **scalar score**:\n",
    "\n",
    "```\n",
    "Candidate A → Score: 0.73  (Why did it fail? No idea.)\n",
    "Candidate B → Score: 0.85  (What made it better? Unknown.)\n",
    "```\n",
    "\n",
    "GEPA's LLM-based reflection can understand **why** a candidate performed the way it did:\n",
    "\n",
    "```\n",
    "Candidate A → Score: 0.73\n",
    "  side_info: {\n",
    "    \"Error\": \"Circle 3 and Circle 7 overlap by 0.02 units\",\n",
    "    \"Boundary violations\": [\"Circle 12 extends past x=1.0\"],\n",
    "    \"Best score achieved\": 2.847\n",
    "  }\n",
    "```\n",
    "\n",
    "Now the LLM knows *exactly* what to fix.\n",
    "\n",
    "## What to Include in ASI\n",
    "\n",
    "| Information Type | Example | Purpose |\n",
    "|-----------------|---------|----------|\n",
    "| **Error messages** | `\"SyntaxError: invalid syntax on line 42\"` | Helps LLM fix code bugs |\n",
    "| **Execution traces** | `\"Called API 3x, timeout on 3rd call\"` | Helps LLM understand behavior |\n",
    "| **Partial results** | `\"3/5 test cases passed\"` | Helps LLM identify failure patterns |\n",
    "| **Expected vs Actual** | `\"Expected: [1,2,3], Got: [1,2,4]\"` | Helps LLM understand what went wrong |\n",
    "| **Domain feedback** | `\"Circles overlap at positions (0.5, 0.3)\"` | Helps LLM make domain-aware improvements |\n",
    "| **Reasoning traces** | `\"Model's chain-of-thought: ...\"` | Helps LLM understand failure modes |\n",
    "\n",
    "## The ASI Design Principle\n",
    "\n",
    "**Be generous with information.** Include anything that would help a human expert understand why the candidate succeeded or failed. The LLM will use this to make targeted, intelligent improvements rather than random mutations.\n",
    "\n",
    "```python\n",
    "# Good ASI\n",
    "side_info = {\n",
    "    \"Input\": problem_description,\n",
    "    \"Output\": model_output,\n",
    "    \"Expected\": correct_answer,\n",
    "    \"Reasoning\": model_reasoning_trace,\n",
    "    \"Error\": \"Division by zero on line 15\",\n",
    "    \"Partial scores\": {\"accuracy\": 0.8, \"efficiency\": 0.3},\n",
    "}\n",
    "\n",
    "# Bad ASI (not enough information)\n",
    "side_info = {\"score\": 0.73}  # LLM can't help with just this!\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-4\"></a>\n",
    "# 4. Example 1: Mathematical Optimization — Beating Optuna\n",
    "\n",
    "**Result: GEPA outperforms Optuna on the EvalSet benchmark.**\n",
    "\n",
    "This example demonstrates how `optimize_anything` can evolve **code** that implements optimization algorithms—essentially using LLMs to discover optimization strategies automatically.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "Optuna is the industry standard for black-box optimization. But using Optuna effectively requires:\n",
    "- Choosing sampling algorithms (TPE, CMA-ES, Random, etc.)\n",
    "- Defining search spaces manually\n",
    "- Tuning algorithm-specific hyperparameters\n",
    "- Deep knowledge of optimization theory\n",
    "\n",
    "(Luke: the claims above are too strong? Optuna is actually very simplistic)\n",
    "\n",
    "**What if we could just write code that finds minima, and let GEPA evolve the strategy?**\n",
    "\n",
    "## The Task\n",
    "\n",
    "**Given**: A black-box function `objective_function(x) → float` with bounds\n",
    "**Find**: Python code that discovers the minimum\n",
    "\n",
    "**What GEPA optimizes**: The Python code itself—algorithm choice, implementation, hyperparameters, heuristics.\n",
    "\n",
    "<img src=\"./assets/blog/mathematical_optimization.png\" width=\"60%\">\n",
    "\n",
    "*GEPA starts below Optuna but progressively discovers better strategies, eventually surpassing it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "poly-setup",
   "metadata": {},
   "source": [
    "We use the [EvalSet benchmark](https://github.com/sigopt/evalset)—a collection of challenging optimization test functions (Ackley, Rosenbrock, Rastrigin, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "poly-seed",
   "metadata": {},
   "source": [
    "## The Seed Candidate\n",
    "\n",
    "We start with a trivial baseline—random sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "poly-seed-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_candidate = {\"code\": '''\n",
    "import numpy as np\n",
    "\n",
    "def solve(objective_function, config, best_xs=None):\n",
    "    bounds = np.array(config['bounds'])\n",
    "    all_attempts = []\n",
    "\n",
    "    x = np.random.uniform(bounds[:, 0], bounds[:, 1])\n",
    "    score = objective_function(x)\n",
    "    all_attempts.append({\"x\": x.copy(), \"score\": score})\n",
    "\n",
    "    return {\"x\": x, \"score\": score, \"all_attempts\": all_attempts}\n",
    "'''}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "poly-fitness",
   "metadata": {},
   "source": [
    "## The Fitness Function\n",
    "\n",
    "The fitness function executes the code in a sandbox and captures rich diagnostic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "poly-fitness-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.polynomial.utils import execute_code, extract_best_xs\n",
    "\n",
    "PROBLEM_INDEX = 0\n",
    "EVALUATION_BUDGET = 100\n",
    "\n",
    "\n",
    "def fitness_fn(candidate, best_example_evals):\n",
    "    code = candidate[\"code\"]\n",
    "    best_xs = extract_best_xs(best_example_evals)\n",
    "\n",
    "    result = execute_code(\n",
    "        code=code,\n",
    "        problem_index=PROBLEM_INDEX,\n",
    "        budget=EVALUATION_BUDGET,\n",
    "        best_xs=best_xs,\n",
    "    )\n",
    "\n",
    "    side_info = {\n",
    "        \"score\": result[\"score\"],\n",
    "        \"code\": code,\n",
    "        \"top_50_attempts\": result[\"top_50_attempts\"],\n",
    "        \"bottom_50_attempts\": result[\"bottom_50_attempts\"],\n",
    "        \"Stdout\": result.get(\"stdout\", \"\"),\n",
    "        \"Error\": result.get(\"error\", \"\"),\n",
    "        \"Num attempts\": len(result[\"all_attempts\"]),\n",
    "        \"Allowed attempts\": EVALUATION_BUDGET,\n",
    "        \"Traceback\": result.get(\"traceback\", \"\"),\n",
    "    }\n",
    "\n",
    "    return (result[\"score\"], side_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "poly-optimize",
   "metadata": {},
   "source": [
    "## Running GEPA Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "poly-optimize-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.polynomial.utils import SEED_CODE, OBJECTIVE, BACKGROUND\n",
    "from gepa.optimize_anything import (\n",
    "    optimize_anything,\n",
    "    GEPAConfig,\n",
    "    EngineConfig,\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate={\"code\": SEED_CODE},\n",
    "    fitness_fn=fitness_fn,\n",
    "    config=GEPAConfig(engine=EngineConfig(cache_evaluation=True)),\n",
    "    objective=OBJECTIVE,\n",
    "    background=BACKGROUND,\n",
    ")\n",
    "\n",
    "print(\"Optimized code:\")\n",
    "print(result.best_candidate[\"code\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "poly-evolved",
   "metadata": {},
   "source": [
    "## What GEPA Discovered\n",
    "\n",
    "GEPA evolved the trivial random sampler into a sophisticated optimization strategy. Here's a snippet from the evolved code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "poly-evolved-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolved by GEPA - combines multiple strategies:\n",
    "\n",
    "evolved_code = '''\n",
    "import numpy as np                                                                                                                                                                                   \n",
    "                                                                                                                                                                                                       \n",
    "def solve(objective_function, config, prev_best_x=None):                                                                                                                                             \n",
    "    \"\"\"                                                                                                                                                                                              \n",
    "    Hybrid global-local blackbox minimization with adaptive budget allocation.                                                                                                                       \n",
    "                                                                                                                                                                                                    \n",
    "    Strategy:                                                                                                                                                                                        \n",
    "    - Warm-start from prev_best_x when available and compatible                                                                                                                                      \n",
    "    - Global search with quasi-random exploration and sampling around current best                                                                                                                   \n",
    "    - Local search via adaptive coordinate-wise pattern search with random                                                                                                                           \n",
    "    perturbations and occasional global kicks                                                                                                                                                      \n",
    "    - Budget and dimension aware: adapts exploration / exploitation split                                                                                                                            \n",
    "    and step sizes                                                                                                                                                                                 \n",
    "    \"\"\"                                                                                                                                                                                              \n",
    "                                                                                                                                                                                                    \n",
    "    bounds = np.array(config[\"bounds\"], dtype=float)                                                                                                                                                 \n",
    "    dim = int(config.get(\"dim\", len(bounds)))                                                                                                                                                        \n",
    "    budget = int(config.get(\"budget\", 1))                                                                                                                                                            \n",
    "                                                                                                                                                                                                    \n",
    "    if dim <= 0 or budget <= 0:                                                                                                                                                                      \n",
    "        mid = bounds[:, 0] + 0.5 * (bounds[:, 1] - bounds[:, 0])                                                                                                                                     \n",
    "        return np.asarray(mid, dtype=float)                                                                                                                                                          \n",
    "                                                                                                                                                                                                    \n",
    "    lower = bounds[:, 0].astype(float)                                                                                                                                                               \n",
    "    upper = bounds[:, 1].astype(float)                                                                                                                                                               \n",
    "    span = upper - lower                                                                                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "    fixed_mask = span <= 0.0                                                                                                                                                                         \n",
    "    span_safe = np.where(fixed_mask, 1.0, span)                                                                                                                                                      \n",
    "                                                                                                                                                                                                    \n",
    "    def clamp(x):                                                                                                                                                                                    \n",
    "        return np.clip(x, lower, upper)                                                                                                                                                              \n",
    "                                                                                                                                                                                                    \n",
    "    evals_used = 0                                                                                                                                                                                   \n",
    "    best_x = None                                                                                                                                                                                    \n",
    "    best_y = None                                                                                                                                                                                    \n",
    "                                                                                                                                                                                                    \n",
    "    def eval_point(x):                                                                                                                                                                               \n",
    "        nonlocal evals_used, best_x, best_y                                                                                                                                                          \n",
    "        if evals_used >= budget:                                                                                                                                                                     \n",
    "            return best_y if best_y is not None else np.inf                                                                                                                                          \n",
    "        y = objective_function(x)                                                                                                                                                                    \n",
    "        evals_used += 1                                                                                                                                                                              \n",
    "        if best_x is None or y < best_y:                                                                                                                                                             \n",
    "            best_x = np.array(x, copy=True)                                                                                                                                                          \n",
    "            best_y = float(y)                                                                                                                                                                        \n",
    "        return y                                                                                                                                                                                     \n",
    "                                                                                                                                                                                                    \n",
    "    # ---- Initialization: warm start + LHS-like starts ----                                                                                                                                         \n",
    "    if prev_best_x is not None:                                                                                                                                                                      \n",
    "        x0 = np.asarray(prev_best_x, dtype=float)                                                                                                                                                    \n",
    "        if x0.shape[0] == dim:                                                                                                                                                                       \n",
    "            x0 = clamp(x0)                                                                                                                                                                           \n",
    "            eval_point(x0)                                                                                                                                                                           \n",
    "                                                                                                                                                                                                    \n",
    "    remaining = budget - evals_used                                                                                                                                                                  \n",
    "    if remaining > 0:                                                                                                                                                                                \n",
    "        if budget < 40:                                                                                                                                                                              \n",
    "            init_trials = min(remaining, 6)                                                                                                                                                          \n",
    "        else:                                                                                                                                                                                        \n",
    "            init_trials = min(max(10, budget // 20), 25)                                                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "        n_init = init_trials                                                                                                                                                                         \n",
    "        if n_init > 0:                                                                                                                                                                               \n",
    "            cut = np.linspace(0.0, 1.0, n_init + 1)                                                                                                                                                  \n",
    "            u = np.random.rand(n_init, dim)                                                                                                                                                          \n",
    "            a = cut[:n_init]                                                                                                                                                                         \n",
    "            b = cut[1:n_init + 1]                                                                                                                                                                    \n",
    "            u = a[:, None] + (b - a)[:, None] * u                                                                                                                                                    \n",
    "            for d in range(dim):                                                                                                                                                                     \n",
    "                np.random.shuffle(u[:, d])                                                                                                                                                           \n",
    "            xs = lower + u * span_safe                                                                                                                                                               \n",
    "            for k in range(n_init):                                                                                                                                                                  \n",
    "                if evals_used >= budget:                                                                                                                                                             \n",
    "                    break                                                                                                                                                                            \n",
    "                eval_point(xs[k])                                                                                                                                                                    \n",
    "                                                                                                                                                                                                    \n",
    "    if best_x is None:                                                                                                                                                                               \n",
    "        x_mid = clamp(lower + 0.5 * span)                                                                                                                                                            \n",
    "        eval_point(x_mid)                                                                                                                                                                            \n",
    "                                                                                                                                                                                                    \n",
    "    if evals_used >= budget:                                                                                                                                                                         \n",
    "        return best_x                                                                                                                                                                                \n",
    "                                                                                                                                                                                                    \n",
    "    remaining = budget - evals_used                                                                                                                                                                  \n",
    "                                                                                                                                                                                                    \n",
    "    # ---- Budget split: global vs local ----                                                                                                                                                        \n",
    "    if remaining < 40 or dim > 20:                                                                                                                                                                   \n",
    "        global_frac = 0.7                                                                                                                                                                            \n",
    "    else:                                                                                                                                                                                            \n",
    "        global_frac = 0.55                                                                                                                                                                           \n",
    "                                                                                                                                                                                                    \n",
    "    global_budget = max(1, int(global_frac * remaining))                                                                                                                                             \n",
    "    global_budget = min(global_budget, remaining)                                                                                                                                                    \n",
    "    local_budget = remaining - global_budget                                                                                                                                                         \n",
    "                                                                                                                                                                                                    \n",
    "    # ---- Quasi-random utilities ----                                                                                                                                                               \n",
    "    def van_der_corput(n, base=2):                                                                                                                                                                   \n",
    "        if n <= 0:                                                                                                                                                                                   \n",
    "            return np.empty(0, dtype=float)                                                                                                                                                          \n",
    "        seq = np.empty(n, dtype=float)                                                                                                                                                               \n",
    "        for i in range(n):                                                                                                                                                                           \n",
    "            v = i                                                                                                                                                                                    \n",
    "            denom = 1.0                                                                                                                                                                              \n",
    "            x = 0.0                                                                                                                                                                                  \n",
    "            while v:                                                                                                                                                                                 \n",
    "                v, r = divmod(v, base)                                                                                                                                                               \n",
    "                denom *= base                                                                                                                                                                        \n",
    "                x += r / denom                                                                                                                                                                       \n",
    "            seq[i] = x                                                                                                                                                                               \n",
    "        return seq                                                                                                                                                                                   \n",
    "                                                                                                                                                                                                    \n",
    "    def quasi_random_points(n_points, dim_):                                                                                                                                                         \n",
    "        if n_points <= 0:                                                                                                                                                                            \n",
    "            return np.empty((0, dim_), dtype=float)                                                                                                                                                  \n",
    "        base_sequence = van_der_corput(n_points + 16, 2)[8:8 + n_points]                                                                                                                             \n",
    "        pts = np.empty((n_points, dim_), dtype=float)                                                                                                                                                \n",
    "        for d in range(dim_):                                                                                                                                                                        \n",
    "            perm = np.random.permutation(n_points)                                                                                                                                                   \n",
    "            pts[:, d] = base_sequence[perm]                                                                                                                                                          \n",
    "        jitter = (np.random.rand(n_points, dim_) - 0.5) / (4.0 * max(n_points, 1))                                                                                                                   \n",
    "        u = np.clip(pts + jitter, 0.0, 1.0)                                                                                                                                                          \n",
    "        return lower + u * span_safe                                                                                                                                                                 \n",
    "                                                                                                                                                                                                    \n",
    "    # ---- Global search ----                                                                                                                                                                        \n",
    "    n_global = global_budget                                                                                                                                                                         \n",
    "    refine_budget = max(0, int(0.3 * n_global))                                                                                                                                                      \n",
    "    pure_explore_budget = max(0, n_global - refine_budget)                                                                                                                                           \n",
    "                                                                                                                                                                                                    \n",
    "    if pure_explore_budget > 0 and evals_used < budget:                                                                                                                                              \n",
    "        xs = quasi_random_points(pure_explore_budget, dim)                                                                                                                                           \n",
    "        for i in range(pure_explore_budget):                                                                                                                                                         \n",
    "            if evals_used >= budget:                                                                                                                                                                 \n",
    "                break                                                                                                                                                                                \n",
    "            eval_point(xs[i])                                                                                                                                                                        \n",
    "                                                                                                                                                                                                    \n",
    "    if refine_budget > 0 and evals_used < budget and best_x is not None:                                                                                                                             \n",
    "        base_sigma = 0.10 * span_safe                                                                                                                                                                \n",
    "        base_sigma[fixed_mask] = 0.0                                                                                                                                                                 \n",
    "        for t in range(refine_budget):                                                                                                                                                               \n",
    "            if evals_used >= budget:                                                                                                                                                                 \n",
    "                break                                                                                                                                                                                \n",
    "            frac = 1.0 - (t / max(refine_budget - 1, 1))                                                                                                                                             \n",
    "            sigma = np.maximum(base_sigma * (0.5 + 0.5 * frac), 1e-16)                                                                                                                               \n",
    "            noise = np.random.randn(dim) * sigma                                                                                                                                                     \n",
    "            cand = clamp(best_x + noise)                                                                                                                                                             \n",
    "            eval_point(cand)                                                                                                                                                                         \n",
    "                                                                                                                                                                                                    \n",
    "    if evals_used >= budget or local_budget <= 0:                                                                                                                                                    \n",
    "        return best_x                                                                                                                                                                                \n",
    "                                                                                                                                                                                                    \n",
    "    # ---- Local search: adaptive coordinate-wise + global kicks ----                                                                                                                                \n",
    "    remaining = budget - evals_used                                                                                                                                                                  \n",
    "                                                                                                                                                                                                    \n",
    "    if remaining < 40:                                                                                                                                                                               \n",
    "        step_frac = 0.16                                                                                                                                                                             \n",
    "    elif dim <= 5:                                                                                                                                                                                   \n",
    "        step_frac = 0.15                                                                                                                                                                             \n",
    "    else:                                                                                                                                                                                            \n",
    "        step_frac = 0.11                                                                                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "    step = step_frac * span_safe                                                                                                                                                                     \n",
    "    step[fixed_mask] = 0.0                                                                                                                                                                           \n",
    "    min_step = 1e-10 * np.maximum(span_safe, 1.0)                                                                                                                                                    \n",
    "                                                                                                                                                                                                    \n",
    "    per_iter_cost = max(2 * dim + 4, 1)                                                                                                                                                              \n",
    "    max_iters = max(1, min(60, local_budget // per_iter_cost))                                                                                                                                       \n",
    "                                                                                                                                                                                                    \n",
    "    it = 0                                                                                                                                                                                           \n",
    "    no_improve_iters = 0                                                                                                                                                                             \n",
    "    second_best_x = None                                                                                                                                                                             \n",
    "    second_best_y = None                                                                                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "    while evals_used < budget and it < max_iters and np.any(step > min_step):                                                                                                                        \n",
    "        it += 1                                                                                                                                                                                      \n",
    "        improved = False                                                                                                                                                                             \n",
    "        current_best_x = best_x.copy()                                                                                                                                                               \n",
    "                                                                                                                                                                                                    \n",
    "        order = np.arange(dim)                                                                                                                                                                       \n",
    "        np.random.shuffle(order)                                                                                                                                                                     \n",
    "                                                                                                                                                                                                    \n",
    "        for j in order:                                                                                                                                                                              \n",
    "            if evals_used >= budget:                                                                                                                                                                 \n",
    "                break                                                                                                                                                                                \n",
    "            if fixed_mask[j]:                                                                                                                                                                        \n",
    "                continue                                                                                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "            for direction in (-1.0, 1.0):                                                                                                                                                            \n",
    "                if evals_used >= budget:                                                                                                                                                             \n",
    "                    break                                                                                                                                                                            \n",
    "                cand = current_best_x.copy()                                                                                                                                                         \n",
    "                cand[j] = cand[j] + direction * step[j]                                                                                                                                              \n",
    "                cand = clamp(cand)                                                                                                                                                                   \n",
    "                y = eval_point(cand)                                                                                                                                                                 \n",
    "                if (second_best_x is None or y < second_best_y) and (best_y is None or y > best_y):                                                                                                  \n",
    "                    second_best_x = cand.copy()                                                                                                                                                      \n",
    "                    second_best_y = float(y)                                                                                                                                                         \n",
    "                if y < best_y:                                                                                                                                                                       \n",
    "                    improved = True                                                                                                                                                                  \n",
    "                    current_best_x = best_x.copy()                                                                                                                                                   \n",
    "                                                                                                                                                                                                    \n",
    "            if evals_used >= budget:                                                                                                                                                                 \n",
    "                break                                                                                                                                                                                \n",
    "                                                                                                                                                                                                    \n",
    "            if step[j] > 0:                                                                                                                                                                          \n",
    "                for _ in range(2):                                                                                                                                                                   \n",
    "                    if evals_used >= budget:                                                                                                                                                         \n",
    "                        break                                                                                                                                                                        \n",
    "                    rnd = (2.0 * np.random.rand() - 1.0) * step[j]                                                                                                                                   \n",
    "                    cand = current_best_x.copy()                                                                                                                                                     \n",
    "                    cand[j] = cand[j] + rnd                                                                                                                                                          \n",
    "                    cand = clamp(cand)                                                                                                                                                               \n",
    "                    y = eval_point(cand)                                                                                                                                                             \n",
    "                    if (second_best_x is None or y < second_best_y) and (best_y is None or y > best_y):                                                                                              \n",
    "                        second_best_x = cand.copy()                                                                                                                                                  \n",
    "                        second_best_y = float(y)                                                                                                                                                     \n",
    "                    if y < best_y:                                                                                                                                                                   \n",
    "                        improved = True                                                                                                                                                              \n",
    "                        current_best_x = best_x.copy()                                                                                                                                               \n",
    "                                                                                                                                                                                                    \n",
    "        if evals_used >= budget:                                                                                                                                                                     \n",
    "            break                                                                                                                                                                                    \n",
    "                                                                                                                                                                                                    \n",
    "        # Gaussian escape step                                                                                                                                                                       \n",
    "        full_noise = np.random.randn(dim) * (0.35 * step)                                                                                                                                            \n",
    "        full_noise[fixed_mask] = 0.0                                                                                                                                                                 \n",
    "        cand = clamp(best_x + full_noise)                                                                                                                                                            \n",
    "        y = eval_point(cand)                                                                                                                                                                         \n",
    "        if (second_best_x is None or y < second_best_y) and (best_y is None or y > best_y):                                                                                                          \n",
    "            second_best_x = cand.copy()                                                                                                                                                              \n",
    "            second_best_y = float(y)                                                                                                                                                                 \n",
    "        if y < best_y:                                                                                                                                                                               \n",
    "            improved = True                                                                                                                                                                          \n",
    "                                                                                                                                                                                                    \n",
    "        # Diversification from second-best when stuck                                                                                                                                                \n",
    "        if (not improved) and (no_improve_iters >= 4) and (second_best_x is not None):                                                                                                               \n",
    "            kick_scale = 0.25                                                                                                                                                                        \n",
    "            noise = np.random.randn(dim) * (kick_scale * np.maximum(step, min_step))                                                                                                                 \n",
    "            noise[fixed_mask] = 0.0                                                                                                                                                                  \n",
    "            cand = clamp(second_best_x + noise)                                                                                                                                                      \n",
    "            y = eval_point(cand)                                                                                                                                                                     \n",
    "            if (second_best_x is None or y < second_best_y) and (best_y is None or y > best_y):                                                                                                      \n",
    "                second_best_x = cand.copy()                                                                                                                                                          \n",
    "                second_best_y = float(y)                                                                                                                                                             \n",
    "            if y < best_y:                                                                                                                                                                           \n",
    "                improved = True                                                                                                                                                                      \n",
    "                                                                                                                                                                                                    \n",
    "        # Step size adaptation                                                                                                                                                                       \n",
    "        if not improved:                                                                                                                                                                             \n",
    "            no_improve_iters += 1                                                                                                                                                                    \n",
    "            if no_improve_iters <= 3:                                                                                                                                                                \n",
    "                decay = 0.7                                                                                                                                                                          \n",
    "            elif no_improve_iters <= 7:                                                                                                                                                              \n",
    "                decay = 0.5                                                                                                                                                                          \n",
    "            else:                                                                                                                                                                                    \n",
    "                decay = 0.35                                                                                                                                                                         \n",
    "            step *= decay                                                                                                                                                                            \n",
    "        else:                                                                                                                                                                                        \n",
    "            no_improve_iters = 0                                                                                                                                                                     \n",
    "            step *= 1.05                                                                                                                                                                             \n",
    "                                                                                                                                                                                                    \n",
    "        step = np.maximum(step, min_step)                                                                                                                                                            \n",
    "                                                                                                                                                                                                    \n",
    "    return best_x\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "poly-takeaway",
   "metadata": {},
   "source": [
    "### Key Takeaway\n",
    "\n",
    "**GEPA vs. Traditional Optimization**:\n",
    "\n",
    "| Aspect | Optuna | GEPA |\n",
    "|--------|--------|------|\n",
    "| Algorithm selection | Manual (TPE, CMA-ES, etc.) | Automatic (evolved) |\n",
    "| Hyperparameter tuning | Required | Evolved |\n",
    "| Domain knowledge needed | High | Low |\n",
    "| What user provides | Search space + sampler config | Baseline code + fitness function |\n",
    "| What gets optimized | Parameter values | The optimization algorithm itself |\n",
    "\n",
    "While Optuna requires users to select algorithms and tune hyperparameters, GEPA automatically **discovers optimization strategies** by evolving code. The user just provides the problem and a baseline—GEPA evolves Halton sequences, surrogate models, local refinement, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-5\"></a>\n",
    "# 5. Example 2: Prompt Engineering — AIME 2025\n",
    "\n",
    "**Result: GEPA improves GPT-4.1 Mini's accuracy from 46.67% to 60.00% on AIME 2025.**\n",
    "\n",
    "This example demonstrates how `optimize_anything` can evolve **prompts**—the natural language instructions that guide LLM behavior.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "Prompt engineering is often done through **trial and error**:\n",
    "1. Write a prompt\n",
    "2. Test on a few examples\n",
    "3. Manually tweak based on intuition\n",
    "4. Repeat until it \"feels right\"\n",
    "\n",
    "This is slow, doesn't scale, and doesn't guarantee you've found the best prompt.\n",
    "\n",
    "## The Task\n",
    "\n",
    "**Given**: A dataset of AIME math competition problems\n",
    "**Find**: A system prompt that maximizes GPT-4.1 Mini's accuracy\n",
    "\n",
    "**What GEPA optimizes**: The instruction prompt—what guidance to give the model.\n",
    "\n",
    "<img src=\"./assets/blog/aime.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aime-setup",
   "metadata": {},
   "source": [
    "## Setting Up the Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aime-setup-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 45 training examples\n",
      "Loaded 45 validation examples\n",
      "Loaded 30 test examples\n",
      "Training: 45 problems\n",
      "Validation: 45 problems\n",
      "Test: 30 problems\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "# Configure the language model\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "lm = dspy.LM(\"gpt-4.1-mini\", api_key=api_key, temperature=1.0, max_tokens=32000)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# Load AIME dataset splits\n",
    "from examples.aime_math.dataset import load_math_dataset\n",
    "trainset, valset, testset = load_math_dataset()\n",
    "\n",
    "print(f\"Training: {len(trainset)} problems\")\n",
    "print(f\"Validation: {len(valset)} problems\")\n",
    "print(f\"Test: {len(testset)} problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aime-module",
   "metadata": {},
   "source": [
    "## The DSPy Module\n",
    "\n",
    "We use DSPy's `ChainOfThought` for step-by-step reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aime-module-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MathSolverSignature(dspy.Signature):\n",
    "    \"\"\"Solve a math competition problem.\"\"\"\n",
    "    input = dspy.InputField(desc=\"The math problem to solve.\")\n",
    "    answer = dspy.OutputField(desc=\"The final numerical answer.\")\n",
    "\n",
    "predictor = dspy.ChainOfThought(MathSolverSignature)\n",
    "\n",
    "def run_llm(example, prompt: str):\n",
    "    \"\"\"Run the LLM on a single example with the given prompt.\"\"\"\n",
    "    predictor.predict.signature.instructions = prompt\n",
    "    return predictor(input=example.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aime-seed",
   "metadata": {},
   "source": [
    "## The Seed Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aime-seed-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_candidate = {\n",
    "    \"prompt\": \"Solve the math problem carefully. Break down the steps and provide the final answer as a single number.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aime-fitness",
   "metadata": {},
   "source": [
    "## The Fitness Function\n",
    "\n",
    "The fitness function runs the predictor and collects detailed feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aime-fitness-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def math_metric(example, prediction):\n",
    "    \"\"\"Compute score and detailed feedback for math problems.\"\"\"\n",
    "    correct_answer, written_solution = int(example.answer), getattr(example, \"solution\", \"\")\n",
    "    solution_suffix = f\" Here's the full step-by-step solution:\\n{written_solution}\\n\\nThink about what takeaways you can learn from this solution to improve your future answers and approach to similar problems\" if written_solution else \"\"\n",
    "\n",
    "    try:\n",
    "        llm_answer = int(prediction.answer)\n",
    "    except (ValueError, TypeError):\n",
    "        feedback_text = f\"The final answer must be a valid integer and nothing else. You responded with '{prediction.answer}', which couldn't be parsed as a python integer. Please ensure your answer is a valid integer without any additional text or formatting. The correct answer is '{correct_answer}'.{solution_suffix}{' and ensure your final answer is a valid integer.' if written_solution else ''}\"\n",
    "        return dspy.Prediction(score=0.0, feedback=feedback_text)\n",
    "\n",
    "    score = float(correct_answer == llm_answer)\n",
    "    status = \"correct\" if score == 1.0 else \"incorrect\"\n",
    "    feedback_text = f\"Your answer is {status}. The correct answer is '{correct_answer}'.{solution_suffix}\"\n",
    "    return dspy.Prediction(score=score, feedback=feedback_text)\n",
    "\n",
    "\n",
    "def fitness_fn(candidate: dict[str, str], example) -> tuple[float, Any, SideInfo]:\n",
    "    \"\"\"Fitness function for GEPA optimization with single example evaluation.\"\"\"\n",
    "    prediction = run_llm(example, candidate[\"prompt\"])\n",
    "    metric_result = math_metric(example, prediction)\n",
    "    score = metric_result.score\n",
    "    feedback = metric_result.feedback\n",
    "\n",
    "    output = {\n",
    "        \"prompt\": candidate[\"prompt\"],\n",
    "        \"answer\": prediction.answer,\n",
    "        \"score\": score,\n",
    "    }\n",
    "\n",
    "    side_info = {\n",
    "        \"Input\": example.input,\n",
    "        \"Output\": prediction.answer,\n",
    "        \"Reasoning\": getattr(prediction, \"reasoning\", \"\"),\n",
    "        \"ExecutionFeedback\": feedback,\n",
    "    }\n",
    "\n",
    "    return (score, output, side_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aime-optimize",
   "metadata": {},
   "source": [
    "## Running GEPA Optimization\n",
    "\n",
    "Note: We use `valset` for generalization testing—GEPA optimizes on `trainset` but tracks performance on held-out `valset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aime-optimize-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Base program full valset score: 0.4666666666666667 over 45 / 45 examples\n",
      "Iteration 1: Selected program 0 score: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "from gepa.optimize_anything import (\n",
    "    optimize_anything,\n",
    "    GEPAConfig,\n",
    "    EngineConfig,\n",
    "    ReflectionConfig,\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=trainset,   # Optimize on training set\n",
    "    valset=valset,      # Track generalization on validation set\n",
    "    config=GEPAConfig(\n",
    "        engine=EngineConfig(\n",
    "            max_metric_calls=800,\n",
    "            track_best_outputs=True,\n",
    "            parallel=True,      \n",
    "            max_workers=32,\n",
    "            cache_evaluation=True,\n",
    "        ),\n",
    "        reflection=ReflectionConfig(\n",
    "            reflection_lm=\"openai/gpt-5\",\n",
    "            reflection_minibatch_size=3,  # Show 3 problems per reflection\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"\\nOptimized prompt:\")\n",
    "print(result.best_candidate[\"prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aime-evolved",
   "metadata": {},
   "source": [
    "## The Optimized Prompt\n",
    "\n",
    "GEPA discovered a detailed, structured prompt with domain-specific strategies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aime-evolved-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This prompt was EVOLVED by GEPA, not written by a human!\n",
    "# Starting from a simple \"Solve carefully and provide the answer\" prompt,\n",
    "# GEPA discovered domain-specific strategies through reflection.\n",
    "\n",
    "optimized_prompt = \"\"\"\n",
    "Solve the math problem carefully and thoroughly. Your goal is to produce a correct, well‑structured solution that leads unambiguously to the requested final result.\n",
    "\n",
    "Follow these rules:\n",
    "\n",
    "1. Restate the problem briefly in your own words.\n",
    "   - Identify what is given and what must be found.\n",
    "   - Note any special conditions (e.g., ordering of variables, geometric configuration).\n",
    "\n",
    "2. Set up notation and equations cleanly before manipulating them.\n",
    "   - Define all variables explicitly (including any you introduce, like substitutions).\n",
    "   - State all constraints and domain conditions (positivity, integrality, ordering, angle ranges, etc.) before using them.\n",
    "   - When you make structural assumptions (e.g., “assume all first k terms are equal”), clearly justify why this does not reduce generality for maximizing/minimizing the desired expression.\n",
    "\n",
    "3. Plan the approach before detailed algebra.\n",
    "   - Briefly outline the main idea (e.g., symmetry, extremal principle, splitting into cases, using inequalities, introducing coordinates).\n",
    "   - For optimization / extremal problems, explain why your configuration is optimal (e.g., by convexity, rearrangement inequality, averaging arguments), not just by constructing one example.\n",
    "   - For existence/uniqueness, mention how you will show all solutions or the unique solution.\n",
    "\n",
    "4. Show clear, logically ordered reasoning.\n",
    "   - Justify each important algebraic, geometric, or inequality step.\n",
    "   - When you split into cases, state:\n",
    "     * why each case must be considered, and\n",
    "     * what assumptions define the case.\n",
    "   - If you invoke a known theorem or fact (e.g., Ptolemy, Power of a Point, Cauchy–Schwarz, AM–GM, similarity, Vieta, extremal principle), name it and show explicitly how it applies in this context.\n",
    "   - For inequality / optimization problems, be explicit about:\n",
    "     * where equalities can occur,\n",
    "     * why boundary or extreme configurations are considered,\n",
    "     * and why they indeed give a global optimum under the constraints.\n",
    "\n",
    "5. Handle dead ends correctly.\n",
    "   - If a line of reasoning leads to a contradiction or dead end, explicitly say so.\n",
    "   - Roll back to the last correct point and choose a new approach; do not keep using a flawed assumption.\n",
    "   - Do not discard potential solutions without checking them against all given conditions.\n",
    "\n",
    "6. Keep the reasoning focused but rigorous.\n",
    "   - Avoid unnecessary numerical approximations when an exact expression is available.\n",
    "   - Do not approximate exact values unless the problem explicitly asks for a decimal or numerical estimate.\n",
    "   - Prefer structural or conceptual arguments (symmetry, convexity, parity, monotonicity, invariants, etc.) over ad hoc trial‑and‑error or guess‑and‑check.\n",
    "   - You may test specific candidate values only after deriving strong constraints that sharply limit the possibilities, and you must explain why those candidates are exhaustive.\n",
    "\n",
    "7. Treat ordering and extremal indices with care.\n",
    "   - For sequences with ordering constraints (e.g., \\(x_1 \\le \\dots \\le x_n\\)), reason about which indices must be negative, zero, or positive to maximize or minimize a given difference.\n",
    "   - When you set many consecutive terms equal (e.g., all smallest terms equal to some \\(b\\), all largest terms equal to some \\(a\\), and middle ones zero), justify that any deviation from this would decrease (or not increase) the desired quantity, using monotonicity or averaging arguments.\n",
    "   - Ensure that sign and ordering constraints are respected in all constructed examples.\n",
    "\n",
    "8. Final consistency check.\n",
    "   - At the end, verify that your solution satisfies:\n",
    "     * all original equations/constraints,\n",
    "     * ordering or geometric conditions,\n",
    "     * and any side conditions (e.g., angle ranges, positivity, distinctness).\n",
    "   - For maximization/minimization problems, explicitly argue that:\n",
    "     * your value is attainable by some configuration, and\n",
    "     * no configuration can exceed (or go below) it.\n",
    "\n",
    "9. At the end, clearly isolate the answer:\n",
    "   - Provide the final answer as a single number or expression on its own line.\n",
    "   - Do not include any extra words, symbols, or explanation on that final line.\n",
    "\"\"\"\n",
    "\n",
    "# 🎯 What GEPA discovered:\n",
    "# - Domain-specific heuristics for different math areas (geometry, combinatorics, NT)\n",
    "# - Structured problem-solving workflow\n",
    "# - Sanity checks and validation strategies\n",
    "# - Explicit handling of common failure modes (mixing counting models, etc.)\n",
    "#\n",
    "# A human prompt engineer might take hours to discover these strategies!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aime-takeaway",
   "metadata": {},
   "source": [
    "### Key Takeaway\n",
    "\n",
    "By including the model's **reasoning trace** in `side_info`, GEPA can understand *how* the model approaches problems—not just whether it got the answer right. This enables:\n",
    "\n",
    "1. **Targeted improvements**: Fix specific reasoning errors, not random prompt tweaks\n",
    "2. **Domain-specific strategies**: The prompt evolved to include geometry workflows, combinatorics rules, etc.\n",
    "3. **Sanity checks**: GEPA discovered that asking for validation prevents common errors\n",
    "\n",
    "The evolved prompt contains strategies that a human prompt engineer might take hours to discover through manual iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-6\"></a>\n",
    "# 6. Example 3: Agent Program Evolution — ARC-AGI\n",
    "\n",
    "**Result: GEPA improves GPT-5's performance from 56.5% to 68.0% on ARC-AGI.**\n",
    "\n",
    "This is the most ambitious example: optimizing not just prompts, but **entire agent architectures**—the DSPy program that defines how an LLM reasons about problems.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "[ARC-AGI](https://arcprize.org/) (Abstraction and Reasoning Corpus) is a benchmark designed to test general intelligence:\n",
    "- Each task shows input-output grid transformation examples\n",
    "- The agent must infer the transformation rule and apply it to test inputs\n",
    "- Tasks require **visual reasoning, pattern recognition, and abstraction**\n",
    "\n",
    "Hand-designing agent architectures for such tasks is extremely difficult.\n",
    "\n",
    "## The Task\n",
    "\n",
    "**Given**: A dataset of ARC-AGI grid transformation tasks\n",
    "**Find**: A DSPy program (agent architecture) that maximizes accuracy\n",
    "\n",
    "**What GEPA optimizes**: The entire DSPy program—signatures, modules, control flow, and prompting strategies.\n",
    "\n",
    "<img src=\"./assets/blog/arc_agi.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba1793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 200\n",
      "Val set: 200\n",
      "Test set: 400\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import dspy\n",
    "import os\n",
    "\n",
    "from gepa.adapters.dspy_full_program_adapter.full_program_adapter import DspyAdapter\n",
    "from examples.arc_agi.main import metric_fn\n",
    "from examples.arc_agi.data import load_data\n",
    "\n",
    "seed = 0\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "\n",
    "task_lm = dspy.LM(\n",
    "        model=\"openai/gpt-4.1-mini\",\n",
    "        temperature=1.0,\n",
    "        max_tokens=32000,\n",
    "        api_key=api_key,\n",
    "        seed=seed,\n",
    "        cache=False,\n",
    "    )\n",
    "\n",
    "adapter = DspyAdapter(\n",
    "        task_lm=task_lm,\n",
    "        metric_fn=metric_fn,\n",
    "        num_threads=64,\n",
    "        reflection_lm=\"openai/gpt-5\",\n",
    "        rng=random.Random(seed),\n",
    "    )\n",
    "    \n",
    "trainset, valset, testset = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc-seed",
   "metadata": {},
   "source": [
    "## The Seed Candidate\n",
    "\n",
    "We start with a minimal Chain-of-Thought agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arc-seed-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_candidate = {\n",
    "    \"program\": \"\"\"\n",
    "import dspy\n",
    "from typing import List\n",
    "import pydantic\n",
    "\n",
    "MATRIX = List[List[int]]\n",
    "\n",
    "class TrainingExample(pydantic.BaseModel):\n",
    "    input: MATRIX\n",
    "    output: MATRIX\n",
    "\n",
    "class SolveTaskSignature(dspy.Signature):\n",
    "    training_examples: List[TrainingExample] = dspy.InputField(description=\"Input and output examples demonstrating the task to be performed.\")\n",
    "    test_inputs: List[MATRIX] = dspy.InputField(description=\"Input matrices to be solved following the task described in the training examples.\")\n",
    "    test_outputs: List[MATRIX] = dspy.OutputField(description=\"Output matrices corresponding to the test inputs.\")\n",
    "\n",
    "program = dspy.ChainOfThought(SolveTaskSignature)\n",
    "\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc-fitness",
   "metadata": {},
   "source": [
    "## The Fitness Function\n",
    "\n",
    "The fitness function compiles and executes the DSPy program, capturing detailed error information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arc-fitness-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def fitness_fn(candidate, example):\n",
    "    program = candidate[\"program\"]\n",
    "\n",
    "    try:\n",
    "        evaluation_results = adapter.evaluate(\n",
    "            [example], candidate, capture_traces=True\n",
    "        )\n",
    "    except Exception as e:\n",
    "        side_info = {\"input\": example, \"error\": str(e), \"program\": program}\n",
    "        return (0.0, side_info, side_info)\n",
    "\n",
    "    # Program error\n",
    "    if (\n",
    "        not isinstance(evaluation_results.trajectories, list)\n",
    "        or len(evaluation_results.trajectories) == 0\n",
    "    ):\n",
    "        print(\"Error: \")\n",
    "        print(evaluation_results.trajectories)\n",
    "        side_info = {\n",
    "            \"input\": example,\n",
    "            \"error\": f\"All examples failed. Program error: {str(evaluation_results.trajectories)}\",\n",
    "            \"program\": program,\n",
    "        }\n",
    "        return (0.0, side_info, side_info)\n",
    "\n",
    "    # Process evaluations with no program errors\n",
    "    trajectory = evaluation_results.trajectories[0]\n",
    "    metric_result = trajectory.get(\"score\")\n",
    "    score = metric_result.get(\"score\")\n",
    "    feedback = metric_result.get(\"feedback\")\n",
    "    prediction = trajectory.get(\"prediction\")\n",
    "\n",
    "    side_info = {\n",
    "        \"input\": example,\n",
    "        \"reasoning\": prediction.get(\"reasoning\"),\n",
    "        \"feedback\": feedback,\n",
    "        \"output\": prediction.get(\"test_outputs\"),\n",
    "    }\n",
    "\n",
    "    return (score, side_info, side_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc-optimize",
   "metadata": {},
   "source": [
    "## Running GEPA Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arc-optimize-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.arc_agi.prompt import BACKGROUND\n",
    "from gepa.optimize_anything import (\n",
    "    EngineConfig,\n",
    "    GEPAConfig,\n",
    "    ReflectionConfig,\n",
    "    optimize_anything,\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=trainset,\n",
    "    valset=valset,\n",
    "    objective=\"Optimize the dspy agent program to solve ARC-AGI tasks effectively.\",\n",
    "    background=BACKGROUND,\n",
    "    config=GEPAConfig(\n",
    "        engine=EngineConfig(\n",
    "            max_metric_calls=4000,\n",
    "            track_best_outputs=True,\n",
    "            use_cloudpickle=True,\n",
    "            parallel=True,\n",
    "            max_workers=64,\n",
    "            cache_evaluation=True,\n",
    "        ),\n",
    "        reflection=ReflectionConfig(\n",
    "            reflection_lm=\"openai/gpt-5\",\n",
    "            reflection_minibatch_size=3,\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc-evolved",
   "metadata": {},
   "source": [
    "## What GEPA Discovered\n",
    "\n",
    "GEPA evolved the simple ChainOfThought into a sophisticated 5-step code synthesis pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arc-evolved-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evolved by GEPA - A code synthesis agent with self-refinement\n",
    "# This program was DISCOVERED through optimization, not hand-written!\n",
    "\n",
    "evolved_program = '''\n",
    "import dspy\n",
    "from typing import List, Tuple, Optional, Any, Dict\n",
    "import pydantic\n",
    "import re\n",
    "import copy\n",
    "import textwrap\n",
    "from collections import Counter\n",
    "\n",
    "MATRIX = List[List[int]]\n",
    "\n",
    "class TrainingExample(pydantic.BaseModel):\n",
    "    input: MATRIX\n",
    "    output: MATRIX\n",
    "\n",
    "def _strip_code_fences(s: str) -> str:\n",
    "    if s is None:\n",
    "        return \"\"\n",
    "    s = s.strip()\n",
    "    # Remove fenced blocks and language markers\n",
    "    if s.startswith(\"```\"):\n",
    "        s = \"\\n\".join(s.split(\"\\n\")[1:])\n",
    "    if s.endswith(\"```\"):\n",
    "        s = \"\\n\".join(s.split(\"\\n\")[:-1])\n",
    "    s = re.sub(r\"^```[a-zA-Z0-9_+-]*\\s*\", \"\", s.strip())\n",
    "    s = re.sub(r\"\\s*```$\", \"\", s.strip())\n",
    "    return s.strip()\n",
    "\n",
    "def _ensure_transform_code(code: str) -> str:\n",
    "    \"\"\"\n",
    "    Ensure code contains a def transform(grid): function.\n",
    "    If code appears to be just the body, wrap it. Otherwise, return full code as-is.\n",
    "    \"\"\"\n",
    "    code = _strip_code_fences(code)\n",
    "    if \"def transform\" in code:\n",
    "        # Keep helpers that may be defined before/after transform.\n",
    "        return code\n",
    "    # If it's likely just a body (has return or grid indexing), wrap it\n",
    "    lines = code.strip().splitlines()\n",
    "    body = code.strip()\n",
    "    if len(body) == 0:\n",
    "        return \"\"\n",
    "    if \"return\" in body or \"grid\" in body:\n",
    "        wrapped = \"def transform(grid):\\n\" + textwrap.indent(body, \"    \")\n",
    "        return wrapped\n",
    "    return \"\"\n",
    "\n",
    "def _height(grid: MATRIX) -> int:\n",
    "    return len(grid)\n",
    "\n",
    "def _width(grid: MATRIX) -> int:\n",
    "    return len(grid[0]) if grid and isinstance(grid[0], list) else 0\n",
    "\n",
    "def _in_bounds(grid: MATRIX, r: int, c: int) -> bool:\n",
    "    h, w = _height(grid), _width(grid)\n",
    "    return 0 <= r < h and 0 <= c < w\n",
    "\n",
    "def _colors(grid: MATRIX) -> List[int]:\n",
    "    s = set()\n",
    "    for row in grid:\n",
    "        for v in row:\n",
    "            try:\n",
    "                s.add(int(v))\n",
    "            except Exception:\n",
    "                pass\n",
    "    return sorted(list(s))\n",
    "\n",
    "def _color_counts(grid: MATRIX) -> Dict[int, int]:\n",
    "    cnt = Counter()\n",
    "    for row in grid:\n",
    "        for v in row:\n",
    "            try:\n",
    "                cnt[int(v)] += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "    return dict(cnt)\n",
    "\n",
    "def _positions_of(grid: MATRIX, color: int) -> List[Tuple[int, int]]:\n",
    "    pos = []\n",
    "    for r, row in enumerate(grid):\n",
    "        for c, v in enumerate(row):\n",
    "            if v == color:\n",
    "                pos.append((r, c))\n",
    "    return pos\n",
    "\n",
    "def _bbox_of(grid: MATRIX, colors: Optional[List[int]] = None, nonzero: bool = True) -> Optional[Tuple[int, int, int, int]]:\n",
    "    h, w = _height(grid), _width(grid)\n",
    "    rs = []\n",
    "    if colors is not None:\n",
    "        color_set = set(colors)\n",
    "        for r in range(h):\n",
    "            for c in range(w):\n",
    "                if grid[r][c] in color_set:\n",
    "                    rs.append((r, c))\n",
    "    elif nonzero:\n",
    "        for r in range(h):\n",
    "            for c in range(w):\n",
    "                if grid[r][c] != 0:\n",
    "                    rs.append((r, c))\n",
    "    else:\n",
    "        # if not using nonzero and no colors, bbox of entire grid\n",
    "        for r in range(h):\n",
    "            for c in range(w):\n",
    "                rs.append((r, c))\n",
    "    if not rs:\n",
    "        return None\n",
    "    rmin = min(r for r, _ in rs)\n",
    "    rmax = max(r for r, _ in rs)\n",
    "    cmin = min(c for _, c in rs)\n",
    "    cmax = max(c for _, c in rs)\n",
    "    return (rmin, cmin, rmax, cmax)\n",
    "\n",
    "def _crop(grid: MATRIX, bbox: Tuple[int, int, int, int]) -> MATRIX:\n",
    "    rmin, cmin, rmax, cmax = bbox\n",
    "    out = []\n",
    "    for r in range(rmin, rmax + 1):\n",
    "        row = []\n",
    "        for c in range(cmin, cmax + 1):\n",
    "            row.append(int(grid[r][c]))\n",
    "        out.append(row)\n",
    "    return out\n",
    "\n",
    "def _transpose(grid: MATRIX) -> MATRIX:\n",
    "    h, w = _height(grid), _width(grid)\n",
    "    if h == 0 or w == 0:\n",
    "        return []\n",
    "    return [[int(grid[r][c]) for r in range(h)] for c in range(w)]\n",
    "\n",
    "def _new_grid(h: int, w: int, fill: int = 0) -> MATRIX:\n",
    "    return [[int(fill) for _ in range(w)] for _ in range(h)]\n",
    "\n",
    "def _normalize_matrix(mat: MATRIX) -> MATRIX:\n",
    "    out: MATRIX = []\n",
    "    for row in mat:\n",
    "        new_row = []\n",
    "        for v in row:\n",
    "            try:\n",
    "                iv = int(v)\n",
    "            except Exception:\n",
    "                iv = 0\n",
    "            if iv < 0:\n",
    "                iv = 0\n",
    "            if iv > 9:\n",
    "                iv = 9\n",
    "            new_row.append(iv)\n",
    "        out.append(new_row)\n",
    "    return out\n",
    "\n",
    "def _same_shape(a: MATRIX, b: MATRIX) -> bool:\n",
    "    if len(a) != len(b):\n",
    "        return False\n",
    "    return all(len(ra) == len(rb) for ra, rb in zip(a, b))\n",
    "\n",
    "def _compare_matrices(a: MATRIX, b: MATRIX) -> Tuple[bool, List[Tuple[int, int, int, int]]]:\n",
    "    diffs: List[Tuple[int, int, int, int]] = []\n",
    "    if not _same_shape(a, b):\n",
    "        return False, diffs\n",
    "    for i, (ra, rb) in enumerate(zip(a, b)):\n",
    "        for j, (va, vb) in enumerate(zip(ra, rb)):\n",
    "            if va != vb:\n",
    "                diffs.append((i, j, va, vb))\n",
    "    return (len(diffs) == 0), diffs\n",
    "\n",
    "def _verify_on_training(transform_fn, training_examples: List[TrainingExample]) -> Tuple[bool, str]:\n",
    "    reports = []\n",
    "    all_ok = True\n",
    "    for idx, ex in enumerate(training_examples):\n",
    "        try:\n",
    "            out = transform_fn(copy.deepcopy(ex.input))\n",
    "        except Exception as e:\n",
    "            all_ok = False\n",
    "            reports.append(f\"Example {idx}: Exception during transform: {repr(e)}\")\n",
    "            continue\n",
    "        if not isinstance(out, list) or (len(out) > 0 and not isinstance(out[0], list)):\n",
    "            all_ok = False\n",
    "            reports.append(f\"Example {idx}: Output is not a 2D list.\")\n",
    "            continue\n",
    "        out = _normalize_matrix(out)\n",
    "        # For ARC, output shape must match the example's output shape, not necessarily the input shape.\n",
    "        if not _same_shape(out, ex.output):\n",
    "            all_ok = False\n",
    "            reports.append(f\"Example {idx}: Shape mismatch. Got {len(out)}x{len(out[0]) if out else 0}, expected {len(ex.output)}x{len(ex.output[0]) if ex.output else 0}.\")\n",
    "            continue\n",
    "        ok, diffs = _compare_matrices(out, ex.output)\n",
    "        if not ok:\n",
    "            all_ok = False\n",
    "            sample_diffs = diffs[:20]\n",
    "            reports.append(f\"Example {idx}: {len(diffs)} cells differ. Sample diffs (r,c got->exp): \" +\n",
    "                           \", \".join([f\"({r},{c} {gv}->{ev})\" for r, c, gv, ev in sample_diffs]))\n",
    "    return all_ok, \"\\n\".join(reports)\n",
    "\n",
    "def _apply_code_to_tests(code: str, test_inputs: List[MATRIX]) -> List[MATRIX]:\n",
    "    fn = _safe_exec_transform(code)\n",
    "    if not fn:\n",
    "        return []\n",
    "    outputs = []\n",
    "    for idx, ti in enumerate(test_inputs):\n",
    "        try:\n",
    "            out = fn(copy.deepcopy(ti))\n",
    "        except Exception:\n",
    "            return []\n",
    "        if not isinstance(out, list) or (len(out) > 0 and not isinstance(out[0], list)):\n",
    "            return []\n",
    "        out = _normalize_matrix(out)\n",
    "        outputs.append(out)\n",
    "    return outputs\n",
    "\n",
    "def _safe_exec_transform(code: str) -> Optional[Any]:\n",
    "    \"\"\"\n",
    "    Exec the transform function in a restricted namespace with helper utilities.\n",
    "    Returns callable transform or None if failure.\n",
    "    \"\"\"\n",
    "    code = _ensure_transform_code(code)\n",
    "    if not code:\n",
    "        return None\n",
    "\n",
    "    # Safe helper library exposed to the model's code.\n",
    "    sandbox_globals: Dict[str, Any] = {\n",
    "        \"__builtins__\": {\n",
    "            \"range\": range,\n",
    "            \"len\": len,\n",
    "            \"enumerate\": enumerate,\n",
    "            \"min\": min,\n",
    "            \"max\": max,\n",
    "            \"sum\": sum,\n",
    "            \"abs\": abs,\n",
    "            \"all\": all,\n",
    "            \"any\": any,\n",
    "            \"sorted\": sorted,\n",
    "            \"zip\": zip,\n",
    "            \"list\": list,\n",
    "            \"set\": set,\n",
    "            \"tuple\": tuple,\n",
    "            \"int\": int\n",
    "        },\n",
    "        \"deepcopy\": copy.deepcopy,\n",
    "        # helpers\n",
    "        \"height\": _height,\n",
    "        \"width\": _width,\n",
    "        \"in_bounds\": _in_bounds,\n",
    "        \"colors\": _colors,\n",
    "        \"color_counts\": _color_counts,\n",
    "        \"positions_of\": _positions_of,\n",
    "        \"bbox_of\": _bbox_of,\n",
    "        \"crop\": _crop,\n",
    "        \"transpose\": _transpose,\n",
    "        \"new_grid\": _new_grid,\n",
    "    }\n",
    "    sandbox_locals: Dict[str, Any] = {}\n",
    "    try:\n",
    "        exec(code, sandbox_globals, sandbox_locals)\n",
    "        fn = sandbox_locals.get(\"transform\") or sandbox_globals.get(\"transform\")\n",
    "        if callable(fn):\n",
    "            return fn\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def _matrix_shape(mat: MATRIX) -> Tuple[int, int]:\n",
    "    if not isinstance(mat, list) or (mat and not isinstance(mat[0], list)):\n",
    "        return (0, 0)\n",
    "    return (len(mat), len(mat[0]) if mat else 0)\n",
    "\n",
    "def _stats_for_grid(grid: MATRIX) -> Dict[str, Any]:\n",
    "    h, w = _matrix_shape(grid)\n",
    "    pal = _colors(grid)\n",
    "    cnt = _color_counts(grid)\n",
    "    nonzero_bbox = _bbox_of(grid, colors=None, nonzero=True)\n",
    "    counts_str = \",\".join(f\"{k}:{cnt[k]}\" for k in sorted(cnt.keys()))\n",
    "    return {\n",
    "        \"shape\": [h, w],\n",
    "        \"palette\": pal,\n",
    "        \"counts\": counts_str,\n",
    "        \"nonzero_bbox\": nonzero_bbox\n",
    "    }\n",
    "\n",
    "def _build_training_summary(training_examples: List[TrainingExample]) -> str:\n",
    "    # Construct a concise, structured summary string for the LM.\n",
    "    lines = []\n",
    "    for i, ex in enumerate(training_examples):\n",
    "        in_stats = _stats_for_grid(ex.input)\n",
    "        out_stats = _stats_for_grid(ex.output)\n",
    "        lines.append(\n",
    "            f\"Example {i}: input_shape={in_stats['shape']}, output_shape={out_stats['shape']}, \"\n",
    "            f\"input_palette={in_stats['palette']}, output_palette={out_stats['palette']}, \"\n",
    "            f\"input_counts={in_stats['counts']}, output_counts={out_stats['counts']}, \"\n",
    "            f\"input_nonzero_bbox={in_stats['nonzero_bbox']}, output_nonzero_bbox={out_stats['nonzero_bbox']}\"\n",
    "        )\n",
    "    # Heuristics across examples:\n",
    "    shape_deltas = []\n",
    "    for ex in training_examples:\n",
    "        ih, iw = _matrix_shape(ex.input)\n",
    "        oh, ow = _matrix_shape(ex.output)\n",
    "        shape_deltas.append((oh - ih, ow - iw))\n",
    "    unique_deltas = sorted(set(shape_deltas))\n",
    "    lines.append(f\"Unique shape deltas (oh-ih, ow-iw) across training: {unique_deltas}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "class InduceRuleSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    You are given several training input/output pairs from an ARC task. Infer a single deterministic transformation rule\n",
    "    that maps any input grid to its output grid. Produce:\n",
    "    1) A succinct, generalized rule_summary describing the pattern.\n",
    "    2) A Python function `def transform(grid): ...` implementing the rule.\n",
    "\n",
    "    Execution constraints and helpers:\n",
    "      - grid is a 2D list of ints (0..9). Deterministic logic only (loops, conditionals, list ops).\n",
    "      - Do not import modules or use randomness.\n",
    "      - You MAY change the output shape when the task demands it. Match the training outputs' shapes for their inputs.\n",
    "      - Indices must be in-bounds; handle arbitrary rectangular shapes.\n",
    "      - Mutations: copy if needed; avoid mutating the input in-place unless safe.\n",
    "      - Values must remain ints 0..9.\n",
    "\n",
    "    Common pitfalls to avoid:\n",
    "      - Off-by-one when cropping or expanding; mixing up row/col order.\n",
    "      - Assuming output has same shape as input when training shows otherwise.\n",
    "      - Forgetting to preserve anchor colors or key markers when summarizing patterns.\n",
    "      - Using unavailable libraries (numpy/pandas).\n",
    "\n",
    "    Successful strategies:\n",
    "      - Use bounding boxes of non-zero or target colors to crop or extract regions (bbox_of, crop).\n",
    "      - Build frequency maps to pick dominant or anchor colors (color_counts, colors).\n",
    "      - Compress by selecting rows/cols that contain target colors; preserve ordering.\n",
    "      - When outputs are smaller, they often summarize a motif or mask of specific colors (e.g., 1 and 2).\n",
    "\n",
    "    Helper functions available in the environment:\n",
    "      - height(grid), width(grid), in_bounds(grid,r,c)\n",
    "      - colors(grid) -> sorted list of unique colors\n",
    "      - color_counts(grid) -> dict color->count\n",
    "      - positions_of(grid, color) -> list of (r,c)\n",
    "      - bbox_of(grid, colors=None, nonzero=True) -> (rmin,cmin,rmax,cmax) inclusive or None\n",
    "      - crop(grid, bbox) -> returns subgrid bounded by bbox\n",
    "      - transpose(grid), new_grid(h,w,fill)\n",
    "\n",
    "    Return fields:\n",
    "      - rule_summary: Concise paragraph of the inferred rule.\n",
    "      - python_code: Only the code defining def transform(grid): ...; no extra commentary or fences.\n",
    "\n",
    "    Important: Return only rule_summary and python_code; do not include explanations beyond those fields.\n",
    "    \"\"\"\n",
    "    training_examples: List[TrainingExample] = dspy.InputField(desc=\"Examples showing input->output mappings for the task.\")\n",
    "    training_summary: str = dspy.InputField(desc=\"Structured stats about shapes, palettes, counts, and bboxes across examples.\")\n",
    "    rule_summary: str = dspy.OutputField(desc=\"One concise paragraph describing the inferred rule.\")\n",
    "    python_code: str = dspy.OutputField(desc=\"Only the code defining def transform(grid): ...; no explanations.\")\n",
    "\n",
    "class RefineRuleSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    The previous Python transform did not perfectly match all training examples.\n",
    "    Given the training_examples, training_summary (stats), the prior_code for transform(grid), and a failure_report\n",
    "    describing mismatches, produce a corrected version of transform(grid).\n",
    "\n",
    "    Instructions:\n",
    "    - Keep the same overall approach but fix the logic to satisfy all training pairs.\n",
    "    - You MAY alter the output shape; match each training output's shape for its input.\n",
    "    - Maintain determinism; no external imports; values are ints 0..9.\n",
    "    - Be careful with off-by-one, bounds, and row/col order.\n",
    "    - Return only a complete, standalone function definition: def transform(grid): ...\n",
    "    \"\"\"\n",
    "    training_examples: List[TrainingExample] = dspy.InputField(desc=\"Authoritative input/output examples.\")\n",
    "    training_summary: str = dspy.InputField(desc=\"Structured stats about shapes, palettes, counts, and bboxes across examples.\")\n",
    "    prior_code: str = dspy.InputField(desc=\"Previous attempt's function code.\")\n",
    "    failure_report: str = dspy.InputField(desc=\"Concrete mismatches and diagnostics from verification.\")\n",
    "    python_code: str = dspy.OutputField(desc=\"Revised code: only def transform(grid): ...\")\n",
    "\n",
    "class DirectSolveSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    If code induction fails, directly produce outputs for test_inputs using a consistent rule induced from training.\n",
    "    Requirements:\n",
    "    - Return only a Python literal list of output grids aligned with test_inputs (e.g., [[[...],[...]], [[...], ...]]).\n",
    "    - Do not include any commentary, bullets, or extra text.\n",
    "    - Output ints in 0..9 only. Shapes may differ from inputs; match the pattern demonstrated in training pairs.\n",
    "    - Apply the same inferred rule consistently across all test inputs.\n",
    "    \"\"\"\n",
    "    training_examples: List[TrainingExample] = dspy.InputField(desc=\"Training pairs for the task.\")\n",
    "    test_inputs: List[MATRIX] = dspy.InputField(desc=\"Unseen inputs to solve.\")\n",
    "    test_outputs: List[MATRIX] = dspy.OutputField(desc=\"Predicted outputs for each test input.\")\n",
    "\n",
    "class ARCRuleProgram(dspy.Module):\n",
    "    def __init__(self, max_refinements: int = 4):\n",
    "        super().__init__()\n",
    "        self.induce = dspy.ChainOfThought(InduceRuleSignature)\n",
    "        self.refine = dspy.ChainOfThought(RefineRuleSignature)\n",
    "        self.direct = dspy.ChainOfThought(DirectSolveSignature)\n",
    "        self.max_refinements = max_refinements\n",
    "\n",
    "    def forward(self, training_examples: List[TrainingExample], test_inputs: List[MATRIX]) -> dspy.Prediction:\n",
    "        training_summary = _build_training_summary(training_examples)\n",
    "\n",
    "        # Step 1: Induce rule and code\n",
    "        draft = self.induce(training_examples=training_examples, training_summary=training_summary)\n",
    "        code = draft.python_code or \"\"\n",
    "        code = _strip_code_fences(code)\n",
    "\n",
    "        # Step 2: Verify and refine iteratively\n",
    "        for _ in range(self.max_refinements + 1):\n",
    "            fn = _safe_exec_transform(code)\n",
    "            if fn is None:\n",
    "                failure_report = \"Could not exec transform function. Ensure a valid def transform(grid): ... exists and no imports.\"\n",
    "            else:\n",
    "                ok, report = _verify_on_training(fn, training_examples)\n",
    "                if ok:\n",
    "                    # Step 3: Apply to tests\n",
    "                    outputs = _apply_code_to_tests(code, test_inputs)\n",
    "                    if outputs:\n",
    "                        return dspy.Prediction(test_outputs=outputs)\n",
    "                    failure_report = \"Execution on test inputs failed or returned invalid outputs.\"\n",
    "                else:\n",
    "                    failure_report = report\n",
    "            # Attempt refinement\n",
    "            refined = self.refine(\n",
    "                training_examples=training_examples,\n",
    "                training_summary=training_summary,\n",
    "                prior_code=code,\n",
    "                failure_report=failure_report\n",
    "            )\n",
    "            new_code = _strip_code_fences(refined.python_code or \"\")\n",
    "            if not new_code or new_code.strip() == code.strip():\n",
    "                code = new_code or code\n",
    "                break\n",
    "            code = new_code\n",
    "\n",
    "        # Fallback: direct solve via LM\n",
    "        direct = self.direct(training_examples=training_examples, test_inputs=test_inputs)\n",
    "        safe_outs: List[MATRIX] = []\n",
    "        if isinstance(direct.test_outputs, list):\n",
    "            for mat in direct.test_outputs:\n",
    "                try:\n",
    "                    safe_outs.append(_normalize_matrix(mat))\n",
    "                except Exception:\n",
    "                    # Skip invalid entries\n",
    "                    pass\n",
    "        return dspy.Prediction(test_outputs=safe_outs)\n",
    "\n",
    "class SolveTaskSignature(dspy.Signature):\n",
    "    \"\"\"\n",
    "    Solve ARC tasks using rule induction with verifiable code and robust fallback.\n",
    "    Inputs:\n",
    "      - training_examples: list of TrainingExample(input, output)\n",
    "      - test_inputs: list of matrices to solve\n",
    "    Output:\n",
    "      - test_outputs: list of predicted output matrices\n",
    "    \"\"\"\n",
    "    training_examples: List[TrainingExample] = dspy.InputField(desc=\"Input/output examples demonstrating the task to be performed.\")\n",
    "    test_inputs: List[MATRIX] = dspy.InputField(desc=\"Input matrices to be solved following the task described in the training examples.\")\n",
    "    test_outputs: List[MATRIX] = dspy.OutputField(desc=\"Output matrices corresponding to the test inputs.\")\n",
    "\n",
    "class SolveARC(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.core = ARCRuleProgram()\n",
    "\n",
    "    def forward(self, training_examples: List[TrainingExample], test_inputs: List[MATRIX]) -> dspy.Prediction:\n",
    "        return self.core(training_examples=training_examples, test_inputs=test_inputs)\n",
    "\n",
    "program = SolveARC()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arc-takeaway",
   "metadata": {},
   "source": [
    "### Key Takeaway: Emergent Self-Refinement\n",
    "\n",
    "GEPA discovered **self-refinement**—having the LLM validate and fix its own code before producing outputs. This is remarkable because:\n",
    "\n",
    "1. **Not programmed**: Self-refinement emerged from optimization, not from human design\n",
    "2. **Sophisticated strategy**: The agent now verifies on training before applying to test\n",
    "3. **Multi-attempt recovery**: Up to 5 refinement attempts with targeted feedback\n",
    "4. **Code synthesis**: Instead of direct prediction, the agent writes executable code\n",
    "\n",
    "This demonstrates GEPA's ability to discover **complex reasoning pipelines** that humans might not think to design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-7\"></a>\n",
    "# 7. Example 4: Algorithmic Discovery — Circle Packing\n",
    "\n",
    "**Result: GEPA matches or exceeds AlphaEvolve, ShinkaEvolve, and OpenEvolve on circle packing.**\n",
    "\n",
    "This example demonstrates **algorithmic discovery**—evolving code to solve a well-known NP-hard optimization problem.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "Circle packing is a classic problem with real-world applications (chip layout, material cutting, logistics):\n",
    "- Pack N non-overlapping circles inside a unit square [0,1] × [0,1]\n",
    "- Maximize the sum of all radii\n",
    "- This is **NP-hard**—no known polynomial-time algorithm exists\n",
    "\n",
    "Recent work from DeepMind (AlphaEvolve), and open-source efforts (ShinkaEvolve, OpenEvolve) have used LLMs to evolve packing algorithms.\n",
    "\n",
    "## The Task\n",
    "\n",
    "**Given**: The number of circles N (e.g., N=26)\n",
    "**Find**: Python code that computes optimal circle placements\n",
    "\n",
    "**What GEPA optimizes**: The packing algorithm code—placement strategies, local optimization, constraint handling.\n",
    "\n",
    "<img src=\"./assets/blog/circle_packing_26.png\">\n",
    "\n",
    "<img src=\"./assets/blog/circle_packing_visualization_26.png>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circle-setup",
   "metadata": {},
   "source": [
    "## Setting Up the Problem\n",
    "\n",
    "Circle packing is a single-instance optimization problem—no dataset needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "circle-setup-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_circles = 26\n",
    "objective = f\"Optimize circle packing code and refiner prompt to maximize sum of circle radii within a unit square for N={num_circles} circles.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circle-seed",
   "metadata": {},
   "source": [
    "## The Seed Candidate\n",
    "\n",
    "The same one from ShinkaEvolve. \n",
    "A simple concentric ring layout (1 center circle + 8 inner ring + remaining outer ring)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "circle-seed-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.circle_packing.llms import SEED_REFINEMENT_PROMPT\n",
    "\n",
    "\n",
    "seed_candidate = {\n",
    "    \"code\": '''\n",
    "import numpy as np\n",
    "\n",
    "def main(timeout, current_best_solution):\n",
    "    \"\"\"\n",
    "    Circle packing optimization.\n",
    "\n",
    "    Args:\n",
    "        timeout: Time budget in seconds\n",
    "        current_best_solution: Previous best circles array (n, 3) or None\n",
    "\n",
    "    Returns:\n",
    "        dict with 'circles' (n, 3) array and 'all_scores' list\n",
    "    \"\"\"\n",
    "    n = 26\n",
    "\n",
    "    # Use current_best_solution if provided, otherwise start fresh\n",
    "    if current_best_solution is not None:\n",
    "        circles = current_best_solution.copy()\n",
    "    else:\n",
    "        # Simple initial placement\n",
    "        centers = np.zeros((n, 2))\n",
    "\n",
    "        # Center circle\n",
    "        centers[0] = [0.5, 0.5]\n",
    "\n",
    "        # Ring of 8 around center\n",
    "        for i in range(min(8, n - 1)):\n",
    "            angle = 2 * np.pi * i / 8\n",
    "            centers[i + 1] = [0.5 + 0.3 * np.cos(angle), 0.5 + 0.3 * np.sin(angle)]\n",
    "\n",
    "        # Outer ring for remaining\n",
    "        if n > 9:\n",
    "            remaining = n - 9\n",
    "            for i in range(remaining):\n",
    "                angle = 2 * np.pi * i / remaining\n",
    "                centers[i + 9] = [0.5 + 0.7 * np.cos(angle), 0.5 + 0.7 * np.sin(angle)]\n",
    "\n",
    "        centers = np.clip(centers, 0.01, 0.99)\n",
    "        radii = compute_max_radii(centers)\n",
    "        circles = np.hstack([centers, radii.reshape(-1, 1)])\n",
    "\n",
    "    score = float(np.sum(circles[:, 2]))\n",
    "    return {'circles': circles, 'all_scores': [score]}\n",
    "\n",
    "\n",
    "def compute_max_radii(centers):\n",
    "    \"\"\"Compute maximum radii that don't overlap and stay in unit square.\"\"\"\n",
    "    n = centers.shape[0]\n",
    "    radii = np.ones(n)\n",
    "\n",
    "    # Limit by distance to borders\n",
    "    for i in range(n):\n",
    "        x, y = centers[i]\n",
    "        radii[i] = min(x, y, 1 - x, 1 - y)\n",
    "\n",
    "    # Limit by distance to other circles\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            dist = np.sqrt(np.sum((centers[i] - centers[j]) ** 2))\n",
    "            if radii[i] + radii[j] > dist:\n",
    "                scale = dist / (radii[i] + radii[j])\n",
    "                radii[i] *= scale\n",
    "                radii[j] *= scale\n",
    "\n",
    "    return radii\n",
    "''', \n",
    "    \"refiner_prompt\": SEED_REFINEMENT_PROMPT,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2b80e",
   "metadata": {},
   "source": [
    "### Refiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e06943a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "import os\n",
    "\n",
    "class RefinerSignature(dspy.Signature):\n",
    "    \"\"\"Refine the code based on its evaluation results by fixing the errors and improving the performance.\"\"\"\n",
    "\n",
    "    refiner_prompt = dspy.InputField(desc=\"Instructions for how to refine the code\")\n",
    "    code_to_improve = dspy.InputField(desc=\"Code to improve\")\n",
    "    code_results = dspy.InputField(\n",
    "        desc=\"Evaluation results of the code to improve by fixing the errors and improving the performance\"\n",
    "    )\n",
    "    refined_code = dspy.OutputField(\n",
    "        desc=\"Next iteration of improved code based on the evaluation results\"\n",
    "    )\n",
    "\n",
    "refiner_predictor = dspy.Predict(RefinerSignature)\n",
    "\n",
    "refiner_lm = dspy.LM(\n",
    "    \"openai/gpt-5.1\",\n",
    "    temperature=1.0,\n",
    "    max_tokens=32000,\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circle-fitness",
   "metadata": {},
   "source": [
    "## The Fitness Function\n",
    "\n",
    "The fitness function validates constraints and returns detailed violation information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "circle-fitness-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.circle_packing.utils import execute_code\n",
    "from examples.circle_packing.main import refine_code, StateTracker\n",
    "\n",
    "state_tracker = StateTracker()\n",
    "timeout = 600\n",
    "\n",
    "def compute_multiple_metrics(\n",
    "    global_best_score: float, all_scores: list[float]\n",
    ") -> dict[str, float]:\n",
    "    candidate_best_score = max(all_scores)\n",
    "    alpha_fixed = 0.1\n",
    "    ema_fixed = all_scores[0]\n",
    "    for s in all_scores[1:]:\n",
    "        ema_fixed = alpha_fixed * s + (1 - alpha_fixed) * ema_fixed\n",
    "    alpha_adaptive = 2.0 / (len(all_scores) + 1)\n",
    "    ema_adaptive = all_scores[0]\n",
    "    for s in all_scores[1:]:\n",
    "        ema_adaptive = alpha_adaptive * s + (1 - alpha_adaptive) * ema_adaptive\n",
    "\n",
    "    return {\n",
    "        \"max_score\": max(all_scores),\n",
    "        \"mean_score\": sum(all_scores) / len(all_scores),\n",
    "        \"ema_score_fixed\": ema_fixed,\n",
    "        \"ema_score_adaptive\": ema_adaptive,\n",
    "        \"score_improvement_from_previous_best\": candidate_best_score\n",
    "        - global_best_score,\n",
    "    }\n",
    "\n",
    "def fitness_fn(candidate: dict[str, str], *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Evaluate code candidate on batch of problems with optional refinement.\n",
    "    \"\"\"\n",
    "    code_candidate = candidate[\"code\"]\n",
    "\n",
    "    # Code candidate evaluation\n",
    "    global_best_score, global_best_solution = state_tracker.get_best_solution()\n",
    "    cache_key = code_candidate\n",
    "    code_candidate_cache = state_tracker.get(cache_key)\n",
    "\n",
    "    if code_candidate_cache is not None:\n",
    "        code_score, code_side_info = code_candidate_cache\n",
    "    else:\n",
    "        code_result = execute_code(code_candidate, timeout, global_best_solution)\n",
    "        circles = None\n",
    "\n",
    "        if code_result[\"success\"]:\n",
    "            circles = code_result[\"result\"][\"circles\"]\n",
    "            all_scores = code_result[\"result\"][\"all_scores\"]\n",
    "            code_score = code_result[\"result\"][\"validation_details\"][\"sum_radii\"]\n",
    "            code_side_info = {\n",
    "                \"scores\": compute_multiple_metrics(global_best_score, all_scores),\n",
    "                \"Code\": code_candidate,\n",
    "                \"Circles\": circles,\n",
    "                \"Global best circles at the time of evaluation\": global_best_solution,\n",
    "                \"Stdout\": code_result[\"stdout\"],\n",
    "            }\n",
    "        else:\n",
    "            code_score = 0.0\n",
    "            code_side_info = {\n",
    "                \"scores\": {\"sum_radii\": 0.0},\n",
    "                \"Code\": code_candidate,\n",
    "                \"Error\": code_result[\"error\"],\n",
    "                \"Traceback\": code_result.get(\"traceback\", \"\"),\n",
    "                \"Stdout\": code_result[\"stdout\"],\n",
    "                \"Validation Details\": code_result.get(\"validation_details\"),\n",
    "            }\n",
    "\n",
    "        # Cache after computing values\n",
    "        state_tracker.set(\n",
    "            cache_key,\n",
    "            (code_score, code_side_info),\n",
    "            score=code_score,\n",
    "            solution=circles,\n",
    "            artifact={\n",
    "                \"code\": code_candidate,\n",
    "                \"arg_current_best_solution\": global_best_solution,\n",
    "                \"validation details\": code_result.get(\"validation_details\"),\n",
    "            },\n",
    "        )\n",
    "\n",
    "    print(\"Code candidate side info:\")\n",
    "    print(code_side_info)\n",
    "\n",
    "    # Refiner prompt evaluation\n",
    "    # Now that we've got the code's results, we can set a cache key as (prompt, code, best_solution)\n",
    "    # the refiner will receive the code, the\n",
    "    print(\"Refining code...\")\n",
    "\n",
    "    refiner_prompt_candidate = candidate[\"refiner_prompt\"]\n",
    "    global_best_score, global_best_solution = state_tracker.get_best_solution()\n",
    "\n",
    "    # Refine code for this problem\n",
    "    (\n",
    "        refiner_score,\n",
    "        refiner_code,\n",
    "        refiner_side_info,\n",
    "    ) = refine_code(\n",
    "        code=code_candidate,\n",
    "        code_score=code_score,\n",
    "        code_side_info=code_side_info,\n",
    "        refiner_prompt=refiner_prompt_candidate,\n",
    "        refiner_predictor=refiner_predictor,\n",
    "        refiner_lm=refiner_lm,\n",
    "        timeout=timeout,\n",
    "        state_tracker=state_tracker,\n",
    "    )\n",
    "\n",
    "    if refiner_score > code_score:\n",
    "        best_score = refiner_score\n",
    "        best_code = refiner_code\n",
    "        best_circles = refiner_side_info.get(\"Circles\", None)\n",
    "    else:\n",
    "        best_score = code_score\n",
    "        best_code = code_candidate\n",
    "        best_circles = code_side_info.get(\"Circles\", None)\n",
    "\n",
    "    if best_circles is not None:\n",
    "        best_circles = best_circles.tolist()\n",
    "\n",
    "    output = {\n",
    "        \"best_score\": best_score,\n",
    "        \"best_code\": best_code,\n",
    "        \"best_circles\": best_circles,\n",
    "        \"code_candidate\": code_candidate,\n",
    "        \"code_score\": code_score,\n",
    "        \"refiner_prompt\": refiner_prompt_candidate,\n",
    "        \"refiner_code\": refiner_code,\n",
    "        \"refiner_score\": refiner_score,\n",
    "    }\n",
    "\n",
    "    side_info = {\n",
    "        \"scores\": {\n",
    "            \"best_score_from_code_and_refiner\": max(code_score, refiner_score),\n",
    "            \"initial_code\": code_score,\n",
    "            \"refiner_prompt\": refiner_score,\n",
    "        },\n",
    "        \"Input\": {\n",
    "            \"Timeout (s)\": timeout,\n",
    "        },\n",
    "        \"code_specific_info\": code_side_info,\n",
    "        \"refiner_prompt_specific_info\": refiner_side_info,\n",
    "    }\n",
    "\n",
    "    return (best_score, output, side_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circle-optimize",
   "metadata": {},
   "source": [
    "## Running GEPA Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circle-optimize-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gepa.optimize_anything import (\n",
    "    EngineConfig,\n",
    "    GEPAConfig,\n",
    "    ReflectionConfig,\n",
    "    optimize_anything,\n",
    ")\n",
    "from examples.circle_packing.llms import CIRCLE_PACKING_BACKGROUND, SEED_REFINEMENT_PROMPT\n",
    "\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    objective=objective,\n",
    "    background=CIRCLE_PACKING_BACKGROUND,\n",
    "    config=GEPAConfig(\n",
    "        engine=EngineConfig(\n",
    "            max_metric_calls=200,\n",
    "            track_best_outputs=True,\n",
    "            frontier_type=\"objective\",\n",
    "            cache_evaluation=True,\n",
    "        ),\n",
    "        reflection=ReflectionConfig(\n",
    "            reflection_lm=\"openai/gpt-5\",\n",
    "            reflection_minibatch_size=1,\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f9ad7f",
   "metadata": {},
   "source": [
    "## Best Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba58f0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (3.12.3) (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/data/lukedhlee/gepa_luke/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def main(timeout, current_best_solution):\n",
    "    \"\"\"\n",
    "    BREAKTHROUGH approach: Large-Neighborhood Sequential Linear Programming (LN-SLP)\n",
    "    with exact LP for radii. We optimize centers by repeatedly solving LPs over\n",
    "    subsets of centers with linearized pairwise constraints and boundary constraints.\n",
    "    Multi-start + global SLP + LNS refinement + dual-informed subset selection.\n",
    "    \"\"\"\n",
    "    n = 26\n",
    "    start_time = time.time()\n",
    "    time_budget = max(1.0, float(timeout) - 0.5)\n",
    "    rng = np.random.default_rng(2026)\n",
    "    eps = 1e-6\n",
    "    r_min = 1e-8\n",
    "    all_scores = []\n",
    "\n",
    "    def time_left():\n",
    "        return time_budget - (time.time() - start_time)\n",
    "\n",
    "    def clamp01(xy):\n",
    "        return np.clip(xy, eps, 1.0 - eps)\n",
    "\n",
    "    def boundary_limits(centers):\n",
    "        x = centers[:, 0]\n",
    "        y = centers[:, 1]\n",
    "        return np.minimum(np.minimum(x, 1 - x), np.minimum(y, 1 - y))\n",
    "\n",
    "    def pairwise_distances(centers):\n",
    "        diff = centers[:, None, :] - centers[None, :, :]\n",
    "        D = np.sqrt(np.maximum(np.sum(diff * diff, axis=2), 0.0))\n",
    "        return D\n",
    "\n",
    "    def solve_radii_lp_fallback(centers, r_min_local):\n",
    "        # Projection-like repair (feasible radii)\n",
    "        b = boundary_limits(centers)\n",
    "        r = np.minimum(b, 0.5).copy()\n",
    "        r = np.maximum(r, r_min_local)\n",
    "        D = pairwise_distances(centers)\n",
    "        max_iter = 1500\n",
    "        tol = 1e-10\n",
    "        for _ in range(max_iter):\n",
    "            r = np.minimum(r, b)\n",
    "            viol = 0.0\n",
    "            for i in range(n):\n",
    "                ri = r[i]\n",
    "                for j in range(i + 1, n):\n",
    "                    dij = D[i, j]\n",
    "                    if dij <= 0:\n",
    "                        r[j] = r_min_local\n",
    "                        continue\n",
    "                    s = ri + r[j]\n",
    "                    if s > dij:\n",
    "                        excess = s - dij\n",
    "                        viol = max(viol, excess)\n",
    "                        total = ri + r[j]\n",
    "                        if total <= 1e-16:\n",
    "                            dec_i = dec_j = 0.5 * excess\n",
    "                        else:\n",
    "                            dec_i = excess * (ri / total)\n",
    "                            dec_j = excess * (r[j] / total)\n",
    "                        ri = max(r_min_local, ri - dec_i)\n",
    "                        r[j] = max(r_min_local, r[j] - dec_j)\n",
    "                r[i] = ri\n",
    "            if viol < tol:\n",
    "                break\n",
    "        r = np.minimum(r, b)\n",
    "        r = np.maximum(r, r_min_local)\n",
    "        return r, True, None\n",
    "\n",
    "    def solve_radii_lp(centers, r_min_local):\n",
    "        try:\n",
    "            from scipy.optimize import linprog\n",
    "            x = centers[:, 0]; y = centers[:, 1]\n",
    "            D = pairwise_distances(centers)\n",
    "            A_rows = []\n",
    "            b_vals = []\n",
    "            # Boundary constraints\n",
    "            for i in range(n):\n",
    "                row = np.zeros(n); row[i] = 1.0; A_rows.append(row); b_vals.append(x[i])\n",
    "                row = np.zeros(n); row[i] = 1.0; A_rows.append(row); b_vals.append(1.0 - x[i])\n",
    "                row = np.zeros(n); row[i] = 1.0; A_rows.append(row); b_vals.append(y[i])\n",
    "                row = np.zeros(n); row[i] = 1.0; A_rows.append(row); b_vals.append(1.0 - y[i])\n",
    "            # Pairwise constraints\n",
    "            for i in range(n):\n",
    "                for j in range(i + 1, n):\n",
    "                    row = np.zeros(n); row[i] = 1.0; row[j] = 1.0\n",
    "                    A_rows.append(row); b_vals.append(D[i, j])\n",
    "            A_ub = np.array(A_rows, dtype=float) if A_rows else None\n",
    "            b_ub = np.array(b_vals, dtype=float) if b_vals else None\n",
    "            bounds = [(r_min_local, None)] * n\n",
    "            c = -np.ones(n, dtype=float)\n",
    "            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n",
    "            if getattr(res, \"success\", False) and res.x is not None:\n",
    "                r = np.array(res.x, dtype=float)\n",
    "                b = boundary_limits(centers)\n",
    "                r = np.minimum(r, b)\n",
    "                r = np.maximum(r, r_min_local)\n",
    "                # Try to extract duals for guidance\n",
    "                weights = None\n",
    "                try:\n",
    "                    ine = getattr(res, \"ineqlin\", None)\n",
    "                    if ine is not None and hasattr(ine, \"marginals\"):\n",
    "                        y_dual = np.array(ine.marginals, dtype=float)\n",
    "                        weights = -y_dual\n",
    "                        weights = np.maximum(weights, 0.0)\n",
    "                except Exception:\n",
    "                    weights = None\n",
    "                return r, True, weights\n",
    "            else:\n",
    "                return solve_radii_lp_fallback(centers, r_min_local)\n",
    "        except Exception:\n",
    "            return solve_radii_lp_fallback(centers, r_min_local)\n",
    "\n",
    "    def build_slp_subset_lp(centers, subset_idx, trust):\n",
    "        try:\n",
    "            from scipy.optimize import linprog  # noqa: F401\n",
    "        except Exception:\n",
    "            return None\n",
    "        m = len(subset_idx)\n",
    "        var_dim = 2 * m + n\n",
    "        idx_map = {subset_idx[k]: k for k in range(m)}\n",
    "        A_rows = []\n",
    "        b_vals = []\n",
    "\n",
    "        x = centers[:, 0]; y = centers[:, 1]\n",
    "        # Boundary constraints\n",
    "        for i in range(n):\n",
    "            # r_i - dx_i <= x_i\n",
    "            row = np.zeros(var_dim)\n",
    "            row[2 * m + i] = 1.0\n",
    "            if i in idx_map:\n",
    "                k = idx_map[i]\n",
    "                row[2 * k + 0] = -1.0\n",
    "            A_rows.append(row); b_vals.append(x[i])\n",
    "            # r_i + dx_i <= 1 - x_i\n",
    "            row = np.zeros(var_dim)\n",
    "            row[2 * m + i] = 1.0\n",
    "            if i in idx_map:\n",
    "                k = idx_map[i]\n",
    "                row[2 * k + 0] = 1.0\n",
    "            A_rows.append(row); b_vals.append(1.0 - x[i])\n",
    "            # r_i - dy_i <= y_i\n",
    "            row = np.zeros(var_dim)\n",
    "            row[2 * m + i] = 1.0\n",
    "            if i in idx_map:\n",
    "                k = idx_map[i]\n",
    "                row[2 * k + 1] = -1.0\n",
    "            A_rows.append(row); b_vals.append(y[i])\n",
    "            # r_i + dy_i <= 1 - y_i\n",
    "            row = np.zeros(var_dim)\n",
    "            row[2 * m + i] = 1.0\n",
    "            if i in idx_map:\n",
    "                k = idx_map[i]\n",
    "                row[2 * k + 1] = 1.0\n",
    "            A_rows.append(row); b_vals.append(1.0 - y[i])\n",
    "\n",
    "        # Pairwise linearization at current centers\n",
    "        diff = centers[:, None, :] - centers[None, :, :]\n",
    "        Dij = np.sqrt(np.maximum(np.sum(diff * diff, axis=2), 0.0))\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                dij = Dij[i, j]\n",
    "                if dij <= 1e-12:\n",
    "                    ang = rng.uniform(0, 2 * np.pi)\n",
    "                    ux, uy = np.cos(ang), np.sin(ang)\n",
    "                else:\n",
    "                    u = diff[i, j] / dij\n",
    "                    ux, uy = float(u[0]), float(u[1])\n",
    "                row = np.zeros(var_dim)\n",
    "                if i in idx_map:\n",
    "                    ki = idx_map[i]\n",
    "                    row[2 * ki + 0] += -ux\n",
    "                    row[2 * ki + 1] += -uy\n",
    "                if j in idx_map:\n",
    "                    kj = idx_map[j]\n",
    "                    row[2 * kj + 0] += ux\n",
    "                    row[2 * kj + 1] += uy\n",
    "                row[2 * m + i] += 1.0\n",
    "                row[2 * m + j] += 1.0\n",
    "                A_rows.append(row); b_vals.append(dij)\n",
    "\n",
    "        A_ub = np.array(A_rows, dtype=float) if A_rows else None\n",
    "        b_ub = np.array(b_vals, dtype=float) if b_vals else None\n",
    "\n",
    "        bounds = []\n",
    "        # Displacement bounds (trust region and box)\n",
    "        for k, i in enumerate(subset_idx):\n",
    "            xi, yi = centers[i]\n",
    "            dx_lo = max(-trust, eps - xi)\n",
    "            dx_hi = min(trust, 1.0 - eps - xi)\n",
    "            dy_lo = max(-trust, eps - yi)\n",
    "            dy_hi = min(trust, 1.0 - eps - yi)\n",
    "            bounds.append((dx_lo, dx_hi))\n",
    "            bounds.append((dy_lo, dy_hi))\n",
    "        # Radii bounds\n",
    "        for _ in range(n):\n",
    "            bounds.append((r_min, None))\n",
    "\n",
    "        c = np.zeros(var_dim, dtype=float)\n",
    "        c[2 * m:] = -1.0\n",
    "        return c, A_ub, b_ub, bounds\n",
    "\n",
    "    def slp_subset_step(centers, subset_idx, trust):\n",
    "        try:\n",
    "            from scipy.optimize import linprog\n",
    "        except Exception:\n",
    "            return centers, None, False\n",
    "        built = build_slp_subset_lp(centers, subset_idx, trust)\n",
    "        if built is None:\n",
    "            return centers, None, False\n",
    "        c, A_ub, b_ub, bounds = built\n",
    "        try:\n",
    "            res = linprog(c, A_ub=A_ub, b_ub=b_ub, bounds=bounds, method='highs')\n",
    "            if not (getattr(res, \"success\", False) and res.x is not None):\n",
    "                return centers, None, False\n",
    "            m = len(subset_idx)\n",
    "            sol = np.array(res.x, dtype=float)\n",
    "            dxy = sol[:2 * m].reshape(m, 2)\n",
    "            r_lin = sol[2 * m:]\n",
    "            centers_new = centers.copy()\n",
    "            for idx_local, i in enumerate(subset_idx):\n",
    "                centers_new[i] = centers_new[i] + dxy[idx_local]\n",
    "            centers_new = clamp01(centers_new)\n",
    "            return centers_new, r_lin, True\n",
    "        except Exception:\n",
    "            return centers, None, False\n",
    "\n",
    "    def refine_by_slp_iterative(centers_init, max_outer=8, init_trust=0.08):\n",
    "        centers = centers_init.copy()\n",
    "        r, ok, _ = solve_radii_lp(centers, r_min)\n",
    "        if not ok:\n",
    "            return centers, r, False\n",
    "        best_score = float(np.sum(r))\n",
    "        best_centers = centers.copy()\n",
    "        trust = init_trust\n",
    "        for _ in range(max_outer):\n",
    "            if time_left() < 0.15:\n",
    "                break\n",
    "            subset_idx = list(range(n))\n",
    "            centers_cand, _, ok_step = slp_subset_step(centers, subset_idx, trust)\n",
    "            if not ok_step:\n",
    "                trust *= 0.7\n",
    "                if trust < 1e-3:\n",
    "                    break\n",
    "                continue\n",
    "            r_rep, ok2, _ = solve_radii_lp(centers_cand, r_min)\n",
    "            if ok2:\n",
    "                sc = float(np.sum(r_rep))\n",
    "                if sc > best_score + 1e-10:\n",
    "                    centers = centers_cand\n",
    "                    r = r_rep\n",
    "                    best_score = sc\n",
    "                    best_centers = centers.copy()\n",
    "                    trust = min(trust * 1.3, 0.2)\n",
    "                else:\n",
    "                    trust *= 0.6\n",
    "                    if trust < 1e-3:\n",
    "                        break\n",
    "            else:\n",
    "                trust *= 0.6\n",
    "                if trust < 1e-3:\n",
    "                    break\n",
    "        return best_centers, r, True\n",
    "\n",
    "    def dual_inform_weights(centers, r, duals):\n",
    "        w = np.zeros(n, dtype=float)\n",
    "        if duals is not None:\n",
    "            num_boundary = 4 * n\n",
    "            if duals.shape[0] >= num_boundary:\n",
    "                db = duals[:num_boundary].reshape(n, 4)\n",
    "                w += np.sum(db, axis=1)\n",
    "                dp = duals[num_boundary:]\n",
    "                idx = 0\n",
    "                for i in range(n):\n",
    "                    for j in range(i + 1, n):\n",
    "                        if idx >= dp.shape[0]:\n",
    "                            break\n",
    "                        val = dp[idx]\n",
    "                        w[i] += val\n",
    "                        w[j] += val\n",
    "                        idx += 1\n",
    "        with np.errstate(divide='ignore'):\n",
    "            inv_r = 1.0 / np.maximum(r, 1e-6)\n",
    "        w += 0.2 * inv_r\n",
    "        s = np.sum(w)\n",
    "        if s <= 0:\n",
    "            w = np.ones(n) / n\n",
    "        else:\n",
    "            w = w / s\n",
    "        return w\n",
    "\n",
    "    def init_hex_grid():\n",
    "        K = n\n",
    "        cols = int(np.ceil(np.sqrt(K)))\n",
    "        rows = int(np.ceil(K / cols))\n",
    "        xs = np.linspace(0.1, 0.9, cols)\n",
    "        ys = np.linspace(0.1, 0.9, rows)\n",
    "        pts = []\n",
    "        cnt = 0\n",
    "        for r_idx, yy in enumerate(ys):\n",
    "            off = 0.0 if (r_idx % 2 == 0) else (xs[1] - xs[0]) * 0.5 if len(xs) > 1 else 0.0\n",
    "            for xx in xs:\n",
    "                if cnt >= K:\n",
    "                    break\n",
    "                x = np.clip(xx + off, 0.06, 0.94)\n",
    "                x += rng.normal(0, 0.01)\n",
    "                y = yy + rng.normal(0, 0.01)\n",
    "                pts.append([x, y])\n",
    "                cnt += 1\n",
    "            if cnt >= K:\n",
    "                break\n",
    "        pts = np.array(pts, dtype=float)\n",
    "        while pts.shape[0] < K:\n",
    "            pts = np.vstack([pts, rng.uniform(0.15, 0.85, size=(1, 2))])\n",
    "        return clamp01(pts[:n])\n",
    "\n",
    "    def init_edges():\n",
    "        pts = []\n",
    "        e = 1e-3\n",
    "        corners = [[e, e], [1 - e, e], [e, 1 - e], [1 - e, 1 - e]]\n",
    "        pts.extend(corners)\n",
    "        ts = np.linspace(0.15, 0.85, 6)\n",
    "        for t in ts:\n",
    "            pts.append([t, e]); pts.append([t, 1 - e])\n",
    "            pts.append([e, t]); pts.append([1 - e, t])\n",
    "        pts = np.array(pts[:n], dtype=float)\n",
    "        if pts.shape[0] < n:\n",
    "            while pts.shape[0] < n:\n",
    "                edge = rng.integers(0, 4)\n",
    "                t = rng.uniform(0.08, 0.92)\n",
    "                if edge == 0: pts = np.vstack([pts, [t, e]])\n",
    "                elif edge == 1: pts = np.vstack([pts, [t, 1 - e]])\n",
    "                elif edge == 2: pts = np.vstack([pts, [e, t]])\n",
    "                else: pts = np.vstack([pts, [1 - e, t]])\n",
    "        return clamp01(pts[:n])\n",
    "\n",
    "    def init_center_biased():\n",
    "        pts = 0.75 * rng.uniform(0.05, 0.95, size=(n, 2)) + 0.25 * 0.5\n",
    "        pts += rng.normal(0, 0.03, size=(n, 2))\n",
    "        return clamp01(pts)\n",
    "\n",
    "    def init_uniform():\n",
    "        return clamp01(rng.uniform(0.1, 0.9, size=(n, 2)))\n",
    "\n",
    "    def evaluate_centers(centers):\n",
    "        centers = clamp01(centers)\n",
    "        r, ok, duals = solve_radii_lp(centers, r_min)\n",
    "        if not ok or r is None:\n",
    "            b = boundary_limits(centers)\n",
    "            r = np.maximum(np.minimum(b, 0.5), r_min)\n",
    "            duals = None\n",
    "        return np.hstack([centers, r.reshape(-1, 1)]), float(np.sum(r)), duals\n",
    "\n",
    "    # Seed centers\n",
    "    seed_centers_list = []\n",
    "    if isinstance(current_best_solution, np.ndarray):\n",
    "        try:\n",
    "            cb = current_best_solution\n",
    "            if cb.shape[0] == n and cb.shape[1] >= 2:\n",
    "                centers_cb = clamp01(cb[:, :2].astype(float))\n",
    "                seed_centers_list.append(centers_cb)\n",
    "                for _ in range(2):\n",
    "                    seed_centers_list.append(clamp01(centers_cb + rng.normal(0, 0.01, size=centers_cb.shape)))\n",
    "        except Exception:\n",
    "            pass\n",
    "    seed_centers_list.append(init_hex_grid())\n",
    "    seed_centers_list.append(init_edges())\n",
    "    seed_centers_list.append(init_center_biased())\n",
    "    seed_centers_list.append(init_uniform())\n",
    "    seed_centers_list.append(clamp01(init_hex_grid() + rng.normal(0, 0.02, size=(n, 2))))\n",
    "\n",
    "    # Deduplicate seeds with slight jitter on collisions\n",
    "    unique_seeds = []\n",
    "    seen = set()\n",
    "    for c in seed_centers_list:\n",
    "        h = tuple(np.round(c.ravel(), 3))\n",
    "        if h in seen:\n",
    "            c = clamp01(c + rng.normal(0, 0.005, size=c.shape))\n",
    "        unique_seeds.append(c)\n",
    "        seen.add(h)\n",
    "    seed_centers_list = unique_seeds\n",
    "\n",
    "    best_circles = None\n",
    "    best_score = -1e18\n",
    "    best_duals = None\n",
    "\n",
    "    # Initial evaluation of seeds\n",
    "    for centers in seed_centers_list:\n",
    "        circles, score, duals = evaluate_centers(centers)\n",
    "        if score > best_score + 1e-12:\n",
    "            best_score = score\n",
    "            best_circles = circles\n",
    "            best_duals = duals\n",
    "            all_scores.append(best_score)\n",
    "\n",
    "    # Global SLP refine on seeds\n",
    "    per_seed_time = max(0.4, time_left() / max(1, len(seed_centers_list)))\n",
    "    for centers0 in seed_centers_list:\n",
    "        if time_left() < 0.4:\n",
    "            break\n",
    "        t_seed_start = time.time()\n",
    "\n",
    "        def time_left_seed():\n",
    "            return min(time_left(), per_seed_time - (time.time() - t_seed_start))\n",
    "\n",
    "        if time_left_seed() < 0.2:\n",
    "            continue\n",
    "        centers_ref, r_ref, _ = refine_by_slp_iterative(centers0, max_outer=8, init_trust=0.08)\n",
    "        circles, score, duals = evaluate_centers(centers_ref)\n",
    "        if score > best_score + 1e-12:\n",
    "            best_score = score\n",
    "            best_circles = circles\n",
    "            best_duals = duals\n",
    "            all_scores.append(best_score)\n",
    "\n",
    "    # LNS loop\n",
    "    if best_circles is None:\n",
    "        centers = init_edges()\n",
    "        r, _, _ = solve_radii_lp(centers, r_min)\n",
    "        best_circles = np.hstack([centers, r.reshape(-1, 1)])\n",
    "        best_score = float(np.sum(r))\n",
    "        all_scores.append(best_score)\n",
    "\n",
    "    centers = best_circles[:, :2].copy()\n",
    "    r, ok, duals = solve_radii_lp(centers, r_min)\n",
    "    if ok:\n",
    "        best_duals = duals\n",
    "\n",
    "    stagnation = 0\n",
    "    attempts = 0\n",
    "    max_attempts = 1000000\n",
    "    while time_left() > 0.25 and attempts < max_attempts:\n",
    "        attempts += 1\n",
    "        # Determine subset size\n",
    "        base_m = 8\n",
    "        if stagnation > 8:\n",
    "            base_m = 12\n",
    "        elif stagnation > 3:\n",
    "            base_m = 10\n",
    "        m = int(np.clip(base_m + rng.integers(-2, 3), 5, 14))\n",
    "        # Select subset indices\n",
    "        weights = dual_inform_weights(centers, r if r is not None else np.ones(n), best_duals)\n",
    "        try:\n",
    "            subset_idx = rng.choice(n, size=m, replace=False, p=weights)\n",
    "        except Exception:\n",
    "            subset_idx = rng.choice(n, size=m, replace=False)\n",
    "        trust = 0.08 * (0.9 ** (stagnation // 3))\n",
    "        trust = float(np.clip(trust, 0.01, 0.2))\n",
    "\n",
    "        improved_local = False\n",
    "        for _ in range(3):\n",
    "            if time_left() < 0.15:\n",
    "                break\n",
    "            centers_cand, _, ok_step = slp_subset_step(centers, list(subset_idx), trust)\n",
    "            if not ok_step:\n",
    "                trust *= 0.7\n",
    "                continue\n",
    "            r_cand, ok_rep, duals_cand = solve_radii_lp(centers_cand, r_min)\n",
    "            if ok_rep:\n",
    "                sc = float(np.sum(r_cand))\n",
    "                if sc > best_score + 1e-10:\n",
    "                    centers = centers_cand\n",
    "                    r = r_cand\n",
    "                    best_score = sc\n",
    "                    best_circles = np.hstack([centers, r.reshape(-1, 1)])\n",
    "                    best_duals = duals_cand\n",
    "                    all_scores.append(best_score)\n",
    "                    improved_local = True\n",
    "                    stagnation = 0\n",
    "                    trust = min(trust * 1.3, 0.25)\n",
    "                else:\n",
    "                    trust *= 0.8\n",
    "            else:\n",
    "                trust *= 0.7\n",
    "        if not improved_local:\n",
    "            stagnation += 1\n",
    "            # Occasional global SLP to escape\n",
    "            if stagnation % 6 == 0 and time_left() > 0.25:\n",
    "                centers_glob, r_glob, _ = refine_by_slp_iterative(centers, max_outer=5, init_trust=0.06)\n",
    "                circles_glob, sc_glob, duals_glob = evaluate_centers(centers_glob)\n",
    "                if sc_glob > best_score + 1e-10:\n",
    "                    best_score = sc_glob\n",
    "                    best_circles = circles_glob\n",
    "                    centers = circles_glob[:, :2].copy()\n",
    "                    r = circles_glob[:, 2].copy()\n",
    "                    best_duals = duals_glob\n",
    "                    all_scores.append(best_score)\n",
    "                    stagnation = 0\n",
    "            # Occasional random shake of a few smallest-r circles\n",
    "            if stagnation % 4 == 0:\n",
    "                if r is None or not np.all(np.isfinite(r)):\n",
    "                    r = boundary_limits(centers)\n",
    "                kshake = max(3, n // 6)\n",
    "                idx_sorted = np.argsort(r)\n",
    "                picks = idx_sorted[:kshake]\n",
    "                perturb = rng.normal(0, 0.02 * (1 + 0.05 * stagnation), size=(len(picks), 2))\n",
    "                centers_shake = centers.copy()\n",
    "                centers_shake[picks] = clamp01(centers_shake[picks] + perturb)\n",
    "                r_shake, ok_sh, duals_sh = solve_radii_lp(centers_shake, r_min)\n",
    "                if ok_sh:\n",
    "                    sc = float(np.sum(r_shake))\n",
    "                    if sc > best_score + 1e-10:\n",
    "                        centers = centers_shake\n",
    "                        r = r_shake\n",
    "                        best_score = sc\n",
    "                        best_circles = np.hstack([centers, r.reshape(-1, 1)])\n",
    "                        best_duals = duals_sh\n",
    "                        all_scores.append(best_score)\n",
    "                        stagnation = 0\n",
    "\n",
    "        if stagnation > 18:\n",
    "            # Re-diversify by mixing with a new seed\n",
    "            seed = init_uniform() if rng.random() < 0.5 else init_hex_grid()\n",
    "            centers_mix = 0.5 * centers + 0.5 * seed\n",
    "            centers_mix = clamp01(centers_mix)\n",
    "            r_mix, ok_mix, duals_mix = solve_radii_lp(centers_mix, r_min)\n",
    "            if ok_mix:\n",
    "                sc = float(np.sum(r_mix))\n",
    "                if sc > best_score + 1e-10:\n",
    "                    centers = centers_mix\n",
    "                    r = r_mix\n",
    "                    best_score = sc\n",
    "                    best_circles = np.hstack([centers, r.reshape(-1, 1)])\n",
    "                    best_duals = duals_mix\n",
    "                    all_scores.append(best_score)\n",
    "                    stagnation = 0\n",
    "                else:\n",
    "                    stagnation = max(stagnation - 5, 0)\n",
    "\n",
    "    # Final feasibility and polish\n",
    "    try:\n",
    "        centers_final = best_circles[:, :2]\n",
    "        r_final, ok_fin, _ = solve_radii_lp(centers_final, r_min)\n",
    "        if ok_fin and r_final is not None:\n",
    "            best_circles = np.hstack([centers_final, r_final.reshape(-1, 1)])\n",
    "            best_score = float(np.sum(r_final))\n",
    "            if not all_scores or best_score > all_scores[-1] + 1e-9:\n",
    "                all_scores.append(best_score)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        'circles': best_circles.astype(float),\n",
    "        'all_scores': [float(s) for s in all_scores] if all_scores else [float(best_score)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circle-evolved",
   "metadata": {},
   "source": [
    "## What GEPA Discovered\n",
    "\n",
    "GEPA evolved the simple grid-based baseline into a **sophisticated multi-strategy optimizer**. Here's what the evolved code includes:\n",
    "\n",
    "### Strategies Discovered by GEPA\n",
    "\n",
    "| Strategy | Description | How It Helps |\n",
    "|----------|-------------|--------------|\n",
    "| **Halton sequences** | Quasi-random initialization | Better initial coverage than random |\n",
    "| **Zero-vector seeding** | Start from origin | Often near polynomial optima |\n",
    "| **CMA-ES-style evolution** | Covariance matrix adaptation | Adapts search direction to landscape |\n",
    "| **Quadratic surrogate models** | Local function approximation | Efficient local optimization |\n",
    "| **Coordinate descent** | Per-dimension refinement | Fine-tunes individual coordinates |\n",
    "| **Nelder-Mead subspace** | Simplex method in active dimensions | Exploits important variables |\n",
    "| **Ridge-linear probes** | Gradient estimation from archive | Uses history for direction hints |\n",
    "\n",
    "### Results\n",
    "\n",
    "The evolved code achieves packing densities that **match or exceed** published results from:\n",
    "- **AlphaEvolve** (DeepMind)\n",
    "- **ShinkaEvolve**\n",
    "- **OpenEvolve**\n",
    "\n",
    "All without any human optimization expertise—just the problem definition and a baseline!\n",
    "\n",
    "### Key Takeaway\n",
    "\n",
    "GEPA automatically discovered advanced optimization strategies (Halton sequences, CMA-ES, surrogate models) that typically require expert knowledge to implement. The user only needed to:\n",
    "1. Define the problem (pack circles)\n",
    "2. Provide a naive baseline (grid placement)\n",
    "3. Return informative `side_info` (violations, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e571da",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# KernelBench\n",
    "\n",
    "This example optimizes CUDA kernels against the KernelBench suite. GEPA evolves two prompts: a kernel generator prompt and a refiner prompt.\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "KernelBench provides PyTorch reference models. The candidate must produce a `ModelNew` with custom CUDA kernels (via `load_inline`) that is correct and faster than the PyTorch baseline.\n",
    "\n",
    "## The Task\n",
    "\n",
    "**Given**: PyTorch reference models + baseline runtimes\n",
    "**Find**: Prompts that generate correct, faster CUDA kernels\n",
    "\n",
    "V100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921eaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import dspy\n",
    "\n",
    "from examples.kernelbench.prompts import BACKGROUND, KERNEL_GEN_PROMPT, REFINER_PROMPT\n",
    "from examples.kernelbench.eval import get_free_gpus, init_gpu_manager, load_dataset, load_or_measure_baselines\n",
    "from examples.kernelbench.main import create_fitness_fn, PromptCache, StateTracker, LLM\n",
    "from gepa.optimize_anything import EngineConfig, GEPAConfig, ReflectionConfig, optimize_anything\n",
    "\n",
    "run_name = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "log_dir = f\"outputs/artifacts/kernelbench/{run_name}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "dataset = load_dataset()\n",
    "baselines = load_or_measure_baselines(dataset)\n",
    "\n",
    "available_gpus = get_free_gpus()\n",
    "init_gpu_manager(device_list=available_gpus, lock_dir=os.path.join(log_dir, \"gpu_locks\"))\n",
    "\n",
    "lm = dspy.LM(LLM, temperature=1.0, max_tokens=32000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888fcd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = \"Generate an LLM prompt that produces fast, correct CUDA kernels outperforming PyTorch baselines.\"\n",
    "\n",
    "seed_candidate = {\n",
    "    \"kernel_gen_prompt\": KERNEL_GEN_PROMPT,\n",
    "    \"refiner_prompt\": REFINER_PROMPT.format(objective=objective),\n",
    "}\n",
    "\n",
    "fitness_fn = create_fitness_fn(\n",
    "    lm,\n",
    "    baselines=baselines,\n",
    "    max_refinements=2,\n",
    ")\n",
    "\n",
    "config = GEPAConfig(\n",
    "    engine=EngineConfig(\n",
    "        run_dir=log_dir,\n",
    "        max_metric_calls=2000,\n",
    "        cache_evaluation=True,\n",
    "        track_best_outputs=True,\n",
    "        parallel=False,\n",
    "        max_workers=1,\n",
    "    ),\n",
    "    reflection=ReflectionConfig(\n",
    "        reflection_minibatch_size=3,\n",
    "        reflection_lm=LLM,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=dataset,\n",
    "    config=config,\n",
    "    objective=objective,\n",
    "    background=BACKGROUND,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979cc0c5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "KernelBench provides PyTorch reference models. The candidate must produce a `ModelNew` with custom CUDA kernels (via `load_inline`) that is correct and faster than the PyTorch baseline.\n",
    "\n",
    "## The Task\n",
    "\n",
    "**Given**: PyTorch reference models + baseline runtimes\n",
    "**Find**: Prompts that generate correct, faster CUDA kernels\n",
    "\n",
    "Results are hardware-dependent; see `outputs/artifacts/kernelbench/` for latest runs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b2b01",
   "metadata": {},
   "source": [
    "# 8. Example 5: Systems Optimization — Cloud Infrastructure\n",
    "\n",
    "**Result: GEPA discovers cost-saving strategies for real cloud infrastructure problems.**\n",
    "\n",
    "We demonstrate `optimize_anything` on two challenging systems problems from the [ADRS project](https://adrs-ucb.notion.site/):\n",
    "\n",
    "| Problem | Domain | Baseline Cost | Optimized Cost | Savings |\n",
    "|---------|--------|---------------|----------------|---------|\n",
    "| **Can't Be Late** | Spot Instance Scheduling | 96.48 | 89.86 | **6.9%** |\n",
    "| **Cloudcast** | Multi-Cloud Broadcast | $209 | $146 | **30.4%** |\n",
    "\n",
    "These problems involve optimizing complex algorithms with real-world constraints—exactly where traditional optimization struggles and LLM-based reflection excels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5bb9ff",
   "metadata": {},
   "source": [
    "## 8.1 Can't Be Late: Spot Instance Scheduling\n",
    "\n",
    "The [Can't Be Late problem](https://www.usenix.org/conference/nsdi24/presentation/wu-zhanghao) from NSDI'24 challenges us to minimize cloud computing costs while meeting deadlines.\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "A cloud job must complete before a deadline using:\n",
    "- **SPOT instances**: Cheap (~$0.3/hour) but can be preempted at any time\n",
    "- **ON_DEMAND instances**: Expensive (~$1/hour) but guaranteed availability  \n",
    "- **NONE**: Wait without using any instances\n",
    "\n",
    "The strategy must decide dynamically which instance type to use based on:\n",
    "- Time remaining until deadline\n",
    "- Current spot availability\n",
    "- Restart overhead when preempted\n",
    "\n",
    "**Goal**: Minimize cost while ensuring task completion before deadline.\n",
    "\n",
    "### Why This is Hard\n",
    "\n",
    "- Spot preemption is **stochastic** — you can't predict when you'll lose your instance\n",
    "- The optimal strategy depends on **multiple factors**: deadline slack, restart cost, spot availability\n",
    "- Simple heuristics (always use spot, always use on-demand) are suboptimal\n",
    "\n",
    "### Setup\n",
    "\n",
    "```bash\n",
    "# Extract trace data\n",
    "cd examples/adrs/can_be_late/simulator\n",
    "tar -xzf real_traces.tar.gz\n",
    "\n",
    "# Install dependencies\n",
    "pip install -r examples/adrs/can_be_late/simulator/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1475c",
   "metadata": {},
   "source": [
    "### The Seed Candidate\n",
    "\n",
    "We start with a simple baseline strategy that uses spot when available and switches to on-demand only when deadline is tight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e01ebfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the seed strategy as a string (required for GEPA optimization)\n",
    "INITIAL_PROGRAM = \"\"\"import math\n",
    "from sky_spot.strategies.strategy import Strategy\n",
    "from sky_spot.utils import ClusterType\n",
    "\n",
    "class EvolveSingleRegionStrategy(Strategy):\n",
    "    NAME = 'evolve_single_region'\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)\n",
    "    \n",
    "    def reset(self, env, task):\n",
    "        super().reset(env, task)\n",
    "    \n",
    "    def _step(self, last_cluster_type: ClusterType, has_spot: bool) -> ClusterType:\n",
    "        env = self.env\n",
    "        \n",
    "        # Task completion check\n",
    "        remaining_task_time = self.task_duration - sum(self.task_done_time)\n",
    "        if remaining_task_time <= 1e-3:\n",
    "            return ClusterType.NONE\n",
    "        \n",
    "        # Calculate remaining time until deadline\n",
    "        remaining_time = self.deadline - env.elapsed_seconds\n",
    "        \n",
    "        # Simple deadline check: if we're running out of time, use ON_DEMAND\n",
    "        # Add restart overhead to account for potential restart\n",
    "        if remaining_task_time + self.restart_overhead >= remaining_time:\n",
    "            # We need ON_DEMAND to guarantee completion\n",
    "            return ClusterType.ON_DEMAND\n",
    "        \n",
    "        # Simple greedy logic: use SPOT if available, wait otherwise\n",
    "        if has_spot:\n",
    "            return ClusterType.SPOT\n",
    "        else:\n",
    "            # Just wait for SPOT to become available\n",
    "            return ClusterType.NONE\n",
    "    \n",
    "    @classmethod\n",
    "    def _from_args(cls, parser):\n",
    "        args, _ = parser.parse_known_args()\n",
    "        return cls(args)\n",
    "\"\"\"\n",
    "\n",
    "# Create seed candidate\n",
    "seed_candidate = {\"program\": INITIAL_PROGRAM}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833e5bea",
   "metadata": {},
   "source": [
    "### The Fitness Function\n",
    "\n",
    "The fitness function runs simulations on real AWS spot availability traces. The full evaluator is in `examples/adrs/can_be_late/evaluator.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94dd3cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from typing import Any\n",
    "\n",
    "from gepa.optimize_anything import SideInfo\n",
    "from examples.adrs.can_be_late.evaluator import (\n",
    "    evaluate_stage1,      # Syntax validation\n",
    "    run_single_simulation, # Runs simulator subprocess\n",
    "    FAILED_SCORE,         # Score for failed programs (-100000.0)\n",
    ")\n",
    "from examples.adrs.can_be_late.trace_dataset import load_trace_dataset\n",
    "\n",
    "# Load real AWS spot availability traces\n",
    "dataset_root = \"examples/adrs/can_be_late/simulator/real\"\n",
    "splits = load_trace_dataset(dataset_root=dataset_root)\n",
    "train_set, val_set, test_set = splits[\"train\"], splits[\"val\"], splits[\"test\"]\n",
    "\n",
    "def create_fitness_function(timeout: int = 300):\n",
    "    \"\"\"\n",
    "    Create fitness function for GEPA optimization.\n",
    "    \n",
    "    The fitness function evaluates a candidate strategy on trace samples,\n",
    "    running simulations and returning scores with diagnostic information.\n",
    "    \"\"\"\n",
    "    # Cache to avoid redundant file I/O when evaluating same program on multiple examples\n",
    "    _cache: dict[str, Any] = {\n",
    "        \"program_code\": None,\n",
    "        \"program_path\": None,\n",
    "        \"tmpdir\": None,\n",
    "        \"stage1_result\": None,\n",
    "    }\n",
    "\n",
    "    def _get_or_create_program_file(program_code: str) -> tuple[str, dict]:\n",
    "        \"\"\"Get cached program file or create new one if program changed.\"\"\"\n",
    "        if _cache[\"program_code\"] != program_code:\n",
    "            if _cache[\"tmpdir\"] is not None:\n",
    "                shutil.rmtree(_cache[\"tmpdir\"], ignore_errors=True)\n",
    "            \n",
    "            tmpdir = tempfile.mkdtemp(prefix=\"cant_be_late_eval_\")\n",
    "            program_path = os.path.join(tmpdir, \"strategy.py\")\n",
    "            with open(program_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(program_code)\n",
    "            \n",
    "            stage1_result = evaluate_stage1(program_path)\n",
    "            \n",
    "            _cache[\"program_code\"] = program_code\n",
    "            _cache[\"program_path\"] = program_path\n",
    "            _cache[\"tmpdir\"] = tmpdir\n",
    "            _cache[\"stage1_result\"] = stage1_result\n",
    "        \n",
    "        return _cache[\"program_path\"], _cache[\"stage1_result\"]\n",
    "\n",
    "    def fitness_fn(\n",
    "        candidate: dict[str, str], example: dict[str, Any], **kwargs\n",
    "    ) -> tuple[float, Any, SideInfo]:\n",
    "        \"\"\"\n",
    "        Evaluate a candidate strategy on a single trace sample.\n",
    "        \n",
    "        Args:\n",
    "            candidate: Dict with \"program\" key containing strategy code\n",
    "            example: Sample dict with 'trace_file' and 'config'\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (score, output, side_info)\n",
    "        \"\"\"\n",
    "        program_code = candidate[\"program\"]\n",
    "        program_path, stage1_result = _get_or_create_program_file(program_code)\n",
    "\n",
    "        # Stage 1: Check syntax\n",
    "        if stage1_result.get(\"runs_successfully\", 0.0) < 1.0:\n",
    "            error_msg = stage1_result.get(\"error\", \"Syntax validation failed\")\n",
    "            side_info: SideInfo = {\n",
    "                \"scores\": {\"cost\": FAILED_SCORE},\n",
    "                \"Input\": {\n",
    "                    \"trace_file\": example.get(\"trace_file\", \"unknown\"),\n",
    "                    \"config\": example.get(\"config\", {}),\n",
    "                },\n",
    "                \"Error\": error_msg,\n",
    "            }\n",
    "            return (FAILED_SCORE, {\"error\": error_msg}, side_info)\n",
    "\n",
    "        # Stage 2: Run simulation\n",
    "        trace_file = example.get(\"trace_file\")\n",
    "        config = example.get(\"config\")\n",
    "\n",
    "        if not trace_file or not config:\n",
    "            side_info = {\n",
    "                \"scores\": {\"cost\": FAILED_SCORE},\n",
    "                \"Input\": {\"trace_file\": trace_file, \"config\": config},\n",
    "                \"Error\": \"Invalid sample: missing trace_file or config\",\n",
    "            }\n",
    "            return (FAILED_SCORE, {\"error\": \"Invalid sample\"}, side_info)\n",
    "\n",
    "        success, cost, error_msg, detailed_info = run_single_simulation(\n",
    "            program_path, trace_file, config\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            score = -cost  # Lower cost = higher score\n",
    "            cli_segments = detailed_info.get(\"cli_segments\", {})\n",
    "            timeline_events = cli_segments.get(\"timeline_events\", [])\n",
    "            timeline_str = \" | \".join(timeline_events[:12]) if timeline_events else \"N/A\"\n",
    "\n",
    "            side_info = {\n",
    "                \"scores\": {\"cost\": score},\n",
    "                \"Input\": {\n",
    "                    \"trace_file\": os.path.basename(trace_file),\n",
    "                    \"duration\": f\"{config['duration']}h\",\n",
    "                    \"deadline\": f\"{config['deadline']}h\",\n",
    "                    \"overhead\": f\"{config['overhead']}h\",\n",
    "                    \"spot_availability\": cli_segments.get(\"spot_availability\", \"N/A\"),\n",
    "                },\n",
    "                \"Output\": {\n",
    "                    \"cost\": f\"${cost:.2f}\",\n",
    "                    \"timeline\": timeline_str,\n",
    "                },\n",
    "            }\n",
    "            return (score, {\"cost\": cost, \"score\": score}, side_info)\n",
    "        else:\n",
    "            side_info = {\n",
    "                \"scores\": {\"cost\": FAILED_SCORE},\n",
    "                \"Input\": {\"trace_file\": os.path.basename(trace_file) if trace_file else \"unknown\"},\n",
    "                \"Error\": error_msg,\n",
    "            }\n",
    "            return (FAILED_SCORE, {\"error\": error_msg}, side_info)\n",
    "\n",
    "    return fitness_fn\n",
    "\n",
    "# Create fitness function\n",
    "fitness_fn = create_fitness_function(timeout=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1036e",
   "metadata": {},
   "source": [
    "### Running GEPA Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a5bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai._api_client:The project/location from the environment variables will take precedence over the API key from the environment variables.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     20\u001b[39m OPTIMIZATION_BACKGROUND = \u001b[33m\"\"\"\u001b[39m\u001b[33mKey information:\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[33m- ClusterType.SPOT: Cheap (~$0.3/hour) but can be preempted\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33m- ClusterType.ON_DEMAND: Expensive (~$1/hour) but guaranteed\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[33m- ClusterType.NONE: Wait without using instances\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[33m- restart_overhead: Time penalty when switching instances\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[33m- Lower cost is better (scores are negative cost in dollars)\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     27\u001b[39m gepa_config = GEPAConfig(\n\u001b[32m     28\u001b[39m     engine=EngineConfig(\n\u001b[32m     29\u001b[39m         run_dir=\u001b[33m\"\u001b[39m\u001b[33mruns/cant_be_late\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     ),\n\u001b[32m     38\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m result = \u001b[43moptimize_anything\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed_candidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed_candidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfitness_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfitness_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOPTIMIZATION_OBJECTIVE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m=\u001b[49m\u001b[43mOPTIMIZATION_BACKGROUND\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgepa_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/resources/gepa-optimize-anything/src/gepa/optimize_anything.py:794\u001b[39m, in \u001b[36moptimize_anything\u001b[39m\u001b[34m(seed_candidate, fitness_fn, dataset, valset, objective, background, config)\u001b[39m\n\u001b[32m    792\u001b[39m \u001b[38;5;66;03m# --- 15. Run optimization ---\u001b[39;00m\n\u001b[32m    793\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m experiment_tracker:\n\u001b[32m--> \u001b[39m\u001b[32m794\u001b[39m     state = \u001b[43mengine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m GEPAResult.from_state(state, run_dir=config.engine.run_dir, seed=config.engine.seed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/resources/gepa-optimize-anything/src/gepa/core/engine.py:219\u001b[39m, in \u001b[36mGEPAEngine.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    212\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ValsetEvaluation(\n\u001b[32m    213\u001b[39m         outputs_by_val_id=outputs_dict,\n\u001b[32m    214\u001b[39m         scores_by_val_id=scores_dict,\n\u001b[32m    215\u001b[39m         objective_scores_by_val_id=objective_scores_dict,\n\u001b[32m    216\u001b[39m     )\n\u001b[32m    218\u001b[39m \u001b[38;5;66;03m# Initialize state\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m state = \u001b[43minitialize_gepa_state\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed_candidate\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseed_candidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalset_evaluator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalset_evaluator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrack_best_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrack_best_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrontier_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrontier_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluation_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_initial_evaluation_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[38;5;66;03m# Log base program score\u001b[39;00m\n\u001b[32m    230\u001b[39m base_val_avg, base_val_coverage = state.get_program_average_val_subset(\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/resources/gepa-optimize-anything/src/gepa/core/state.py:621\u001b[39m, in \u001b[36minitialize_gepa_state\u001b[39m\u001b[34m(run_dir, logger, seed_candidate, valset_evaluator, track_best_outputs, frontier_type, evaluation_cache)\u001b[39m\n\u001b[32m    617\u001b[39m     \u001b[38;5;66;03m# else: keep the loaded cache (gepa_state.evaluation_cache is already set)\u001b[39;00m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    619\u001b[39m     num_evals_run = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m621\u001b[39m     eval_result = \u001b[43mvalset_evaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed_candidate\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m run_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    623\u001b[39m         write_eval_outputs_to_directory(\n\u001b[32m    624\u001b[39m             eval_result.outputs_by_val_id, os.path.join(run_dir, \u001b[33m\"\u001b[39m\u001b[33mgenerated_best_outputs_valset\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    625\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/resources/gepa-optimize-anything/src/gepa/core/engine.py:206\u001b[39m, in \u001b[36mGEPAEngine.run.<locals>.valset_evaluator\u001b[39m\u001b[34m(program)\u001b[39m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalset_evaluator\u001b[39m(\n\u001b[32m    203\u001b[39m     program: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[32m    204\u001b[39m ) -> ValsetEvaluation[RolloutOutput, DataId]:\n\u001b[32m    205\u001b[39m     all_ids = \u001b[38;5;28mlist\u001b[39m(valset.all_ids())\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     outputs, scores, objective_scores = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     outputs_dict = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(all_ids, outputs, strict=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m    208\u001b[39m     scores_dict = \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(all_ids, scores, strict=\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/resources/gepa-optimize-anything/src/gepa/core/engine.py:74\u001b[39m, in \u001b[36mGEPAEngine.__init__.<locals>.evaluator\u001b[39m\u001b[34m(batch, program)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluator\u001b[39m(\n\u001b[32m     72\u001b[39m     batch: \u001b[38;5;28mlist\u001b[39m[DataInst], program: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]\n\u001b[32m     73\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mlist\u001b[39m[RolloutOutput], \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m], Sequence[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]] | \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     eval_result = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_traces\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m eval_result.outputs, eval_result.scores, eval_result.objective_scores\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/resources/gepa-optimize-anything/src/gepa/adapters/optimize_anything_adapter/optimize_anything_adapter.py:34\u001b[39m, in \u001b[36mOptimizeAnythingAdapter.evaluate\u001b[39m\u001b[34m(self, batch, candidate, capture_traces)\u001b[39m\n\u001b[32m     32\u001b[39m     eval_output = \u001b[38;5;28mself\u001b[39m._evaluate_parallel(batch, candidate)\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     eval_output = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfitness_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m     35\u001b[39m scores = [score \u001b[38;5;28;01mfor\u001b[39;00m score, _, _ \u001b[38;5;129;01min\u001b[39;00m eval_output]\n\u001b[32m     36\u001b[39m side_infos: \u001b[38;5;28mlist\u001b[39m[SideInfo] = [info \u001b[38;5;28;01mfor\u001b[39;00m _, _, info \u001b[38;5;129;01min\u001b[39;00m eval_output]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 95\u001b[39m, in \u001b[36mcreate_fitness_function.<locals>.fitness_fn\u001b[39m\u001b[34m(candidate, example, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m     side_info = {\n\u001b[32m     89\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mscores\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mcost\u001b[39m\u001b[33m\"\u001b[39m: FAILED_SCORE},\n\u001b[32m     90\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mInput\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mtrace_file\u001b[39m\u001b[33m\"\u001b[39m: trace_file, \u001b[33m\"\u001b[39m\u001b[33mconfig\u001b[39m\u001b[33m\"\u001b[39m: config},\n\u001b[32m     91\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mError\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mInvalid sample: missing trace_file or config\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     92\u001b[39m     }\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (FAILED_SCORE, {\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mInvalid sample\u001b[39m\u001b[33m\"\u001b[39m}, side_info)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m success, cost, error_msg, detailed_info = \u001b[43mrun_single_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogram_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m    100\u001b[39m     score = -cost  \u001b[38;5;66;03m# Lower cost = higher score\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/resources/gepa-optimize-anything/examples/adrs/can_be_late/evaluator.py:436\u001b[39m, in \u001b[36mrun_single_simulation\u001b[39m\u001b[34m(program_path, trace_file, config)\u001b[39m\n\u001b[32m    422\u001b[39m cmd = [\n\u001b[32m    423\u001b[39m     sys.executable,\n\u001b[32m    424\u001b[39m     \u001b[38;5;28mstr\u001b[39m(SIMULATOR_DIR / \u001b[33m\"\u001b[39m\u001b[33mmain.py\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    432\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m--output-dir=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    433\u001b[39m ]\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m436\u001b[39m     result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    439\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    440\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m300\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSIMULATOR_DIR\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    444\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m    445\u001b[39m         error_msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRun failed for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(trace_file)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:1209\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1206\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1211\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1212\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1213\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:2115\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2108\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2109\u001b[39m                         stdout, stderr,\n\u001b[32m   2110\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2111\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2112\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2113\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2115\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2116\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2118\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2119\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/selectors.py:415\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    413\u001b[39m ready = []\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from gepa.optimize_anything import optimize_anything, GEPAConfig, EngineConfig, ReflectionConfig\n",
    "from examples.adrs.can_be_late.main import get_reflection_lm\n",
    "\n",
    "# =============================================================================\n",
    "# Language Model Configuration\n",
    "# =============================================================================\n",
    "# The reflection_lm can be:\n",
    "#   1. A string for LiteLLM-compatible models: \"openai/gpt-4o\", \"anthropic/claude-3-opus\", etc.\n",
    "#   2. A callable that takes a prompt and returns a string response\n",
    "#\n",
    "# get_reflection_lm() creates a callable for Gemini and OpenAI models.\n",
    "#   - get_reflection_lm(\"gemini-2.0-flash-001\")  # Fast Gemini model\n",
    "#   - get_reflection_lm(\"gemini-3-pro-preview\")  # Latest Gemini Pro\n",
    "reflection_lm = get_reflection_lm(\"gemini-3-pro-preview\")\n",
    "\n",
    "OPTIMIZATION_OBJECTIVE = \"\"\"Optimize a cloud scheduling strategy for the \"Can't Be Late\" problem.\n",
    "\n",
    "The strategy decides when to use SPOT instances (cheap but can be preempted) vs ON_DEMAND \n",
    "instances (expensive but reliable) to complete a task before its deadline. The goal is to \n",
    "minimize cost while ensuring the task completes on time.\"\"\"\n",
    "\n",
    "OPTIMIZATION_BACKGROUND = \"\"\"Key information about the problem domain:\n",
    "\n",
    "- ClusterType.SPOT: Use spot instances (cheap, ~$0.3/hour, but can be preempted at any time)\n",
    "- ClusterType.ON_DEMAND: Use on-demand instances (expensive, ~$1/hour, but guaranteed availability)\n",
    "- ClusterType.NONE: Wait without using any instances (no cost, but no progress)\n",
    "- restart_overhead: Time penalty incurred when switching from one instance type to another\n",
    "- The strategy MUST ensure task completion before the deadline (hard constraint)\n",
    "- Lower cost is better (scores are negative, representing cost in dollars)\n",
    "\n",
    "Evaluation feedback format:\n",
    "- Timeline format: start-end:TYPE@REGION[progress%] (e.g., \"0.0-5.0:S@R0[50%]\" means SPOT from hour 0-5 reaching 50% progress)\n",
    "- Spot availability: S=available, X=unavailable (e.g., \"0.0-10.0:S | 10.0-15.0:X\" means spot available first 10h, then unavailable)\n",
    "\n",
    "Optimization targets:\n",
    "1. Reduce overall cost while maintaining deadline guarantees\n",
    "2. Make better decisions about when to use SPOT vs ON_DEMAND\n",
    "3. Handle spot unavailability more intelligently\n",
    "4. Consider the trade-offs between waiting for spot and using on-demand\"\"\"\n",
    "\n",
    "gepa_config = GEPAConfig(\n",
    "    engine=EngineConfig(\n",
    "        run_dir=\"runs/cant_be_late\",\n",
    "        seed=0,\n",
    "        max_metric_calls=15000,\n",
    "        track_best_outputs=True,\n",
    "        use_cloudpickle=True,\n",
    "        display_progress_bar=True,\n",
    "    ),\n",
    "    reflection=ReflectionConfig(\n",
    "        reflection_minibatch_size=3,\n",
    "        reflection_lm=reflection_lm,\n",
    "        skip_perfect_score=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=train_set,\n",
    "    valset=val_set,\n",
    "    objective=OPTIMIZATION_OBJECTIVE,\n",
    "    background=OPTIMIZATION_BACKGROUND,\n",
    "    config=gepa_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae19fa9",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Can't Be Late Optimization](examples/adrs/can_be_late/optimization_trajectory.png)\n",
    "\n",
    "GEPA evolved a strategy that achieves **6.9% cost reduction** compared to the baseline:\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Base Cost | 96.48 |\n",
    "| Optimized Cost | 89.86 |\n",
    "| **Cost Savings** | **6.9%** |\n",
    "\n",
    "The evolved strategy learned nuanced decision boundaries for when to switch between spot and on-demand instances based on deadline slack and restart overhead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84190d6",
   "metadata": {},
   "source": [
    "### What GEPA Discovered\n",
    "\n",
    "GEPA evolved a sophisticated strategy with several key improvements over the baseline:\n",
    "1. Overhead-aware switching: Considers restart cost when deciding to switch instance types\n",
    "2. Anti-thrashing logic: Prevents expensive restart loops by \"latching\" to ON_DEMAND\n",
    "3. Dynamic safety buffer: Scales buffer with remaining task size (max(2h, 10% of remaining))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8950a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sky_spot.strategies.strategy import Strategy\n",
    "from sky_spot.utils import ClusterType\n",
    "\n",
    "class EvolveSingleRegionStrategy(Strategy):\n",
    "    NAME = 'evolve_single_region'\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)\n",
    "    \n",
    "    def reset(self, env, task):\n",
    "        super().reset(env, task)\n",
    "    \n",
    "    def _step(self, last_cluster_type: ClusterType, has_spot: bool) -> ClusterType:\n",
    "        env = self.env\n",
    "        \n",
    "        # Calculate remaining task work\n",
    "        remaining_task_time = self.task_duration - sum(self.task_done_time)\n",
    "        if remaining_task_time <= 1e-3:\n",
    "            return ClusterType.NONE\n",
    "        \n",
    "        # Calculate remaining wall clock time until deadline\n",
    "        remaining_time = self.deadline - env.elapsed_seconds\n",
    "        \n",
    "        # Calculate overhead to switch to (or stay on) ON_DEMAND.\n",
    "        # If we are already on ON_DEMAND, continuing incurs no overhead.\n",
    "        # If we are on SPOT or NONE, switching to ON_DEMAND incurs restart_overhead.\n",
    "        overhead_to_od = self.restart_overhead if last_cluster_type != ClusterType.ON_DEMAND else 0.0\n",
    "        \n",
    "        # 1. Hard Deadline Constraint (Point of No Return)\n",
    "        # If we wait any longer, we won't finish even with guaranteed ON_DEMAND.\n",
    "        # We must verify we have enough time for the work plus any switch overhead.\n",
    "        if remaining_task_time + overhead_to_od >= remaining_time:\n",
    "            return ClusterType.ON_DEMAND\n",
    "        \n",
    "        # 2. Spot Usage Strategy\n",
    "        if has_spot:\n",
    "            # Check if switching to SPOT is safe regarding the deadline.\n",
    "            # Switching to SPOT incurs overhead (if not already on it).\n",
    "            overhead_to_spot = self.restart_overhead if last_cluster_type != ClusterType.SPOT else 0.0\n",
    "            \n",
    "            # If the overhead of switching to SPOT consumes the remaining slack such that \n",
    "            # we can't finish, we must stick with (or switch to) ON_DEMAND.\n",
    "            if remaining_task_time + overhead_to_spot >= remaining_time:\n",
    "                return ClusterType.ON_DEMAND\n",
    "                \n",
    "            return ClusterType.SPOT\n",
    "        \n",
    "        # 3. Unavailable Spot Strategy\n",
    "        # Spot is unavailable. We must decide whether to Wait (NONE) or Run (ON_DEMAND).\n",
    "        \n",
    "        # Calculate current slack: Time margin we can afford to waste.\n",
    "        current_slack = remaining_time - remaining_task_time - overhead_to_od\n",
    "        \n",
    "        # Safety Buffer:\n",
    "        # Maintain a buffer to handle future volatility.\n",
    "        # We use max(2.0h, 10% of remaining task) to scale with task size.\n",
    "        safety_buffer = max(2.0, 0.1 * remaining_task_time)\n",
    "        \n",
    "        # Anti-Thrashing Logic (Latching):\n",
    "        # If we are currently running ON_DEMAND (due to low slack or PNR), we should\n",
    "        # maintain this state until Spot returns. Switching back to NONE (waiting) \n",
    "        # when slack is marginally above the buffer causes expensive restart loops \n",
    "        # (thrashing) as the buffer size dynamically adjusts with task progress.\n",
    "        if last_cluster_type == ClusterType.ON_DEMAND:\n",
    "            return ClusterType.ON_DEMAND\n",
    "        \n",
    "        # If we are currently Waiting (NONE) or were on SPOT, check if slack is critically low.\n",
    "        if current_slack < safety_buffer:\n",
    "            return ClusterType.ON_DEMAND\n",
    "            \n",
    "        # Slack is sufficient; wait for cheaper SPOT instances.\n",
    "        return ClusterType.NONE\n",
    "    \n",
    "    @classmethod\n",
    "    def _from_args(cls, parser):\n",
    "        args, _ = parser.parse_known_args()\n",
    "        return cls(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdc6083",
   "metadata": {},
   "source": [
    "## 8.2 Cloudcast: Multi-Cloud Broadcast Optimization\n",
    "\n",
    "The Cloudcast problem optimizes data broadcast across multiple cloud providers (AWS, GCP, Azure).\n",
    "\n",
    "### The Challenge\n",
    "\n",
    "Transfer data from a single source to multiple destinations across cloud providers:\n",
    "- **Heterogeneous pricing**: Egress costs vary dramatically between providers\n",
    "- **Bandwidth constraints**: Different regions have different throughput limits\n",
    "- **Partitioning**: Data can be split and sent via different paths\n",
    "\n",
    "**Goal**: Minimize total cost (egress fees + instance costs) while delivering data to all destinations.\n",
    "\n",
    "### Why This is Hard\n",
    "\n",
    "- The search space is **combinatorial** — exponentially many possible routing trees\n",
    "- Costs are **non-uniform** — inter-cloud transfers cost more than intra-cloud\n",
    "- Simple shortest-path algorithms ignore cost structure\n",
    "\n",
    "### Setup\n",
    "\n",
    "```bash\n",
    "pip install networkx pandas numpy\n",
    "pip install -r examples/adrs/cloudcast/requirements.txt\n",
    "```\n",
    "\n",
    "### The Seed Candidate\n",
    "\n",
    "We start with a simple Dijkstra shortest-path baseline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48317df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the seed algorithm as a string (required for GEPA optimization)\n",
    "INITIAL_PROGRAM = \"\"\"import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class SingleDstPath(Dict):\n",
    "    partition: int\n",
    "    edges: List[List]  # [[src, dst, edge data]]\n",
    "\n",
    "\n",
    "class BroadCastTopology:\n",
    "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
    "        self.src = src\n",
    "        self.dsts = dsts\n",
    "        self.num_partitions = num_partitions\n",
    "        if paths is not None:\n",
    "            self.paths = paths\n",
    "        else:\n",
    "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
    "\n",
    "    def get_paths(self):\n",
    "        return self.paths\n",
    "\n",
    "    def set_num_partitions(self, num_partitions: int):\n",
    "        self.num_partitions = num_partitions\n",
    "\n",
    "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
    "        partition = str(partition)\n",
    "        self.paths[dst][partition] = paths\n",
    "\n",
    "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
    "        partition = str(partition)\n",
    "        if self.paths[dst][partition] is None:\n",
    "            self.paths[dst][partition] = []\n",
    "        self.paths[dst][partition].append(path)\n",
    "\n",
    "\n",
    "def search_algorithm(src, dsts, G, num_partitions):\n",
    "    \\\"\\\"\\\"\n",
    "    Find broadcast paths from source to all destinations.\n",
    "    \n",
    "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
    "    \n",
    "    Args:\n",
    "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
    "        dsts: List of destination node identifiers\n",
    "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
    "        num_partitions: Number of data partitions\n",
    "        \n",
    "    Returns:\n",
    "        BroadCastTopology object with paths for all destinations and partitions\n",
    "    \\\"\\\"\\\"\n",
    "    h = G.copy()\n",
    "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
    "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
    "\n",
    "    for dst in dsts:\n",
    "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
    "        for i in range(0, len(path) - 1):\n",
    "            s, t = path[i], path[i + 1]\n",
    "            for j in range(bc_topology.num_partitions):\n",
    "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
    "\n",
    "    return bc_topology\n",
    "\"\"\"\n",
    "\n",
    "# Create seed candidate\n",
    "seed_candidate = {\"program\": INITIAL_PROGRAM}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8d5150",
   "metadata": {},
   "source": [
    "### The Fitness Function\n",
    "\n",
    "The fitness function simulates the broadcast and computes costs. Full evaluator is in `examples/adrs/cloudcast/evaluator.py`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80aebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "from typing import Any\n",
    "\n",
    "from gepa.optimize_anything import SideInfo\n",
    "from examples.adrs.cloudcast.evaluator import (\n",
    "    evaluate_stage1,      # Syntax validation\n",
    "    run_single_config,    # Runs broadcast simulation\n",
    "    FAILED_SCORE,         # Score for failed programs (-100000.0)\n",
    "    load_config_dataset,  # Loads configuration files\n",
    ")\n",
    "\n",
    "# Load broadcast configuration scenarios\n",
    "config_dir = \"examples/adrs/cloudcast/cloudcast/config\"\n",
    "samples = load_config_dataset(config_dir=config_dir)\n",
    "train_set = val_set = test_set = samples  # Use all configs for train/val/test\n",
    "\n",
    "def create_fitness_function(timeout: int = 300):\n",
    "    \"\"\"\n",
    "    Create fitness function for GEPA optimization.\n",
    "    \n",
    "    The fitness function evaluates a candidate search algorithm on configuration\n",
    "    samples, running simulations and returning scores with diagnostic information.\n",
    "    \"\"\"\n",
    "    # Cache to avoid redundant file I/O when evaluating same program on multiple examples\n",
    "    _cache: dict[str, Any] = {\n",
    "        \"program_code\": None,\n",
    "        \"program_path\": None,\n",
    "        \"tmpdir\": None,\n",
    "        \"stage1_result\": None,\n",
    "    }\n",
    "\n",
    "    def _get_or_create_program_file(program_code: str) -> tuple[str, dict]:\n",
    "        \"\"\"Get cached program file or create new one if program changed.\"\"\"\n",
    "        if _cache[\"program_code\"] != program_code:\n",
    "            if _cache[\"tmpdir\"] is not None:\n",
    "                shutil.rmtree(_cache[\"tmpdir\"], ignore_errors=True)\n",
    "            \n",
    "            tmpdir = tempfile.mkdtemp(prefix=\"cloudcast_eval_\")\n",
    "            program_path = os.path.join(tmpdir, \"program.py\")\n",
    "            with open(program_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(program_code)\n",
    "            \n",
    "            stage1_result = evaluate_stage1(program_path)\n",
    "            \n",
    "            _cache[\"program_code\"] = program_code\n",
    "            _cache[\"program_path\"] = program_path\n",
    "            _cache[\"tmpdir\"] = tmpdir\n",
    "            _cache[\"stage1_result\"] = stage1_result\n",
    "        \n",
    "        return _cache[\"program_path\"], _cache[\"stage1_result\"]\n",
    "\n",
    "    def fitness_fn(\n",
    "        candidate: dict[str, str], example: dict[str, Any], **kwargs\n",
    "    ) -> tuple[float, Any, SideInfo]:\n",
    "        \"\"\"\n",
    "        Evaluate a candidate search algorithm on a single configuration.\n",
    "        \n",
    "        Args:\n",
    "            candidate: Dict with \"program\" key containing search algorithm code\n",
    "            example: Sample dict with 'config_file' and optional 'num_vms'\n",
    "        \n",
    "        Returns:\n",
    "            Tuple of (score, output, side_info)\n",
    "        \"\"\"\n",
    "        program_code = candidate[\"program\"]\n",
    "        program_path, stage1_result = _get_or_create_program_file(program_code)\n",
    "\n",
    "        # Stage 1: Check syntax\n",
    "        if stage1_result.get(\"runs_successfully\", 0.0) < 1.0:\n",
    "            error_msg = stage1_result.get(\"error\", \"Syntax validation failed\")\n",
    "            side_info: SideInfo = {\n",
    "                \"scores\": {\"cost\": FAILED_SCORE},\n",
    "                \"Input\": {\"config_file\": example.get(\"config_file\", \"unknown\")},\n",
    "                \"Error\": error_msg,\n",
    "            }\n",
    "            return (FAILED_SCORE, {\"error\": error_msg}, side_info)\n",
    "\n",
    "        # Stage 2: Run simulation\n",
    "        config_file = example.get(\"config_file\")\n",
    "        num_vms = example.get(\"num_vms\", 2)\n",
    "\n",
    "        if not config_file:\n",
    "            side_info = {\n",
    "                \"scores\": {\"cost\": FAILED_SCORE},\n",
    "                \"Input\": {\"config_file\": config_file},\n",
    "                \"Error\": \"Invalid sample: missing config_file\",\n",
    "            }\n",
    "            return (FAILED_SCORE, {\"error\": \"Invalid sample\"}, side_info)\n",
    "\n",
    "        success, cost, transfer_time, error_msg, detailed_info = run_single_config(\n",
    "            program_path, config_file, num_vms\n",
    "        )\n",
    "\n",
    "        if success:\n",
    "            # Score = 1 / (1 + cost) - lower cost = higher score\n",
    "            score = 1.0 / (1.0 + cost)\n",
    "            config_name = detailed_info.get(\"config_name\", os.path.basename(config_file))\n",
    "            \n",
    "            side_info = {\n",
    "                \"scores\": {\"cost_score\": score, \"raw_cost\": cost},\n",
    "                \"Input\": {\n",
    "                    \"config\": config_name,\n",
    "                    \"source\": detailed_info.get(\"source\", \"N/A\"),\n",
    "                    \"num_destinations\": len(detailed_info.get(\"destinations\", [])),\n",
    "                },\n",
    "                \"Output\": {\n",
    "                    \"cost\": f\"${cost:.4f}\",\n",
    "                    \"transfer_time\": f\"{transfer_time:.2f}s\",\n",
    "                },\n",
    "            }\n",
    "            return (score, {\"cost\": cost, \"score\": score}, side_info)\n",
    "        else:\n",
    "            side_info = {\n",
    "                \"scores\": {\"cost\": FAILED_SCORE},\n",
    "                \"Input\": {\"config_file\": os.path.basename(config_file) if config_file else \"unknown\"},\n",
    "                \"Error\": error_msg,\n",
    "            }\n",
    "            return (FAILED_SCORE, {\"error\": error_msg}, side_info)\n",
    "\n",
    "    return fitness_fn\n",
    "\n",
    "# Create fitness function\n",
    "fitness_fn = create_fitness_function(timeout=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3266cc",
   "metadata": {},
   "source": [
    "### Running GEPA Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfab99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai._api_client:The project/location from the environment variables will take precedence over the API key from the environment variables.\n",
      "GEPA Optimization:   0%|          | 0/1000 [00:00<?, ?rollouts/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of total cost = egress cost ($162.0) + instance cost ($3.024) = $165.024\n",
      "Sum of total cost = egress cost ($144.0) + instance cost ($0.945) = $144.945\n",
      "Sum of total cost = egress cost ($159.0) + instance cost ($2.4686) = $161.469\n",
      "Sum of total cost = egress cost ($267.0) + instance cost ($1.8514) = $268.851\n",
      "Sum of total cost = egress cost ($303.0) + instance cost ($2.5714) = $305.571\n",
      "Iteration 0: Base program full valset score: 0.00519955683867755 over 5 / 5 examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   0%|          | 5/1000 [00:34<1:53:27,  6.84s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($303.0) + instance cost ($2.5714) = $305.571\n",
      "Sum of total cost = egress cost ($159.0) + instance cost ($2.4686) = $161.469\n",
      "Sum of total cost = egress cost ($144.0) + instance cost ($0.945) = $144.945\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003261882663426356\n",
      "\n",
      "### raw_cost\n",
      "305.57142\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_gaz2\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "7\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$305.5714\n",
      "\n",
      "### transfer_time\n",
      "857.14s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006155036708392727\n",
      "\n",
      "### raw_cost\n",
      "161.468568\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_gcp\n",
      "\n",
      "### source\n",
      "gcp:us-east1-b\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$161.4686\n",
      "\n",
      "### transfer_time\n",
      "1028.57s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006851896262290589\n",
      "\n",
      "### raw_cost\n",
      "144.945\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_azure\n",
      "\n",
      "### source\n",
      "azure:australiaeast\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$144.9450\n",
      "\n",
      "### transfer_time\n",
      "450.00s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: Proposed new text for program: import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Optimizes total cost (Egress + Instance) by considering both edge cost and throughput.\n",
      "    Uses iterative penalization to find diverse paths for different partitions (Multipath), \n",
      "    maximizing aggregate bandwidth and reducing transfer time.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    # Create a working copy of the graph to avoid modifying the input\n",
      "    base_graph = G.copy()\n",
      "    \n",
      "    # Remove incoming edges to source and self-loops as per standard routing logic\n",
      "    base_graph.remove_edges_from(list(base_graph.in_edges(src)) + list(nx.selfloop_edges(base_graph)))\n",
      "    \n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    # Heuristic constant to balance Cost vs Throughput.\n",
      "    # Metric = Cost + (TIME_FACTOR / Throughput)\n",
      "    # This prevents selecting 0-cost paths that have extremely low bandwidth,\n",
      "    # which would otherwise cause instance costs to skyrocket due to long runtimes.\n",
      "    TIME_FACTOR = 0.1\n",
      "\n",
      "    for dst in dsts:\n",
      "        # Create a specific search graph for this destination to allow \n",
      "        # path penalization (for multipath discovery) without affecting other destinations.\n",
      "        search_graph = base_graph.copy()\n",
      "        \n",
      "        # Initialize composite weights\n",
      "        for u, v, data in search_graph.edges(data=True):\n",
      "            c = data.get('cost', 0.0)\n",
      "            t = data.get('throughput', 1.0)\n",
      "            if t <= 0: t = 1e-6  # Safety against division by zero\n",
      "            \n",
      "            # Composite weight prefers cheap edges but heavily penalizes bottlenecks\n",
      "            data['weight'] = c + (TIME_FACTOR / t)\n",
      "\n",
      "        # Iterate through partitions to assign paths\n",
      "        # We attempt to find distinct paths for each partition to utilize available bandwidth (Multipath)\n",
      "        for part_idx in range(num_partitions):\n",
      "            try:\n",
      "                # Find optimal path based on current composite weights\n",
      "                path_nodes = nx.dijkstra_path(search_graph, src, dst, weight='weight')\n",
      "                \n",
      "                # Construct the edge list for the topology object\n",
      "                path_edges = []\n",
      "                for i in range(len(path_nodes) - 1):\n",
      "                    u, v = path_nodes[i], path_nodes[i + 1]\n",
      "                    \n",
      "                    # Use original edge data from G for the result\n",
      "                    original_data = G[u][v]\n",
      "                    path_edges.append([u, v, original_data])\n",
      "                    \n",
      "                    # Penalize the edges used in this path within the search_graph.\n",
      "                    # Multiplying weight discourages reuse, promoting diversity (ECMP-like behavior)\n",
      "                    # to increase total aggregate throughput.\n",
      "                    if search_graph.has_edge(u, v):\n",
      "                        search_graph[u][v]['weight'] *= 2.0\n",
      "                \n",
      "                # Set the calculated path for this partition\n",
      "                bc_topology.set_dst_partition_paths(dst, part_idx, path_edges)\n",
      "\n",
      "            except nx.NetworkXNoPath:\n",
      "                # Fallback mechanism: if the weighted search fails (e.g. graph disconnected),\n",
      "                # try a standard cost-based path on the original graph to ensure connectivity if possible.\n",
      "                try:\n",
      "                    path_nodes = nx.dijkstra_path(G, src, dst, weight='cost')\n",
      "                    path_edges = [[path_nodes[i], path_nodes[i+1], G[path_nodes[i]][path_nodes[i+1]]] \n",
      "                                  for i in range(len(path_nodes) - 1)]\n",
      "                    bc_topology.set_dst_partition_paths(dst, part_idx, path_edges)\n",
      "                except nx.NetworkXNoPath:\n",
      "                    # Destination is truly unreachable\n",
      "                    pass\n",
      "\n",
      "    return bc_topology\n",
      "Sum of total cost = egress cost ($373.23) + instance cost ($24.0686) = $397.299\n",
      "Sum of total cost = egress cost ($185.7) + instance cost ($21.6617) = $207.362\n",
      "Sum of total cost = egress cost ($178.2) + instance cost ($3.078) = $181.278\n",
      "Iteration 1: New subsample score 0.012796150431932819 is not better than old score 0.016268815634109673, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   1%|          | 11/1000 [02:16<3:39:15, 13.30s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($162.0) + instance cost ($3.024) = $165.024\n",
      "Sum of total cost = egress cost ($267.0) + instance cost ($1.8514) = $268.851\n",
      "Sum of total cost = egress cost ($267.0) + instance cost ($1.8514) = $268.851\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006023225557750687\n",
      "\n",
      "### raw_cost\n",
      "165.024\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_aws\n",
      "\n",
      "### source\n",
      "aws:ap-northeast-1\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$165.0240\n",
      "\n",
      "### transfer_time\n",
      "1440.00s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003705743001527392\n",
      "\n",
      "### raw_cost\n",
      "268.851417\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_agz\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$268.8514\n",
      "\n",
      "### transfer_time\n",
      "685.71s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003705743001527392\n",
      "\n",
      "### raw_cost\n",
      "268.851417\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_agz\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$268.8514\n",
      "\n",
      "### transfer_time\n",
      "685.71s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2: Proposed new text for program: import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "from itertools import islice\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def _composite_weight(u, v, d):\n",
      "    \"\"\"\n",
      "    Calculate edge weight balancing cost and throughput.\n",
      "    \n",
      "    The goal is to minimize total cost (Egress + Instance Time).\n",
      "    Weight = Cost ($/GB) + (Alpha / Throughput (Gbps))\n",
      "    \n",
      "    An alpha of 0.05 implies that increasing throughput is worth paying \n",
      "    slightly higher egress costs to reduce instance runtime.\n",
      "    This effectively penalizes low-bandwidth links (e.g., < 0.5 Gbps) \n",
      "    that would cause timeouts or high instance costs.\n",
      "    \"\"\"\n",
      "    cost = d.get(\"cost\", 0.0)\n",
      "    throughput = d.get(\"throughput\", 0.0)\n",
      "    \n",
      "    # Handle edge case where throughput is zero or missing to avoid div by zero\n",
      "    if throughput <= 1e-9:\n",
      "        return float('inf')\n",
      "        \n",
      "    return cost + (0.05 / throughput)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations using multipath routing.\n",
      "    \n",
      "    Optimizations:\n",
      "    1. Metric: Uses a composite weight of cost and throughput to minimize total\n",
      "       operational cost (egress fees + runtime instance costs).\n",
      "    2. Multipath: Uses K-Shortest Paths to find distinct routes, utilizing\n",
      "       available bandwidth across the network rather than saturating a single link.\n",
      "    3. Balancing: Distributes partitions across the found optimal paths.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with 'cost' and 'throughput' edge attributes\n",
      "        num_partitions: Number of data partitions to route\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with optimized paths\n",
      "    \"\"\"\n",
      "    # Work on a copy to ensure graph integrity\n",
      "    h = G.copy()\n",
      "    \n",
      "    # Remove incoming edges to source to prevent cycles back to start\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    \n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        # Skip if source is the destination\n",
      "        if src == dst:\n",
      "            continue\n",
      "            \n",
      "        try:\n",
      "            # Find K shortest simple paths using the composite weight function.\n",
      "            # Using islice to lazily compute only the top 'num_partitions' paths.\n",
      "            # This is more efficient than computing all paths for the graph.\n",
      "            path_generator = nx.shortest_simple_paths(h, src, dst, weight=_composite_weight)\n",
      "            k_paths = list(islice(path_generator, num_partitions))\n",
      "        except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
      "            # If destination is unreachable, we leave the paths as None (default)\n",
      "            continue\n",
      "            \n",
      "        if not k_paths:\n",
      "            continue\n",
      "            \n",
      "        # Distribute partitions across the discovered K paths\n",
      "        # This implements multipath routing: if 2 good paths exist, \n",
      "        # partitions will alternate between them.\n",
      "        for i in range(num_partitions):\n",
      "            # Select path in a round-robin fashion from the K best paths found\n",
      "            selected_path_nodes = k_paths[i % len(k_paths)]\n",
      "            \n",
      "            # Construct the list of edges for this path\n",
      "            path_edges = []\n",
      "            for k in range(len(selected_path_nodes) - 1):\n",
      "                u = selected_path_nodes[k]\n",
      "                v = selected_path_nodes[k+1]\n",
      "                # Use original graph G to ensure we carry the correct edge data\n",
      "                path_edges.append([u, v, G[u][v]])\n",
      "                \n",
      "            # Assign this full path to the specific partition\n",
      "            bc_topology.set_dst_partition_paths(dst, i, path_edges)\n",
      "\n",
      "    return bc_topology\n",
      "Sum of total cost = egress cost ($150.9) + instance cost ($9.792) = $160.692\n",
      "Sum of total cost = egress cost ($324.42) + instance cost ($22.8189) = $347.239\n",
      "Sum of total cost = egress cost ($324.42) + instance cost ($22.8189) = $347.239\n",
      "Iteration 2: New subsample score 0.011927781948430947 is not better than old score 0.01343471156080547, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   2%|▏         | 17/1000 [03:39<3:41:32, 13.52s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($144.0) + instance cost ($0.945) = $144.945\n",
      "Sum of total cost = egress cost ($162.0) + instance cost ($3.024) = $165.024\n",
      "Sum of total cost = egress cost ($303.0) + instance cost ($2.5714) = $305.571\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006851896262290589\n",
      "\n",
      "### raw_cost\n",
      "144.945\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_azure\n",
      "\n",
      "### source\n",
      "azure:australiaeast\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$144.9450\n",
      "\n",
      "### transfer_time\n",
      "450.00s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006023225557750687\n",
      "\n",
      "### raw_cost\n",
      "165.024\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_aws\n",
      "\n",
      "### source\n",
      "aws:ap-northeast-1\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$165.0240\n",
      "\n",
      "### transfer_time\n",
      "1440.00s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003261882663426356\n",
      "\n",
      "### raw_cost\n",
      "305.57142\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_gaz2\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "7\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$305.5714\n",
      "\n",
      "### transfer_time\n",
      "857.14s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3: Proposed new text for program: import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List, Any\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src: str, dsts: List[str], G: nx.DiGraph, num_partitions: int) -> BroadCastTopology:\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Optimizes for a balance of egress cost and throughput to minimize total cost \n",
      "    (egress fees + instance runtime costs). Uses K-shortest paths to facilitate \n",
      "    multipath routing, distributing partitions across the best available routes.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with 'cost' ($/GB) and 'throughput' (Gbps) edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    \n",
      "    # Heuristic weight function: balances Cost vs. Time\n",
      "    # Total Cost ~ (Volume * EgressCost) + (Volume/Throughput * InstanceRate)\n",
      "    # We use a composite weight: cost + (alpha / throughput)\n",
      "    # This penalizes low-bandwidth links which inflate instance costs.\n",
      "    def composite_weight(u, v, d):\n",
      "        cost = d.get('cost', 0.0)\n",
      "        throughput = d.get('throughput', 0.0)\n",
      "        \n",
      "        # Avoid division by zero; treat 0 throughput as extremely high cost\n",
      "        if throughput <= 1e-6:\n",
      "            return float('inf')\n",
      "            \n",
      "        # Alpha=0.2 is a heuristic constant.\n",
      "        # Example: \n",
      "        #  - Link A: $0.02/GB, 0.1 Gbps -> Weight: 0.02 + 2.0 = 2.02 (Expensive due to time)\n",
      "        #  - Link B: $0.05/GB, 1.0 Gbps -> Weight: 0.05 + 0.2 = 0.25 (Cheaper overall)\n",
      "        return cost + (0.2 / throughput)\n",
      "\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        if src == dst:\n",
      "            continue\n",
      "            \n",
      "        try:\n",
      "            # Use shortest_simple_paths (Yen's algorithm implementation in NetworkX)\n",
      "            # to find the K best paths based on the composite metric.\n",
      "            # This enables multipath routing: different partitions take different optimal paths.\n",
      "            path_generator = nx.shortest_simple_paths(G, src, dst, weight=composite_weight)\n",
      "            \n",
      "            found_paths = []\n",
      "            try:\n",
      "                # Retrieve up to num_partitions distinct paths\n",
      "                for _ in range(num_partitions):\n",
      "                    found_paths.append(next(path_generator))\n",
      "            except StopIteration:\n",
      "                # Fewer than num_partitions paths exist\n",
      "                pass\n",
      "            \n",
      "            if not found_paths:\n",
      "                continue\n",
      "\n",
      "            # Assign paths to partitions\n",
      "            for i in range(num_partitions):\n",
      "                # Round-robin distribution if fewer unique paths than partitions\n",
      "                node_path = found_paths[i % len(found_paths)]\n",
      "                \n",
      "                # Convert node sequence [u, v, w] to edge list [[u,v,d], [v,w,d]]\n",
      "                edge_path = []\n",
      "                for u, v in zip(node_path[:-1], node_path[1:]):\n",
      "                    edge_path.append([u, v, G[u][v]])\n",
      "                \n",
      "                # Set the complete path for this partition\n",
      "                bc_topology.set_dst_partition_paths(dst, i, edge_path)\n",
      "\n",
      "        except nx.NetworkXNoPath:\n",
      "            # Destination unreachable\n",
      "            continue\n",
      "\n",
      "    return bc_topology\n",
      "Sum of total cost = egress cost ($181.2) + instance cost ($3.8475) = $185.047\n",
      "Sum of total cost = egress cost ($150.9) + instance cost ($9.792) = $160.692\n",
      "Sum of total cost = egress cost ($370.23) + instance cost ($26.784) = $397.014\n",
      "Iteration 3: New subsample score 0.014072043758482833 is not better than old score 0.01613700448346763, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   2%|▏         | 23/1000 [04:55<3:35:12, 13.22s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($159.0) + instance cost ($2.4686) = $161.469\n",
      "Sum of total cost = egress cost ($267.0) + instance cost ($1.8514) = $268.851\n",
      "Sum of total cost = egress cost ($267.0) + instance cost ($1.8514) = $268.851\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006155036708392727\n",
      "\n",
      "### raw_cost\n",
      "161.468568\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_gcp\n",
      "\n",
      "### source\n",
      "gcp:us-east1-b\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$161.4686\n",
      "\n",
      "### transfer_time\n",
      "1028.57s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003705743001527392\n",
      "\n",
      "### raw_cost\n",
      "268.851417\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_agz\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$268.8514\n",
      "\n",
      "### transfer_time\n",
      "685.71s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003705743001527392\n",
      "\n",
      "### raw_cost\n",
      "268.851417\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_agz\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$268.8514\n",
      "\n",
      "### transfer_time\n",
      "685.71s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4: Proposed new text for program: import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "import itertools\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Optimizes for a balance of total cost (egress + instance runtime) and transfer time.\n",
      "    Uses K-Shortest Paths with a composite weight metric to identify efficient, high-throughput \n",
      "    paths and distributes partitions across them to utilize available bandwidth (Multipath).\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "\n",
      "    # Define composite weight to balance Egress Cost ($/GB) and Time (related to 1/throughput).\n",
      "    # Total Cost includes instance costs which accumulate over time.\n",
      "    # Weight = Cost + (Alpha / Throughput).\n",
      "    # Alpha determines the penalty for low bandwidth. \n",
      "    # Value 0.05 implies: \n",
      "    # - 10 Gbps link adds 0.005 penalty (negligible vs cost)\n",
      "    # - 0.01 Gbps link adds 5.0 penalty (high, avoids bottleneck)\n",
      "    alpha = 0.05\n",
      "    \n",
      "    for u, v, data in h.edges(data=True):\n",
      "        cost = data.get('cost', 0.0)\n",
      "        bw = data.get('throughput', 1e-6) # Prevent division by zero\n",
      "        data['composite_weight'] = cost + (alpha / bw)\n",
      "\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        try:\n",
      "            # Use K-Shortest Paths to find multiple valid routes for the partitions.\n",
      "            # This enables multipath routing: spreading partitions across different paths \n",
      "            # increases aggregate throughput compared to a single path.\n",
      "            path_generator = nx.shortest_simple_paths(h, src, dst, weight=\"composite_weight\")\n",
      "            \n",
      "            # Fetch up to 'num_partitions' best paths. \n",
      "            # Using islice is efficient as shortest_simple_paths is a generator.\n",
      "            candidates = list(itertools.islice(path_generator, num_partitions))\n",
      "            \n",
      "            if not candidates:\n",
      "                continue\n",
      "\n",
      "            # Distribute partitions across the found candidate paths in a Round-Robin fashion.\n",
      "            # This ensures we use the best path most often, but utilize others to reduce total transfer time.\n",
      "            for i in range(num_partitions):\n",
      "                node_path = candidates[i % len(candidates)]\n",
      "                \n",
      "                # Convert the sequence of nodes [u, v, w] into the edge format required by BroadCastTopology:\n",
      "                # [[u, v, data], [v, w, data]]\n",
      "                edge_path = []\n",
      "                for k in range(len(node_path) - 1):\n",
      "                    u, v = node_path[k], node_path[k+1]\n",
      "                    edge_path.append([u, v, G[u][v]])\n",
      "                \n",
      "                bc_topology.set_dst_partition_paths(dst, i, edge_path)\n",
      "\n",
      "        except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
      "            # Destination unreachable\n",
      "            pass\n",
      "\n",
      "    return bc_topology\n",
      "Sum of total cost = egress cost ($177.0) + instance cost ($16.416) = $193.416\n",
      "Sum of total cost = egress cost ($324.42) + instance cost ($22.8189) = $347.239\n",
      "Sum of total cost = egress cost ($324.42) + instance cost ($22.8189) = $347.239\n",
      "Iteration 4: New subsample score 0.010886794364774934 is not better than old score 0.013566522711447511, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   3%|▎         | 29/1000 [06:08<3:27:43, 12.84s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($303.0) + instance cost ($2.5714) = $305.571\n",
      "Sum of total cost = egress cost ($267.0) + instance cost ($1.8514) = $268.851\n",
      "Sum of total cost = egress cost ($162.0) + instance cost ($3.024) = $165.024\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003261882663426356\n",
      "\n",
      "### raw_cost\n",
      "305.57142\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_gaz2\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "7\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$305.5714\n",
      "\n",
      "### transfer_time\n",
      "857.14s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003705743001527392\n",
      "\n",
      "### raw_cost\n",
      "268.851417\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_agz\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$268.8514\n",
      "\n",
      "### transfer_time\n",
      "685.71s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006023225557750687\n",
      "\n",
      "### raw_cost\n",
      "165.024\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_aws\n",
      "\n",
      "### source\n",
      "aws:ap-northeast-1\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$165.0240\n",
      "\n",
      "### transfer_time\n",
      "1440.00s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5: Proposed new text for program: import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "from itertools import islice\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations using multipath routing.\n",
      "\n",
      "    Optimizes for a balance of Egress Cost and Transfer Time (Throughput) to minimize\n",
      "    total operational costs (egress fees + instance runtime).\n",
      "    \n",
      "    Uses K-Shortest Paths with a composite weight metric to find distinct, efficient \n",
      "    routes for different data partitions, addressing previous bottlenecks where \n",
      "    low-cost but slow links caused high total instance costs.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    # Heuristic factor: Cost of Time. \n",
      "    # Represents the willingness to pay extra egress cost ($) per unit of inverse throughput.\n",
      "    # A value of 0.05 balances reducing transfer time (instance cost) against raw egress fees.\n",
      "    ALPHA_TIME_WEIGHT = 0.05\n",
      "\n",
      "    def composite_weight(u, v, d):\n",
      "        # Base cost: Egress fee per GB\n",
      "        cost = d.get('cost', 0.0)\n",
      "        # Throughput in Gbps\n",
      "        throughput = d.get('throughput', 0.0)\n",
      "        \n",
      "        # Penalize edges with near-zero throughput to avoid bottlenecks\n",
      "        if throughput <= 1e-6:\n",
      "            return float('inf')\n",
      "            \n",
      "        # Composite weight: Cost + (Alpha / Throughput)\n",
      "        # This forces the algorithm to avoid cheap but extremely slow links\n",
      "        return cost + (ALPHA_TIME_WEIGHT / throughput)\n",
      "\n",
      "    for dst in dsts:\n",
      "        try:\n",
      "            # Generate K shortest simple paths based on composite weight\n",
      "            # K = num_partitions allows each partition to potentially take a different optimized route,\n",
      "            # maximizing aggregate bandwidth usage (Multipath Routing).\n",
      "            path_generator = nx.shortest_simple_paths(h, src, dst, weight=composite_weight)\n",
      "            \n",
      "            # Slice the generator to get up to 'num_partitions' paths\n",
      "            k_paths = list(islice(path_generator, num_partitions))\n",
      "            \n",
      "            if not k_paths:\n",
      "                continue\n",
      "\n",
      "            # Assign paths to partitions\n",
      "            # If fewer paths than partitions found, cycle through the available paths (Round Robin)\n",
      "            for i in range(num_partitions):\n",
      "                selected_path = k_paths[i % len(k_paths)]\n",
      "                \n",
      "                # Convert list of nodes to list of edges with data\n",
      "                edges_list = []\n",
      "                for idx in range(len(selected_path) - 1):\n",
      "                    u, v = selected_path[idx], selected_path[idx + 1]\n",
      "                    edges_list.append([u, v, G[u][v]])\n",
      "                \n",
      "                bc_topology.set_dst_partition_paths(dst, i, edges_list)\n",
      "                \n",
      "        except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
      "            # If destination is unreachable, paths remain None for that destination\n",
      "            pass\n",
      "\n",
      "    return bc_topology\n",
      "Sum of total cost = egress cost ($365.52) + instance cost ($24.9943) = $390.514\n",
      "Sum of total cost = egress cost ($324.42) + instance cost ($22.8189) = $347.239\n",
      "Sum of total cost = egress cost ($150.9) + instance cost ($9.792) = $160.692\n",
      "Iteration 5: New subsample score 0.011610375295611387 is not better than old score 0.012990851222704436, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   4%|▎         | 35/1000 [07:20<3:21:47, 12.55s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($144.0) + instance cost ($0.945) = $144.945\n",
      "Sum of total cost = egress cost ($159.0) + instance cost ($2.4686) = $161.469\n",
      "Sum of total cost = egress cost ($159.0) + instance cost ($2.4686) = $161.469\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006851896262290589\n",
      "\n",
      "### raw_cost\n",
      "144.945\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_azure\n",
      "\n",
      "### source\n",
      "azure:australiaeast\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$144.9450\n",
      "\n",
      "### transfer_time\n",
      "450.00s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006155036708392727\n",
      "\n",
      "### raw_cost\n",
      "161.468568\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_gcp\n",
      "\n",
      "### source\n",
      "gcp:us-east1-b\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$161.4686\n",
      "\n",
      "### transfer_time\n",
      "1028.57s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006155036708392727\n",
      "\n",
      "### raw_cost\n",
      "161.468568\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_gcp\n",
      "\n",
      "### source\n",
      "gcp:us-east1-b\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$161.4686\n",
      "\n",
      "### transfer_time\n",
      "1028.57s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6: Proposed new text for program: import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "import itertools\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Optimizes for total cost (egress + instance) by balancing edge cost and throughput\n",
      "    and utilizing multiple paths for partitions.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    # Create a working graph excluding incoming edges to source to prevent cycles/loops back to start\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    \n",
      "    # Calculate composite metric for routing\n",
      "    # This addresses the failure patterns where low-cost but low-throughput paths \n",
      "    # caused high instance costs and timeouts.\n",
      "    for u, v, data in h.edges(data=True):\n",
      "        # Default values if missing\n",
      "        cost = data.get('cost', 0.0)\n",
      "        throughput = data.get('throughput', 1.0)\n",
      "        \n",
      "        # Avoid division by zero and handle extremely low throughputs\n",
      "        if throughput < 1e-6:\n",
      "            throughput = 1e-6\n",
      "            \n",
      "        # Composite Weight Formula: Metric = Cost + (Alpha / Throughput)\n",
      "        # We value egress cost savings, but apply a penalty for low throughput \n",
      "        # which acts as a proxy for transfer time and instance costs.\n",
      "        # 0.001 is a heuristic balancing factor ($/GB vs Inverse Gbps).\n",
      "        data['metric'] = cost + (0.001 / throughput)\n",
      "\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        try:\n",
      "            # Use K-Shortest Paths to find diverse routes for partitions.\n",
      "            # This enables multipath routing: distinct partitions can take different paths \n",
      "            # to aggregate bandwidth and avoid single-link bottlenecks, improving transfer time.\n",
      "            \n",
      "            # shortest_simple_paths returns a generator ordered by weight\n",
      "            path_generator = nx.shortest_simple_paths(h, src, dst, weight=\"metric\")\n",
      "            \n",
      "            # Extract top K paths, where K = num_partitions\n",
      "            # Slicing the generator ensures we don't compute more than needed\n",
      "            best_paths = list(itertools.islice(path_generator, num_partitions))\n",
      "            \n",
      "            if not best_paths:\n",
      "                continue\n",
      "\n",
      "            # Assign paths to partitions\n",
      "            # If fewer paths than partitions are found (e.g., only 2 valid paths exist),\n",
      "            # we cycle through the best ones available (Round-Robin).\n",
      "            for i in range(num_partitions):\n",
      "                path_nodes = best_paths[i % len(best_paths)]\n",
      "                \n",
      "                # Reconstruct edge list with full metadata for the topology object\n",
      "                path_edges = []\n",
      "                for k in range(len(path_nodes) - 1):\n",
      "                    u, v = path_nodes[k], path_nodes[k+1]\n",
      "                    path_edges.append([u, v, G[u][v]])\n",
      "                \n",
      "                # Set the path for this partition\n",
      "                bc_topology.set_dst_partition_paths(dst, i, path_edges)\n",
      "\n",
      "        except (nx.NetworkXNoPath, nx.NodeNotFound):\n",
      "            # Destination unreachable\n",
      "            continue\n",
      "        except Exception:\n",
      "            continue\n",
      "\n",
      "    return bc_topology\n",
      "Sum of total cost = egress cost ($181.2) + instance cost ($3.8475) = $185.047\n",
      "Sum of total cost = egress cost ($177.0) + instance cost ($16.416) = $193.416\n",
      "Sum of total cost = egress cost ($177.0) + instance cost ($16.416) = $193.416\n",
      "Iteration 6: New subsample score 0.01566219203304421 is not better than old score 0.019161969679076043, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   4%|▍         | 41/1000 [09:02<3:43:32, 13.99s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($303.0) + instance cost ($2.5714) = $305.571\n",
      "Sum of total cost = egress cost ($267.0) + instance cost ($1.8514) = $268.851\n",
      "Sum of total cost = egress cost ($162.0) + instance cost ($3.024) = $165.024\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003261882663426356\n",
      "\n",
      "### raw_cost\n",
      "305.57142\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_gaz2\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "7\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$305.5714\n",
      "\n",
      "### transfer_time\n",
      "857.14s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.003705743001527392\n",
      "\n",
      "### raw_cost\n",
      "268.851417\n",
      "\n",
      "## Input\n",
      "### config\n",
      "inter_agz\n",
      "\n",
      "### source\n",
      "gcp:asia-southeast1-a\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$268.8514\n",
      "\n",
      "### transfer_time\n",
      "685.71s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006023225557750687\n",
      "\n",
      "### raw_cost\n",
      "165.024\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_aws\n",
      "\n",
      "### source\n",
      "aws:ap-northeast-1\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$165.0240\n",
      "\n",
      "### transfer_time\n",
      "1440.00s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7: Proposed new text for program: import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Optimizes for a balance of total cost (egress + instance) by considering both \n",
      "    edge costs and throughput. Utilizes multipath routing (K-shortest paths) \n",
      "    to distribute partitions across available links, improving transfer times \n",
      "    and bandwidth utilization.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    # Create a working graph for path finding calculations\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    \n",
      "    # Weight Calculation Configuration\n",
      "    # We define a composite weight to balance Egress Cost ($/GB) and Throughput (Gbps).\n",
      "    # Minimizing purely for cost leads to low-throughput paths that increase instance \n",
      "    # runtime costs (total_cost = egress + runtime * instance_rate).\n",
      "    #\n",
      "    # Formula: weight = cost + (ALPHA / throughput)\n",
      "    # ALPHA represents the trade-off factor. A value of 0.1 suggests that we are willing\n",
      "    # to pay slightly more in egress to avoid very low throughput links that would \n",
      "    # drift transfer times drastically.\n",
      "    ALPHA = 0.1\n",
      "\n",
      "    for u, v, data in h.edges(data=True):\n",
      "        cost = data.get('cost', 0.0)\n",
      "        throughput = data.get('throughput', 1.0)\n",
      "        # Clamp throughput to a small positive value to avoid division by zero\n",
      "        tp = max(throughput, 0.001)\n",
      "        \n",
      "        # Calculate composite weight\n",
      "        data['composite_weight'] = cost + (ALPHA / tp)\n",
      "\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        try:\n",
      "            # Multipath Routing Strategy:\n",
      "            # Find K shortest paths using the composite weight. \n",
      "            # Utilizing multiple paths increases effective bandwidth and resilience.\n",
      "            # We limit K to avoid selecting drastically inefficient paths.\n",
      "            k_limit = min(num_partitions, 4)\n",
      "            \n",
      "            # Generator for K shortest simple paths\n",
      "            path_generator = nx.shortest_simple_paths(h, src, dst, weight=\"composite_weight\")\n",
      "            \n",
      "            candidate_paths = []\n",
      "            for _ in range(k_limit):\n",
      "                try:\n",
      "                    candidate_paths.append(next(path_generator))\n",
      "                except StopIteration:\n",
      "                    break\n",
      "            \n",
      "            if not candidate_paths:\n",
      "                continue\n",
      "\n",
      "            # Assign partitions to the found paths in a Round-Robin fashion\n",
      "            for i in range(num_partitions):\n",
      "                # Select one of the candidate paths\n",
      "                node_path = candidate_paths[i % len(candidate_paths)]\n",
      "                \n",
      "                # Convert the sequence of nodes into a sequence of edges with original attributes\n",
      "                edge_path = []\n",
      "                for j in range(len(node_path) - 1):\n",
      "                    u, v = node_path[j], node_path[j+1]\n",
      "                    # Use original graph G to ensure output contains clean edge data\n",
      "                    edge_path.append([u, v, G[u][v]])\n",
      "                \n",
      "                # Set the full path for this specific partition\n",
      "                bc_topology.set_dst_partition_paths(dst, i, edge_path)\n",
      "\n",
      "        except nx.NetworkXNoPath:\n",
      "            # Handle cases where destination is unreachable\n",
      "            continue\n",
      "\n",
      "    return bc_topology\n",
      "Sum of total cost = egress cost ($339.3) + instance cost ($7.4057) = $346.706\n",
      "Sum of total cost = egress cost ($303.3) + instance cost ($6.9943) = $310.294\n",
      "Sum of total cost = egress cost ($143.1) + instance cost ($6.6528) = $149.753\n",
      "Iteration 7: New subsample score 0.012721765459811234 is not better than old score 0.012990851222704436, skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GEPA Optimization:   5%|▍         | 47/1000 [10:37<3:51:36, 14.58s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8: Selected program 0 score: 0.00519955683867755\n",
      "Sum of total cost = egress cost ($159.0) + instance cost ($2.4686) = $161.469\n",
      "Sum of total cost = egress cost ($144.0) + instance cost ($0.945) = $144.945\n",
      "Sum of total cost = egress cost ($144.0) + instance cost ($0.945) = $144.945\n",
      "Calling LM with prompt: You are an expert optimization assistant. Your task is to analyze evaluation feedback and propose an improved version of a system component.\n",
      "\n",
      "## Optimization Goal\n",
      "\n",
      "Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
      "\n",
      "The algorithm decides how to route data from a single source to multiple destinations\n",
      "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
      "(egress fees + instance costs) while maintaining good transfer times.\n",
      "\n",
      "## Domain Context & Constraints\n",
      "\n",
      "Key information about the problem domain:\n",
      "\n",
      "- The network is represented as a directed graph where:\n",
      "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
      "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
      "\n",
      "- Data is partitioned into num_partitions chunks that can be routed independently\n",
      "- Each partition can take a different path to reach each destination\n",
      "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
      "\n",
      "- The algorithm must return a BroadCastTopology object containing:\n",
      "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
      "  - Each destination must have at least one valid path for each partition\n",
      "\n",
      "Evaluation feedback format:\n",
      "- Cost: Total transfer cost in dollars\n",
      "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
      "\n",
      "Optimization targets:\n",
      "1. Reduce total cost (egress + instance costs)\n",
      "2. Find paths that balance cost and throughput\n",
      "3. Consider multipath routing for better bandwidth utilization\n",
      "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\n",
      "\n",
      "## Current Component\n",
      "\n",
      "The component being optimized:\n",
      "\n",
      "```\n",
      "import networkx as nx\n",
      "import pandas as pd\n",
      "import os\n",
      "from typing import Dict, List\n",
      "\n",
      "\n",
      "class SingleDstPath(Dict):\n",
      "    partition: int\n",
      "    edges: List[List]  # [[src, dst, edge data]]\n",
      "\n",
      "\n",
      "class BroadCastTopology:\n",
      "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
      "        self.src = src\n",
      "        self.dsts = dsts\n",
      "        self.num_partitions = num_partitions\n",
      "        if paths is not None:\n",
      "            self.paths = paths\n",
      "        else:\n",
      "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
      "\n",
      "    def get_paths(self):\n",
      "        return self.paths\n",
      "\n",
      "    def set_num_partitions(self, num_partitions: int):\n",
      "        self.num_partitions = num_partitions\n",
      "\n",
      "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
      "        partition = str(partition)\n",
      "        self.paths[dst][partition] = paths\n",
      "\n",
      "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
      "        partition = str(partition)\n",
      "        if self.paths[dst][partition] is None:\n",
      "            self.paths[dst][partition] = []\n",
      "        self.paths[dst][partition].append(path)\n",
      "\n",
      "\n",
      "def search_algorithm(src, dsts, G, num_partitions):\n",
      "    \"\"\"\n",
      "    Find broadcast paths from source to all destinations.\n",
      "\n",
      "    Uses Dijkstra's shortest path algorithm based on cost as the edge weight.\n",
      "\n",
      "    Args:\n",
      "        src: Source node identifier (e.g., \"aws:ap-northeast-1\")\n",
      "        dsts: List of destination node identifiers\n",
      "        G: NetworkX DiGraph with cost and throughput edge attributes\n",
      "        num_partitions: Number of data partitions\n",
      "\n",
      "    Returns:\n",
      "        BroadCastTopology object with paths for all destinations and partitions\n",
      "    \"\"\"\n",
      "    h = G.copy()\n",
      "    h.remove_edges_from(list(h.in_edges(src)) + list(nx.selfloop_edges(h)))\n",
      "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
      "\n",
      "    for dst in dsts:\n",
      "        path = nx.dijkstra_path(h, src, dst, weight=\"cost\")\n",
      "        for i in range(0, len(path) - 1):\n",
      "            s, t = path[i], path[i + 1]\n",
      "            for j in range(bc_topology.num_partitions):\n",
      "                bc_topology.append_dst_partition_path(dst, j, [s, t, G[s][t]])\n",
      "\n",
      "    return bc_topology\n",
      "\n",
      "```\n",
      "\n",
      "## Evaluation Results\n",
      "\n",
      "Performance data from evaluating the current component across test cases:\n",
      "\n",
      "```\n",
      "# Example 1\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006155036708392727\n",
      "\n",
      "### raw_cost\n",
      "161.468568\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_gcp\n",
      "\n",
      "### source\n",
      "gcp:us-east1-b\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$161.4686\n",
      "\n",
      "### transfer_time\n",
      "1028.57s\n",
      "\n",
      "\n",
      "\n",
      "# Example 2\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006851896262290589\n",
      "\n",
      "### raw_cost\n",
      "144.945\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_azure\n",
      "\n",
      "### source\n",
      "azure:australiaeast\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$144.9450\n",
      "\n",
      "### transfer_time\n",
      "450.00s\n",
      "\n",
      "\n",
      "\n",
      "# Example 3\n",
      "## Scores (Higher is Better)\n",
      "### cost_score\n",
      "0.006851896262290589\n",
      "\n",
      "### raw_cost\n",
      "144.945\n",
      "\n",
      "## Input\n",
      "### config\n",
      "intra_azure\n",
      "\n",
      "### source\n",
      "azure:australiaeast\n",
      "\n",
      "### num_destinations\n",
      "6\n",
      "\n",
      "## Output\n",
      "### cost\n",
      "$144.9450\n",
      "\n",
      "### transfer_time\n",
      "450.00s\n",
      "\n",
      "\n",
      "```\n",
      "\n",
      "## Your Task\n",
      "\n",
      "Analyze the evaluation results systematically:\n",
      "\n",
      "- **Goal alignment**: How well does the current component achieve the stated optimization goal?\n",
      "- **Failure patterns**: What specific errors, edge cases, or failure modes appear in the evaluation data?\n",
      "- **Success patterns**: What behaviors or approaches worked well and should be preserved?\n",
      "- **Root causes**: What underlying issues explain the observed failures?\n",
      "- **Constraint compliance**: Does the component satisfy all requirements from the domain context?\n",
      "\n",
      "Based on your analysis, propose an improved version that:\n",
      "1. Addresses the identified failure patterns and root causes\n",
      "2. Preserves successful behaviors from the current version\n",
      "3. Makes meaningful improvements rather than superficial changes\n",
      "4. Adheres to all constraints and requirements from the domain context\n",
      "\n",
      "## Output Format\n",
      "\n",
      "Provide ONLY the improved version within ``` blocks. The output must be a complete, \n",
      "drop-in replacement for the current component (whether it's a prompt, configuration, \n",
      "code, or any other parameter type).\n",
      "Do not include explanations, commentary, or markdown outside the ``` blocks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n"
     ]
    }
   ],
   "source": [
    "from gepa.optimize_anything import optimize_anything, GEPAConfig, EngineConfig, ReflectionConfig\n",
    "from examples.adrs.cloudcast.main import get_reflection_lm\n",
    "\n",
    "# =============================================================================\n",
    "# Language Model Configuration\n",
    "# =============================================================================\n",
    "# Choose your LLM - examples:\n",
    "#   - get_reflection_lm(\"gemini-2.0-flash-001\")  # Fast Gemini model\n",
    "#   - get_reflection_lm(\"gemini-3-pro-preview\")  # Latest Gemini Pro\n",
    "#   - get_reflection_lm(\"openai/gpt-4o\")         # OpenAI GPT-4o via LiteLLM\n",
    "#   - \"openai/gpt-4o\"  # Or just pass a string directly for LiteLLM models\n",
    "reflection_lm = get_reflection_lm(\"gemini-3-pro-preview\")\n",
    "\n",
    "OPTIMIZATION_OBJECTIVE = \"\"\"Optimize a broadcast routing algorithm for multi-cloud data transfer.\n",
    "\n",
    "The algorithm decides how to route data from a single source to multiple destinations\n",
    "across cloud providers (AWS, GCP, Azure). The goal is to minimize total cost \n",
    "(egress fees + instance costs) while maintaining good transfer times.\"\"\"\n",
    "\n",
    "OPTIMIZATION_BACKGROUND = \"\"\"Key information about the problem domain:\n",
    "\n",
    "- The network is represented as a directed graph where:\n",
    "  - Nodes are cloud regions (e.g., \"aws:us-east-1\", \"gcp:europe-west1-a\", \"azure:eastus\")\n",
    "  - Edges have 'cost' ($/GB for egress) and 'throughput' (Gbps bandwidth) attributes\n",
    "  \n",
    "- Data is partitioned into num_partitions chunks that can be routed independently\n",
    "- Each partition can take a different path to reach each destination\n",
    "- Total cost = egress costs (data_vol × edge_cost) + instance costs (runtime × cost_per_hour)\n",
    "\n",
    "- The algorithm must return a BroadCastTopology object containing:\n",
    "  - paths[dst][partition] = list of edges [[src, dst, edge_data], ...]\n",
    "  - Each destination must have at least one valid path for each partition\n",
    "\n",
    "Evaluation feedback format:\n",
    "- Cost: Total transfer cost in dollars\n",
    "- Transfer time: Maximum time for all destinations to receive data (seconds)\n",
    "\n",
    "Optimization targets:\n",
    "1. Reduce total cost (egress + instance costs)\n",
    "2. Find paths that balance cost and throughput\n",
    "3. Consider multipath routing for better bandwidth utilization\n",
    "4. Exploit cloud provider pricing differences (e.g., intra-provider is cheaper)\"\"\"\n",
    "\n",
    "gepa_config = GEPAConfig(\n",
    "    engine=EngineConfig(\n",
    "        run_dir=\"runs/cloudcast\",\n",
    "        seed=0,\n",
    "        max_metric_calls=1000,\n",
    "        track_best_outputs=True,\n",
    "        use_cloudpickle=True,\n",
    "        display_progress_bar=True,\n",
    "    ),\n",
    "    reflection=ReflectionConfig(\n",
    "        reflection_minibatch_size=3,\n",
    "        reflection_lm=reflection_lm,\n",
    "        skip_perfect_score=False,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=train_set,\n",
    "    valset=val_set,\n",
    "    objective=OPTIMIZATION_OBJECTIVE,\n",
    "    background=OPTIMIZATION_BACKGROUND,\n",
    "    config=gepa_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeabc0e",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "![Cloudcast Optimization](examples/adrs/cloudcast/optimization_trajectory.png)\n",
    "\n",
    "GEPA evolved a routing algorithm that achieves **30.4% cost reduction**:\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Base Cost | $209 |\n",
    "| Optimized Cost | $146 |\n",
    "| **Cost Savings** | **30.4%** |\n",
    "\n",
    "The evolved algorithm discovered strategies for:\n",
    "- Preferring intra-cloud paths when possible\n",
    "- Intelligent partition routing to balance load\n",
    "- Cost-aware path selection over naive shortest-path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9482a5f",
   "metadata": {},
   "source": [
    "### What GEPA Discovered\n",
    "\n",
    "GEPA evolved a sophisticated routing algorithm with several key innovations:\n",
    "1. Iterative Marginal-Cost Shortest Path: Replaces Steiner Tree heuristic\n",
    "2. Zero marginal cost for reused edges: Encourages multicast tree building\n",
    "3. Congestion-aware routing: Penalties based on partition-level usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132ab8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "from typing import Dict, List\n",
    "\n",
    "class SingleDstPath(Dict):\n",
    "    partition: int\n",
    "    edges: List[List]  # [[src, dst, edge data]]\n",
    "\n",
    "class BroadCastTopology:\n",
    "    def __init__(self, src: str, dsts: List[str], num_partitions: int = 4, paths: Dict[str, 'SingleDstPath'] = None):\n",
    "        self.src = src\n",
    "        self.dsts = dsts\n",
    "        self.num_partitions = num_partitions\n",
    "        if paths is not None:\n",
    "            self.paths = paths\n",
    "        else:\n",
    "            self.paths = {dst: {str(i): None for i in range(num_partitions)} for dst in dsts}\n",
    "\n",
    "    def get_paths(self):\n",
    "        return self.paths\n",
    "\n",
    "    def set_num_partitions(self, num_partitions: int):\n",
    "        self.num_partitions = num_partitions\n",
    "\n",
    "    def set_dst_partition_paths(self, dst: str, partition: int, paths: List[List]):\n",
    "        partition = str(partition)\n",
    "        self.paths[dst][partition] = paths\n",
    "\n",
    "    def append_dst_partition_path(self, dst: str, partition: int, path: List):\n",
    "        partition = str(partition)\n",
    "        if self.paths[dst][partition] is None:\n",
    "            self.paths[dst][partition] = []\n",
    "        self.paths[dst][partition].append(path)\n",
    "\n",
    "def search_algorithm(src, dsts, G, num_partitions):\n",
    "    \"\"\"\n",
    "    Optimized broadcast routing algorithm using Iterative Marginal-Cost Shortest Path.\n",
    "    \n",
    "    Improvements:\n",
    "    1. Replaced complex Steiner Tree heuristic with a destination-iterative Shortest Path approach.\n",
    "       - This prevents the creation of inefficient, deep trees which were hurting transfer times.\n",
    "       - It maintains 'Multicast' cost benefits by setting the cost of edges already used \n",
    "         in the current partition to zero (Marginal Cost logic).\n",
    "    2. Congestion Management:\n",
    "       - Tracks usage at the partition level.\n",
    "       - Penalties are applied to throughput to balance load across partitions.\n",
    "    3. Tuning:\n",
    "       - ALPHA increased to 0.02 to better balance Egress Cost vs Transfer Time.\n",
    "       - Random shuffle of destinations prevents bias in shared path construction.\n",
    "    \"\"\"\n",
    "    \n",
    "    # PARAMETERS\n",
    "    # Balances Cost ($) vs 1/Throughput (Time). \n",
    "    # Increased from 0.005 to 0.02 to penalize low-bandwidth paths more aggressively,\n",
    "    # addressing high transfer times observed in evaluation.\n",
    "    ALPHA = 0.02 \n",
    "    \n",
    "    # Seed for reproducibility\n",
    "    random.seed(42)\n",
    "\n",
    "    bc_topology = BroadCastTopology(src, dsts, num_partitions)\n",
    "    \n",
    "    # Global usage: (u, v) -> count of partitions utilizing this link\n",
    "    # We use this to calculate the 'Time Penalty' for subsequent partitions.\n",
    "    global_edge_usage = {} \n",
    "\n",
    "    # We iterate through each partition to assign paths\n",
    "    for part_id in range(num_partitions):\n",
    "        # Track edges activated in the CURRENT partition.\n",
    "        # In an overlay multicast model, the source pays egress only once per link per partition,\n",
    "        # regardless of how many destinations share that link.\n",
    "        partition_active_edges = set()\n",
    "        \n",
    "        # Shuffle destinations to avoid routing bias (e.g., always optimizing for the first dst)\n",
    "        current_dsts = list(dsts)\n",
    "        random.shuffle(current_dsts)\n",
    "        \n",
    "        # Define a dynamic weight function for Dijkstra\n",
    "        def get_weight(u, v, d):\n",
    "            # 1. Throughput / Congestion Component\n",
    "            throughput = d.get('throughput', 1.0)\n",
    "            if throughput < 1e-6: throughput = 1e-6\n",
    "            \n",
    "            # Usage penalty applies to the 'Time' aspect.\n",
    "            # We assume bandwidth is shared or congested by total active partitions.\n",
    "            usage = global_edge_usage.get((u, v), 0)\n",
    "            time_penalty = (1.0 + usage) / throughput\n",
    "            \n",
    "            # 2. Cost Component\n",
    "            # If the edge is already active in this partition, marginal egress cost is 0.\n",
    "            # This encourages building a shared multicast tree greedily.\n",
    "            if (u, v) in partition_active_edges:\n",
    "                cost = 0.0\n",
    "            else:\n",
    "                cost = d.get('cost', 0.0)\n",
    "            \n",
    "            return cost + (ALPHA * time_penalty)\n",
    "\n",
    "        for dst in current_dsts:\n",
    "            if dst == src:\n",
    "                continue\n",
    "            \n",
    "            path_segments = []\n",
    "            try:\n",
    "                # Find shortest path using the custom marginal-cost weights\n",
    "                # This naturally gravitates towards reusing existing branches of the tree (Steiner-like)\n",
    "                # but will branch out (Unicast) if the shared path is too slow or expensive.\n",
    "                path_nodes = nx.shortest_path(G, source=src, target=dst, weight=get_weight)\n",
    "                \n",
    "                # Reconstruct path data\n",
    "                for i in range(len(path_nodes) - 1):\n",
    "                    u, v = path_nodes[i], path_nodes[i+1]\n",
    "                    path_segments.append([u, v, G[u][v]])\n",
    "                    \n",
    "                    # Mark edge as active for this partition\n",
    "                    partition_active_edges.add((u, v))\n",
    "                    \n",
    "            except nx.NetworkXNoPath:\n",
    "                # Fallback if unreachable\n",
    "                path_segments = []\n",
    "            \n",
    "            bc_topology.set_dst_partition_paths(dst, part_id, path_segments)\n",
    "        \n",
    "        # After routing all destinations for this partition, update global congestion stats\n",
    "        for u, v in partition_active_edges:\n",
    "            global_edge_usage[(u, v)] = global_edge_usage.get((u, v), 0) + 1\n",
    "\n",
    "    return bc_topology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8bdac",
   "metadata": {},
   "source": [
    "### Key Takeaways from Systems Optimization\n",
    "\n",
    "1. **Rich Side Information Matters**: Both problems provide detailed simulation output (costs, timings, paths taken). This lets GEPA understand *why* a strategy underperforms—not just that it does.\n",
    "\n",
    "2. **Domain Complexity**: These problems involve stochastic elements (spot preemption), complex constraints (deadlines, bandwidth limits), and non-linear cost structures. Traditional optimizers struggle here.\n",
    "\n",
    "3. **Code as the Optimized Artifact**: Unlike prompt optimization, we're evolving actual *algorithms*—decision functions and routing strategies. GEPA treats code as just another text artifact to optimize.\n",
    "\n",
    "4. **Real-World Impact**: These aren't toy problems. The Cloudcast savings of 37% on a large-scale data transfer could mean thousands of dollars saved per transfer.\n",
    "\n",
    "---\n",
    "\n",
    "The complete code for both examples is available in:\n",
    "- `examples/adrs/can_be_late/` — Spot instance scheduling\n",
    "- `examples/adrs/cloudcast/` — Multi-cloud broadcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-8\"></a>\n",
    "# 9. How It Works Under the Hood\n",
    "\n",
    "GEPA (Generative Evolutionary Prompting with ASI) operates through a loop of **evaluation**, **reflection**, and **proposal**:\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                              GEPA LOOP                                       │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│                                                                             │\n",
    "│   ┌──────────────┐                                                          │\n",
    "│   │  EVALUATE    │  Run fitness_fn on candidates                            │\n",
    "│   │              │  → Collect scores AND side_info                          │\n",
    "│   └──────┬───────┘                                                          │\n",
    "│          │                                                                  │\n",
    "│          ▼                                                                  │\n",
    "│   ┌──────────────┐                                                          │\n",
    "│   │   SELECT     │  Choose candidates for mutation                          │\n",
    "│   │              │  → Pareto selection across objectives/instances          │\n",
    "│   │              │  → Epsilon-greedy exploration                            │\n",
    "│   └──────┬───────┘                                                          │\n",
    "│          │                                                                  │\n",
    "│          ▼                                                                  │\n",
    "│   ┌──────────────┐                                                          │\n",
    "│   │   REFLECT    │  LLM analyzes evaluation results                         │\n",
    "│   │              │  → \"Why did this candidate fail?\"                        │\n",
    "│   │              │  → Uses side_info to understand failure modes            │\n",
    "│   └──────┬───────┘                                                          │\n",
    "│          │                                                                  │\n",
    "│          ▼                                                                  │\n",
    "│   ┌──────────────┐                                                          │\n",
    "│   │   PROPOSE    │  LLM generates improved candidates                       │\n",
    "│   │              │  → Targeted mutations based on reflection                │\n",
    "│   │              │  → Preserves successful behaviors                        │\n",
    "│   └──────┬───────┘                                                          │\n",
    "│          │                                                                  │\n",
    "│          └──────────────────► REPEAT until stopping condition               │\n",
    "│                                                                             │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "## Key Components\n",
    "\n",
    "### 1. Pareto Frontier\n",
    "GEPA maintains a **Pareto frontier** of candidates that are optimal on different subsets of the data:\n",
    "- **Multi-objective**: Some candidates optimize for accuracy, others for speed\n",
    "- **Instance-level**: Some candidates excel on certain problem types\n",
    "- **Diversity**: The frontier preserves diverse strategies for exploration\n",
    "\n",
    "### 2. Reflective Mutation\n",
    "Unlike **random mutation** in traditional evolutionary algorithms, GEPA uses LLMs to make **targeted improvements**:\n",
    "\n",
    "| Traditional EA | GEPA |\n",
    "|---------------|------|\n",
    "| Random bit flips | LLM analyzes failure modes |\n",
    "| Blind crossover | LLM preserves working patterns |\n",
    "| Requires many generations | Sample-efficient |\n",
    "| No domain knowledge | Uses side_info for context |\n",
    "\n",
    "### 3. Side Information Flow\n",
    "The `side_info` returned by your fitness function powers the reflection:\n",
    "\n",
    "```python\n",
    "# What the LLM sees during reflection:\n",
    "\"\"\"\n",
    "Current candidate: {code: \"def solve(x): ...\"}\n",
    "\n",
    "Evaluation results on 3 examples:\n",
    "  Example 1: Score 0.8\n",
    "    Input: \"Pack 26 circles\"\n",
    "    Output: circles array\n",
    "    Error: \"Circles 3 and 7 overlap\"\n",
    "    \n",
    "  Example 2: Score 0.0  \n",
    "    Input: \"Pack 26 circles\"\n",
    "    Error: \"IndexError on line 42\"\n",
    "    \n",
    "  Example 3: Score 1.0\n",
    "    Input: \"Pack 26 circles\"\n",
    "    Output: Valid packing with sum_radii=2.89\n",
    "\n",
    "Propose an improved version that fixes these issues.\n",
    "\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23cdcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_fn = create_fitness_fn(\n",
    "    lm,\n",
    "    baselines=baselines,\n",
    "    use_rag=True,\n",
    "    max_refinements=5,\n",
    "    tracker=tracker,\n",
    "    kernel_gen_cache=kernel_gen_cache,\n",
    "    refiner_cache=refiner_cache,\n",
    ")\n",
    "\n",
    "config = GEPAConfig(\n",
    "    engine=EngineConfig(\n",
    "        run_dir=log_dir,\n",
    "        max_metric_calls=2000,\n",
    "        cache_evaluation=True,\n",
    "        track_best_outputs=True,\n",
    "        parallel=False,\n",
    "        max_workers=1,\n",
    "    ),\n",
    "    reflection=ReflectionConfig(\n",
    "        reflection_minibatch_size=3,\n",
    "        reflection_lm=LLM,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=dataset,\n",
    "    config=config,\n",
    "    objective=objective,\n",
    "    background=BACKGROUND,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section-9\"></a>\n",
    "# 10. Conclusion: From Imperative to Declarative Optimization\n",
    "\n",
    "We are witnessing a **paradigm shift** in optimization—from imperative implementations to declarative specifications:\n",
    "\n",
    "| **Old Paradigm** | **New Paradigm with `optimize_anything`** |\n",
    "|------------------|------------------------------------------|\n",
    "| Imperative: specify *how* to optimize | Declarative: specify *what* to optimize |\n",
    "| Different libraries for different problems | **One API for everything** |\n",
    "| Mathematically-specific algorithms | Language-driven proposal generation |\n",
    "| Scalar fitness only | **Rich diagnostic information (ASI)** |\n",
    "| Random mutations | **Targeted, reflective mutations** |\n",
    "| Expert knowledge required | LLM brings domain knowledge |\n",
    "\n",
    "## The `optimize_anything` Vision\n",
    "\n",
    "**If it can be represented as text, it can be optimized.**\n",
    "\n",
    "| Domain | What You Optimize | Example |\n",
    "|--------|-------------------|---------|\n",
    "| **Code** | Algorithms, implementations | Black-box optimization code |\n",
    "| **Prompts** | Instructions, examples | System prompts for math problems |\n",
    "| **Agent Architectures** | Program structure, control flow | DSPy programs for ARC-AGI |\n",
    "| **Configurations** | Hyperparameters, settings | JSON/YAML configs |\n",
    "| **Data Structures** | Schemas, templates | API specifications |\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "1. **Democratization**: You don't need a PhD in optimization to solve hard problems\n",
    "2. **Generalization**: One framework, infinite applications\n",
    "3. **Sample Efficiency**: LLM reflection beats random search\n",
    "4. **Emergent Capabilities**: GEPA discovers strategies you wouldn't think of\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "```bash\n",
    "pip install gepa\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "getting-started-code",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gepa.optimize_anything import optimize_anything, GEPAConfig, EngineConfig, ReflectionConfig\n",
    "\n",
    "# 1. Define your seed candidate (starting point)\n",
    "seed_candidate = {\n",
    "    \"my_param\": \"initial value\"  # Can be code, prompt, config, etc.\n",
    "}\n",
    "\n",
    "# 2. Define your fitness function (how to measure success)\n",
    "def fitness_fn(candidate, example=None):\n",
    "    # Run your system with the candidate\n",
    "    output = run_my_system(candidate[\"my_param\"], example)\n",
    "    \n",
    "    # Compute score (higher is better)\n",
    "    score = compute_score(output, example)\n",
    "    \n",
    "    # Collect rich diagnostic information (ASI)\n",
    "    side_info = {\n",
    "        \"Input\": example,\n",
    "        \"Output\": output,\n",
    "        \"Expected\": example.get(\"answer\") if example else None,\n",
    "        \"Error\": get_error_message(output),\n",
    "        \"Feedback\": analyze_performance(output),\n",
    "    }\n",
    "    \n",
    "    return score, output, side_info\n",
    "\n",
    "# 3. Run optimization\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=my_examples,  # Optional: for multi-instance mode\n",
    "    objective=\"Find a parameter that maximizes performance\",  # Optional: guidance\n",
    "    config=GEPAConfig(\n",
    "        engine=EngineConfig(max_metric_calls=100),\n",
    "        reflection=ReflectionConfig(reflection_lm=\"openai/gpt-4o\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 4. Use the optimized result\n",
    "print(\"Best candidate:\", result.best_candidate)\n",
    "print(\"Best score:\", result.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final-takeaways",
   "metadata": {},
   "source": [
    "## Summary: What We Showed\n",
    "\n",
    "| Example | What We Optimized | Key Insight |\n",
    "|---------|-------------------|-------------|\n",
    "| **Mathematical Optimization** | Python code for black-box optimization | GEPA discovers algorithms automatically |\n",
    "| **Prompt Engineering** | System prompts for math problems | LLM reflection finds domain-specific strategies |\n",
    "| **Agent Evolution** | DSPy programs for ARC-AGI | Self-refinement emerged without being programmed |\n",
    "| **Algorithmic Discovery** | Circle packing algorithms | Matches state-of-the-art (AlphaEvolve, etc.) |\n",
    "| **Systems: Scheduling** | Spot instance strategies | 6.9% cost reduction on real AWS traces |\n",
    "| **Systems: Networking** | Multi-cloud broadcast routing | 30.4% cost reduction on cloud transfers |\n",
    "\n",
    "## Key Takeaways\n",
    "\n",
    "1. **Unified Interface**: One API for prompts, code, configs, and agent architectures\n",
    "\n",
    "2. **Side Information (ASI) is Key**: The more diagnostic information you provide, the better GEPA can reason about improvements\n",
    "\n",
    "3. **Beyond Scalar Optimization**: Traditional optimizers only see scores; GEPA sees error messages, execution traces, and domain-specific feedback\n",
    "\n",
    "4. **Emergent Capabilities**: Sophisticated strategies (like self-refinement in ARC-AGI) emerge without explicit programming\n",
    "\n",
    "5. **The Convex Hull**: `optimize_anything` is designed to cover all text-based optimization problems under one abstraction\n",
    "\n",
    "---\n",
    "\n",
    "## Try It Yourself\n",
    "\n",
    "**If you can express your system's parameters as text and compute a score with diagnostic feedback, GEPA can optimize it.**\n",
    "\n",
    "```python\n",
    "pip install gepa\n",
    "```\n",
    "\n",
    "```python\n",
    "from gepa.optimize_anything import optimize_anything\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate={\"your_param\": \"your_value\"},\n",
    "    fitness_fn=your_fitness_function,\n",
    ")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "*GEPA is open-source. Star us on [GitHub](https://github.com/stanfordnlp/gepa)!*\n",
    "\n",
    "---\n",
    "\n",
    "## Appendix: Full Code Examples\n",
    "\n",
    "The complete, runnable code for all examples in this post can be found in the `examples/` directory:\n",
    "\n",
    "- `examples/new_polynomial/` — Mathematical optimization (EvalSet)\n",
    "- `examples/math/` — Prompt engineering (AIME 2025)\n",
    "- `examples/arc_agi/` — Agent program evolution (ARC-AGI)\n",
    "- `examples/circle_packing/` — Algorithmic discovery (Circle Packing)\n",
    "- `examples/adrs/can_be_late/` — Spot instance scheduling\n",
    "- `examples/adrs/cloudcast/` — Multi-cloud broadcast optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a689649",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Minimal Working Example: Optimize a Sorting Function\n",
    "\n",
    "Here's a complete, runnable example that optimizes a Python sorting function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2dcd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Minimal working example: Optimize a sorting function\n",
    "This evolves Python code that sorts a list of numbers.\n",
    "\"\"\"\n",
    "import time\n",
    "from gepa.optimize_anything import optimize_anything, GEPAConfig, EngineConfig, ReflectionConfig\n",
    "\n",
    "# 1. SEED CANDIDATE: A naive bubble sort implementation\n",
    "seed_candidate = {\n",
    "    \"code\": \"\"\"\n",
    "def sort_list(arr):\n",
    "    '''Sort a list of numbers in ascending order.'''\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        for j in range(0, n-i-1):\n",
    "            if arr[j] > arr[j+1]:\n",
    "                arr[j], arr[j+1] = arr[j+1], arr[j]\n",
    "    return arr\n",
    "\"\"\"\n",
    "}\n",
    "\n",
    "# 2. DATASET: Test cases to optimize on\n",
    "dataset = [\n",
    "    {\"input\": [64, 34, 25, 12, 22, 11, 90], \"expected\": [11, 12, 22, 25, 34, 64, 90]},\n",
    "    {\"input\": [5, 1, 4, 2, 8], \"expected\": [1, 2, 4, 5, 8]},\n",
    "    {\"input\": [3, 3, 1, 2, 1], \"expected\": [1, 1, 2, 3, 3]},\n",
    "    {\"input\": list(range(100, 0, -1)), \"expected\": list(range(1, 101))},  # Worst case\n",
    "]\n",
    "\n",
    "# 3. FITNESS FUNCTION: Measure correctness and speed\n",
    "def fitness_fn(candidate, example):\n",
    "    code = candidate[\"code\"]\n",
    "    \n",
    "    try:\n",
    "        # Execute the code\n",
    "        exec(code, globals())\n",
    "        \n",
    "        # Time the execution\n",
    "        start = time.time()\n",
    "        result = sort_list(example[\"input\"].copy())\n",
    "        elapsed = time.time() - start\n",
    "        \n",
    "        # Check correctness\n",
    "        correct = result == example[\"expected\"]\n",
    "        score = 1.0 if correct else 0.0\n",
    "        \n",
    "        # Bonus for speed (if correct)\n",
    "        if correct and elapsed < 0.001:\n",
    "            score += 0.1\n",
    "        \n",
    "        # Rich side_info for LLM reflection\n",
    "        side_info = {\n",
    "            \"Input\": example[\"input\"],\n",
    "            \"Output\": result,\n",
    "            \"Expected\": example[\"expected\"],\n",
    "            \"Correct\": correct,\n",
    "            \"Time (ms)\": elapsed * 1000,\n",
    "            \"Error\": None,\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        score = 0.0\n",
    "        side_info = {\n",
    "            \"Input\": example[\"input\"],\n",
    "            \"Error\": str(e),\n",
    "            \"Code\": code,\n",
    "        }\n",
    "    \n",
    "    return score, {\"code\": code, \"result\": result if 'result' in dir() else None}, side_info\n",
    "\n",
    "# 4. RUN OPTIMIZATION\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=dataset,\n",
    "    objective=\"Optimize the sorting function for correctness and speed.\",\n",
    "    background=\"Consider algorithms like quicksort, mergesort, or heapsort.\",\n",
    "    config=GEPAConfig(\n",
    "        engine=EngineConfig(max_metric_calls=50),\n",
    "        reflection=ReflectionConfig(reflection_lm=\"openai/gpt-4o-mini\"),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# 5. USE THE RESULT\n",
    "print(\"=\" * 60)\n",
    "print(\"OPTIMIZED CODE:\")\n",
    "print(\"=\" * 60)\n",
    "print(result.best_candidate[\"code\"])\n",
    "print(f\"\\nBest score: {result.best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa1609",
   "metadata": {},
   "source": [
    "### What This Example Demonstrates\n",
    "\n",
    "1. **Seed Candidate**: We start with a naive O(n²) bubble sort\n",
    "2. **Dataset**: Four test cases including a worst-case reversed list\n",
    "3. **Fitness Function**: \n",
    "   - Returns correctness score (0 or 1)\n",
    "   - Returns **rich side_info** including input, output, timing, and errors\n",
    "4. **Optimization**: GEPA will evolve the code to find faster algorithms\n",
    "5. **Result**: Often discovers quicksort or similar O(n log n) algorithms\n",
    "\n",
    "The key is the `side_info` dictionary—it tells GEPA exactly what went wrong so it can make targeted improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729fb723",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "KernelBench provides PyTorch reference models. The candidate must produce a `ModelNew` with custom CUDA kernels (via `load_inline`) that is correct and faster than the PyTorch baseline.\n",
    "\n",
    "## The Task\n",
    "\n",
    "**Given**: PyTorch reference models + baseline runtimes\n",
    "**Find**: Prompts that generate correct, faster CUDA kernels\n",
    "\n",
    "Results are hardware-dependent; see `outputs/artifacts/kernelbench/` for latest runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9885dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "levels = [\"level1\"]\n",
    "run_name = time.strftime(\"%y%m%d_%H%M%S\")\n",
    "log_dir = f\"outputs/artifacts/kernelbench/{run_name}\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "dataset = load_dataset(levels=levels)\n",
    "baselines = load_or_measure_baselines(dataset)\n",
    "\n",
    "available_gpus = get_free_gpus() or list(range(4))\n",
    "init_gpu_manager(device_list=available_gpus, lock_dir=os.path.join(log_dir, \"gpu_locks\"))\n",
    "\n",
    "tracker = StateTracker(log_dir=log_dir, total_problems=len(dataset))\n",
    "kernel_gen_cache = PromptCache(cache_dir=os.path.join(log_dir, \"kernel_gen_cache\"), name=\"kernel_gen\")\n",
    "refiner_cache = PromptCache(cache_dir=os.path.join(log_dir, \"refiner_cache\"), name=\"refiner\")\n",
    "\n",
    "lm = dspy.LM(LLM, temperature=1.0, max_tokens=32000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae63f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness_fn = create_fitness_fn(\n",
    "    lm,\n",
    "    baselines=baselines,\n",
    "    use_rag=True,\n",
    "    max_refinements=5,\n",
    "    tracker=tracker,\n",
    "    kernel_gen_cache=kernel_gen_cache,\n",
    "    refiner_cache=refiner_cache,\n",
    ")\n",
    "\n",
    "config = GEPAConfig(\n",
    "    engine=EngineConfig(\n",
    "        run_dir=log_dir,\n",
    "        max_metric_calls=2000,\n",
    "        cache_evaluation=True,\n",
    "        track_best_outputs=True,\n",
    "        parallel=False,\n",
    "        max_workers=1,\n",
    "    ),\n",
    "    reflection=ReflectionConfig(\n",
    "        reflection_minibatch_size=3,\n",
    "        reflection_lm=LLM,\n",
    "    ),\n",
    ")\n",
    "\n",
    "result = optimize_anything(\n",
    "    seed_candidate=seed_candidate,\n",
    "    fitness_fn=fitness_fn,\n",
    "    dataset=dataset,\n",
    "    config=config,\n",
    "    objective=objective,\n",
    "    background=BACKGROUND,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b326af7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## When to Use `optimize_anything`\n",
    "\n",
    "### Best Use Cases\n",
    "\n",
    "| Problem Type | Example | Why GEPA Excels |\n",
    "|--------------|---------|-----------------|\n",
    "| **Prompt Engineering** | System prompts, few-shot examples | LLM understands language nuances |\n",
    "| **Code Evolution** | Algorithm design, bug fixes | LLM can read and write code |\n",
    "| **Agent Architecture** | DSPy programs, reasoning pipelines | LLM can propose structural changes |\n",
    "| **Configuration Tuning** | JSON/YAML configs | LLM understands parameter relationships |\n",
    "| **Template Optimization** | Email templates, API specs | LLM understands domain context |\n",
    "\n",
    "### When Traditional Methods May Be Better\n",
    "\n",
    "| Problem Type | Better Alternative | Why |\n",
    "|--------------|-------------------|-----|\n",
    "| **Neural Network Training** | PyTorch + SGD | Gradient information is crucial |\n",
    "| **Convex Optimization** | SciPy, CVXPY | Mathematical structure exploitable |\n",
    "| **Combinatorial (small scale)** | OR-Tools, SAT solvers | Exact methods available |\n",
    "\n",
    "### The Rule of Thumb\n",
    "\n",
    "**Use `optimize_anything` when:**\n",
    "1. The artifact being optimized can be meaningfully represented as text\n",
    "2. You can provide informative feedback about why candidates fail\n",
    "3. Domain knowledge would help but isn't easily encoded as math\n",
    "4. The search space is too complex for grid/random search\n",
    "\n",
    "---\n",
    "\n",
    "*Questions? Issues? Contributions welcome at [github.com/stanfordnlp/gepa](https://github.com/stanfordnlp/gepa)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
